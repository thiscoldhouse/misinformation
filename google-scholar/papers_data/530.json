[{"title": "Sub-Standards and Mal-Practices: Misinformation's Role in Insular, Polarized, and Toxic Interactions on Reddit", "year": "2023", "pdf_data": "Sub-Standards and Mal-Practices: Misinformation\u2019s Role in\nInsular, Polarized, and Toxic Interactions on Reddit\nHANS W. A. HANLEY, Stanford University, USA\nZAKIR DURUMERIC, Stanford University, USA\nIn this work, we examine the influence of unreliable information on political incivility and toxicity on the social\nmedia platform Reddit. We show that comments on articles from unreliable news websites are posted more\noften in right-leaning subreddits and that within individual subreddits, comments, on average, are 32% more\nlikely to be toxic compared to comments on reliable news articles. Using a regression model, we show that\nthese results hold after accounting for partisanship and baseline toxicity rates within individual subreddits.\nUtilizing a zero-inflated negative binomial regression, we further show that as the toxicity of subreddits\nincreases, users are more likely to comment on posts from known unreliable websites. Finally, modeling user\ninteractions with an exponential random graph model, we show that when reacting to a Reddit submission\nthat links to a website known for spreading unreliable information, users are more likely to be toxic to users\nof different political beliefs. Our results collectively illustrate that low-quality/unreliable information not only\npredicts increased toxicity but also polarizing interactions between users of different political orientations.\nCCS Concepts: \u2022Human-centered computing \u2192Collaborative and social computing ;Empirical studies\nin collaborative and social computing ;\u2022Information systems \u2192Web Mining ;\u2022Networks \u2192Online\nsocial networks ;\nAdditional Key Words and Phrases: Misinformation, Toxicity, Political Polarization, Reddit, Online Communi-\nties\n1 INTRODUCTION\nContent Warning : This paper studies online toxicity. When necessary for clarity, this paper\nquotes user content that contains profane, politically inflammatory, and hateful content.\nOver the last decade, misinformation, incivility, and political polarization have corroded the\npublic\u2019s trust in democratic institutions [ 17,25,51,52,55]. Despite their shared roles in dis-\nrupting discourse and stoking political division, misinformation, online toxicity, and polariza-\ntion are separate phenomena, and their complex interaction remains debated and somewhat un-\nclear [ 20,29,32,36,54,95,125,134,138]. For instance, recent work from Quattrociocchi et al. [ 105]\nfound that on that X (formerly Twitter), toxic language is equally distributed across conversations\nregardless of the presence of reliable or unreliable news. Similarly, Cinelli et al. found that \u201cthere\nare no significant differences between the proportions of hate speech detected in comments on\nvideos from questionable and reliable channels\u201d on YouTube [ 29]. In contrast, Mosleh et al. [ 97,98]\nfound that false headlines on Twitter are correlated with increased toxicity and Dicicco et al. [ 35]\nfound that throughout the COVID-19 pandemic, conspiracy theories emerged amongst users who\nregularly employed toxic language.\nIn this work, we investigate the interplay of toxicity, partisanship, and unreliable information in\na more controlled environment: Reddit. In contrast to prior work, which has studied unstructured\nplatforms like Twitter and YouTube [ 101,115], Reddit communities have relatively distinct and stable\npolitical and toxicity norms [ 84,94,110], allowing for more direct study of the complex interplay\nof toxicity, partisanship, and unreliable information. By investigating individual communities,\nquantifying their level of political engagement, and identifying internal differences between and\nwithin them, we analyze the extent to which partisanship, polarization, and unreliable news predict\nAuthors\u2019 addresses: Hans W. A. Hanley, hhanley@cs.stanford.edu, Stanford University, 450 Serra Mall, Stanford, California,\nUSA, 94305; Zakir Durumeric, zakir@cs.stanford.edu, Stanford University, 450 Serra Mall, Stanford, California, USA, 94305.\n2 Hans W. A. Hanley and Zakir Durumeric\nincreased toxicity. Furthermore, in contrast to prior work, which has been limited to explicitly\npolitical settings, we analyze a diverse set of subreddits, measuring the influence of misinformation\non toxicity while accounting for the \u201cpoliticalness\u201d of each community [ 94]. Concretely, we ask the\nfollowing research questions:\n(1)Do Reddit posts linking to articles from unreliable websites have increased toxicity in their\nengagement? How do subreddit norms (e.g., political partisanship) predict toxicity?\n(2)Does unreliable news exacerbate toxic interactions between users with political partisanship\ndifferences (i.e., affective polarization)?\nTo answer these questions, we measure the levels of toxicity, political partisanship, and propensity to\npost articles from websites known to spread misinformation on Reddit over 18 months (January 2020\nto June 2021). We determine the number of toxic comments within each subreddit and from\nindividual users using the Google Jigsaw API [ 2], a commonly deployed classifier for identifying\ntoxic language. Then, utilizing a Word2Vec approach from Waller et al. [ 141], we approximate\nthe partisanship and \u201cpoliticalness\u201d of a subset of subreddits and users along the US left\u2013right\npolitical spectrum. Finally, we utilize previously curated lists of reliable and unreliable news\nsites to determine the levels at which communities and users link to websites known to spread\nmisinformation. From these calculations, we analyze the relationships between toxicity, political\npartisanship, and misinformation:\nRQ1: Toxicity, Partisanship, and Unreliable Information. We first determine whether there\nare distinct levels of user political partisanship and toxicity in the comments that respond to\narticles from unreliable versus reliable news outlets. We find that comments posted on articles\nfrom unreliable websites are on average 32% more toxic within individual subreddits and 25% more\ntoxic across Reddit as a whole than comments responding to reliable websites. Fitting a linear\nregression against the average toxicity of users\u2019 comments, we find that the \u201cpoliticalness\u201d/level of\npolitical engagement, each subreddit/community\u2019s toxicity norms, and prominently whether a post\ninvolves a low-reliability news website predict the toxicity of conversations. Finally, we show that\nas subreddits become more toxic, users are more likely to comment on unreliable news articles. In\ncontrast, submissions linked to reliable sources are less likely to be engaged with in more toxic\ncommunities.\nRQ2: Engagement with Unreliable News Source\u2019s Predicting Inter-Political Strife. Having\nidentified that users who comment on unreliable sources are more likely to post toxic comments\nthan those who respond to reliable website posts, we examine the role of political partisanship in\nthese toxic interactions. We find that users who comment under Reddit submissions to unreliable\nsources have a higher rate of inter-partisan toxicity compared to users who comment under reliable\nsources (1.38 odds ratio) and on Reddit generally (1.19). Indeed, users who comment on unreliable\ndomain submissions are more likely to respond to users of different political views in a toxic manner\nand to reciprocate toxic comments aimed at them.\nAltogether, we show unreliable websites\u2019 role in promoting toxicity on Reddit. Our work, one\nof the first to examine the relationship between unreliable news sources, toxicity, and political\npartisanship within and between different communities of varying levels of political engagement\nillustrates the need to fully understand the complex interactions between these phenomena so that\nplatforms can better understand and address toxicity online.\n2 BACKGROUND & RELATED WORK\nIn this section, we detail key definitions, provide background on Reddit, and overview prior works\nthat analyze the effects of misinformation, toxicity, and political polarization on social media.\nSub-Standards and Mal-Practices 3\n2.1 Terminology\nBuilding on extensive prior work on misinformation, toxicity, and political polarization [ 28,58,61,\n130], we utilize community-accepted definitions of the following terms:\nReliable and Unreliable Domains. As in previous studies [ 9,59,61,70,77,90,143], we define\nmisinformation as information that is false or inaccurate regardless of author intention. Similarly,\nwe define unreliable domains as websites that regularly publish false information about current\nevents and that do not engage in journalistic norms such as attributing authors and correcting\nerrors [ 4,9,26,61,67,100,123,149]. Conversely, we define reliable domains as websites that\ngenerally adhere to journalistic norms including attributing authors and correcting errors; altogether\npublishing mostly true information [61, 67, 149].\nOnline Toxicity and Incivility. Given our use of the Google Jigsaw Perspective API [ 2], we use\ntheir definition of toxicity: \u201c (explicit) rudeness, disrespect or unreasonableness of a comment that is\nlikely to make one leave the discussion. \u201d\nPartisanship. We define partisanship as users\u2019 and communities\u2019 place on the US left\u2013right political\nspectrum [ 113]. We note the limitation of this definition given the variety of political views within\nthe US. However, in line with previous work [ 64,116,117], we utilize this definition, which largely\nfits much of US-centered political discussion, to understand how right-leaning and left-leaning\nusers and communities interact with one another and news.\nAffective Political Polarization: Affective political polarization is the tendency of individuals to\ndistrust and be negative to those of different political beliefs while being positive towards people\nof similar political views [37].\n2.2 Reddit\nReddit is an online social media platform composed of millions of subcommunities known as\nsubreddits [ 3,23]. Subreddits are dedicated to specific topics, ranging from politics (r/politics) and\nscience (r/science) to Pokemon (r/pokemon). Depending on the community, users can submit news\narticles, opinions, images, and memes as submissions . Underneath these submissions, other users\ncan comment or reply to comments from other users. Anyone can create a subreddit and subred-\ndits are moderated by Reddit content policies, subreddit-specific rules, and implicit community\nnorms [ 23,42,75]. Subreddit norms vary widely [ 144] and encompass political behaviors, tolerance\nto misinformation, and toxic behavior [23, 75, 110, 144].\n2.3 Partisanship and Polarization\nPeople, both in real life and on the Internet, tend to associate with like-minded people [ 13,14,\n60,62,71,81,106]. Wojcieszak et al. [ 146] find that while the majority of political discussions\nonline are between participants who share the same viewpoint, many users doenjoy conversations\nwith people with different viewpoints [ 128]. Despite this, past works have found that social media\nplatforms are one of the drivers of political polarization [ 20,22,65,81]. Sunstein, Garett et al.,\nand Quattrociocchi et al. all argue that the \u201cindividualized\u201d experience offered by social media\nplatforms comes with the risk of creating \u201cinformation cocoons\u201d and \u201cecho chambers\u201d that accelerate\npolarization [ 50,107,129]. Conover et al. [ 30] find that Twitter/X\u2019s structure fosters increased\nlevels of politically polarized conversations. Bessi et al. [ 16], examining the behaviors of 12 million\nusers, find that partisan echo chambers are driven by the algorithms of both Facebook and YouTube.\nTorres et al. [ 131] find the specific Twitter behavior of \u201cfollow trains\u201d induce highly politically\npolarized behavior on the platform.\nIn a similar vein, prior work has found that the increased political polarization engendered\nby social media causes several negative downstream effects including the increased sharing of\n4 Hans W. A. Hanley and Zakir Durumeric\nmisinformation and toxic online behaviors. Imhoff et al. [ 74], for example, find that political\npolarization is associated with beliefs in conspiracy theories. Ebling et al. [ 39] similarly find that\npolitical partisanship levels on social media are associated with medical misinformation about\nCOVID-19. Other studies have further interrogated the adverse effects that social media has\nhad on the democratic process due to the increased political polarization associated with social\nmedia [57, 103, 134, 135].\n2.4 Misinformation\nMisinformation has increasingly become a major aspect of the conversations on social media [ 9,\n48,53]. Even after controlling for cascade size, Juul and Ugander find that false information\nspreads deeper and wider on Twitter/X than true information [ 80]. Furthermore, misinformation\noften convinces those who are exposed to it. A large percentage of US adults were exposed to\nmisinformation stories by social media during the 2016 election [ 9] and many believed these false\nstories [ 8,59]. As COVID-19 spread throughout the world, online misinformation and conspiracy\ntheories became a major hurdle to curbing its spread [114, 124].\nTo prevent the spread of misinformation, recent research has focused on tracking and stemming\nits flow [ 61,134]. For example, Mahl et al. [ 93], track the spread of 10 conspiracy theories on Twitter,\nidentifying one of the largest conspiracy theorist networks. Ahmed et al. [ 5] use a similar approach\nto track the spread of COVID-19 and 5G conspiracy theories. They find well-known misinformation\nwebsites were some of the largest sources spreading these conspiracy theories on Twitter. Gruzd [ 58]\nfound that a single Tweet about how COVID-19 was a hoax, spurred an entire conspiracy theory,\neventually prompting large groups of people to film their local hospitals to prove that COVID-19\nwas not real. In addition to network-based approaches, others have used advancements in natural\nlanguage processing to identify and track misinformation. Hanley et al. [ 63], for example, utilize\nsemantic search to identify and track Russian state-media narratives on Reddit. Fong et al. [ 44]\nutilized linguistic and social features to understand the psychology of Twitter users that engaged\nwith known conspiracy theorists. Finally, several works have performed in-depth case studies on\nthe spread of specific false narratives: Wilson and Starbird et al. look at the Syrian White Helmets\non Twitter and B\u00e4r et al. look at the spread of QAnon on Parler [19, 145].\n2.5 Toxicity\nOnline toxicity takes many forms including threats, sexual harassment, doxing, coordinated bullying,\nand political incivility [ 46,47,92,130]. Toxic comments, in particular, are one of the most common\nforms of hate and harassment online [ 130] and are seemingly an inescapable part of social media [ 31,\n85,99,130,147]. Past studies have found that 41% of Americans and 40% of those globally have\nexperienced bullying or harassment online [ 38,130]. Facebook estimates that 0.14\u20130.15% of all\nviews on their platform are of toxic comments [ 41]. This type of incivility, in addition to damaging\nonline conversations, has been found to also damage civil institutions [ 17,135] having dangerous\nreal-world implications. For example, Fink et al. [ 43] find that politically charged anti-Muslim hate\nspeech on Facebook in Myanmar was a prominent aspect preceding the Rohingya genocide.\nTo limit toxicity, platforms have designed and implemented a variety of safeguards [ 1,2,41].\nOther researchers have further performed in-depth studies on users\u2019 behavior to understand\nabusers and victims of abuse. For instance, Founta et al. [ 45] identify a set of network and account\ncharacteristics of abusive accounts on Twitter. Hua et al. [ 69] look at properties of the accounts\nthat have heavily negative interactions with political candidates on Twitter. Finally, Chang et al.,\nXia et al., Zhang et al., and Lambert et al. all look at the set of causes that make conversations\nunhealthy or toxic [88, 148, 150, 151].\nSub-Standards and Mal-Practices 5\n2.6 The Interplay of Misinformation, Online Toxicity, and Political Polarization\nSeveral works have attempted to understand how political partisanship, online toxicity, and misin-\nformation interact. Online toxicity, for instance, has been heavily associated with increased political\npolarization and misinformation [ 29,134]. Rajadesingan et al. [ 109], find that political discussions\nin non-overtly political subreddits often lead to less toxic conversations. Cinelli et al. [ 29], show\nthat misinformation about COVID-19 on YouTube promoted hate and toxicity. Chen et al. [ 25],\nutilizing network-based analysis, find that misleading online videos often lead to increased incivility\nin their comments. Separately, Rains et al. [ 108] find that political extremism is a major factor\nin toxicity online. De Francisci Morales et al. [ 33] find, most markedly that the interaction of\nindividuals of different political orientations increased negative conversational outcomes. Similarly,\nKim et al., Kwon et al., and Shen et al. find that exposure to negative conversations increases\nobservers\u2019 tendency to further engage in incivility [ 83,87,125]. Finally, Imhoff et al. [ 74] find that\npolitical polarization is a key aspect of people\u2019s belief in false narratives. However, despite this\npanoply of research, it is unclear how political partisanship and toxicity interact in the presence\nof misinformation and across political environments. In this work, we seek to understand this\ndynamic.\n2.7 Present Work\nWhile several previous works have studied partisanship and affective polarization [ 33,40,94],\nfinding evidence of inter-partisan hostility, these works has been limited to explicitly politically-\noriented spaces and do not study the influence of unreliable information or misinformation. As\nshown by Rajadesingan et al. [ 109] and Mamakos et al. [ 94], political discussions frequently take\nplace in non-overtly political subreddits. Limiting the study of how partisanship and unreliable\ninformation affect users\u2019 discussions to only overly political subreddits, as in past works, can thus\ngive an incomplete picture of user behavior. As found by Efstratiou et al., different subreddits can\nhave different \u201cecho chamber-like\u201d behaviors and inter-partisan discussions depending on their\npoliticalness [40].\nOur work seeks to understand how partisanship and unreliable news sources that spread largely\nnon-factual information contribute to this toxicity and user engagement in both political and non-\npolitical contexts and within individual subreddits/communities. Given that our work quantifies the\npoliticalness and other characteristics of a subreddit or a user utilizing the methodology outlined\nby Waller et al. [ 141], we can account for this factor in contributing to toxicity and explore how\nunreliable sources interact in different subreddit environments and across different community\nstandards. By examining how these unreliable and reliable sources differ in toxicity both within\nand between individual subreddits and across subreddits of different types of politicalness, we seek\nto understand the extent to which unreliable news promotes toxicity and engagement among users\nof different political orientations.\n3 DATASETS AND METHODS\nIn this section, we provide an overview of our datasets and describe how we calculate the political\npartisanship of users and subreddits, how we determine the toxicity of posts and comments, and\nhow we identify user interactions with unreliable and reliable website sources.\n3.1 Reddit Dataset\nWe study 18 months of Reddit comments and submissions from January 2020 to June 2021, which we\ncollect using Pushshift [ 15]. Altogether, we gather 2.2 billion comments and 491 million submissions.\nEach comment and submission includes its timestamp, author\u2019s username, subreddit, and the\n6 Hans W. A. Hanley and Zakir Durumeric\nconversation thread where the comment was posted. We note that all data was collected before\nPushshift fell outside Reddit\u2019s Terms of Service in April 2023. Using this data, we reconstruct the\nconversation threads for each user and subreddit.\nAs in Kumar et al. [ 84], given that many Reddit comments labeled as toxic are simply sexually\nexplicit and contained within 18+ communities, we exclude 18+ subreddits from our study. As\nargued by Kumar et al. [ 84], while toxic behaviors do occur within these subreddits, the explicit\nallowance of sexually explicit language leads to a large number of false positives, complicating\nanalysis. In addition to filtering out 18+ subreddits, we limit our analysis to English-language\nmisinformation and thus filter our dataset using the whatlanggo Go language library1to only\nEnglish-language comments. Finally, given the model that we utilize to detect toxicity, we limit\nour analysis to comments that are 15\u2013300 characters in length [ 85]. Finally, to ensure that the user\nand subreddit characteristics that we extract are robust, we only calculate statistics for subreddits\nwith at least 100 comments and users that posted at least 5 comments. Altogether, our final dataset\nconsists of 327M Reddit submissions, 1.6B comments, and 15.5M users from 57.2K subreddits.\n3.2 Unreliable and Reliable Domain Dataset\nTo analyze how users interact with misinformation, we first gather a set of unreliable and re-\nliable websites (as a control). Specifically, we aggregate a list of unreliable/misinformation and\nreliable/authentic-news domains from Media-Bias/Fact-Check.2We consider websites as \u201cunreli-\nable\u201d if their factfulness rating from Media-Bias/Fact-Check is \u201cLow\u201d or \u201cVery Low\u201d; conversely,\nwe consider a website as \u201creliable\u201d if its factuality rating from Media-Bias/Fact-Check is \u201cMostly\nFactual\u201d, \u201cHigh\u201d, or \u201cVery High\u201d. We include \u201cMostly Factual\u201d in this category given that it includes\nwebsites like cnn.com and washtingtonpost.com. To ensure consistency, we further cross-reference\nthese two lists of websites against news websites previously gathered by Iffy News,3OpenSources,4\nPolitifact,5Snopes,6Melissa Zimdars,7and Hanley et al. [ 64]. Our final list of misinformation\noutlets consists of 1,054 websites, which encompass sites like theconservativetreehouse.com and\ninfowars.com [ 64]. Separately, our list of reliable news sites consists of 3,754 websites from across\nthe political spectrum, including sites like cnn.com and nytimes.com.\n3.3 Approximating the Partisanship of Subreddits and Users\nTo approximate the political partisanship of subreddits and Reddit users, we adopt the neural\nembedding approach described by Waller et al. [ 140,141], which learns subreddit and user embed-\ndings/vectors based on the interaction data of users within subreddits. This is such that a high\ncosine similarity between two users would indicate that the two users comment/post in similar\nor the same subreddits; conversely, a high similarity between two subreddits would indicate that\nthey share similar user bases. By computing subreddit and user similarity scores along a political\npartisanship dimension created when training the Wor2Vec model, as in Waller et al. [ 141], this\napproach enables the approximation of the partisanship of users and subreddits. We utilize this\napproach as it allows us to avoid biases in previous manual labels of the political orientation of\nsubreddits and because it allows us to label the orientation. Specifically, as in Waller et al. [ 141], we\napply the Word2Vec algorithm to our Reddit data where subreddits are treated as \u201cwords\u201d and users\n1https://github.com/abadojack/whatlanggo\n2https://mediabiasfactcheck.com/\n3https://iffy.news/index\n4https://github.com/several27/FakeNewsCorpus\n5https://www.politifact.com/article/2017/apr/20/politifacts-guide-fake-news-websites-and-what-they/\n6https://github.com/Aloisius/fake-news\n7https://library.athenstech.edu/fake\nSub-Standards and Mal-Practices 7\nare treated as \u201ccontexts\u201d. In this approach, every individual instance of a Reddit user commenting\nor submitting in a given subreddit is considered a word-context pair. Upon aggregating these\nword-context pairs, we subsequently train a Word2Vec using skip-gram with negative sampling\noutputting the vector embedding for each subreddit and for each user.\nFrom our vector embeddings, as specified by Waller et al. [ 141], we identify the political partisan-\nship dimension elicited by the Word2Vec to then categorize the political orientation of individual\nsubreddits and users. More concretely, after extracting our embeddings, we identify two simi-\nlar communities that differ primarily in the our dimension of interest; in this case, r/democrats\nand r/conservative. From the Word2Vec embeddings sr\ud835\udc5f\u21d1\ud835\udc51\ud835\udc52\ud835\udc5a\ud835\udc5c\ud835\udc50\ud835\udc5f\ud835\udc4e\ud835\udc61\ud835\udc60 and sr\ud835\udc5f\u21d1\ud835\udc50\ud835\udc5c\ud835\udc5b\ud835\udc60\ud835\udc52\ud835\udc5f\ud835\udc63\ud835\udc4e\ud835\udc61\ud835\udc56\ud835\udc63\ud835\udc52 that we\nelicited from these subreddits, we then compute the political partisanship dimensional vector\npr1=sr\ud835\udc5f\u21d1\ud835\udc51\ud835\udc52\ud835\udc5a\ud835\udc5c\ud835\udc50\ud835\udc5f\ud835\udc4e\ud835\udc61\ud835\udc60 \u2212sr\ud835\udc5f\u21d1\ud835\udc50\ud835\udc5c\ud835\udc5b\ud835\udc60\ud835\udc52\ud835\udc5f\ud835\udc63\ud835\udc4e\ud835\udc61\ud835\udc56\ud835\udc63\ud835\udc52 . To ensure that the political dimension that we are studying is\nnot overly specific to our seed communities of sr\ud835\udc5f\u21d1\ud835\udc51\ud835\udc52\ud835\udc5a\ud835\udc5c\ud835\udc50\ud835\udc5f\ud835\udc4e\ud835\udc61\ud835\udc60 and sr\ud835\udc5f\u21d1\ud835\udc50\ud835\udc5c\ud835\udc5b\ud835\udc60\ud835\udc52\ud835\udc5f\ud835\udc63\ud835\udc4e\ud835\udc61\ud835\udc56\ud835\udc63\ud835\udc52 , we subsequently\nidentify other pairs of similar communities whose difference vector has a high cosine similarity\nto our political partisanship dimensional vector pr1(i.e., other pairs of communities that differ\nprimarily in political partisanship direction). For example, in our work, other pairs of commu-\nnities that differed primarily along our political dimension included: r/liberalgunowners and\nr/gunpolitics, r/climatechange and r/climateskeptics, and r/askaliberal and r/askaconservative. As\nin Waller et al. [ 141], we average thee vectors to get our final partisanship dimensional vector pr1\n=sr\ud835\udc5f\u21d1\ud835\udc51\ud835\udc52\ud835\udc5a\ud835\udc5c\ud835\udc50\ud835\udc5f\ud835\udc4e\ud835\udc61\ud835\udc60 \u2212sr\ud835\udc5f\u21d1\ud835\udc50\ud835\udc5c\ud835\udc5b\ud835\udc60\ud835\udc52\ud835\udc5f\ud835\udc63\ud835\udc4e\ud835\udc61\ud835\udc56\ud835\udc63\ud835\udc52 using 10 unique political pairs.\npr=1\n1010\n\u2211\n\ud835\udc56pr\ud835\udc56 (1)\nTo project individual subreddits onto the political partisanship dimension, we compute the\ncosine similarity between a given community\u2019s Word2Vec embedding sr\ud835\udc5f\u21d1\ud835\udc4e\ud835\udc5b\ud835\udc66_\ud835\udc60\ud835\udc62\ud835\udc4f\ud835\udc5f\ud835\udc52\ud835\udc51\ud835\udc51\ud835\udc56\ud835\udc61 and the\ncomputed political partisanship dimension prvector. To make these values more interpretable, as in\nWaller et al. [ 141], we determine the z-scores for each community\u2019s projected value on the political\npartisanship dimension. This is such that a community with a z-score of -1 could be interpreted\nas having a leftward stance with a political partisanship level of 1 standard deviation below the\nmean subreddit. As in Waller et al. [ 141], in addition to calculating the political partisanship of\nindividual subreddits, by taking the sum of the vectors of our communities utilized to compute\nthe political dimension, rather than the difference, we can also determine the \u201cpolitical\u201d-ness of\nindividual subreddits and communities. This measure assesses the level of political engagement of\na community or user, rather than pinpointing their position on the political spectrum. For example,\nthe r/law subreddit, while not particularly partisan (-0.19 \ud835\udf0e), is over two standard deviations above\nthe mean for politicalness (2.10 \ud835\udf0e).\nWe lastly note that given the many individual hyperparameters utilized within Word2Vec models\n(e.g., embedding size, down-sampling threshold, starting learning rate, etc...), we perform a grid-\nsearch on these parameters and subsequently validate the political partisanship scores those of\nWaller et al. [ 141]. We select the model with partisanship scores that have the greatest Pearson\ncorrelation with those provided by Waller et al.8We detail the hyperparameters and the values\nthat we optimize over in Appendix A.\n3.4 Identifying Toxic Comments and Approximating User and Subreddit Toxicity\nTo approximate the toxicity of Reddit users and subreddits, we utilize the Perspective API, a set of\nout-of-box toxicity classifiers from Google Jigsaw [ 2] that has been utilized extensively in prior\n8We do not utilize the political partisanship scores provided by Waller et al. [ 141] given that their study is limited to\n10,006 ubreddits and given that they do not provide vectors or partisanship scores for individual users.\n8 Hans W. A. Hanley and Zakir Durumeric\n6\n5\n4\n3\n2\n1\n0\n1\n2\n3\n4\n5\n6\nEstimated Political Partisanship Z-score010002000300040005000600070008000Number of Subredditsr/antitrumpalliancer/antitrumpalliancer/youthforbidenr/youthforbiden\nr/dekachinr/dekachinr/texasconservativesr/texasconservatives r/politicsr/politicsr/askredditr/askreddit\n3\n2\n1\n0\n1\n2\n3\n4\n5\n6\nEstimated Political Politcal-ness Z-score010002000300040005000600070008000Number of Subredditsr/bolognar/bolognar/canadianmusicr/canadianmusic\nr/actualliberalgunownerr/actualliberalgunownerr/politicsr/politicsr/askredditr/askreddit\nFig. 1. Subreddit political partisanship and politicalness distribution \u2014 We determine the political partisanship\n(where a subreddit falls on the US left/right political spectrum) and how political a subreddit is by utilizing\nWaller et al.\u2019s [ 141] method for creating subreddit and user embeddings using an extension of Word2Vec [ 86].\n0.000 0.025 0.050 0.075 0.100 0.125 0.150 0.175 0.200\nEstimated Proportion T oxic0500010000150002000025000300003500040000Number of Subredditsr/homophobicr/homophobic\nr/beatmywifetoitr/beatmywifetoitr/beatmywifetoitr/beatmywifetoitr/pokemonplazar/pokemonplaza\nr/sapr/sapr/plagueincr/plagueinc\nr/infinitoder/infinitode r/fernsr/ferns\n0.000 0.025 0.050 0.075 0.100 0.125 0.150 0.175 0.200\nEstimated Proportion T oxic05000100001500020000250003000035000Number of Users\nFig. 2. Subreddit and User Toxicity scores\u2014We determine the toxicity norms for subreddits with at least\n100 comments and for users with at least 5 comments. Each user and subreddit has distinctive toxicity\nnorms, posting toxic comments at different rates. At a threshold of 0.80, most users and the subreddit\u2019s usual\ncomments/posts are not considered toxic by the Perspective API SEVERE_TOXICITY classifier.\nworks [ 85,110,118]. Each classifier takes comments as input and returns a toxicity score of 0.00\u2013\n1.00; the closer a comment\u2019s score is to 1, the more likely the comment is to be toxic. In line with\nprior work, to consider a comment as toxic, we utilize a threshold of 0.80 on the SEVERE_TOXICITY\nclassifier [ 27,88]. As found by Kumar et al. [ 84,85], utilizing this particular classifier, while limiting\nrecall, provides an acceptable precision for identifying toxic online content.\n3.5 Ethical Considerations\nWithin this work, we focus on identifying trends in how subreddits interact with misinformation,\nlevels of toxicity, and levels of political polarization. While we do calculate toxicity and polarization\nlevels for individual users, we do not analyze specific users, we do not publish their usernames,\nand we do not attempt to contact or deanonymize them. We note that the Reddit submissions and\ncomments analyzed in this work were public and available through the Pushshift API [15].\n4 TOXICITY AND PARTISANSHIP IN MISINFORMATION POSTS\nIn this section, we examine the relationship between Reddit submissions utilizing unreliable\ninformation sources and their corresponding partisanship, toxicity, and user engagement ( i.e.,\nnumber of comments). Using reliable news submissions as a control and accounting for the types of\nsubreddits where posts to unreliable sources appear, we measure whether Reddit posts that link to\nknown unreliable information sources predict increased toxicity. After examining the distributional\ndifferences in several characteristics amongst the users and subreddits of unreliable and reliable\nSub-Standards and Mal-Practices 9\nTop Unreliable websites # Links Top Reliable websites # Links Top Unreliable Subreddits # Links Top Reliable Subreddits # Links\noann.com 188,678 nytimes.com 493,032 r/TheNewsFeed 133,600 r/AutoNewspaper 1,010,948\ndailymailk.co.uk 110,491 cnn.com 392,392 r/ConservativeNewsWeb 64,565 r/politics 426,931\nrt.com 27,347 reuters.com 245,633 r/OneAmericaNews 54,138 r/news 208,612\nwnd.com 25,732 thehil.com 219,826 r/trendandstyle 47,171 r/worldnews 195,644\nnewsmax.com 25,204 cnbc.com 179,157 r/StateoftheUnionNONF 27,232 r/Coronavirus 178,555\namericanthinker.com 22,247 nbcnews.com 174,430 r/Conservative 22,859 r/nofeenews 92,815\nsputniknews.com 19,736 yahoo.com 164,489 r/StonkFeed 16,941 r/nytimes 89,795\nrumble.com 17,172 usatoday.com 147,323 r/TheBlogFeed 15,543 r/NoFilterNews 85,960\nzerohedge.com 15,409 washingtonpst.com 128,579 r/conspiracy 13,510 r/NBCauto 83,361\nbitchute.com 12,788 latimes.com 124,742 r/boogalorian 8,730 r/CNNauto 79,436\nTable 1. Top mainstream and websites hyperlinked within Reddit Submission and the top subreddits with\nunreliable websites and reliable websites hyperlinked. Altogether, within our set of studied 57K subreddits,\nwe identify 633,585 submission hyperlinks to our set of unreliable news websites and a total of 7,546,917\nsubmission hyperlinks to our set of reliable news.\nnews submissions, we finish this section by fitting a linear model and a negative binomial model to\nunderstand the degree to which each of these features predicts toxicity and user engagement on\nReddit.\nTo understand the characteristics of users and communities that interact with unreliable sources,\nwe identify submissions that link to our 1,057 unreliable and 3,754 reliable websites. Altogether,\nwe find 633.59K submissions of unreliable news websites and a corresponding set of 5.29 million\ncomments and 7.55 million submissions that link to our set of reliable websites and 267 million\ncorresponding comments. We list the most frequently linked websites and subreddits that most\ncommonly link to our sets of sites in Table 1. Altogether, hyperlinks to unreliable websites were\nposted in 9,462 subreddits and to reliable websites in 29,673 subreddits (8,611 subreddits had links\nto both). The difference in the magnitude of submission is likely due to the greater popularity and\nwidespread appeal of reliable mainstream news compared with alternative, fringe websites [ 64].\nIndeed, utilizing the Alexa Top Million list from March 1, 2021 [ 7], we find that 991 reliable news\nwebsites (26.39%) were in the top 100K websites compared to 139 unreliable websites (13.19%).\nFor the rest of this section, while using partisanship, politicalness, and toxicity averages com-\nputed from our full Reddit dataset (see Section 3), we analyze the set of Reddit submissions and\nReddit comments that involve unreliable and reliable website submissions. We additionally remove\nAutoModerator comments and comments from accounts labeled as \u201cbots.\u201d\n4.1 Differences Between Unreliable and Reliable Website Submissions\nAcross our dataset, we find that 1.26% of all comments within our datasets were classified as toxic\n(i.e., Perspective SEV_TOX score>0.80), 1.24% of comments under reliable website submissions\nwere considered toxic, and 1.55% of comments on unreliable submissions (a 25% relative increase).\nHowever, as previously mentioned, these comments are largely posted in different communities\non Reddit and likely by different users. Performing a comparison across individual subreddits, we\nfind that there remains a mean absolute percentage increase of 0.35% (32.2% relative increase) in\ntoxicity ( \ud835\udc5d<1\u00d710\u221216) for toxicity on unreliable news articles compared to reliable news articles.\nIn this section, we thus determine the differences between subreddits and users that interact with\nreliable versus unreliable news to understand this increase in toxicity.\nSubreddits. As seen in Table 2, on average, the subreddits where unreliable website submissions\nare posted are 1.13 standard deviations more right-leaning on the US political spectrum than those\nof reliable websites. This accords with previous research that has found that right-leaning users and\necosystems are more likely to spread misinformation [ 79]. However, we also observe that unreliable\nwebsite submissions tend to be posted in subreddits that are typically 0.75 standard deviations\nless political than reliable website submissions. For example, r/StreetFighter, a subreddit dedicated\n10 Hans W. A. Hanley and Zakir Durumeric\nUnreliable Reliable Cohen\u2019s D\nAvg. Subreddit Partisanship 0.96 \ud835\udf0e -0.17\ud835\udf0e 0.79\nAvg. Subreddit Politcalness 2.37 \ud835\udf0e 3.12\ud835\udf0e -0.47\nAvg. Subreddit Toxicity 2.01% 1.40% \u2014\nAvg. Submitter Partisanship -0.04 \ud835\udf0e -0.19\ud835\udf0e 0.19\nAvg. Submitter Politicalness -0.01 \ud835\udf0e 0.49\ud835\udf0e -1.42\nAvg. Submitter Toxicity 0.93% 0.90% \u2014\nAvg. Submitter Account Age (Years) 2.57 4.32 -0.54\nAvg. Commenter Partisanship 0.56 \ud835\udf0e 0.09\ud835\udf0e 0.57\nAvg. Commenter Partisanship Var. 0.45 0.48 -0.07\nAvg. Commenter Politicalness 0.20 \ud835\udf0e 0.26\ud835\udf0e -0.20\nAvg. Commenter Politicalness Var. 0.13 0.15 -0.19\nAvg. Commenter Toxicity 1.48% 1.36% \u2014-\nAvg. Commenter Account Age (Years) 4.88 5.25 -0.12\n% Removed Comments 2.01% 2.82% \u2014\n% Mod/Admin Involved 16.74% 16.26% \u2014\nTable 2. We determine different characteristics of the subreddits, commenters, and submitters that interact\nwith reliable and unreliable website submissions and subsequently determine the Cohen\u2019s effect size between\nthese values for unreliable news submissions and reliable news submissions. We perform Mann-Whitney U\ntests to ensure that the differences in the averages between unreliable and reliable website submissions are\nsignificant. We perform two-sample proportion tests for the percentages. Note, we performed a Bonferonni\ncorrection to assess whether values were significant, but all p-values tested were \ud835\udc5d<1\u00d710\u221216and significant.\n0 1 2 3 4 5 6 7 8\n|Post Age - Submitter Age|(Years)0.00.10.20.30.40.50.60.7Densityreliable=4.32\nunreliable=2.57\nUnreliable Domain Submitters\nReliable Domain Submitters\n(a) Age of Submitters\n0 2 4 6 8 10 12 14 16\n|Post Age - Commenter Age|(Years)0.0000.0250.0500.0750.1000.1250.1500.175Densityreliable=5.25\nunreliable=4.88\nUnreliable Domain Commenters\nReliable Domain Commenters (b) Age of Commenters\nFig. 3. Younger accounts are much more likely to submit and comment on unreliable website submissions.\nto the video game Street Fighter (politcalness=-0.47 \ud835\udf0e) contained 409 submissions to 4chan.org\nand r/MMA (politcalness=-0.43 \ud835\udf0e), had 81 links known Russian propaganda website rt.com [ 21]\nand far-right conspiracy site infowars.com [ 136]. Unreliable website submissions tend to be in\nsubreddits with higher average toxicity (2.01% vs. 1.40% of comments), which may explain the\nhigher likelihood of toxic comments in response to misinformation posts.\nSubmitters. In line with prior work, we find that users who submit unreliable websites articles as\nReddit submissions tend to be more right-leaning (-0.04 \ud835\udf0evs. -0.19 \ud835\udf0e), tend to be less political (-0.01 \ud835\udf0e\nvs. 0.49 \ud835\udf0e), tend to have slightly more toxic comments (0.93% 0.90%), and tend to have younger\naccounts (Table 2). Performing a subreddit pairwise comparison ( i.e., comparing the users who\nsubmitted unreliable websites in one subreddit to the users who also submitted reliable websites in\nthesame subreddit), we indeed find that users that submit unreliable websites tended to be more\nright-leaning (Cohen\u2019s D = 0.26, \ud835\udc5d<1\u00d710\u221216using the paired Wilcoxon signed-rank test), were\nvery slightly more political (Cohen\u2019s D = 0.01, \ud835\udc5d<1\u00d710\u221216), and were slightly more toxic overall\n(0.12% absolute percentage increase, \ud835\udc5d<1\u00d710\u221216).\nSub-Standards and Mal-Practices 11\nWe further observe that submitters of unreliable website hyperlinks tend to have younger\naccounts. As argued elsewhere, when posting inflammatory, revealing, or otherwise sensitive\ninformation [ 11,84,89], Reddit users often utilize disposable \u201cthrow-away\u201d accounts that are used\nonly to post this information anonymously. Indeed, as seen in Figure 3, within our dataset, we\nfind that while only 0.88% of reliable website submissions are submitted within the first week of\nan account\u2019s lifespan, 2.64% are submitted in the first week for unreliable websites (we perform a\nproportion test and find this difference to be significant \ud835\udc5d<1\u00d710\u221216).\nCommenters. Commenters on unreliable website submissions tend to be slightly more right-\nleaning (0.56 \ud835\udf0evs. 0.09 \ud835\udf0e), slightly less political (0.20 \ud835\udf0evs. 0.25 \ud835\udf0e), but slightly more toxic (1.48% vs.\n1.36%). Performing a subreddit pairwise comparison ( i.e., comparing the users that commented\non unreliable websites in one subreddit to the users who commented on reliable websites in the\nsame subreddit), we find that the users who comment on unreliable websites have no significant\ndifference (using the paired Wilcoxon signed-rank test) in partisanship nor toxicity, but do differ\nslightly in politicalness (Cohen\u2019s D = -0.07). We thus see that after accounting for the subreddit,\nthat is largely the same type of users that comment on unreliable and reliable website submissions\nwithin a given subreddit . Despite seeing that within subreddits the users of similar partisanship and\ntoxicity post on unreliable and reliable news submissions, again performing this subreddit pairwise\ncomparison, we find as previously reported that there is a mean absolute percentage increase of\n0.35% (32.2% relative increase) in toxicity ( \ud835\udc5d<1\u00d710\u221216) for unreliable submissions within each\nsubreddit. This illustrates that despite similar users participating in conversations surrounding\nunreliable and reliable news within a given subreddit, unreliable news comments tend to have\nmore toxic language.\nAs for submitters (Figure 3), we find that commenters on unreliable website submissions have\nyounger accounts than those for reliable website submissions (4.88 years vs. 5.25 years). We note\nthat, as with submitters, this may partially explain the increased toxicity of unreliable submission\ncommenters. Plotting the age of accounts versus the proportion of toxic comments in Figure 3a, we\nobserve that age is indeed correlated with the toxicity of commenters, with (as expected) unreliable\nnews websites having the highest toxicity overall regardless of the age of the account.\nModeration and Removed Comments. A potential confounder that can cloud our analysis is the\nactivity of Reddit moderators. Reddit moderators are members of particular subreddit communities\nwho help set rules and norms and help moderate content [ 10]. When a moderator on the Reddit\nplatform removes a comment, the comment is replaced with \u201c[removed]\u201d and other Reddit users can\nno longer view the comments. Altogether, 14,642 comments were removed from our set of unreliable\nwebsite submissions and 3,305,138 comments were removed from our set of reliable website\nsubmissions. As seen in Table 2, on average, reliable website submissions are more moderated\ncompared to unreliable website submissions (with an average of 2.00% comments being removed\ncompared to 2.82%). However, again performing a subreddit-wise pairwise comparison, we find\nthat within the subreddits where both reliable and unreliable submissions appear, unreliable news\ncommenters are actually moderated more heavily (Cohen\u2019s D = 0.37, \ud835\udc5d<1\u00d710\u221216using the\npaired Wilcoxon signed-rank test). This indicates, within subreddits that have both unreliable and\nreliable domain hyperlinks that unreliable ones are moderated more heavily; conversely, outside of\nthese subreddits, these unreliable website submissions are moderated more leniently. For example,\nwithin the r/bicycling subreddit, while 2.01% of reliable domain comments were removed, 19.35% of\nunreliable domain comments were removed. In contrast within the r/bitchute, where there were no\ncomments on reliable news domain hyperlinks, only 0.50% of comments were removed (BitChute\nis an alternative to YouTube known for hosting toxic and conspiratorial content [133]).\n12 Hans W. A. Hanley and Zakir Durumeric\nVariable Coefficient Std.\nIntercept 1.03\u00d710\u22122\u2217\u2217\u22171.00\u00d710\u22125\nSubreddit Toxicity 2.80\u00d710\u22123\u2217\u2217\u22174.20\u00d710\u22125\nSubreddit Politicalness - 2.00\u00d710\u22124\u22174.66\u00d710\u22125\nCommenter Toxicities 1.02\u00d710\u22122\u2217\u2217\u22173.74\u00d710\u22125\nCommenter Partisanships - 1.00\u00d710\u22123\u2217\u2217\u22175.80\u00d710\u22125\nCommenter Politcalness 1.50\u00d710\u22123\u2217\u2217\u22171.00\u00d710\u22124\nCommenter Partisanship:Subreddit Partisanship 2.00\u00d710\u22124\u2217\u2217\u22171.00\u00d710\u22125\nCommenter Politicalness:Subreddit Politicalness - 4.00\u00d710\u22124\u2217\u2217\u22171.00\u00d710\u22125\nModerator of Admin Involved - 5.00\u00d710\u22125\u2217\u2217\u22179.37\u00d710\u22125\nIs an Unreliable website submission 1.30\u00d710\u22123\u2217\u2217\u22171.00\u00d710\u22125\n\u2217\ud835\udc5d<0.05;\u2217\u2217\ud835\udc5d<0.01;\u2217\u2217\u2217\ud835\udc5d<0.001\nTable 3. Model of the toxicity of the comments in Reddit submissions. We fit a linear model to model the\npercentage of toxicity in each of the Reddit threads that contained a reliable domain or an unreliable domain\nin the submission. We perform backward selection based on the AIC to prevent overfitting.\nWe lastly examine the cases where a moderator left a comment or interacted with users in the\nsubreddit. As seen in Table 2, across all our submissions, moderators were involved in slightly more\nsubmissions in unreliable domain submissions, either as the submitter or as a commenter. We find\nthat the comments of submissions that had a moderator/admin involved were less toxic than those\nthat did not (1.04% vs. 1.66% for unreliable website submissions; 0.70% vs 1.12% for reliable website\nsubmissions). Performing a subreddit-wise pairwise comparison on the proportions of submissions\nper subreddit that had moderator involvement, we again see that unreliable news websites were\nvery slightly more likely to have a moderator involved (Cohen\u2019s D =0.05, \ud835\udc5d<1\u00d710\u221216using the\npaired Wilcoxon signed-rank test).\nSummary. In this section, we showed that links to websites known to spread unreliable information\nare correlated with higher toxicity: toxic comments under unreliable website submissions are posted\nat a rate of 1.55% while toxic comments in response to reliable website submissions are posted at a\nrate of 1.24%. Within individual subreddits, we find that on average, the toxicity rate increases on\naverage by an absolute 0.35% (32.2% relative increase). In addition, we observed that users who\npost and comment on misinformation are right-leaning.\n4.2 Prediction of Toxicity by Use of Unreliable Sources and Partisanship\nHaving seen the higher toxicity in response to unreliable website submissions, we now examine\nhow the factors previously examined interact with one another to collectively predict toxicity.\nSetup. We fit a linear model to understand how each of the features previously considered (Table 2)\npredicts the average toxicity comments responding to Reddit submissions. Specifically, we fit our\nmodel against the percentage of toxic comments in our 633.59K unreliable and 7.55M reliable website\nsubmissions. To ensure that our model does not overfit, we run a backward variable selection [ 34]\nbased on the Akaike information criterion [ 6] accounting for interaction between our variables.\nWe detail the variables and their found coefficients in Table 3.\nResults. As seen in Table 3, even after accounting for subreddit and user conditions, we see that\nthere is increased toxicity on Reddit in response to an unreliable website submission. Indeed, our\nmodel finds this variable to have the fourth largest coefficient ( \ud835\udefd=1.30\u00d710\u22123) in predicting\nthe overall toxicity of Reddit conversation, behind only overall subreddit toxicity, commenters\u2019\npropensity for toxicity, and the commenters\u2019 politicalness. Our fitted model further finds, as\nexpected from our previous analysis, that moderator involvement is associated with reduced\ntoxicity ( \ud835\udefd=\u22125.00\u00d710\u22125). This again reinforces that moderator involvement on the Reddit\nplatform is indeed associated with decreased measured toxicity [ 132]. As would further be expected,\nSub-Standards and Mal-Practices 13\nour model determines that subreddit toxicity ( \ud835\udefd=2.80\u00d710\u22123) and average toxicity of the users\nthat comment ( \ud835\udefd=1.02\u00d710\u22122) on a given submission is associated with increased toxicity within a\ngiven submission\u2019s comments. This further shows that the toxicity norms in particular subreddits\ndoaffect [110] how users interact.\nOur model determines that as subreddits become more political, ( i.e., are more aligned along\nthe US political spectrum) overall toxicity decreases. While this result is limited to posts that are\ncentered around news articles, increased politicalness of subreddits in the context of news articles\nappears to have a slight mitigating effect on toxicity. For example, as previously noted, the r/law\nsubreddit, while not being particularly partisan (-0.19 \ud835\udf0e), is over two standard deviations above the\nmean for politicalness (2.10 \ud835\udf0e) and only 0.49% of the subreddits\u2019 comments are considered toxic. We\nfurther see that this is the case when examining the interaction between commenter politicalness\nand subreddit politicalness ( \ud835\udefd=\u22124.00\u00d710\u22124), and the partisanship of individual commenters\n(\ud835\udefd=\u22121.00\u00d710\u22123). We hypothesize, as found in Rajadesingan et al. [ 110] that as subreddits become\nmore aligned to the political spectrum and their users further become aligned to the politicalness\nof the subreddit or community, stronger community norms are built and overall toxicity decreases.\nHowever, like Mamakos et al. [ 94], we find that as the overall partisanship, rather than simply\nthe politicalness of users and subreddits, increases, the toxicity of conversations increases ( \ud835\udefd=\n2.00\u00d710\u22124). Finally, again, as in Mamakos et al. [ 94], we find that as commenters become more\npolitical and engage in political discussions ( \ud835\udefd=1.50\u00d710\u22123), particularly if they engage in both\nright-leaning and left-leaning discussions and subreddits they tend to have increased toxicity and\nspread more toxic content on the Reddit platform.\nSummary. In this section, after fitting a linear regression model utilizing backward elimination,\nwe find that after accounting for partisanship and other commenter and subreddit-level factors,\nunreliable website submissions predict increased toxicity on Reddit. Our linear model further\nidentifies that a subreddit\u2019s level of political engagement along the US spectrum and toxicity norms\nalso play a role in predicting toxicity.\n4.3 Prediction of Engagement via Toxicity, Use of Unreliable Sources, and Partisanship\nHaving shown how the use of unreliable sources predicts increased toxicity on Reddit, we now\ndetermine some of the factors that may induce users increased engagement with unreliable websites\nand their information. Namely, having seen that unreliable sources are associated with more\ntoxicity and more politically right-wing environments compared to reliable sources, are toxicity,\npoliticalness, and partisanship correlated with more engagement with misinformation?\nSetup. To measure user engagement with unreliable and reliable website submissions, we utilize the\nnumber of comments that each submission receives.9As before, to properly model the number of\ncomments, we remove comments from Reddit \u201cauto moderator\u201d or explicitly \u201cbot\u201d labeled accounts.\nAltogether, we analyze our set of 633.59K unreliable website submissions, our set of 7.55M reliable\nwebsite submissions, and each of these sets\u2019 associated comments.\nTo model the number of comments on submissions, we utilize a zero-inflated negative binomial\nregression [ 112]. Within our model, each observation data point represents a single submission and\nits associated number of posted comments. We utilize a zero-inflated negative binomial regression\nas it appropriately models our set of count data. Unlike a Poisson model, which is often utilized\nto model count data, negative binomial regressions do not make the strong assumption that the\nmean of the data is equal to the variance [ 96]. (Some submissions garner thousands of comments\nwhile others garner none.) We further utilize the zero-inflated version of this regression given the\n9We utilize the number of comments rather than the number of upvotes/downvotes because Pushshift often fails to keep\nup-to-date information about the number of votes for submissions [15].\n14 Hans W. A. Hanley and Zakir Durumeric\nheavy preponderance of submissions that do not receive any comments. After removing comments\nfrom auto moderators and bots, 61.50% of our reliable website submissions within our dataset did\nnot receive any comments, and 81.67% of our unreliable website submissions did not receive any\ncomments. A Poisson or normal negative binomial model would be unable to correctly model this\nbehavior.\nWe finally note that zero-inflated negative binomial regressions return two sets of coefficients.\nOne set of coefficients, the zero-inflated coefficients, estimated using logistic regression, reports the\nprobability that the given submission would receive zero comments as a function of the covariates.\nPositive coefficients for these zero-inflated coefficients indicate that increases in the predictor\nvariable make the submissions receiving zero comments more likely. Thus the more negative a\ncoefficient, the more the given covariate correlates with inducing at least 1 comment. The second set\nof coefficients, the negative binomial coefficients, model the number of comments as a function of\nthe covariates. For these coefficients, positive coefficients indicate that the larger the corresponding\ncovariate, the more comments that submission was likely to have received. We thus, in our analysis,\ncan understand how different covariates affect the probability that a given submission will receive\nanycomments andhow these same covariates affect the number of comments received. As factors\ninfluencing the number of comments, we utilize:\n(1) the submitter\u2019s admin/moderator status\n(2) the relative age of the account that posted the submission\n(3) the submitter\u2019s partisanship\n(4) the submitter\u2019s politcalness\n(5) the submitter\u2019s account\u2019s age\n(6) the submitter\u2019s toxicity\n(7) the subreddit\u2019s partisanship\n(8) subreddit\u2019s politcalness\n(9) the subreddit\u2019s toxicity\n(10) the average number of comments per submission of the subreddit\nWe again utilize backward variable selection based on the AIC for selecting variables.10\nResults. We now give an overview and describe some of the implications of our results using our\nnegative binomial regression to predict levels of user engagement based on levels of politicalness,\npartisanship, toxicity, and the use of unreliable news articles.\nSubmitter Admin/Moderator Status. For unreliable website submissions, we find that when a\nmoderator posts the submission they are more likely to get at least one comment compared to\na non-moderator account ( \ud835\udefd=\u22121.25). In contrast, for reliable website submissions, we find that\nthese moderator or admin accounts are less likely to gain at least one comment compared to\nnon-moderator accounts ( \ud835\udefd=0.20). For both unreliable and reliable website submissions, however,\nwe observe that when admin or moderator accounts post, do gain posts, they are more likely to\nreceive more comments than normal accounts. This largely accords with moderators\u2019 role on the\nplatform when making announcements in subreddits on which users then comment [91].\n10We spot-check our results to ensure that the higher the average number of comments in a given subreddit, the more likely\na submission is to see comments andthat this average correlates with more comments on submissions. In other words, we\ncheck that submissions in subreddits where users comment more, also see receive comments. As seen in both Tables 4 and 5,\nfor both unreliable and reliable website Reddit submissions, as the average number of comments in a subreddit increases, (1)\nthe more likely a submission is to receive comments and (2) the more comments it is likely to receive. Having observed this\nbehavior, we now examine the rest of the covariates within our fits (Tables 4 and 5).\nSub-Standards and Mal-Practices 15\nSubmitter Toxicity. Examining the submitting users\u2019 toxicity, we see somewhat similar behaviors\nfor both reliable and unreliable information submissions. Most notably, as the submitting users\nbecome more toxic, for both unreliable and reliable website submissions, they are more likely\nto provoke at least one comment. However, for unreliable website submissions, we observe that\nthe submitter\u2019s toxicity has a much larger effect on the probability of receiving at least one\ncomment( \ud835\udefd=\u221219.47vs.\ud835\udefd=\u22120.06). This illustrates that while for unreliable websites, increased\ntoxicity may induce greater initial engagement, this effect is not as strong for reliable websites.\nHowever, again in both cases, we see that while user toxicity often provokes at least one person to\nreact, we see that this toxicity often does not lead to more comments (the coefficient for unreliable\nwebsites is not statistically significant).\nSubmitter Politicalness. While we observe that for unreliable websites, the higher a user\u2019s politi-\ncalness, the more likely to induce at least one comment ( \ud835\udefd=\u22121.14), there is the opposite effect for\nreliable websites ( \ud835\udefd=2.43). This appears to indicate that in the case of reliable website submissions,\nNumber of Comments on Unreliable Website Submissions\nZero Inflated Negative Binomial\nnegative coefficient = positive coefficient =\nmore likely to get comments Std Error more comments Std Error\nIntercept 3.30\u2217\u2217\u22170.14 0.36\u2217\u2217\u22170.04\nSubmitter Is Moderator -1.25\u2217\u2217\u22170.06 0.30\u2217\u2217\u22170.04\nSubmitter Toxicity -19.47\u2217\u2217\u22171.73 -0.15 0.54\nSubmitter Politicalness -1.14\u2217\u2217\u22170.24 -0.49\u2217\u2217\u22170.09\nSubmitter Partisanship 5.41\u2217\u2217\u22170.34 -0.12 0.12\nSubmitter Age -0.23\u2217\u2217\u22170.01 0.02\u2217\u2217\u22170.003\nSubreddit Toxicity -0.99\u2217\u2217\u22170.03 -0.09\u2217\u2217\u22170.01\nSubreddit Politicalness 1.05\u2217\u2217\u22170.03 0.04\u2217\u2217\u22170.01\nSubreddit Partisanship 0.64\u2217\u2217\u22170.03 0.12\u2217\u2217\u22170.01\n|Subreddit Partisanship - Submitter Partisanship| -0.19\u2217\u2217\u22170.04 -0.34\u2217\u2217\u22170.01\nAverage # Subreddit Comments -2.48\u2217\u2217\u22170.05 0.12\u2217\u2217\u22170.001\n\u2217\ud835\udc5d<0.05;\u2217\u2217\ud835\udc5d<0.01;\u2217\u2217\u2217\ud835\udc5d<0.001\nTable 4. Fit of our zero-inflated negative binomial regression on the number of comments on our set of\nunreliable URL submissions across different subreddits.\nNumber of Comments on Reliable Website Submissions\nZero Inflated Negative Binomial\nnegative coefficient = positive coefficient =\nmore likely to get comments Std Error more comments Std Error\nIntercept -3.37\u2217\u2217\u22170.02 0.63\u2217\u2217\u22170.01\nSubmitter Is Moderator 0.20\u2217\u2217\u22170.01 0.49\u2217\u2217\u22170.01\nSubmitter Toxicity -0.06\u2217\u2217\u22170.003 -0.02\u2217\u2217\u22170.002\nSubmitter Politicalness 2.43\u2217\u2217\u22170.02 0.22\u2217\u2217\u22170.006\nSubmitter Partisanship -0.31\u2217\u2217\u22170.006 -0.05\u2217\u2217\u22170.003\nSubmitter Age -0.15\u2217\u2217\u22170.004 0.12\u2217\u2217\u22170.002\nSubreddit Toxicity 0.23\u2217\u2217\u22170.005 0.11\u2217\u2217\u22170.004\nSubreddit Politicalness 0.79\u2217\u2217\u22170.004 0.19\u2217\u2217\u22170.002\nSubreddit Partisanship 0.51\u2217\u2217\u22170.004 0.43\u2217\u2217\u22170.002\n|Subreddit Partisanship - Submitter Partisanship| 0.46\u2217\u2217\u22170.006 0.08\u2217\u2217\u22170.003\nAverage # Subreddit Comments -2.94\u2217\u2217\u22170.01 1.60\u2217\u2217\u22170.003\n\u2217\ud835\udc5d<0.05;\u2217\u2217\ud835\udc5d<0.01;\u2217\u2217\u2217\ud835\udc5d<0.001\nTable 5. Fit of our zero-inflated negative binomial regression on the number of comments on our set of\nmainstream URL submissions across different subreddits.\n16 Hans W. A. Hanley and Zakir Durumeric\nReddit users are perhaps being \u201cturned off\u201d and are engaging less with highly ideological users\ncompared to less political users [ 66]. However, we also find that the more political a user becomes\n(if the submission gets comments), the fewer comments unreliable website submissions are likely\nto receive ( \ud835\udefd=\u22120.49) in contrast to reliable website submissions which receive more comments\n(\ud835\udefd=0.22). This illustrates that highly politicized users may be more likely to engender a discussion\namongst users for reliable website submissions, but are less effective at gathering comments for\nunreliable website submissions.\nSubmitter Partisanship. For unreliable websites, we find that the more right-leaning a user, the\nless likely the user\u2019s post is to attract any user comments. Given the right-leaning nature of most\nof the subreddits (0.97 \ud835\udf0e) in which unreliable domain posts are submitted, this could likely be\ndue to these user\u2019s posts being seen as \u201cnormal\u201d and the posts not receiving many comments\n(\ud835\udefd=5.41). In contrast, for reliable news ( \ud835\udefd=\u22120.31), we see that as the submission\u2019s submitter\nbecomes more politically right-wing, the more likely their posts are to receive comments. Given\nreliable website submissions tend to be posted in left-leaning subreddits ( \u22120.17\ud835\udf0e), submissions from\nmore right-leaning users may be seen as more novel resulting in at least one user comment [ 68,\n82]. This also supports prior research that has found that out-group animosity may drive online\nengagement [ 111]. However, despite right-leaning users being able to attract at least one comment\nfor reliable website submission, we also observe, that as the posting user becomes more right-leaning\npartisan ideological, the fewer comments their post is likely to receive ( \ud835\udefd=\u22120.05) [66].\nSubmitter Age. For both unreliable and reliable websites, we find that older accounts are more\nlikely to provoke at least one comment and that the older the account the more comments that its\nsubmission is likely to get. This may indicate that accounts with more history may attract more\nengagement with their posts.\nSubreddit Toxicity. Looking at the subreddit toxicity coefficient in predicting whether a submission\nreceives comments, we see a marked difference between reliable website submissions and unreliable\nwebsite submissions. We see, notably, for misinformation submissions, the more toxic a subreddit\nis, the more likely the submission is to get comments ( \ud835\udefd=\u22120.99). In contrast, for reliable website\nsubmissions, the more toxic the subreddit, the more likely the submission is to not get any comments\n(\ud835\udefd=0.23). Misinformation websites often post inflammatory articles designed to engender angst in\ntheir readership.\nHowever, we further find, for reliable website submissions, that as subreddit toxicity increases,\nthe more comments submissions are likely to garner. In contrast for unreliable website submissions,\nthe more toxic the subreddit, the fewer comments the submission is likely to garner. This reflects\nthat when reliable website submissions get noticed or spark engagement in a toxic community, the\nmore toxic the environment the more users seem to comment and engage with the submissions.\nIn contrast, when articles from unreliable sources are noticed in toxic environments, they do not\nappear to draw extensive interactions. We thus see that reliable website submissions are more\noften ignored in toxic subreddits when compared to unreliable websites, and simultaneously that\nas communities get more toxic, they tend to comment more on reliable information and less on\nunreliable information submissions.\nSubreddit Politicalness. For both unreliable and reliable website submissions, the more political\na subreddit, the fewer users are likely to comment at all ( \ud835\udefd=1.05and \ud835\udefd=0.79. This largely\ndemonstrates again a novelty aspect given that highly political subreddits receive constant news\nupdates. However, for both unreliable ( \ud835\udefd=0.04) and reliable submissions( \ud835\udefd=0.19), we find that\nwhen a submission is commented on, subreddits\u2019 politicalnesses increase the likelihood of more\ncomments. This association is again probably largely a result of the fact that work measures\nSub-Standards and Mal-Practices 17\nusers\u2019 interaction with reliable and unreliable sources and that subreddits that are more politically\nengaged on the US political spectrum are more likely to be interested in news [ 56] and subsequently\ncomment on posts when they gain traction.\nSubreddit Partisanship. We find that for reliable websites, the more politically right-leaning a\nsubreddit, the less likely it is to gain any comments ( \ud835\udefd=0.51). Rather, as documented by Wang\net al. [142] subreddits like these often ignore more trustworthy sources. We similarly find for\nunreliable websites, the more politically right-leaning, the less likely these posts are to get any\ncomments ( \ud835\udefd=0.64). As before, given the right-leaning nature of most of the subreddits (+0.97 \ud835\udf0e) in\nwhich unreliable domain posts are submitted, this could likely be due to these users\u2019 posts being\nseen as \u201cnormal\u201d. In contrast, for both misinformation and reliable website submissions, we find\nthat as the subreddit\u2019s right-leaning partisanship goes up, the more comments given submissions\nare likely to garner.\n|Subreddit Partisanship - Submitter Partisanship|. For unreliable websites, we find that as the\ndifference between the submitter\u2019s partisanship and the subreddit\u2019s partisanship increases, the\nmore likely the post is to get at least one comment ( \ud835\udefd=\u22120.19). Various works have found that\nusers not aligned to political norms of a given environment [ 110], provoke engagement from\nusers as they become \u201coutraged\u201d by the presented content [ 49,82] and can largely be observed\nhere. We note that we do not observe a similar phenomenon for reliable website submissions\n(\ud835\udefd=0.43), which may result from the reliable website submission being unable to provoke initial\ncomments. However, for reliable website submissions, we find as the difference between the\nsubmitting user\u2019s partisanship and the subreddit\u2019s partisanship increases, the more comments that\nthat submission is likely to get. This indicates that when the reliable submission manages to gain\ninitiate comments, the farther the submitter\u2019s partisanship for the subreddit as a whole, the longer\nthe ensuing conversation. In contrast, for unreliable website submissions, our model finds that\nas the submitters\u2019s partisanship moves further away from the subreddit\u2019s own partisanship, after\ninitially accruing an initial comment, it is less likely to gain additional ones.\n4.4 Summary\nIn this section, we find that submitter toxicity, submitter politicalness, submitter age, subreddit\ntoxicity, and subreddit politicalness all encourage initial interaction with unreliable website sub-\nmissions. In contrast, submitter toxicity and subreddit toxicity play much more muted roles for\nreliable news submissions with the subreddit toxicity actually predicting less initial engagement\nwith reliable news sources. This appears to overall suggest a higher degree of initial engagement\nwith unreliable news outlets in political and toxic settings compared to reliable sources.\nWe further find that moderator involvement, subreddit politicalness, and subreddit partisanship\nall encourage users to have longer sustained interactions with unreliable information while sub-\nreddit toxicity predicts shorter conversations. In contrast for reliable news, we find that subreddit\ntoxicity, subreddit politicalness, and subreddit partisanship all predict increased user engagement\n(if users initially comment at all). This illustrates that while toxic environments may induce initial\nengagement with unreliable news, it does not predict sustained interactions, with the opposite\nbeing true of reliable news.\n5 UNRELIABLE WEBSITES AND POLARIZED TOXIC INTERACTIONS\nIn the previous section, we showed that unreliable website submissions are correlated with in-\ncreased toxicity and that increased toxicity is also correlated with comments on unreliable website\nsubmissions. To understand the user-level dynamics of toxicity in response to unreliable news\nsubmissions, we reconstruct the conversational dyads that exist underneath each Reddit submission.\n18 Hans W. A. Hanley and Zakir Durumeric\n1.56%1.33%\n1.28%1.49%Right\nLeftLeft\nRight\nTargetAuthor\n(a) Unreliable Website Submission Dyads1.10%0.98%\n1.05%1.12%Right\nLeftLeft\nRight\nTargetAuthor\n(b) Reliable Website Submission Dyads\n1.05%0.87%\n1.10%1.03%Right\nLeftLeft\nRight\nTargetAuthor\n(c) All Submission Dyads\nFig. 4. Percentage of interactions that are toxic in all, unreliable, reliable website submissions for Right and\nleft-leaning authors against Right and left-leaning targets.\nUsing the approach outlined in Section 3.1, we then determine the partisanship, politicalness, and\naverage toxicity of the users in these conversational dyads, mapping out different types of political\ninteractions. From these averages, we label users as right-leaning (greater than 0.5 \ud835\udf0epartisanship) or\nleft-leaning (less than -0.5 \ud835\udf0epartisanship). Then, looking at each conversational dyad, we determine\nif each comment is toxic using the Perspective API (as outlined in Section 3.1). As an example of\nsuch as dyad, in the r/Coronavirus subreddit, a user with a left-leaning bias posted:\nWhy oh why are people spitting on strangers? And can we get some spit for the evil 80 who own\nhalf the planet? No? Ok.\nto which another user with a right-leaning bias replied:\nCome the fuck on. I don\u2019t care what your opinions are or if it was just a really shitty joke. Don\u2019t\nwish for people to catch this, that\u2019s an asshole move right there.\nFor a comparison of how conversations differ between unreliable website and reliable website\ncomments, we finally separate the set of conversational dyads that appear under unreliable versus\nreliable website submissions.\n5.1 Interactions within Unreliable and Reliable Information Ecoysystems\nWe observe (as expected) that many users primarily interact with users of the same partisan-\nship [ 128]: 71.80% of interactions were between users that share the same partisanship-lean. For\nunreliable news submissions, this rises to 83%, and for reliable website submissions, it drops to\n66%. We similarly find that 72.08% of toxic interactions (where a user responded to another user\nwith a toxic reply) were between users who shared the same partisanship leaning among all dyads,\n80.63% for unreliable website submissions, and 63.34% for reliable website submissions. This is likely\nbecause, as previously found, unreliable domains are largely posted in somewhat more insular\nSub-Standards and Mal-Practices 19\nsubreddits (average partisanship = 0.97 \ud835\udf0e; Table 2) and in communities with higher degrees of\ntoxicity (2.01%; Table 2).\nDespite users largely interacting with users of the same partisanship, we find some increased rates\nof affective polarization between users of different partisanships. As seen in Figure 4, we observe\nincreased toxicity between users of different partisanships for our set of website submissions, with\nthis difference most marked for unreliable website submissions. Indeed calculating the odds ratios\nbetween the percentages of inter-partisanship toxicity against those of intra-partisanship toxicity,\nwe get values of 0.99 across all dyads, 1.19 for unreliable domain dyads, and 1.08 for reliable domain\ndyads. We thus observe a slight increase in inter-partisanship toxicity between users who comment\nunder submissions with attached domain hyperlinks. Further, calculating the odds ratio between\nthe rates of toxicity between unreliable websites and reliable website conversational dyads, we get\nvalues of 1.38 for inter-partisanship toxicity and 1.26 for intra-partisanship toxicity. We thus observe\nthat amongst our set of conversations, there is an even heightened rate of affective polarization for\nunreliable news interactions compared to reliable news interactions.\n5.2 Modeling Toxic Interactions Between Users\nTo concretely show that users of different political stripes are more likely to reply in a toxic manner\nto each other in conversations under unreliable domain submissions, we fit our network data of\ntoxic interactions into an exponential random graph model. An Exponential Random Graph Model\n(ERGM) is a form of modeling that predicts connections ( e.g., toxic interactions) between nodes\n(users) in a given network [ 72]. ERGM models assume that connections are determined by a random\nvariable \ud835\udc5d\u2217that is dependent on input variables. As in Chen et al. [25] and Peng et al. [102], we\nutilize this modeling as it does not assume that its data input is independent; given that, we want\nto model the interactions of polarization, toxicity, this relaxed restriction is key (we have already\nseen that they are largely not independent) [72, 137].\nSetup. Utilizing our ERGM, we predict the probability of toxic interactions between two users\nwithin misinformation submissions as a function of:\n(1) the users\u2019 percentage of toxic comments\n(2) the users\u2019 partisanship\n(3) hthe difference in the author and target\u2019s political polarization\n(4) the users\u2019 politicalness\n(5) the age of the two users\n(6)the reciprocity between the two users ( i.e., if both users had a toxic comment aimed at each\nother)\n(7)the number of comments that the two users have in subreddits in which they both post\ncomments\nWe include the number of comments that the users have made in shared subreddits to account for\nthe fact that users with more overlap in user activity ( i.e., frequent the same subreddits) are more\nlikely to interact with one another. When fitting our models we again utilize backward selection\nand minimize the AIC to determine the variables used in our final models.\nResults. We find that account age, partisanship, and the politicanlness of a given user do not have\nsignificant effects on the likelihood of toxic interactions (removed from fit after minimizing the\nAIC). This indicates that just because a user is highly partisan or political it does not necessarily\nmean that they are likely to engage in toxicity. For all domain interactions, as seen in Table 6, we\nfind that (1) that the more toxic a user, the more likely they are to engage in toxic interactions,\nand (2) that users are more likely to respond in a toxic manner to users who engage with them\nin a toxic manner (reciprocity). Indeed we find that in unreliable website submissions, users are\n20 Hans W. A. Hanley and Zakir Durumeric\nUnreliable Domain Interactions Coeff. Std.\nIntercept 8.65*** 0.05\nUser Partisanship Differences -0.20*** 0.04\nUser Toxicity 5.88*** 0.46\nShared Subreddits Comments 0.004* 0.001\nReciprocity 4.79*** 0.18\n\u2217\ud835\udc5d<0.05;\u2217\u2217\ud835\udc5d<0.01;\u2217\u2217\u2217\ud835\udc5d<0.001Reliable Domain Interactions Coeff. Std.\nIntercept 8.73*** 0.05\nUser Partisanship Differences -0.29*** 0.04\nUser Toxicity 6.48*** 0.74\nShared Subreddits Comments 0.001*** 0.0004\nReciprocity 3.97*** 0.27\n\u2217\ud835\udc5d<0.05;\u2217\u2217\ud835\udc5d<0.01;\u2217\u2217\u2217\ud835\udc5d<0.001\nTable 6. Toxic Unreliable and Reliable Website Submission Interactions. As confirmed in our ERGM, differences\nin the political orientation of users are predictive of increased incivility and toxicity, with users of differing\npolitical orientations more likely to engage in toxic interactions within misinformation submissions than on\nmainstream submissions. Similarly, the higher each user\u2019s toxicity norm, the more they are likely to target\nother users with toxic comments.\nmore likely to reply in a toxic manner to another user if that user has already corresponded with\nthem in a toxic manner ( \ud835\udefd=4.79vs.\ud835\udefd=3.97). However, most importantly, we find that while\nmost toxic interactions occur among users that are politically similar to each other, compared to\nreliable domain interactions, users discussing unreliable website submissions are more likely to send\ntoxic comments to users of different political ideologies than users under mainstream submissions\n(\ud835\udefd=\u22120.20vs.\ud835\udefd=\u22120.29).\nSummary. In this section, we showed that unreliable website submissions not only promote higher\nlevels of toxicity in their comments but are also correlated with increased inter-partisanship toxicity\ncompared to reliable website submissions. Fitting an ERGM to our toxic conversational dyads posted\nin response to misinformation stories, we show that political differences, along with reciprocity\nand each user\u2019s toxicity, drive more toxic interactions.\n6 LIMITATIONS\nIn this work, we used a quantitative, large-scale approach to understand the role of misinformation\nin toxic interactions online. We outline the limitations of our approach in this section.\nUnreliable Information. One of the limitations of our approach is our use of hyperlinks to\ndetermine the presence of unreliable/factually inaccurate information. As we examined much of\nReddit\u2019s 2.2 billion comments, we were unable to take a comment-by-comment-based approach to\nunderstand the levels of unreliable news. As a result, our approach inevitably missed some subtleties\nof unreliable information across subreddits. However, as found in several past works [ 61,67,121,\n139], examining unreliable information from a domain-based perspective enables researchers to\ntrack readily identifiable and questionable information across different platforms and is a reliable\nway of understanding the presence of unreliable information in large communities or websites\n(e.g., subreddits). Our approach thus relies on the presence of largely US-based domains on given\nsubreddits and largely only measures English unreliable information and partisanship. As a result,\nwe cannot simply apply our results to non-English subreddits and non-US-oriented environments.\nHowever, we note, that while our work centers on US-based political environments, as found\nin prior works, highly political environments across different cultures often utilize unreliable\ninformation and often share many of the same characteristics as US ones [ 61,74]. We leave the full\ninvestigation of this phenomenon on Reddit to future work.\nMeasuring Toxicity. Another limitation of our approach, given our use of the Perspective API to\nestimate toxicity, is that it is limited to relatively active users and subreddits. We are only able to\ndevelop, in line with past works, toxicity norms and political estimations for subreddits that have\nat least 100 comments. As such, our results are skewed to more active subreddits and users. At the\nsame time, these subreddits and users make up a large percentage of users\u2019 experiences on Reddit.\nSub-Standards and Mal-Practices 21\nConfounds, Correlation, and Causation. We lastly acknowledge that while we account for many\nuser-level and subreddit-level features, there may be other hidden confounders. For example, while\nwe attempted to remove automated accounts from much of our analysis by removing accounts\nthat were labeled as \u201cbot\u201d accounts, due to the rapid rise of AI, within Reddit as a whole there\ncould still be automated accounts. We note that we conducted this analysis for data in 2020 and\n2022, before the release of ChatGPT however. We further emphasize that while we work to account\nfor confounders, the results we present describe the correlation between misinformation, political\npolarization, and toxicity; we cannot ascribe causation. However, our results do align with a large\nliterature of similar results [12\u201314] some of which have found causal results.\n7 DISCUSSION\nIn this work, we examined the relationship between unreliable information, political partisanship,\nuser engagement, and toxicity across and within both political and non-political subreddits. Using\npreviously published lists of unreliable and reliable websites, we find that on Reddit, we find that\ncomments posted in response to submissions with hyperlinks to unreliable news websites have\n25% more toxic comments overall (an average of 32% more within individual subreddits). Utilizing\na zero-inflated negative binomial model to model engagement with unreliable versus reliable\ninformation sources, we observe that subreddit toxicity is a major predictor of whether unreliable\ndomain submissions receive comments. This contrasts with reliable domain submissions, where\ntoxicity plays a more muted role, and the more toxic the subreddit, the more likely that reliable\nsubmissions are to not get any comments. Finally, examining how partisanship affects the increase\nin toxicity in response to unreliable information, we find, confirming with an Exponential Random\nGraph Model (ERGM), that articles from unreliable news outlets correlate with increased toxicity\namong users of different political leanings ( i.e., affective polarization).\n7.1 Unreliable Information\u2019s Correlation with Toxicity\nOur work shows that while unreliable websites have much less of a presence on Reddit compared\nto reliable websites (633.6K posts/601 submissions per domain vs 7.55M posts/2010.4 submissions\nper domain), unreliable news websites play a large role on the platform. As documented by others,\noften millions of comments discuss and spread false information [ 122]. In addition to misleading\nusers, unreliable information\u2019s effect on the discourse on these subreddits can often be pernicious\nwith articles from websites known to promote unreliable news increasing inter-political strife.\nIndeed as was seen in Table 2 and was found in our unreliable domain submission dyads, unreliable\ndomain submissions are associated with increased toxicity, particularly among users of different\npartisanship alignments. This largely accords with the work of Dicicco et al. [ 35] that showed that\nusers who comment on YouTube videos promoting COVID-19 conspiracy theories often utilize\ntoxic and vulgar language. Our paper results bolster this work, showing that increased unreliable\ndomains correlate with increased incivility on Reddit. This largely goes to promote and affirm the\nview that unreliable news/misinformation does have a relationship [ 35,97] with user toxicity and\nis not uncorrelated with toxicity [29, 105].\nIn our conversational dyads, we further find that across much of Reddit, unreliable websites\nare correlated with more insular and politically one-sided conversations, while reliable domains\nare correlated with increased discussions between users of different political ideologies (with\nboth increasing inter-political toxicity). Community norms for particular environments appear to\naffect how users engage with different materials. As found with our zero-inflated negative binomial\nmodel, subreddit toxicity norms are also predictive of user engagement with unreliable news articles.\nUnreliable and factually inaccurate, is found within toxic environments. The more toxic/uncivil\na given environment, the more likely at least one person is to engage with misinformation or\n22 Hans W. A. Hanley and Zakir Durumeric\nunreliable sources. However, simultaneously, in more toxic environments, where these posts most\ncommonly appear, these same posts are less likely to gain extensive engagement and a large number\nof comments. This appears to reflect that unreliable news websites often utilize \u201cclickbait\u201d titles that\ninduce readers to initially comment, but then cause the reader to not often thoroughly engage with\nmaterial [ 24,104]. In contrast, in less toxic environments where these posts more rarely appear, if\nthey do gain traction ( e.g., at least one comment), they are more likely to gain more comments.\n7.2 Implications of the Reddit Platform\nOur work indicates that unreliable domains correlate with increased overall toxicity of conversa-\ntions on Reddit, particularly between users of different partisanships. We note that this increased\nrancor persists despite individual subreddits moderating unreliable domain submissions more\nheavily compared to reliable domain submissions. Given the lower prevalence of unreliable sources\nthroughout Reddit compared to reliable sources and the decreased toxicity of conversations with\nmoderator involvement, a potential solution to decrease toxicity may be for Reddit admins (who\nare not already doing so), to engage more thoroughly or to flag submissions that contain hyperlinks\nto known unreliable and specious websites. However, as argued by Bozrath et al. [ 18], different\napproaches for moderating this content in different subreddits however will be necessary. Some\nlarger subreddits already take a machine-learning approach to remove misinformation [ 76] while\nothers take a manual approach that relies on crowd wisdom or individual moderator involve-\nment [ 73,78,119]. However, given that Reddit removed links to Russian state-based propaganda\nin the wake of the Russo-Ukrainian War [ 127] and has previously taken steps to remove highly\ntoxic material and subreddits [ 126], we recommend that Reddit itself also take more proactive steps\nto alert users to unreliable information and to identify new websites and known websites that\npromote unreliable information and flag, label, or remove them from their platform. Further as\nagain found by Bozrath et al. [ 18] moderating one type of misinformation or unreliable source\ncan be similar to moderating other types, allowing Reddit to take a generalized approach to alert\nsubreddits to the presence of unreliable news and propaganda.\nPolitical Echo-Chambers, Politics Discussions, and Reliable News on Reddit. Similar to\npast work, we find that most toxic interactions take place among users of the same political\norientation [ 40]. Reddit specifically creates communities for like-minded people and as a result,\nmost interactions (both toxic and non-toxic interactions) on the platform are between people\nof the same political orientation. However, most interestingly, in the comments of submissions\nwith hyperlinks to reliable news sources, the rate of inter-partisan interactions slightly increases\ncompared to interaction across Reddit. This is in contrast to unreliable domain submissions where\nthe rates of interaction between users and different partisanship decreases. We argue, that if Reddit,\nas a whole, desires to lower levels of political incivility and toxicity on its platform, taking a more\nproactive approach to policing questionable sources could help alleviate these issues. As found by\nGallacher et al. [ 49], toxic online interactions between political groups often lead to offline real-\nworld political violence. Given that unreliable news appears to be correlated with and reinforces\ntoxic interactions between different political groups, this highlights the need to research its effects\nand curtail its spread.\nSub-Standards/Community Norms. We have found throughout this work that subreddits interact\nwith reliable and unreliable sources differently. For example, while more toxic subreddits are more\nlikely to interact with unreliable information sources, the more toxic a subreddit, the more likely\nthe reliable submissions are to not get any comments. We thus find often complex relationships\nbetween different types of subreddits and their interactions with different types of posts. There is\nno one-size-fits-all approach to understanding user engagement and toxicity on Reddit [ 120,152].\nSub-Standards and Mal-Practices 23\nWe thus argue that a subreddit/community-based approach that takes into account the community\nnorms of the community must be taken when trying to understand the information flows within\nit [42]. Similarly, in attempting to prevent engagement with unreliable news on particular subreddits,\nunderstanding their toxicity norms, their political ideology, and who is posting the article within the\nsubreddit is key [ 152]. For example, as found by Zhan et al [ 152], different communities responded\nand engaged with COVID-19 misinformation in widely divergent manners. We thus argue that\napproaches that attempt to understand how users engage with unreliable information (particularly\non Reddit), must take into account the particular nuances of that community.\n8 CONCLUSION\nUnreliable information persists across many different types of subreddits. Its spread furthermore\nseems to be affected by the type of community it is posted in. Unreliable and factually incorrect\nappears to be more likely to gain traction when it is posted in more toxic/uncivil environments.\nFurthermore, the communities with large amounts of unreliable news appear to be more politically\ninsular with more of their interactions occurring between users of similar political orientations. As\nusers become more politically dissimilar when commenting under unreliable information, as found\nwith our ERGM, they are more likely to be toxic/uncivil to one another compared to users who\ncomment under reliable information. Our work, one of the first to examine the relationship between\nunreliable news, toxicity, and political ideology at scale, illustrates the need to fully understand the\nfull effect of unreliable information. Not only does unreliable news mislead people but it also can\nmagnify political differences and lead to more toxic online environments.\nREFERENCES\n[1]2021. Twitter. Rules enforcement. https://transparency.twitter.com/en/reports/rules-enforcement.html-2020-jul-dec.\n[2] 2022. Google Jigsaw. Perspective API. https://www.perspectiveapi.com/#/home.\n[3]2022. Metrics For Reddit - Complete List Of Subreddits - Updated Weekly. https://frontpagemetrics.com/list-all-\nsubreddits\n[4]Sara Abdali, Rutuja Gurav, Siddharth Menon, Daniel Fonseca, Negin Entezari, Neil Shah, and Evangelos E Papalexakis.\n2021. Identifying Misinformation from Website Screenshots. In International AAAI Conference on Web and Social\nMedia (ICWSM) 2021 .\n[5]Wasim Ahmed, Josep Vidal-Alaball, Joseph Downing, Francesc L\u00f3pez Segu\u00ed, et al .2020. COVID-19 and the 5G\nconspiracy theory: social network analysis of Twitter data. Journal of medical internet research 22, 5 (2020), e19458.\n[6]Hirotugu Akaike. 2011. Akaike\u2019s information criterion. International encyclopedia of statistical science (2011), 25\u201325.\n[7] Alexa Internet, Inc. 2021. Top 1,000,000 Sites. http://s3.amazonaws.com/alexa-static/top-1m.csv.zip.\n[8]Hunt Allcott and Matthew Gentzkow. 2017. Social media and fake news in the 2016 election. Journal of economic\nperspectives 31, 2 (2017), 211\u201336.\n[9]Hunt Allcott, Matthew Gentzkow, and Chuan Yu. 2019. Trends in the diffusion of misinformation on social media.\nResearch & Politics 6, 2 (2019), 2053168019848554.\n[10] Hind Almerekhi, Supervised by Bernard J Jansen, and co-supervised by Haewoon Kwak. 2020. Investigating toxicity\nacross multiple Reddit communities, users, and moderators. In Companion proceedings of the web conference 2020 .\n294\u2013298.\n[11] Tawfiq Ammari, Sarita Schoenebeck, and Daniel Romero. 2019. Self-declared throwaway accounts on Reddit:\nHow platform affordances and shared norms enable parenting disclosure and support. Proceedings of the ACM on\nHuman-Computer Interaction 3, CSCW (2019), 1\u201330.\n[12] Christopher A Bail, Lisa P Argyle, Taylor W Brown, John P Bumpus, Haohan Chen, MB Fallin Hunzaker, Jaemin Lee,\nMarcus Mann, Friedolin Merhout, and Alexander Volfovsky. 2018. Exposure to opposing views on social media can\nincrease political polarization. Proceedings of the National Academy of Sciences 115, 37 (2018), 9216\u20139221.\n[13] Pablo Barber\u00e1. 2014. How social media reduces mass political polarization. Evidence from Germany, Spain, and the\nUS.Job Market Paper, New York University 46 (2014), 1\u201346.\n[14] Pablo Barber\u00e1, John T Jost, Jonathan Nagler, Joshua A Tucker, and Richard Bonneau. 2015. Tweeting from left to\nright: Is online political communication more than an echo chamber? Psychological science 26, 10 (2015), 1531\u20131542.\n[15] Jason Baumgartner, Savvas Zannettou, Brian Keegan, Megan Squire, and Jeremy Blackburn. 2020. The pushshift\nreddit dataset. In Proceedings of the international AAAI conference on web and social media , Vol. 14. 830\u2013839.\n24 Hans W. A. Hanley and Zakir Durumeric\n[16] Alessandro Bessi, Fabiana Zollo, Michela Del Vicario, Michelangelo Puliga, Antonio Scala, Guido Caldarelli, Brian\nUzzi, and Walter Quattrociocchi. 2016. Users polarization on Facebook and Youtube. PloS one 11, 8 (2016), e0159641.\n[17] Porismita Borah. 2013. Interactions of news frames and incivility in the political blogosphere: Examining perceptual\noutcomes. Political Communication 30, 3 (2013), 456\u2013473.\n[18] Lia Bozarth, Jane Im, Christopher Quarles, and Ceren Budak. 2023. Wisdom of Two Crowds: Misinformation\nModeration on Reddit and How to Improve this Process\u2014A Case Study of COVID-19. Proceedings of the ACM on\nHuman-Computer Interaction 7, CSCW1 (2023), 1\u201333.\n[19] Dominik B\u00e4r, Nicolas Pr\u00f6llochs, and Stefan Feuerriegel. 2022. Finding Qs: Profiling QAnon Supporters on Parler.\nhttps://doi.org/10.48550/ARXIV.2205.08834\n[20] Michael A Cacciatore, Dietram A Scheufele, and Shanto Iyengar. 2016. The end of framing as we know it. . . and the\nfuture of media effects. Mass communication and society 19, 1 (2016), 7\u201323.\n[21] Global Engagement Center. 2020. Pillars of Russia\u2019s disinformation and propaganda ecosystem.\n[22] Pew Research Center. 2017. The partisan divide on political values grows even wider. Pew Research Center (2017).\n[23] Eshwar Chandrasekharan, Mattia Samory, Shagun Jhaver, Hunter Charvat, Amy Bruckman, Cliff Lampe, Jacob\nEisenstein, and Eric Gilbert. 2018. The Internet\u2019s hidden rules: An empirical study of Reddit norm violations at micro,\nmeso, and macro scales. Proceedings of the ACM on Human-Computer Interaction 2, CSCW (2018), 1\u201325.\n[24] Yimin Chen, Niall J Conroy, and Victoria L Rubin. 2015. Misleading online content: recognizing clickbait as\" false\nnews\". In Proceedings of the 2015 ACM on workshop on multimodal deception detection . 15\u201319.\n[25] Yingying Chen and Luping Wang. 2022. Misleading political advertising fuels incivility online: A social network\nanalysis of 2020 US presidential election campaign video comments on YouTube. Computers in Human Behavior 131\n(2022), 107202.\n[26] Lu Cheng, Ruocheng Guo, Kai Shu, and Huan Liu. 2021. Causal understanding of fake news dissemination on social\nmedia. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining . 148\u2013157.\n[27] Yun Yu Chong and Haewoon Kwak. 2022. Understanding Toxicity Triggers on Reddit in the Context of Singapore. In\nProceedings of the International AAAI Conference on Web and Social Media , Vol. 16. 1383\u20131387.\n[28] Matteo Cinelli, Gianmarco De Francisci Morales, Alessandro Galeazzi, Walter Quattrociocchi, and Michele Starnini.\n2021. The echo chamber effect on social media. Proceedings of the National Academy of Sciences 118, 9 (2021),\ne2023301118.\n[29] Matteo Cinelli, Andra\u017e Pelicon, Igor Mozeti\u010d, Walter Quattrociocchi, Petra Kralj Novak, and Fabiana Zollo. 2021.\nDynamics of online hate and misinformation. Scientific reports 11, 1 (2021), 1\u201312.\n[30] Michael D Conover, Bruno Gon\u00e7alves, Jacob Ratkiewicz, Alessandro Flammini, and Filippo Menczer. 2011. Predicting\nthe political alignment of twitter users. In 2011 IEEE third international conference on privacy, security, risk and trust\nand 2011 IEEE third international conference on social computing . IEEE, 192\u2013199.\n[31] Dana Cuomo and Natalie Dolci. 2019. Gender-Based Violence and Technology-Enabled Coercive Control in Seattle:\nChallenges & Opportunities.\n[32] Alina Darmstadt, Mick Prinz, and Oliver Saal. 2019. The murder of Keira: misinformation and hate speech as far-right\nonline strategies. (2019).\n[33] Gianmarco De Francisci Morales, Corrado Monti, and Michele Starnini. 2021. No echo in the chambers of political\ninteractions on Reddit. Scientific reports 11, 1 (2021), 1\u201312.\n[34] Shelley Derksen and Harvey J Keselman. 1992. Backward, forward and stepwise automated subset selection algorithms:\nFrequency of obtaining authentic and noise variables. Brit. J. Math. Statist. Psych. 45, 2 (1992), 265\u2013282.\n[35] Karen DiCicco, Nahiyan B Noor, Niloofar Yousefi, Maryam Maleki, Billy Spann, and Nitin Agarwal. 2020. Toxicity\nand Networks of COVID-19 discourse communities: a tale of two social media platforms. Proceedings http://ceur-ws.\norg ISSN 1613 (2020), 0073.\n[36] Shiri Dori-Hacohen, Keen Sung, Jengyu Chou, and Julian Lustig-Gonzalez. 2021. Restoring Healthy Online Discourse\nby Detecting and Reducing Controversy, Misinformation, and Toxicity Online. In Proceedings of the 44th International\nACM SIGIR Conference on Research and Development in Information Retrieval . 2627\u20132628.\n[37] James N Druckman, Samara Klar, Yanna Krupnikov, Matthew Levendusky, and John Barry Ryan. 2021. Affective\npolarization, local contexts and public opinion in America. Nature human behaviour 5, 1 (2021), 28\u201338.\n[38] Maeve Duggan. 2017. Online Harassment 2017 | Pew Research Center. https://www.pewresearch.org/internet/2017/\n07/11/online-harassment-2017/\n[39] R\u00e9gis Ebeling, Carlos Abel C\u00f3rdova S\u00e1enz, J\u00e9ferson Campos Nobre, and Karin Becker. 2022. Analysis of the influence\nof political polarization in the vaccination stance: the Brazilian COVID-19 scenario. In Proceedings of the International\nAAAI Conference on Web and Social Media , Vol. 16. 159\u2013170.\n[40] Alexandros Efstratiou, Jeremy Blackburn, Tristan Caulfield, Gianluca Stringhini, Savvas Zannettou, and Emiliano\nDe Cristofaro. 2023. Non-polar opposites: analyzing the relationship between echo chambers and hostile intergroup\ninteractions on Reddit. In Proceedings of the International AAAI Conference on Web and Social Media , Vol. 17. 197\u2013208.\nSub-Standards and Mal-Practices 25\n[41] Facebook. 2021. Transparency center. https://transparency.fb.com/policies/community-standards/bullying-\nharassment/datz. Accessed: 2021-10-08.\n[42] Casey Fiesler, Joshua McCann, Kyle Frye, Jed R Brubaker, et al .2018. Reddit rules! characterizing an ecosystem of\ngovernance. In Twelfth International AAAI Conference on Web and Social Media .\n[43] Christina Fink. 2018. Dangerous speech, anti-Muslim violence, and Facebook in Myanmar. Journal of International\nAffairs 71, 1.5 (2018), 43\u201352.\n[44] Amos Fong, Jon Roozenbeek, Danielle Goldwert, Steven Rathje, and Sander van der Linden. 2021. The language of\nconspiracy: A psychological analysis of speech used by conspiracy theorists and their followers on Twitter. Group\nProcesses & Intergroup Relations 24, 4 (2021), 606\u2013623.\n[45] Antigoni Maria Founta, Constantinos Djouvas, Despoina Chatzakou, Ilias Leontiadis, Jeremy Blackburn, Gian-\nluca Stringhini, Athena Vakali, Michael Sirivianos, and Nicolas Kourtellis. 2018. Large scale crowdsourcing and\ncharacterization of twitter abusive behavior. In Twelfth International AAAI Conference on Web and Social Media .\n[46] Diana Freed, Jackeline Palmer, Diana Minchala, Karen Levy, Thomas Ristenpart, and Nicola Dell. 2018. \u201cA Stalker\u2019s\nParadise\u201d How Intimate Partner Abusers Exploit Technology. In Proceedings of the 2018 CHI conference on human\nfactors in computing systems . 1\u201313.\n[47] Diana Freed, Jackeline Palmer, Diana Elizabeth Minchala, Karen Levy, Thomas Ristenpart, and Nicola Dell. 2017.\nDigital technologies and intimate partner violence: A qualitative analysis with multiple stakeholders. Proceedings of\nthe ACM on human-computer interaction 1, CSCW (2017), 1\u201322.\n[48] Daniel Funke. 2018. Fact-checkers have debunked this fake news site 80 times. It\u2019s still publishing on Facebook.\nPoynter. org.\n[49] John D Gallacher, Marc W Heerdink, and Miles Hewstone. 2021. Online engagement between opposing political\nprotest groups via social media is linked to physical violence of offline encounters. Social Media+ Society 7, 1 (2021),\n2056305120984445.\n[50] R Kelly Garrett. 2009. Echo chambers online?: Politically motivated selective exposure among Internet news users.\nJournal of computer-mediated communication 14, 2 (2009), 265\u2013285.\n[51] Anthony J Gaughan. 2016. Illiberal democracy: The toxic mix of fake news, hyperpolarization, and partisan election\nadministration. Duke J. Const. L. & Pub. Pol\u2019y 12 (2016), 57.\n[52] Bryan T Gervais. 2015. Incivility online: Affective and behavioral reactions to uncivil political posts in a web-based\nexperiment. Journal of Information Technology & Politics 12, 2 (2015), 167\u2013185.\n[53] Dipayan Ghosh and Ben Scott. 2018. Digital deceit: the technologies behind precision propaganda on the internet.\n(2018).\n[54] Amit Goldenberg and James J Gross. 2020. Digital emotion contagion. Trends in Cognitive Sciences 24, 4 (2020),\n316\u2013328.\n[55] Ine Goovaerts and Sofie Marien. 2020. Uncivil communication and simplistic argumentation: Decreasing political\ntrust, increasing persuasive power? Political Communication 37, 6 (2020), 768\u2013788.\n[56] Doris Appel Graber, Denis McQuail, and Pippa Norris. 1998. The politics of news: The news of politics . CQ press\nWashington, DC.\n[57] Kirsikka Gr\u00f6n and Matti Nelimarkka. 2020. Party Politics, Values and the Design of Social Media Services: Implications\nof political elites\u2019 values and ideologies to mitigating of political polarisation through design. Proceedings of the ACM\non human-computer interaction 4, CSCW2 (2020), 1\u201329.\n[58] Anatoliy Gruzd and Philip Mai. 2020. Going viral: How a single tweet spawned a COVID-19 conspiracy theory on\nTwitter. Big Data & Society 7, 2 (2020), 2053951720938405.\n[59] Andrew Guess, Brendan Nyhan, and Jason Reifler. 2018. Selective exposure to misinformation: Evidence from the\nconsumption of fake news during the 2016 US presidential campaign. European Research Council 9, 3 (2018), 4.\n[60] Yosh Halberstam and Brian Knight. 2016. Homophily, group size, and the diffusion of political information in social\nnetworks: Evidence from Twitter. Journal of public economics 143 (2016), 73\u201388.\n[61] Hans WA Hanley, Deepak Kumar, and Zakir Durumeric. 2022. No Calm in The Storm: Investigating QAnon Website\nRelationships. In Proceedings of the International AAAI Conference on Web and Social Media , Vol. 16. 299\u2013310.\n[62] Hans WA Hanley, Deepak Kumar, and Zakir Durumeric. 2023. \" A Special Operation\": A Quantitative Approach to\nDissecting and Comparing Different Media Ecosystems\u2019 Coverage of the Russo-Ukrainian War. In Proceedings of the\nInternational AAAI Conference on Web and social media , Vol. 17. 339\u2013350.\n[63] Hans WA Hanley, Deepak Kumar, and Zakir Durumeric. 2023. Happenstance: utilizing semantic search to track\nRussian state media narratives about the Russo-Ukrainian war on Reddit. In Proceedings of the international AAAI\nconference on web and social media , Vol. 17. 327\u2013338.\n[64] Hans W. A. Hanley, Deepak Kumar, and Zakir Durumeric. 2023. A Golden Age: Conspiracy Theories\u2019 Relationship with\nMisinformation Outlets, News Media, and the Wider Internet. ACM Conference on Computer Supported Cooperative\nWork (2023).\n26 Hans W. A. Hanley and Zakir Durumeric\n[65] Gordon Heltzel and Kristin Laurin. 2020. Polarization in America: Two possible futures. Current Opinion in Behavioral\nSciences 34 (2020), 179\u2013184.\n[66] Marc J Hetherington. 2008. Turned off or turned on? How polarization affects political engagement. Red and blue\nnation 2 (2008), 1\u201333.\n[67] Austin Hounsel, Jordan Holland, Ben Kaiser, Kevin Borgolte, Nick Feamster, and Jonathan Mayer. 2020. Identifying\nDisinformation Websites Using Infrastructure Features. In USENIX Workshop on Free and Open Communications on\nthe Internet .\n[68] Philip N Howard, Bharath Ganesh, Dimitra Liotsiou, John Kelly, and Camille Fran\u00e7ois. 2019. The IRA, social media\nand political polarization in the United States, 2012-2018. (2019).\n[69] Yiqing Hua, Mor Naaman, and Thomas Ristenpart. 2020. Characterizing twitter users who engage in adversarial\ninteractions against political candidates. In Proceedings of the 2020 CHI conference on human factors in computing\nsystems . 1\u201313.\n[70] Y Linlin Huang, Kate Starbird, Mania Orand, Stephanie A Stanek, and Heather T Pedersen. 2015. Connected through\ncrisis: Emotional proximity and the spread of misinformation online. In Proceedings of the 18th ACM conference on\ncomputer supported cooperative work & social computing . 969\u2013980.\n[71] Robert Huckfeldt, Paul Allen Beck, Russell J Dalton, and Jeffrey Levine. 1995. Political environments, cohesive social\ngroups, and the communication of public opinion. American Journal of Political Science (1995), 1025\u20131054.\n[72] David R Hunter, Mark S Handcock, Carter T Butts, Steven M Goodreau, and Martina Morris. 2008. ergm: A package\nto fit, simulate and diagnose exponential-family models for networks. Journal of statistical software 24, 3 (2008),\nnihpa54860.\n[73] Sohyeon Hwang and Jeremy D Foote. 2021. Why do people participate in small online communities? Proceedings of\nthe ACM on Human-Computer Interaction 5, CSCW2 (2021), 1\u201325.\n[74] Roland Imhoff, Felix Zimmer, Olivier Klein, Jo\u00e3o HC Ant\u00f3nio, Maria Babinska, Adrian Bangerter, Michal Bilewicz,\nNeboj\u0161a Blanu\u0161a, Kosta Bovan, Rumena Bu\u017earovska, et al .2022. Conspiracy mentality and political orientation across\n26 countries. Nature human behaviour 6, 3 (2022), 392\u2013403.\n[75] Shagun Jhaver, Darren Scott Appling, Eric Gilbert, and Amy Bruckman. 2019. \" Did you suspect the post would be\nremoved?\" Understanding user reactions to content removals on Reddit. Proceedings of the ACM on human-computer\ninteraction 3, CSCW (2019), 1\u201333.\n[76] Shagun Jhaver, Iris Birman, Eric Gilbert, and Amy Bruckman. 2019. Human-machine collaboration for content\nregulation: The case of reddit automoderator. ACM Transactions on Computer-Human Interaction (TOCHI) 26, 5 (2019),\n1\u201335.\n[77] Shan Jiang and Christo Wilson. 2018. Linguistic signals under misinformation and fact-checking: Evidence from user\ncomments on social media. Proceedings of the ACM on Human-Computer Interaction 2, CSCW (2018), 1\u201323.\n[78] Ridley Jones, Lucas Colusso, Katharina Reinecke, and Gary Hsieh. 2019. r/science: Challenges and opportunities\nin online science communication. In Proceedings of the 2019 CHI conference on human factors in computing systems .\n1\u201314.\n[79] John T Jost, Sander van der Linden, Costas Panagopoulos, and Curtis D Hardin. 2018. Ideological asymmetries in\nconformity, desire for shared reality, and the spread of misinformation. Current opinion in psychology 23 (2018),\n77\u201383.\n[80] Jonas L Juul and Johan Ugander. 2021. Comparing information diffusion mechanisms by matching on cascade size.\nProceedings of the National Academy of Sciences 118, 46 (2021), e2100786118.\n[81] Julia Kamin. 2019. Social Media and Information Polarization: Amplifying Echoes or Extremes? Ph. D. Dissertation.\n[82] Jin Woo Kim, Andrew Guess, Brendan Nyhan, and Jason Reifler. 2021. The distorting prism of social media: How\nself-selection and exposure to incivility fuel online comment toxicity. Journal of Communication 71, 6 (2021), 922\u2013946.\n[83] Yonghwan Kim and Youngju Kim. 2019. Incivility on Facebook and political polarization: The mediating role of\nseeking further comments and negative emotion. Computers in Human Behavior 99 (2019), 219\u2013227.\n[84] Deepak Kumar, Jeff Hancock, Kurt Thomas, and Zakir Durumeric. 2023. Understanding the behaviors of toxic\naccounts on reddit. In Proceedings of the ACM Web Conference 2023 . 2797\u20132807.\n[85] Deepak Kumar, Patrick Gage Kelley, Sunny Consolvo, Joshua Mason, Elie Bursztein, Zakir Durumeric, Kurt Thomas,\nand Michael Bailey. 2021. Designing Toxic Content Classification for a Diversity of Perspectives. In Seventeenth\nSymposium on Usable Privacy and Security (SOUPS 2021) . 299\u2013318.\n[86] Srijan Kumar, William L Hamilton, Jure Leskovec, and Dan Jurafsky. 2018. Community interaction and conflict on\nthe web. In Proceedings of the 2018 world wide web conference . 933\u2013943.\n[87] K Hazel Kwon and Anatoliy Gruzd. 2017. Is offensive commenting contagious online? Examining public vs interper-\nsonal swearing in response to Donald Trump\u2019s YouTube campaign videos. Internet Research (2017).\n[88] Charlotte Lambert, Ananya Rajagopal, and Eshwar Chandrasekharan. 2022. Conversational Resilience: Quantify-\ning and Predicting Conversational Outcomes Following Adverse Events. In Proceedings of the International AAAI\nSub-Standards and Mal-Practices 27\nConference on Web and Social Media , Vol. 16. 548\u2013559.\n[89] Alex Leavitt. 2015. \" This is a Throwaway Account\" Temporary Technical Identities and Perceptions of Anonymity\nin a Massive Online Community. In Proceedings of the 18th ACM conference on computer supported cooperative work &\nsocial computing . 317\u2013327.\n[90] Stephan Lewandowsky, Ullrich KH Ecker, Colleen M Seifert, Norbert Schwarz, and John Cook. 2012. Misinformation\nand its correction: Continued influence and successful debiasing. Psychological science in the public interest 13, 3\n(2012), 106\u2013131.\n[91] Hanlin Li, Brent Hecht, and Stevie Chancellor. 2022. All that\u2019s happening behind the scenes: Putting the spotlight on\nvolunteer moderator labor in Reddit. In Proceedings of the International AAAI Conference on Web and Social Media ,\nVol. 16. 584\u2013595.\n[92] Lucas Lima, Julio CS Reis, Philipe Melo, Fabricio Murai, Leandro Araujo, Pantelis Vikatos, and Fabricio Benevenuto.\n2018. Inside the right-leaning echo chambers: Characterizing gab, an unmoderated social system. In 2018 IEEE/ACM\nInternational Conference on Advances in Social Networks Analysis and Mining (ASONAM) . IEEE, 515\u2013522.\n[93] Daniela Mahl, Jing Zeng, and Mike S Sch\u00e4fer. 2021. From \u201cNasa Lies\u201d to \u201cReptilian Eyes\u201d: Mapping Communication\nAbout 10 Conspiracy Theories, Their Communities, and Main Propagators on Twitter. Social Media+ Society 7, 2\n(2021), 20563051211017482.\n[94] Michalis Mamakos and Eli J Finkel. 2023. The social media discourse of engaged partisans is toxic even when politics\nare irrelevant. PNAS nexus 2, 10 (2023), pgad325.\n[95] Binny Mathew, Anurag Illendula, Punyajoy Saha, Soumya Sarkar, Pawan Goyal, and Animesh Mukherjee. 2020. Hate\nbegets hate: A temporal study of hate speech. Proceedings of the ACM on Human-Computer Interaction 4, CSCW2\n(2020), 1\u201324.\n[96] Durim Morina and Michael S Bernstein. 2022. A Web-Scale Analysis of the Community Origins of Image Memes.\nProceedings of the ACM on Human-Computer Interaction 6, CSCW1 (2022), 1\u201325.\n[97] Mohsen Mosleh, Rocky Cole, and David G Rand. 2024. Misinformation and harmful language are interconnected,\nrather than distinct, challenges. PNAS nexus 3, 3 (2024), pgae111.\n[98] Mohsen Mosleh and David G Rand. 2022. Measuring exposure to misinformation from political elites on Twitter.\nNature Communications 13, 1 (2022), 7144.\n[99] Chikashi Nobata, Joel Tetreault, Achint Thomas, Yashar Mehdad, and Yi Chang. 2016. Abusive language detection in\nonline user content. In Proceedings of the 25th international conference on world wide web . 145\u2013153.\n[100] Marius Paraschiv, Nikos Salamanos, Costas Iordanou, Nikolaos Laoutaris, and Michael Sirivianos. 2022. A Unified\nGraph-Based Approach to Disinformation Detection using Contextual and Semantic Relations. In Proceedings of the\nInternational AAAI Conference on Web and Social Media , Vol. 16. 747\u2013758.\n[101] Se Jung Park, Yon Soo Lim, and Han Woo Park. 2015. Comparing Twitter and YouTube networks in information\ndiffusion: The case of the \u201cOccupy Wall Street\u201d movement. Technological forecasting and social change 95 (2015),\n208\u2013217.\n[102] Tai-Quan Peng, Mengchen Liu, Yingcai Wu, and Shixia Liu. 2016. Follower-followee network, communication\nnetworks, and vote agreement of the US members of congress. Communication research 43, 7 (2016), 996\u20131024.\n[103] Nathaniel Persily. 2017. The 2016 US Election: Can democracy survive the internet? Journal of democracy 28, 2 (2017),\n63\u201376.\n[104] Martin Potthast, Sebastian K\u00f6psel, Benno Stein, and Matthias Hagen. 2016. Clickbait detection. In European conference\non information retrieval . Springer, 810\u2013817.\n[105] Alessandro Quattrociocchi, Gabriele Etta, Michele Avalle, Matteo Cinelli, and Walter Quattrociocchi. 2022. Reliability\nof news and toxicity in twitter conversations. In International Conference on Social Informatics . Springer, 245\u2013256.\n[106] Walter Quattrociocchi, Rosaria Conte, and Elena Lodi. 2011. Opinions manipulation: Media, power and gossip.\nAdvances in Complex Systems 14, 04 (2011), 567\u2013586.\n[107] Walter Quattrociocchi, Antonio Scala, and Cass R Sunstein. 2016. Echo chambers on Facebook. Available at SSRN\n2795110 (2016).\n[108] Stephen A Rains, Kate Kenski, Kevin Coe, and Jake Harwood. 2017. Incivility and political identity on the Inter-\nnet: Intergroup factors as predictors of incivility in discussions of news online. Journal of Computer-Mediated\nCommunication 22, 4 (2017), 163\u2013178.\n[109] Ashwin Rajadesingan, Ceren Budak, and Paul Resnick. 2021. Political discussion is abundant in non-political\nsubreddits (and less toxic). In Proceedings of the International AAAI Conference on Web and Social Media , Vol. 15.\n525\u2013536.\n[110] Ashwin Rajadesingan, Paul Resnick, and Ceren Budak. 2020. Quick, community-specific learning: How distinctive\ntoxicity norms are maintained in political subreddits. In Proceedings of the International AAAI Conference on Web and\nSocial Media , Vol. 14. 557\u2013568.\n28 Hans W. A. Hanley and Zakir Durumeric\n[111] Steve Rathje, Jay J Van Bavel, and Sander Van Der Linden. 2021. Out-group animosity drives engagement on social\nmedia. Proceedings of the National Academy of Sciences 118, 26 (2021), e2024292118.\n[112] Martin Ridout, John Hinde, and Clarice GB Dem\u00e9trio. 2001. A score test for testing a zero-inflated Poisson regression\nmodel against zero-inflated negative binomial alternatives. Biometrics 57, 1 (2001), 219\u2013223.\n[113] Ronald E Robertson, Shan Jiang, Kenneth Joseph, Lisa Friedland, David Lazer, and Christo Wilson. 2018. Auditing\npartisan audience bias within google search. Proceedings of the ACM on Human-Computer Interaction 2, CSCW (2018),\n1\u201322.\n[114] Daniel Romer and Kathleen Hall Jamieson. 2020. Conspiracy theories as barriers to controlling the spread of\nCOVID-19 in the US. Social science & medicine 263 (2020), 113356.\n[115] Dana Rotman, Jennifer Golbeck, and Jennifer Preece. 2009. The community is where the rapport is\u2013on sense\nand structure in the youtube community. In Proceedings of the fourth international conference on Communities and\ntechnologies . 41\u201350.\n[116] Martin Saveski, Doug Beeferman, David McClure, and Deb Roy. 2022. Engaging Politically Diverse Audiences on\nSocial Media. In Proceedings of the International AAAI Conference on Web and Social Media , Vol. 16. 873\u2013884.\n[117] Martin Saveski, Nabeel Gillani, Ann Yuan, Prashanth Vijayaraghavan, and Deb Roy. 2022. Perspective-taking to\nreduce affective polarization on social media. In Proceedings of the International AAAI Conference on Web and Social\nMedia , Vol. 16. 885\u2013895.\n[118] Martin Saveski, Brandon Roy, and Deb Roy. 2021. The structure of toxic conversations on Twitter. In Proceedings of\nthe Web Conference 2021 . 1086\u20131097.\n[119] Joseph Seering, Juan Pablo Flores, Saiph Savage, and Jessica Hammer. 2018. The social roles of bots: evaluating\nimpact of bots on discussions in online communities. Proceedings of the ACM on Human-Computer Interaction 2,\nCSCW (2018), 1\u201329.\n[120] Joseph Seering, Geoff Kaufman, and Stevie Chancellor. 2022. Metaphors in moderation. New Media & Society 24, 3\n(2022), 621\u2013640.\n[121] Vibhor Sehgal, Ankit Peshin, Sadia Afroz, and Hany Farid. 2021. Mutual hyperlinking among misinformation peddlers.\narXiv preprint arXiv:2104.11694 (2021).\n[122] Vinay Setty and Erlend Rekve. 2020. Truth be Told: Fake News Detection Using User Reactions on Reddit. In\nProceedings of the 29th ACM International Conference on Information & Knowledge Management . 3325\u20133328.\n[123] Karishma Sharma, Emilio Ferrara, and Yan Liu. 2022. Construction of Large-Scale Misinformation Labeled Datasets\nfrom Social Media Discourse using Label Refinement. In Proceedings of the ACM Web Conference 2022 . 3755\u20133764.\n[124] Karishma Sharma, Yizhou Zhang, and Yan Liu. 2022. COVID-19 Vaccine Misinformation Campaigns and Social\nMedia Narratives. In Proceedings of the International AAAI Conference on Web and Social Media , Vol. 16. 920\u2013931.\n[125] Cuihua Shen, Qiusi Sun, Taeyoung Kim, Grace Wolff, Rabindra Ratan, and Dmitri Williams. 2020. Viral vitriol:\nPredictors and contagion of online toxicity in World of Tanks. Computers in Human Behavior 108 (2020), 106343.\n[126] Todd Spangler. 2020. Reddit Finally Bans Hate Speech, Removes 2,000 Racist and Violent Forums Including\nThe_Donald. https://variety.com/2020/digital/news/reddit-bans-hate-speech-groups-removes-2000-subreddits-\ndonald-trump-1234692898/.\n[127] Todd Spangler. 2022. Reddit Bans Links to Russian State Media Across Entire Site. https://variety.com/2022/digital/\nnews/reddit-bans-links-to-russian-state-media-1235195612/.\n[128] Jennifer Stromer-Galley. 2003. Diversity of political conversation on the Internet: Users\u2019 perspectives. Journal of\nComputer-Mediated Communication 8, 3 (2003), JCMC836.\n[129] Cass R Sunstein. 2018. Is social media good or bad for democracy. SUR-Int\u2019l J. on Hum Rts. 27 (2018), 83.\n[130] Kurt Thomas, Devdatta Akhawe, Michael Bailey, Dan Boneh, Elie Bursztein, Sunny Consolvo, Nicola Dell, Zakir\nDurumeric, Patrick Gage Kelley, Deepak Kumar, et al .2021. Sok: Hate, harassment, and the changing landscape of\nonline abuse. In 2021 IEEE Symposium on Security and Privacy (SP) . IEEE, 247\u2013267.\n[131] Christopher Torres-Lugo, Kai-Cheng Yang, and Filippo Menczer. 2022. The Manufacture of Partisan Echo Chambers\nby Follow Train Abuse on Twitter. In Proceedings of the International AAAI Conference on Web and Social Media ,\nVol. 16. 1017\u20131028.\n[132] Amaury Trujillo and Stefano Cresci. 2022. Make reddit great again: assessing community effects of moderation\ninterventions on r/the_donald. Proceedings of the ACM on Human-computer Interaction 6, CSCW2 (2022), 1\u201328.\n[133] Milo Trujillo, Maur\u00edcio Gruppi, Cody Buntain, and Benjamin D Horne. 2020. What is bitchute? characterizing the. In\nProceedings of the 31st ACM conference on hypertext and social media . 139\u2013140.\n[134] Joshua A Tucker, Andrew Guess, Pablo Barber\u00e1, Cristian Vaccari, Alexandra Siegel, Sergey Sanovich, Denis Stukal,\nand Brendan Nyhan. 2018. Social media, political polarization, and political disinformation: A review of the scientific\nliterature. Political polarization, and political disinformation: a review of the scientific literature (March 19, 2018) (2018).\n[135] Joshua A Tucker, Yannis Theocharis, Margaret E Roberts, and Pablo Barber\u00e1. 2017. From liberation to turmoil: Social\nmedia and democracy. Journal of democracy 28, 4 (2017), 46\u201359.\nSub-Standards and Mal-Practices 29\n[136] Hilde Van den Bulck and Aaron Hyzen. 2020. Of lizards and ideological entrepreneurs: Alex Jones and Infowars\nin the relationship between populist nationalism and the post-global media ecology. International communication\ngazette 82, 1 (2020), 42\u201359.\n[137] Johannes van der Pol. 2019. Introduction to network modeling using exponential random graph models (ergm):\ntheory and an application using R-project. Computational Economics 54, 3 (2019), 845\u2013875.\n[138] Michela Del Vicario, Walter Quattrociocchi, Antonio Scala, and Fabiana Zollo. 2019. Polarization and fake news:\nEarly warning of potential misinformation targets. ACM Transactions on the Web (TWEB) 13, 2 (2019), 1\u201322.\n[139] Elliott Waissbluth, Hany Farid, Vibhor Sehgal, Ankit Peshin, and Sadia Afroz. 2022. Domain-Level Detection and\nDisruption of Disinformation. arXiv preprint arXiv:2205.03338 (2022).\n[140] Isaac Waller and Ashton Anderson. 2019. Generalists and specialists: Using community embeddings to quantify\nactivity diversity in online platforms. In The World Wide Web Conference . 1954\u20131964.\n[141] Isaac Waller and Ashton Anderson. 2021. Quantifying social organization and political polarization in online\nplatforms. Nature 600, 7888 (2021), 264\u2013268.\n[142] Yuping Wang, Savvas Zannettou, Jeremy Blackburn, Barry Bradlyn, Emiliano De Cristofaro, and Gianluca Stringhini.\n2021. A Multi-Platform Analysis of Political News Discussion and Sharing on Web Communities. In IEEE Conference\non Big Data .\n[143] Brian E Weeks. 2015. Emotions, partisanship, and misperceptions: How anger and anxiety moderate the effect of\npartisan bias on susceptibility to political misinformation. Journal of communication 65, 4 (2015), 699\u2013719.\n[144] Galen Weld, Amy X Zhang, and Tim Althoff. 2022. What Makes Online Communities \u2018Better\u2019? Measuring Values,\nConsensus, and Conflict across Thousands of Subreddits. In Proceedings of the International AAAI Conference on Web\nand Social Media , Vol. 16. 1121\u20131132.\n[145] Tom Wilson and Kate Starbird. 2020. Cross-platform disinformation campaigns: Lessons learned and next steps.\nHarvard Kennedy School Misinformation Review (2020).\n[146] Magdalena E Wojcieszak and Diana C Mutz. 2009. Online groups and political discourse: Do online discussion spaces\nfacilitate exposure to political disagreement? Journal of communication 59, 1 (2009), 40\u201356.\n[147] Ellery Wulczyn, Nithum Thain, and Lucas Dixon. 2017. Ex machina: Personal attacks seen at scale. In Proceedings of\nthe 26th international conference on world wide web . 1391\u20131399.\n[148] Yan Xia, Haiyi Zhu, Tun Lu, Peng Zhang, and Ning Gu. 2020. Exploring antecedents and consequences of toxicity in\nonline discussions: A case study on reddit. Proceedings of the ACM on Human-computer Interaction 4, CSCW2 (2020),\n1\u201323.\n[149] Savvas Zannettou, Tristan Caulfield, Emiliano De Cristofaro, Nicolas Kourtelris, Ilias Leontiadis, Michael Sirivianos,\nGianluca Stringhini, and Jeremy Blackburn. 2017. The web centipede: understanding how web communities influence\neach other through the lens of mainstream and alternative news sources. In Proceedings of the 2017 internet measurement\nconference . 405\u2013417.\n[150] Justine Zhang, Jonathan Chang, Cristian Danescu-Niculescu-Mizil, Lucas Dixon, Yiqing Hua, Dario Taraborelli, and\nNithum Thain. 2018. Conversations Gone Awry: Detecting Early Signs of Conversational Failure. In Proceedings of\nthe 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) . 1350\u20131361.\n[151] Justine Zhang, Sendhil Mullainathan, and Cristian Danescu-Niculescu-Mizil. 2020. Quantifying the causal effects of\nconversational tendencies. Proceedings of the ACM on Human-Computer Interaction 4, CSCW2 (2020), 1\u201324.\n[152] Jason Shuo Zhang, Brian Keegan, Qin Lv, and Chenhao Tan. 2021. Understanding the diverging user trajectories\nin highly-related online communities during the COVID-19 pandemic. In Proceedings of the International AAAI\nConference on Web and Social Media , Vol. 15. 888\u2013899.\nA EMBEDDINGS HYPERPARAMETER OPTIMIZATION\nVariable Values Considered\nEmbedding Size 100, 150, 200\nNumber of negative examples 30, 35, 40, 45\nDown-Sampling threshold; 0.0025 0.005, 0.0075, 0.01\nThe starting learning rate 0.15, 0.18, 0.21\nTable 7. We optimize our community and user embeddings.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Sub-Standards and Mal-Practices: Misinformation's Role in Insular, Polarized, and Toxic Interactions on Reddit", "author": ["HWA Hanley", "Z Durumeric"], "pub_year": "2023", "venue": "arXiv e-prints", "abstract": "Over the last decade, misinformation, incivility, and political polarization have corroded the  public\u2019s trust in democratic institutions [17, 25, 51, 52, 55]. Despite their shared roles in"}, "filled": false, "gsrank": 841, "pub_url": "https://www.hanshanley.com/files/Sub_Standards_and_Mal_Practices.pdf", "author_id": ["ewdWfOoAAAAJ", "TxPSRHIAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:7ME1eQP2b4AJ:scholar.google.com/&output=cite&scirp=840&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D840%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=7ME1eQP2b4AJ&ei=n7WsaPbEK8DZieoPqdqh8QU&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:7ME1eQP2b4AJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://www.hanshanley.com/files/Sub_Standards_and_Mal_Practices.pdf"}}, {"title": "A Multidimensional Analysis of Text for Automated Detection of Computational Propaganda in Twitter Technical Report: CCC-22-003", "year": "2022", "pdf_data": "A Multidimensional Analysis of Text for\nAutomated Detection of Computational\nPropaganda in Twitter\nTechnical Report: CCC-22-003\nby\nMarco Emanuel Casavantes Moreno\nDoctoral Advisors:\nDr. Manuel Montes-Y-G\u00b4 omez,\nINAOE, Mexico\nDr. Luis Carlos Gonz\u00b4 alez Gurrola,\nUniversidad Aut\u00b4 onoma de Chihuahua, Mexico\nDr. Alberto Barr\u00b4 on Cede\u02dc no,\nAlma Mater Studiorum\u2013Universit` a di Bologna, Italy\nInstituto Nacional de Astrof\u00b4 \u0131sica, \u00b4Optica y Electr\u00b4 onica\n\u00a9Coordinaci\u00b4 on de Ciencias Computacionales\nApril, 2022\nSanta Mar\u00b4 \u0131a de Tonantzintla, Puebla, CP 72840, Mexico.\nContents\n1 Introduction 5\n1.1 Propaganda and its evolution . . . . . . . . . . . . . . . . . . . . . . 5\n1.2 Challenges and research motivation . . . . . . . . . . . . . . . . . . . 6\n2 Related work 9\n2.1 Propaganda Detection at Document Level . . . . . . . . . . . . . . . 9\n2.2 Detection of Propaganda Techniques . . . . . . . . . . . . . . . . . . 10\n2.3 Successful approaches at research workshops . . . . . . . . . . . . . . 12\n2.4 Propaganda detection in social media . . . . . . . . . . . . . . . . . . 14\n2.5 Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18\n3 Research Proposal 21\n3.1 Problem Statement . . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\n3.2 Research Questions . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\n3.3 Hypothesis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22\n3.4 Objectives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23\n3.5 Expected Contributions . . . . . . . . . . . . . . . . . . . . . . . . . 23\n3.6 Methodology . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24\n3.7 Work Plan . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 27\n3.8 Publications Plan . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28\n4 Preliminary Work 29\n4.1 Obtaining datasets related to computational propaganda. . . . . . . . 29\n4.2 Creation of a new dataset . . . . . . . . . . . . . . . . . . . . . . . . 31\n4.3 Cross Domain Text Classification . . . . . . . . . . . . . . . . . . . . 34\n5 Preliminary conclusions 36\n6 Background concepts 37\n6.1 Text Classification . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37\n6.2 Evaluation measures . . . . . . . . . . . . . . . . . . . . . . . . . . . 46\n6.3 Network-based features from Tweet objects . . . . . . . . . . . . . . . 47\n2\nReferences 48\n3\nAbstract\nTechnology has changed the way in which people communicate with each\nother, giving rise to new services such as social networks. Unfortunately, these\nservices can be used to distribute malicious or manipulative content like fake\nnews and propaganda. This raises several concerns about how easy can be\nto influence a population and spread disinformation. Current strategies to\ndetect computational propaganda are focused on analyzing their presence in\nnews articles, and haven\u2019t reached quite thoroughly other sources of informa-\ntion, such as Twitter.\nIn this work we are going to focus on the detection of propaganda on Twitter,\nwhich has the following challenges: scarcity of labeled data, very short texts,\nhigh thematic diversity, among others, although it also presents the opportu-\nnity to consider information of context, and relying on previously generated\ndata from news articles. We propose: 1) the construction of a new propa-\nganda corpus from Twitter, 2) a multidimensional analysis with contextual-\nawareness in the form of bias, geographical origins and metadata; and internal\ndimensions such as writing style, emotions and topics. As preliminary work,\nwe retrieved more than 20k tweets from propagandist and non-propagandist\nnews sources using distant supervision, we recreated baselines on pre-existing\ncollections of propagandist articles and evaluated the usefulness of news arti-\ncles to tweets in a cross-domain experimental setting. These results support\nthe idea of developing a classification method specifically tailored for the social\nmedia domain.\n4\n1 Introduction\nThis technical report is a document that presents a PhD dissertation proposal titled\n\u201dA Multidimensional Analysis of Text for Automated Detection of Computational\nPropaganda in Twitter\u201d, which was approved on April 7th, 2022.\n1.1 Propaganda and its evolution\nAs stated by [1], in 1939 a group of scholars defined propaganda as \u201can expression\nof opinion or action by individuals or groups, deliberately designed to influence\nopinions or actions of other individuals or groups with reference to predetermined\nends\u201d. Computational propaganda is then defined in [2] as \u201cpropaganda created or\ndisseminated using computational (technical) means\u201d.\nThere are two types of computational propaganda: automated and non-automated.\nThe identification of automated accounts (also popularly referred to as bots), used\nto distribute and deceive users on social networks, is temporarily located at the\nbeginning of the year 2010 [3]. However, it was not until the presidential elections of\nthe United States of America in 2016 that their influence and participation during the\ncampaigns drew attention to its effectiveness. Posts created by bots were retweeted\nat the same rate as posts from humans. It was even shown that legitimate users\ncould not determine what information had been generated by a human or by a\nbot. Therefore, in this work we refer to non-automated propaganda as manipulative\nmessages created by genuine sources and accounts, such as particulars, groups or\nnews agencies.\n1.1.1 Types of information disorder\nAccording to [4], there are two main kinds of information disorder based on\nthe purpose behind it: on one hand we have misinformation, which includes\n5\nunintentional falseness such as inaccurate dates, statistics or translations; and on\nthe other hand there\u2019s malinformation, deliberately created with an intent to harm,\nsuch as changing context, dates or content. A middle ground between these two\nexist in the form of disinformation (see Figure 1), intentionally false content created\nwith the purpose of causing harm. It is driven by three main interests: mak-\ning money, gaining political power, or causing disturbance for no reason in particular.\nFigure 1: Types of information disorder, borrowed from [4].\nWe consider important to clarify that propaganda envelops disinformation and\nmalinformation, but since not all propaganda content is generated with bad inten-\ntions, some other disorders fit inside the definition of it as a whole, such as Hoaxes\n(pranking with false stories) or Opinion Spamming (biased reviews towards products\nor services) [5].\n1.2 Challenges and research motivation\nThe impact that social networks, some of them less than two decades old, has had\nis considered incredible in terms of the size, scope and speed of growth they achieve\nevery minute, becoming a phenomenon that appears everywhere in our current daily\nlives [6]. Unfortunately, research indicates that such social networks can also be used\nto distribute malicious, false or manipulative content [5]. Inside a categorization of\n6\nthis content lies propaganda, which is often associated to news articles and political\ncampaigns promoted in traditional media such as newspapers or websites publishing\nnews as their primary content. However, some research has suggested that, as time\nchanged the resources that people consult and read, social media has also shifted\nfrom its traditional use for entertainment to also being an online news provider\n[7], where the posts are noticeable shorter in length, noisier but easier to digest and\nanyone can spread a message to thousands of users in a matter of seconds. This raises\nseveral concerns about how easy can be to influence a population, and even worse,\ndoing so with the intent to harm. Take for instance the volume of information that\nwas divulged in the 2016 US Presidential campaign aimed to smear the reputation of\nspecific candidates, or the safety and health measures that weren\u2019t handed properly\nat the peak of the COVID-19 global infodemic due to the quantity of disinformation\ndisguised as reliable news [8]. Surprisingly, propaganda detection as a computational\ntask has not been explored as thoroughly as other categories of false information,\nsuch as Fake News or Hoaxes [9]. Therefore, there are many aspects of it that remain\nexcluded or isolated in the construction of better detection methods, such as bias\nlevels, geographical origins, metadata, writing style, among others. Each one of\nthese contextual variables represents a different dimension or perspective linked to\nthe propaganda issue. Today\u2019s world is in need of automatic tools built to help the\nstruggle that we are living as a consequence of propagandist content created with\nmal-intent. The aim of this research proposal is to explore propaganda in a social\nnetwork, compare it to traditional propaganda and tailor strategies to match the\nshapes and sizes that this content is taking on a social news platform. This study\nwill examine content created in Twitter \u00aeby media sources labeled as trustworthy\nor questionable by their promotion of propaganda.\nThe remainder of this dissertation proposal is organized as follows. Section 2\nintroduces a brief discussion about the related work on propaganda detection. Sec-\ntion 3 presents the research proposal that includes the problem statement, research\n7\nquestions, hypothesis, objectives, expected contributions and methodology, along\nwith the work and publication plans. Section 4 contains the preliminary work to\nsupport this proposal. Section 5 present the conclusions and Section 6 describes\nbackground concepts.\n8\n2 Related work\n2.1 Propaganda Detection at Document Level\nEven tough propaganda has been around since a very long time, it wasn\u2019t until 2017\nwhen, in a paper about fake news and political fact-checking [10], propaganda was\nincluded in the TSHP-17 dataset to analyze patterns from news articles.\n2.1.1 TSHP-17 dataset\nTo create this corpus, the authors of [10] picked typical trusted news items from\nthe English Gigaword corpus1(a large collection of newswire text data in English\namassed by the Linguistic Data Consortium over the course of several years), and\ncrawled articles from seven distinct unreliable news sites of various categories (Satire,\nHoax and Propaganda). In their study, they investigated linguistic trends across dif-\nferent types of articles, and performed an analytic study characterizing the language\nof political quotes and news media written with varying intents and degrees of truth.\nTable 1 shows the quantity of articles in this dataset.\nTable 1: News articles in TSHP-17, adapted from [10]\nNews Type Source # of Docs.\nTrusted Gigaword News 13,995\nPropaganda The Natural News 15,580\nActivist Report 17,869\n1https://catalog.ldc.upenn.edu/LDC2003T05\n9\n2.1.2 QProp dataset\nIn 2019, motivated by the difficulties of carrying over further research using the\nTSHP-17 Corpus due to the small number of propagandist sources and lack of infor-\nmation from individual articles, [11] compiled an improved corpus. This time they\nconsidered 94 and 10 sources of non-propaganda and propaganda respectively. Table\n2 displays the distribution of their collection. The criteria for labeling news outlets\ncomes from the website MediaBias/FactCheck2, an online resource that categorizes\nmedia according to the bias they exhibit. Their hypothesis was, that classifiers\ntrained with the TSHP-17 Corpus learned to identify the news source because there\nwere only a few of them in the collection. By increasing the size of their corpus se-\nlecting more propagandist news sources, future systems trained with this data could\nlearn to distinguish propaganda from texts without such content instead of learning\nthe writing and publishing style of the news outlets. In the paper, a binary class\nclassification was conducted, starting to shape propaganda detection as a standalone\ntask and distancing it further from the fake news scope.\nTable 2: News articles in QProp, adapted from [11]\nNews Type Sources # of Docs.\nTrustworthy 94 45,557\nPropagandistic 10 5,737\n2.2 Detection of Propaganda Techniques\n2.2.1 PTC Dataset\nIn 2019, [12] proposed a new dataset with more features that previous collections:\nto begin with, it was manually annotated instead of using the news source as labels\n2https://mediabiasfactcheck.com/\n10\n(distant supervision), then it was annotated at the span level, meaning that specific\nsnippets of texts were flagged as opposed to full documents. Their last contribution\nwas changing the binary classification scheme for a multi-class classification task,\nconsidering 18 propaganda techniques. Although there are some techniques that\nappear only a few times in the collection (e.g. a technique called \u201cstraw man\u201d with\n15 instances from a total of 7,485) and therefore may seem unsubstantial, we consider\nit worth mentioning that the two most popular techniques (appearing 3,841 times\ncombined, more than half the instances in the whole collection) share an association\nwith sentiments and emotions:\n\u2022Loaded language.- To affect an audience by using words and phrases with\nintense emotional connotations (either positive or negative).\n\u2022Name calling, labeling.- Using something the target audience either hates or\nloves to label the object of the propaganda campaign.\nAs an interesting fact, the authors of [12] now labeled the \u201ctrustworthy\u201d class as\n\u201cnon-propagandistic\u201d, perhaps as a result of the difference in task purpose between\nfake news and propaganda detection. Table 3 shows the distribution of the PTC\nCorpus.\nTable 3: News articles in PTC, adapted from [12]\nNews Type Sources # of Docs. Prop. Techniques Instances\nNon-propagandistic 36 79 N/A N/A\nPropagandistic 13 372 18 7,485\n2.2.2 SemEval-2021 Task 6\nPushing for a new modality in detection of persuasion techniques in images and texts,\nthe organizers of [13] used the list of 22 techniques based on previous propaganda\n11\nresearch (20 of them applicable to text and 2 to images) to label a collection of english\nmemes from Facebook. The Facebook groups discussed themes such as politics,\nvaccines and gender equality, resulting in 26 groups crawled over a period of various\nmonths in 2020. The annotation step was executed in two phases: 1) independent\nannotation of memes by annotators, and 2) final gold labels by all annotators and\na consolidator. Their final corpus consists of 950 memes, each meme containing at\nleast one persuasion technique.\n2.3 Successful approaches at research workshops\nResearch on computational propaganda has fueled interest in developing solutions to\nthis problem, and some NLP task-oriented workshops have included this area within\ntheir activities.\nFor example, in 2019 the second workshop on NLP for Internet Freedom\n(NLP4IF) presented two subtasks involving propaganda detection, one for identi-\nfication of propagandist texts at fragment-level and a binary classification task at\nsentence-level [14]. In the Sentence-Level Classification, 9 out of 10 teams reported\nthe use of BERT [15] in some form to predict labels, either independently or as part\nof an ensemble. Other teams from the top scores (shown in Table 4) found useful to\nconsider lexical features, sentiments and tackling the class imbalance of the set to\nachieve their final results.\n12\nTable 4: Top Official Results for NLP4IF SLC Task - Test Set.\nRank Classifier F1 System Description\n1 BERT 0.6323Attention Transformer trained on\nWikipedia and BookCorpus.\n2 BERT 0.6249Over-sampled training data and per-\nformed cost-sensitive classification.\n3 BERT 0.6249 Ensemble of models.\n4BERT + LR\n+ CNN0.6230V oting ensemble with features from Fast-\nText embeddings, readability, emotions\nand sentiments.\n5 N/A 0.6183 Not reported at [14]\n6BERT +\nUSE0.6138Ensemble of two BERTs and Universal\nSentence Encoder.\n7BERT +\nbi-LSTM +\nXGBoost0.6112Ensemble with features from GloVe em-\nbeddings, affective and lexical represen-\ntations.\nRecent interest in fake news tasks boosted appeal of the detection of propa-\nganda as an active research area. One of SemEval-2020 tasks focused on detection\nof propaganda techniques in news articles [16], concentrating on fine-grained anal-\nysis of texts that could complement existing strategies. Practically all approaches\nsubmitted for this task relied on systems based on Transformers. The team with\nthe best score for Span Identification trained several of these architectures and com-\nbined them in the end as an ensemble. This result, along with the rest of participants\namong the top five teams, is displayed in Table 5.\n13\nTable 5: Top Results for SemEval-2020 Task 11 Span Identification - Test Set.\nRank Classifier F1 System Description\n1Ensemble\nof 6+ archi-\ntectures51.74Complex heterogeneous multi-layer neural net-\nwork with BIO encoding, Part-of-Speech and\nNamed Entity embeddings.\n2 RoBERTa 49.88Ensemble of models with oversampling by pro-\nducing silver data.\n3 RoBERTa 49.59Ensemble with attached CRF for sequence la-\nbeling.\n4BERT +\nBiLSTM48.16Model with extra features (PoS, NE, sentiment)\nand fine-tuned on 10k additional propaganda ar-\nticles.\n5 BERT 46.63Used masked language modeling to domain-\nadapt their base model with 9M articles (fake,\nsuspicious, hyperpartisan news).\n2.4 Propaganda detection in social media\nAuthors of [17] explored propaganda from different sources. Their paper hypothe-\nsizes that propagandistic sources are sophisticated and creative, and that they will\nfind new ways to deceive by evading trained classifiers. The novelty of their approach\nlies in cross-domain learning, recognizing the scarcity of labeled data where domains\nrepresent different types of sources, such as news articles, social media posts, and\npublic speeches. The data collections used for their experiments fall into precisely\nthese three types of sources. Table 6 shows their distribution of corpora.\n1. First, as political speeches, the authors make the contribution of creating a col-\nlection of speech transcripts from four politicians, arranged in ordered pairs.\n14\nTrump and Obama as contemporary speakers. Trump was seen as more pro-\npagandist than Obama. They also use Joseph Gobbels (Nazi Propaganda\nMinister) and Winston Churchill (UK Prime Minister) as important figures\naround the time of World War II, Gobbels being more propagandistic than\nChurchill. All four of these politicians have given propaganda speeches, and\ntheir supposition is that two of the speakers exhibit less propaganda than the\nother two.\n2. Second, with news as a source, they combined and reorganized the datasets\nused in \u201cHack the News\u201d3, to build an article-level corpus and a sentence-level\ncorpus.\n3. And third, with tweets as a source, they combine two collections, Twitter\nRussian Internet Research Agency (IRA) from 2016 and considered propagan-\ndistic, and twitter7, originally a 2009 collection of almost 476 million tweets\nfrom which they took a sample of the same size as Twitter IRA, and that were\nused as the non-propagandist class.\n3https://www.datasciencesociety.net/hack-news-datathon/\n15\nTable 6: Distribution of corpora from [17]\nSource Size (Articles) Size (Sentences)\nSpeechesTrump: 100 Trump: 7,985\nObama: 100 Obama: 8,336\nGoebbels: 44 Goebbels: 4,482\nChurchill: 44 Churchill: 4,131\nTOTAL: 288 TOTAL: 24,934\nNewsPropagandistic: 3,899 Propagandistic: 3,938\nNormal: 3,899 Normal: 3,938\nTOTAL: 7,798 TOTAL: 7,876\nTweets N/ATwitter IRA: 8,963\nTwitter7: 8,963\nTOTAL: 17,926\nThe four propaganda detection methods that they used were divided in two\ntypes:\n\u2022Attribute-based models: Logistic Regression and Support Vector Machines.\nThe features considered were word count, weighted n-grams with TF-IDF,\nand LIWC word categories.\n\u2022Models based on neural networks, an LSTM baseline and a modification to\nthis baseline, which is a contribution of this work that they call the LSTM or\nLSTMR Pairwise Classification Model (seeing that subjective and noisy train-\ning labels could lead to over-fitting in traditional supervised learning models,\ndecreasing cross-domain generalization, they designed a model that relaxes the\nconstraints of strict labeling on rankings).\nAs part of their analysis, they concluded that the best cross-domain results are\nobtained when training with news and applying those models to speeches or tweets,\n16\nthe performance in articles is better than that of sentences, and the cross-domain\nclassification excluding names leads to poorer performance. Their findings also sug-\ngest that exaggerations (e.g. \u201cabsolutely\u201d) and negative emotions (e.g. \u201clies\u201d or\n\u201cdevastating\u201d) play a key role in audience manipulation. Regarding the character-\nistics of LIWC, words that express negative emotions are typical of propaganda.\nThe authors of [18] conducted a thorough investigation of propaganda on Red-\ndit. They looked at six political forums in the United States and the United King-\ndom, created a dataset (Table 7) and discovered some intriguing patterns:\n\u2022Minority parties are more likely to spread propaganda.\n\u2022Political leaning might be a sign of propaganda.\n\u2022Propaganda techniques in the US are used differently than in the UK.\n\u2022Instead of learning topical confounds, their classifier learns the propagandist\nlanguage pattern.\n\u2022Submissions and comments with more propaganda material gain higher en-\ngagement, as measured by the number of comments, upvotes, and downvotes.\nTheir results for propaganda identification are shown in table 8.\nTable 7: Reddit dataset distribution, adapted from [18]\nSubreddit Submissions Comments\nPolitics 317K 20M\nDemocrats 9.8K 54K\nRepublican 8.2K 41K\nUKPolitics 42K 1.8M\nLabourUK 7K 58K\nTories 1.1K 12K\n17\nTable 8: Reddit propaganda identification results, adapted from [18]\nClassifier Precision Recall F1\nRandom 24.14 25.65 28.87\nBERT 58.52 52.02 55.08\nROBERTA 63.96 41.41 50.28\nXLNet 53.27 59.29 56.12\nEnsemble 62.72 48.57 54.74\nMGN ReLU 60.41 61.58 60.98\n2.5 Discussion\nWe can see that, when it comes to news articles, there are detection tasks aimed\nat document level and sentence level. The techniques used to detect propaganda\non them mostly involve some kind of transformer-based classifier, either stand-alone\nor in an ensemble in addition to deep learning models. There exists a study of\npropaganda on Twitter but using pre-existing collections with labeling schemes based\non assumptions, and a Reddit study focused on political forums from the USA and\nthe UK. However, by reading the shortcomings of the related work, we identified\nsome research opportunities:\n2.5.1 Scarcity of data and difference of format\nThe first inclusion of propaganda in the TSHP-17 dataset shows an area of improve-\nment in terms of considered number of propagandist sources, but also inconsistencies\nin number of documents. For example, although their creators claim to have over\n74k articles, their publicly distributed files only account for approx. 39k articles.\n[11] elaborates on this matter, taking into account more propagandist sources but\nalso describing a more realistic number of documents. Yet, the number of resources\n18\naimed specifically towards propaganda detection on social media is still consider-\nably low, not to mention the fact that texts from Twitter are by their nature noisy,\nthey are brief, contain platform-specific features, and are riddled with typos and\ngrammatical errors [19].\n2.5.2 Distant Supervision\nAs noted in a study of related matters about political ideologies [20], a carefully\nannotated corpus by experts may end up being relatively small, so the authors\nsuggest that future work may explore semi-supervised models or active learning\ntechniques for annotating and preparing larger corpora. Every classifier needs quality\ndata to make good predictions. Similarly to machine learning systems, annotation\nparadigms can be organized in supervised, unsupervised, and alternative approaches.\nAs part of the latter, the distant supervision scheme, initially conceived for relation\nextraction purposes. [21], relies on an external database to provide the labeled\nsources of information to subsequently create instances from them for training data.\nThe labels produced by manual-annotation efforts by experts are considered of higher\nquality in comparison to distant supervision, however, this paradigm doesn\u2019t suffer\nfrom some of the disadvantages of hand-labeled supervised approaches, such as being\nexpensive, time consuming and limited in quantity.\n2.5.3 Contextual Information\nThere are different perspectives in the form of contextual information that can be\n1)further analyzed to unravel social patterns, and 2)explored and transformed to\nbuild a more complete solution to detect propaganda:\n\u2022Bias levels and geographic origins: Aside from \u201cnon-propagandist\u201d or \u201cpro-\npagandist\u201d labels, more dimensions can be associated to news sources, such\n19\nas their bias levels (from \u201cExtreme-Left\u201d to \u201cExtreme-Right\u201d ideologies) and\ntheir country as the place where the news feed is established.\n\u2022Topics: As demonstrated in [20, 18], a dependency between propaganda and\ntopics can be studied, this time focusing on dynamics that might be different\nin other forms of communication such as social media posts.\n\u2022Emotions: Some of the most used propaganda techniques are associated with\nemotions, this suggests that they play an important role in manifestation of\npropaganda [22, 17].\n\u2022Social Media Attributes: In 2020, a survey on computational propaganda de-\ntection [8] offered a study focused on tackling this problem from two different\nperspectives: the content of the propaganda messages and their propagation\nin social networks. They noted that while there\u2019s research within each one\nof these aspects, they are isolated from each other and therefore not working\ntogether. The authors conclude that, in the near future, it will be necessary\nnot only to take into account propagandist texts but also to analyze the net-\nwork through which propaganda is disseminated. Most studies perform data\ncollection and subsequent analysis of annotated datasets containing portions of\ntext. However, social media platforms allow their interactions to contain more\ninformation aside from the text written in messages. This additional info is\ncalled Metadata, it is defined as data that provides information about other\ndata [23].\n20\n3 Research Proposal\n3.1 Problem Statement\nPropaganda can be spread from many different sources, social networks being one\nof them. The volume of text-based exchanges in social media have made human\neditorial approaches unfeasible, and recent decisions and rulings by regulatory au-\nthorities explicitly mention automatic systems as tools to help mitigate the spread\nof mischievous content [24], proving their high social relevance.\nShared tasks events are being held online to tackle this challenge and a fair amount\nof research is published to test new algorithms and approaches. The problem is\nthat most of this research is focused on propaganda extracted exclusively from news\narticles. To the best of our knowledge, the closest connection to propaganda and\nsocial media that we could find comes from [17] as research that combines two pre-\nexisting collections of tweets. Nonetheless, because of the lack of resources and\nlimitations of previous work, the authors of [17] acknowledge the room for improve-\nment and necessity of further research on this subject. To better solve the detection\nof computational propaganda issue, exploration is needed outside the news articles\nscope. Since every day the influence of social networks grows as they become the\nmain means of disseminating information, including malicious news and data, the\ngoal of this work is to conduct a multidimensional analysis of computational propa-\nganda, starting from cross-domain strategies to find out if resources from the news\narticles domain can help to develop a classification system that allows detection of\npropaganda from social media. Then, our second challenge is to see if propaganda\ndetection can be improved by considering multiple types of context information (such\nas bias levels, country of origin, emotions used, topic extraction) and modeling that\ninformation from multiple dimensions or perspectives.\n21\n3.2 Research Questions\nThe information given in the previous section motivated the proposal of the next\nresearch questions:\n\u2022How can the resources that exist in the domain of news articles be used to\ndetect computational propaganda in social networks?\n\u2022How can contextual information of messages be incorporated to improve the\neffectiveness of propaganda detection in them?\n\u2022How can different ways of modeling the content of messages be considered to\nimprove the effectiveness of propaganda detection in them?\n\u2022Should computational propaganda detection be carried out by creating mul-\ntiple classifiers specialized by thematic content instead of a single-classifier\nsolution?\n3.3 Hypothesis\nComputational propaganda detection is a complex task. Automatic detection sys-\ntems are needed to perform in different fields where disinformation is being shared.\nOur working hypothesis is that resources from the news articles domain can be\nadapted to detect non-automated computational propaganda in social media posts,\nand that the combination of content-based and context-based features can be helpful\nto further improve its detection.\n22\n3.4 Objectives\n3.4.1 General objective\nTo propose a multidimensional model for the analysis of computational propaganda\nin tweets, taking advantage of resources on news articles, and considering different\nviews of their content and context, allowing to significantly improve the efficacy of\ncurrent approaches.\n3.4.2 Specific objectives\n\u2022To construct a propaganda corpus from social media, retrieving trustworthy\nand propagandist news sources\u2019 tweets.\n\u2022To determine the relationship between computational propaganda from news\narticles and from tweets, proposing a cross-domain strategy to make the most\nof existing information.\n\u2022To propose a propaganda detection model that considers multiple contextual\nvariables such as bias levels, country of origin and metadata.\n\u2022To propose a propaganda detection model based on multiple representations\nof the messages\u2019 information such as their content, writing style and emotions.\n\u2022To assess the performance of multiple classifiers based on topics against single-\nclassifier solutions to detect computational propaganda.\n3.5 Expected Contributions\n\u2022The creation of a new corpus of propaganda from Twitter.\n\u2022A comprehensive cross-domain analysis of the importance of propaganda arti-\ncles for the detection of propagandist tweets.\n23\n\u2022An approach that incorporates multiple contextual variables for detection of\ncomputational propaganda.\n\u2022An approach that incorporates multiple representations of messages based on\ntheir content for detection of computational propaganda.\n\u2022A thematic strategy to adjust the classification method according to the topics\nincluded in the texts.\n3.6 Methodology\nHaving established the research questions and the objectives of this work, what\nfollows is to order the necessary steps to fulfill each one of them. This section\npresents in detail the methodology to reach the proposed objectives. The proposed\nmethodology consists of six stages, where stages 2, 3, 4, 5 and 6 have the major\ncontributions of this dissertation proposal.\nStage 1: Comprehensive study of the state-of-the-art and available resources.\n\u2022Obtain previous computational propaganda corpora. As criteria to consider a\ndataset effective for our study, each collection must be related to propaganda in\nthe form of text posts from propagandist and non-propagandist computational\nsources.\n\u2022Implement state-of-the-art strategies to detect propagandist texts using the\naforementioned datasets and set baselines. There are many approaches re-\ngarding features to consider and classifiers to use, and experiments putting\nin practice these strategies based on previous studies will determine how to\nproceed in our research.\n24\nStage 2: Creation of a new dataset.\nThis stage involves the creation of a new corpus of computational propaganda content\nwith Twitter as the source of data. The proposed steps are the following:\n\u2022Identify sources of propaganda and trustworthy content, labeled as such by\nMediaBias/FactCheck.\n\u2022Create a list comprised of the propagandist and non-propagandist sources that\nalso manage a Twitter account and get their corresponding handle.\n\u2022Download the available tweets of the list of sources from two time periods:\npast (covering a 2017-2018 time frame, same as QProp dataset) and recent\n(covering 2020-2021).\n\u2022Clean the dataset, filtering noisy tweets that do not meet certain criteria such\nas minimum length and maximum number of hashtags.\nStage 3: Determine the relationship between computational propaganda from news\narticles and from tweets.\nThe purpose of this stage is to use the resources that have already been created for\nthe propaganda detection task in news articles. A performance test, training with\nthese data collections, is proposed to determine if they can be adapted to a detection\ntask for the Twitter posts domain. The suggested activities are:\n\u2022Analyze the performance of a propaganda classifier trained with articles and\ntested on Twitter posts to evaluate the relevance of propaganda articles for\nthe detection of propagandist tweets.\n\u2022Propose a cross-domain strategy to adapt the classifier from the news to the\ntweets domain.\n25\nStage 4: Develop a propaganda detection model incorporating multiple contextual\ninformation variables.\nThis stage involves the development of a model architecture to detect computational\npropaganda adding contextual variables. The following steps are proposed:\n\u2022Extract the level of bias from each data source, cluster the sources by geo-\ngraphic origin, and extract platform specific features such as number of fa-\nvorites, retweets, hashtags and mentions.\n\u2022Use the extracted contextual information as new features.\n\u2022Use the contextual variables as new dimensions to perform classification on\nparallel tasks (multi-task learning)\nStage 5: Develop a propaganda detection model extracting information in different\nrepresentations from the content of the messages.\nThe following steps are proposed:\n\u2022Topic modelling on the short texts to determine their thematic context, analyze\nthe writing style of the news accounts, and perform emotional analysis based\non keywords to extract the main emotion associated to each tweet.\n\u2022Analyze their results, differences and complementarity.\n\u2022Combine the previous representations in a single model.\nStage 6: Assess solutions based on topic specialization.\nThe high diversity of topics covered by news outlets in a data collection present an\nopportunity. An ensemble of classifiers, each one specialized in a single topic, might\n26\nbe better suited for propaganda detection than a single-classifier solution. In this\nstage, the following steps are considered:\n\u2022Propose a \u201cfederated\u201d model for propaganda detection, that considers the\ncombination of several classifiers specialized in particular topics.\n\u2022Evaluate and compare the performance of the federated approach against the\ntraditional approach that considers a single classifier.\n\u2022Propose a method to adjust the classifier to thematic changes.\n3.7 Work Plan\nThe overall schedule for the time period of 2021-2024 is presented in Figure 2, cov-\nering the most relevant activities planned for this research.\nFigure 2: Work plan of activities divided in two-month periods.\n27\n3.8 Publications Plan\nTable 9 shows a tentative plan of publications.\nTable 9: PhD publishing plan.\nType of article Target Publication date Content\nFor conference EMNLP Late 2022Analysis of differences between propaganda\nfrom articles and from tweets.\nFor journal LRE Mid 2023Description of detection method incorporat-\ning context information on new corpus.\nFor journal IP&M Early 2024Description of detection method incorporat-\ning multiple representations of content on\nnew corpus.\n28\n4 Preliminary Work\nThis section presents the preliminary work that has been done to support the feasi-\nbility of this research proposal, summarized in the following steps:\n1. Identifying and obtaining datasets related to computational propaganda and\ntest current classification strategies (part of the first stage in the methodology).\n2. Creating a new dataset of tweets, labeled as propagandist or non-propagandist\n(part of stage 2 in the methodology).\n3. Classifying tweets under a cross-domain setting. A first exploration in using\nnews articles as the auxiliary domain to train classifiers and test them to detect\npropaganda on tweets as target domain (part of stage 3 in the methodology).\n4.1 Obtaining datasets related to computational propaganda.\nOur first step on the propaganda detection task is to evaluate current classification\nstrategies. For this purpose, the datasets of news articles from [10, 11, 12] were\nobtained. These collections are available either by accessing their public repositories\nor by registering as participants of previous shared tasks for research purposes. Table\n10 shows a summary of their sizes.\nTable 10: Datasets obtained for Computational Propaganda detection.\nCorpus Level Documents\nTSHP-17 [10] document 22,580\nQProp [11] document 51,294\nPTC [12] text span 451\nThe QProp Corpus was selected as the starting point of our experiments since,\namong the datasets mentioned previously, it shares the most similarities with the\n29\nkind of data that we want to work with, such as being built using distant supervision,\ndividing its content into two classes and considering a fair amount of propagandist\nsources.\n4.1.1 Classification of propaganda: experimental Settings\nWe ran baseline systems with QProp to experiment with different classification mod-\nels from the main \u201cbranches\u201d used on model generalization [25]: traditional baseline,\ndeep learning and transformer-based.\nLogistic Regression: classifier with a lbfgs solver and C= 1. In this experiment,\nwe work with the length of each sentence as the only feature to train, recreating the\nsame baseline from [11].\nConvolutional Neural Network (CNN): architecture that mimics the brain\u2019s visual\ncortex in the field of image recognition, but have also proved to be successful in\nother tasks, such as natural language processing [26]. As hyperparameters we used\nkernel sizes of [1, 2, 3] and word embeddings of 300 dimensions using the slimmer\nversion of the word2vec pre-trained Google News model4.\nRecurrent Neural Network (RNN): a class of networks specialized to work on se-\nquences as inputs, producing an output and then sending it back to itself as a form\nof memory from previous time steps [26]. The word embeddings utilized are the\nsame as described before for CNN.\nBERT classifier: deep bidirectional transformer. We utilized the BERT Base model\nas feature extractor and classifier, since we are aware it is being used in most NLP\ntasks achieving state-of-the-art results.\nClassifiers and embedding models were implemented from the scikit-learn [38],\n[27], TensorFlow ,Simple Transformers [28] and Gensim python libraries [29].\n4https://github.com/eyaler/word2vec-slim\n30\nTable 11: Baselines for Dev set in QProp.\nClassifier F1-score\nQProp\u2019s MaxEnt [11] 82.93\nLogistic Regression 86.88\nCNN 90.00\nRNN 68.44\nBERT 83.80Table 12: Baselines for Test set in QProp.\nClassifier F1-score\nQProp\u2019s MaxEnt [11] 82.13\nLogistic Regression 85.99\nCNN 89.70\nRNN 68.81\nBERT 84.61\n4.1.2 Results\nTables 11 and 12 show the results obtained in the Development and Test sets of\nQProp, respectively, by the baseline classifiers. After seeing that top results in re-\nlated workshops were obtained by BERT models, it was unexpected to see a CNN and\ntraditional LR work better for us, but also to see RNN getting the worst performance\namong them. This indicates that the decision of labeling content as \u201cpropaganda\u201d or\nas \u201cnon-propaganda\u201d is being made prioritizing subsets of the input stream instead\nof focusing on the whole string at once. In other words, the individual terms that\nare present in the documents are more informative that their sequence itself.\n4.2 Creation of a new dataset\nThe construction of a new data collection began by choosing all available propagan-\ndist sources from Media Bias/FactCheck list of questionable sources5, finding their\nrespective Twitter handle and downloading their tweets as tweet objects from a series\nof time periods. As subjects, we picked every source of information with the word\n\u201cPropaganda\u201d as reasoning in their detailed report. We successfully retrieved the\ntweets shown in Tables 13 and 14, including their date of creation and text content\namong other metadata features. The tweets were retrieved from two time periods:\n\u2022From the beginning of 2021 to the middle of the same year, with almost half\n5https://mediabiasfactcheck.com/fake-news/\n31\nTable 13: Tweets retrieved from 2021-01-01 to 2021-08-20.\nClass Cleaned volume # of Sources Avg. tweet length\nNon-propaganda 312,143 122 23 words\nPropaganda 168,998 124 23 words\nTotal 481,141 246\nTable 14: Tweets retrieved from 2017-10-01 to 2018-12-31.\nClass Cleaned volume # of Sources Avg. tweet length\nNon-propaganda 4,429 7 20 words\nPropaganda 16,550 33 18 words\nTotal 20,979 40\na million tweets from 246 sources, to carry out experiments of stages 4, 5 and\n6 from Section 3.6.\n\u2022Between 2017 and 2018, to match the collection dates of the QProp dataset [11],\nso that time periods were not an issue for later cross-domain experiments. Even\nthough we found more than 200 sources of propaganda and non-propaganda\ncombined, the temporal restriction reduced this number to 40.\nTo clean the new collection of tweets, we discarded retweets and followed guidelines\nfrom [30] by removing the tweets that contain three or more trending topics from\nthat time period. We hope that this corpus will be an important contribution to the\narea of computational propaganda detection, since it would be the first corpus of\ntweets in English specifically built for this task, and aligned with the current existing\nones.\nTable 15 presents the top 10 topics extracted from the collection of tweets\nusing Latent Dirichlet Allocation (LDA)[31], where each topic is represented as a\nmultinomial distribution of words (the name of each topic in the first column was\ndesignated based on the set of words associated to it).\n32\nTable 15: Top 10 topics extracted from tweets dataset.\nTopic Top 10 words (lemmatized and stemmed)\nFreedom live - free - govern - world - nation - today -\nspeech - global- freedom - billion\nMiddle East 1 saudi - turkey - citi - fact - arabia - death - plan\n- germani - nation - syrian\nWomen Rights right - abort - human - vote - women - democrat\n- tell - state - life - senat\nReligious conflicts remnant - muslim - polit - islam - confer - chris-\ntian - america - palestinian - talk - leader\nElections elect - news - presid - latest - miss - china - fake\n- lose - mosher - check\nUS Presidency trump - want - white - media - obama - peopl -\nknow - liber - presid - russia\nGeneral News publish - newsrescu - school - polic - video -\ncorrupt - children - post - health - student\nMiddle East 2 buhari - adzw - syria - newspap - nigeria - isi -\nkill - israel - nigerian - attack\nDonald Trump trump - realdonaldtrump - say - presid - year -\ncountri - peopl - iran - deal - like\nReligion michael - matt - cathol - pope - church - franci -\nvatican - life - middl - east\n33\n4.3 Cross Domain Text Classification\nThe objective of this experiment consists of testing a propaganda detector under the\nnext scenario: there are available resources from an auxiliary domain in the form of\nnews articles but low resources on a target domain consisting of tweets. We want to\ndetermine the label of the tweets, using news articles as the only input for training,\nand see if the collections of articles are useful to carry out the classification task in\nthe tweets domain.\n4.3.1 Preprocessing, Data representation and Experimental settings\nAll text documents, made up by articles and tweets, were prepared by lowercasing\nall letters and removing stopwords. After this step, the documents were represented\nas a Bag-of-words with boolean weighting, to prioritize the importance of presence of\nterms between domains over their frequency (both domains are contrasting in terms\nof document length). Our experiments were performed using the following baseline\nclassifiers:\nLogistic Regression with a lbfgs solver and C= 1.\nSupport Vector Machine with linear kernel and C= 1.\nBoth classifiers were implemented from the scikit-learn python library [32].\n4.3.2 Results and Analysis\nTable 16 shows the in-domain classification results from a 10-fold cross-validation,\nas well as the scores of the classifier trained with news articles (auxiliary domain)\nmaking predictions on the same test partitions of the previous cross validation.\nWe can observe that the classifiers trained out-domain perform far worse than the\nin-domain equivalent, leading us to believe that the creation of a detection model\nspecifically tailored for tweets from scratch might be a better option.\n34\nTable 16: Classification results on tweets dataset.\nModel ACC PRC Recall F1-Score\nLR trained with tweets 90.27 87.85 81.52 84.11\nLinear SVM trained with tweets 87.95 82.07 81.42 81.73\nLR trained with articles 78.82 50.69 50.01 44.21\nLinear SVM trained with articles 77.46 43.26 49.34 44.24\nTo complement the previous experiment, we tried to measure how much the\nauxiliary domain of news articles is related to the target domain of tweets by using\na supervised classifier and a 10 fold cross-validation procedure. Each domain is\ntreated as a class, and each instance is assigned to the class of the domain to which\nit belongs. If the classifier is able to distinguish between the two distributions, its\nperformance indicates the distance between them [33]. As we can see in Table 17,\nthe results obtained by a Logistic Regression classifier are very high in all the scores,\nwhich indicates that the domains are dissimilar, and as a consequence it is easy for\nthe classifier to tell apart a document from another one between domains.\nTable 17: Classification results to measure the gap between domains.\nModel ACC PRC Recall F1-Score\nLR 99.72 99.69 99.72 99.70\nUnder these circumstances, there may be relatively few common elements be-\ntween the article and the tweet domains, and the amount of usable knowledge for\ntraining an effective model for a short and noisy domain such as Twitter is minimal.\n35\n5 Preliminary conclusions\nTo conclude this dissertation proposal, we summarize our preliminary conclusions\nas follows:\n\u2022We are creating a new corpus of computational propaganda with Twitter as\nthe source of data. The first part of the collection includes 246 sources and\nmore than 481k of tweets. The second part of the collection includes 40 sources\nand it has more than 20k of tweets. This represents a contribution to the area\nof computational propaganda given the scarcity of data from social media to\nuse for research on this particular task.\n\u2022Our first experiments in the domain of news articles allowed us to observe that\nthe presence of terms is more relevant than their sequence, and that this allows\nconvolutional neural networks to outperform in some cases other classifiers such\nas recurrent neural networks and transformers-based at document level.\n\u2022Our second experiment, based on a cross-domain text classification approach,\nallowed us to observe that a cross-domain adaptation seems not so straight-\nforward given the differences between the documents from both domains. A\nfuture strategy needs to consider the difference in length and noisiness. We\nalso want to keep testing cross-domain strategies using more classifiers, such\nas a CNN, a RNN and BERT.\nThe percentage of completion of this dissertation proposal, based on the Work\nPlan displayed in Section 3.7 is approximately of 28%. We are currently focusing\nour work on Stage 1 and 3 of the Methodology and their respective objectives.\n36\n6 Background concepts\n6.1 Text Classification\nThe computational propaganda detection task may be thought of as a text classifica-\ntion problem in which text items are assigned to one or more predetermined groups\ndepending on their content [34]. Every automatic text categorization task involves\ntwo major components:\n1. Feature extraction through text representations.\n2. Machine learning methods of classification.\n6.1.1 Text representations\nText data in NLP problems is frequently supplied by human participants and selected\nfrom web forums, chat rooms and social media. Machine learning techniques use two\nprominent feature representations to analyze and extract relevant insights from these\ntexts: Bag-of-Words andWord Embeddings .\n6.1.1.1 Bag-of-Words\nMost machine learning applications in the text domain work with the bag-of-words\nrepresentation (BoW). This model treats each word present in a collection of doc-\numents as a feature, and since each file only contains a small subset of the whole\nvocabulary, BoW is an extremely sparse representation. The value assigned to in-\ndividual features can be either positive (if the word exists within the document) or\nzero (if the word is absent). The positive values can be normalized term frequencies\nor simple binary indicators. For example, consider the next two documents:\n\u2022the weenie dog chases a cat\n37\n\u2022my cat does not like dry food\nA BoW representation of these sentences, filled with binary indicators, would\nlook like Table 18, where each column refers to a term and each row is a document.\nTable 18: Example of a Bag-of-Words .\nthe weenie dog chases acat my does not like dry food\nDoc1 1 1 1 1 1 1 0 0 0 0 0 0\nDoc2 0 0 0 0 0 1 1 1 1 1 1 1\nAlternatively, a BoW can also consider character n-grams as features (Table\n19):\nTable 19: Example of a Bag of Character 3-grams.\nthe wee een eni nie dog cha has ase ses cat ...\nDoc1 1 1 1 1 1 1 1 1 1 1 1 ...\nDoc2 0 0 0 0 0 0 0 0 0 0 1 ...\nThere may be some applications (where a binary input is strictly required, or\nwhen presence is more important than frequency) for which binary representations\nare good enough due to its simplicity. However, if frequency is indeed relevant for\nthe task at hand, the use of normalized frequency of terms is a better way to fill the\nvalues of a BoW. This variant is referred to as the tf-idf model, where tfstands for\ntheterm frequency andidfstands for the inverse document frequency . Consider a\ndocument collection containing ndocuments in ddimensions. If X= (x 1. . . x d)\nis the d-dimensional representation of a document after the term extraction phase,\nthen x irepresents the unnormalized frequency of said document, where all the values\nof x iare nonnegative and most are zero [35].\nThe first step to normalize term frequencies is to compute the inverse document\nfrequency of each term. The inverse document frequency idiof the ith term is a\ndecreasing function of the number of documents n iin which it occurs:\n38\nidi= log ( n/n i) (1)\nThe term frequency is normalized by multiplying it with the inverse document\nfrequency:\nxi\u21d0xi\u00b7idi (2)\nOne problem with idfnormalization is that it might increase the frequency of\nmisspellings and errors that weren\u2019t handled in the preprocessing stage.\nIn summary, the universe of words (or terms) corresponds to the dimensions (or\nfeatures) in this model, turning them into a sparse multidimensional representation,\nwhere the ordering of the terms is not used.\n6.1.1.2 Word and Document Embeddings\nWord ordering conveys semantics that cannot be inferred from the bag-of-words\nrepresentation. For example, consider the following pair of sentences:\n\u2022The cat chased the mouse\n\u2022The mouse chased the cat\nClearly, the two sentences are very different but they are identical from the\npoint of view of the bag-of-words representation. For longer segments of text, term\nfrequency usually conveys sufficient evidence to robustly handle simple machine\nlearning decisions like binary classification. This is one of the reasons that sequence\ninformation is rarely used in simpler settings like classification. On the other hand,\nmore sophisticated applications with fine-grained nuances require a greater degree of\n39\nlinguistic intelligence. A common approach is to convert text sequences to multidi-\nmensional embeddings because of the wide availability of machine learning solutions\nfor multidimensional data. However, the goal is to incorporate the sequential struc-\nture of the data within the embedding. Such embeddings can only be created with\nthe use of sequencing information because of its semantic nature [35]. The simplest\napproach is to use a 2-gram embedding:\n\u2022For each pair of terms tiandtjthe probability P(tj\u2014 t i)that term tjoccurs\njust after tiis computed.\n\u2022A matrix Sis created in which Sijis equal to [ P(ti\u2014 t j)+P(tj\u2014 t i)]/2.\n\u2022Values of Sijbelow a certain threshold are removed.\n\u2022The diagonal entries are set to be equal to the sum of the remaining entries\nin that row. This is done in order to ensure that the matrix is positive semi-\ndefinite.\n\u2022The top- keigenvectors of this matrix can be used to generate a word embed-\nding.\nThe linguistic power in the embedding depends almost completely on the type\nof word-to-word similarity function that is leveraged [35].\n40\nFigure 3: Example of word embeddings on a three-dimensional space.\nAs shown in Figure 3, the main idea behind this technique is that words that\nare similar in context (at least according to the text from which the embeddings\nalgorithm trained with) appear closer to each other in a multidimensional space.\nBased on this, one can use the position of the words in this space to compute the\nsimilarity and relation that the text has with its surroundings.\n6.1.2 Machine Learning Algorithms\nMachine Learning is about making computers modify or adapt their actions (such\nas making predictions), so that these actions get more accurate, where accuracy is\nmeasured by how well the chosen actions reflect the correct ones. It is only over\nthe past decade or so that the inherent multi-disciplinarity of machine learning has\nbeen recognized. It merges ideas from neuroscience and biology, statistics, mathe-\nmatics, and physics, to make computers learn [36]. Machine Learning systems can\nbe classified into broad groups according to the amount and type of supervision they\nget during training. Some of these categories are: supervised learning, unsupervised\nlearning, semi supervised learning and reinforcement learning [26]. When we feed\n41\nthe training data and the desired solutions or labels to an algorithm, we are talk-\ning about supervised learning, and a typical task in this category is classification.\nThe classification problem consists of taking input vectors and deciding which of N\nclasses they belong to, based on training from exemplars of each class. In one-class\nand multi-class classification problems, each example has one or more labels respec-\ntively, but for both tasks the set of classes covers the whole possible output space\n[36].\nFor this research, we saw some baselines in related work based on Linear Re-\ngression as classifiers. This algorithm is considered part of the traditional approaches\nfor most of the NLP tasks, they are well established, reliable and still competitive\nto this day.\n6.1.2.1 Logistic Regression\nEven though it may seem as a contradiction to use the term regression in the name of\na classifier, Logistic Regression (LR) is similar to linear regression, with the exception\nthat instead of predicting a continuous value, it simply predicts whether something\nis true or false, in other words, this algorithm uses a linear regression equation that\nincludes a function called \u201clogistic/sigmoid function\u201d, this function produces an \u201cS\u201d\nshaped curve that is able to tell the probability of class assignment (Figure 4).\n42\nFigure 4: Example of sigmoid function in Logistic Regression.\nThe sigmoid function is defined [37] as:\nf(t) =1\n1 +e\u2212t(3)\nNow, we can consider tas a linear function in a univariate regression model\n[38]:\nt=\u03b20+\u03b21x (4)\nTherefore, the Logistic Equation becomes:\np(x) =1\n1 +e\u2212(\u03b20+\u03b21x)(5)\nThe choice of the model parameters is a problem that involves finding a hy-\npothesis that best explains our data. The \u201cS\u201d curve is fit to the data using a process\ncalled \u201cmaximum likelihood\u201d. Basically, all the data points are used to calculate the\nlikelihood of the data given the line generated by the sigmoid function. This curve\n43\nshifts positions until a line with maximum likelihood is selected (see Figure 5).\nFigure 5: Sigmoid curve tested in different positions to find maximum likelihood.\nOverall, this method helps to shrink real valued continuous inputs into a range\nof(0,1) being useful while dealing with probabilities and producing discrete binary\noutputs [39].\n6.1.2.2 Bidirectional Encoder Representations from Transformers\nThis new representation technique that can also be used to perform classification,\nbetter known as BERT by its initials, solves a restriction that current pre-trained\nlanguage models have, unidirectional architectures. By masking a portion of to-\nkens from the input in a random process called \u201cmasked language model\u201d, a BERT\nrepresentation is enabled to combine left and right contexts, generating a deep bidi-\nrectional Transformer. BERT\u2019s framework consists of a pre-training step, which\ninvolves training parameters on unlabeled data, and a fine-tuning step that contin-\nues adjusting these parameters, only this time with labeled data from downstream\ntasks. This process is illustrated in Figure 6 as a question-answering example.\n44\nFigure 6: General pre-training and fine-tuning mechanisms in BERT, adopted from [15].\nBoth pre-training and fine-tuning of parameters use the same architecture.\nIn BERT, a \u201csentence\u201d refers to an arbitrary span of adjacent text, and a\n\u201csequence\u201d indicates the input token sequence. Each sequence has special tokens,\nsuch as \u201c[CLS]\u201d which symbolizes the beginning of the input, and \u201c[SEP]\u201d, which\nseparates sentences. The construction of an input representation for a given token,\npictured in Figure 7, is the sum of the token, segment and position embeddings.\nFigure 7: Example of BERT input representation, adopted from [15].\n45\n6.2 Evaluation measures\nClassification tasks in supervised learning involves comparing predictions against the\ntrue labels of samples to train models. The possible outcomes of this comparison is\nshown in Figure 8.\nFigure 8: The four outcomes of a 2x2 confusion matrix.\nTo evaluate the performance of the classifiers, the main classification metrics\nare considered, as defined in [40]:\nAccuracy =TP+TN\nTP+TN+FP+FN(6)\nPrecision =TP\nTP+FP(7)\nRecall =TP\nTP+FN(8)\nF1-score =2\n1\nPrecision+1\nRecall(9)\n46\n6.3 Network-based features from Tweet objects\nAlso known as \u201cstatus updates\u201d, these objects represents tweets. Each object has a\nlist of fundamental properties. Table 20 displays the tweet attributes and descrip-\ntions [41] that are relevant for this research.\nTable 20: Metadata of Tweet object.\nAttribute Type Description\nRetweet count Integer \u201cNumber of times this Tweet has been\nretweeted\u201d.\nFavorite count Integer Indicates approximately how many times\nthe Tweet has been liked by Twitter users.\nReplies count Integer Number of times the Tweet has been\nreplied to.\nDate of creation Date \u201cUTC time when this Tweet was created\u201d.\n47\nReferences\n[1] C. Miller, How to Detect and Analyze Propaganda ...: An Address Delivered at\nTown Hall, Monday, February 20, 1939 . A Town Hall pamphlet, Town Hall,\nIncorporated, 1939.\n[2] G. Bolsover and P. Howard, \u201cComputational propaganda and political big data:\nMoving toward a more critical research agenda,\u201d Big data , vol. 5 4, pp. 273\u2013276,\n2017.\n[3] G. Bolsover and P. Howard, \u201cChinese computational propaganda: automation,\nalgorithms and the manipulation of information about chinese politics on twitter\nand weibo,\u201d Information, Communication Society , vol. 22, pp. 1\u201318, 05 2018.\n[4] C. Wardle, \u201cFIRST DRAFT\u2019S Essential Guide to Understanding information\ndisorder,\u201d First Draft , no. October, p. 61, 2019.\n[5] P. Meel and D. K. Vishwakarma, \u201cFake news, rumor, information pollution in\nsocial media and web: A contemporary survey of state-of-the-arts, challenges\nand opportunities,\u201d Expert Systems with Applications , vol. 153, p. 112986, 2020.\n[6] G. Meikle, Social Media: Communication, Sharing and Visibility . Routledge,\n2016.\n[7] N. Newman, W. Dutton, and G. Blank, \u201cSocial media in the changing ecology of\nnews: The fourth and fifth estate in britain,\u201d International Journal of Internet\nScience , vol. 7, 07 2012.\n[8] G. Da San Martino, S. Cresci, A. Barr\u00b4 on-Cede\u02dc no, S. Yu, R. D. Pietro, and\nP. Nakov, \u201cA survey on computational propaganda detection,\u201d in IJCAI , 2020.\n[9] R. Oshikawa, J. Qian, and W. Y. Wang, \u201cA survey on natural language pro-\ncessing for fake news detection,\u201d in Proceedings of the 12th Language Resources\nand Evaluation Conference , pp. 6086\u20136093, 2020.\n48\n[10] H. Rashkin, E. Choi, J. Y. Jang, S. Volkova, and Y. Choi, \u201cTruth of vary-\ning shades: Analyzing language in fake news and political fact-checking,\u201d in\nProceedings of the 2017 Conference on Empirical Methods in Natural Language\nProcessing , (Copenhagen, Denmark), pp. 2931\u20132937, Association for Computa-\ntional Linguistics, Sept. 2017.\n[11] A. Barr\u00b4 on-Cede\u02dc no, I. Jaradat, G. Da San Martino, and P. Nakov, \u201cProppy:\nOrganizing the news based on their propagandistic content,\u201d Information Pro-\ncessing & Management , vol. 56, 05 2019.\n[12] G. Da San Martino, S. Yu, A. Barr\u00b4 on-Cede\u02dc no, R. Petrov, and P. Nakov, \u201cFine-\ngrained analysis of propaganda in news article,\u201d in Proceedings of the 2019 Con-\nference on Empirical Methods in Natural Language Processing and the 9th Inter-\nnational Joint Conference on Natural Language Processing (EMNLP-IJCNLP) ,\n(Hong Kong, China), pp. 5636\u20135646, Association for Computational Linguistics,\nNov. 2019.\n[13] D. Dimitrov, B. B. Ali, S. Shaar, F. Alam, F. Silvestri, H. Firooz, P. Nakov, and\nG. Da San Martino, \u201cSemeval-2021 task 6: Detection of persuasion techniques\nin texts and images,\u201d in Proceedings of the 15th International Workshop on\nSemantic Evaluation (SemEval-2021) , pp. 70\u201398, 2021.\n[14] G. Da San Martino, A. Barr\u00b4 on-Cede\u02dc no, and P. Nakov, \u201cFindings of the NLP4IF-\n2019 shared task on fine-grained propaganda detection,\u201d in Proceedings of the\nSecond Workshop on Natural Language Processing for Internet Freedom: Cen-\nsorship, Disinformation, and Propaganda , (Hong Kong, China), pp. 162\u2013170,\nAssociation for Computational Linguistics, Nov. 2019.\n[15] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, \u201cBERT: Pre-training of\ndeep bidirectional transformers for language understanding,\u201d in Proceedings of\nthe 2019 Conference of the North American Chapter of the Association for\nComputational Linguistics: Human Language Technologies, Volume 1 (Long\n49\nand Short Papers) , (Minneapolis, Minnesota), pp. 4171\u20134186, Association for\nComputational Linguistics, June 2019.\n[16] G. Da San Martino, A. Barr\u00b4 on-Cedeno, H. Wachsmuth, R. Petrov, and\nP. Nakov, \u201cSemeval-2020 task 11: Detection of propaganda techniques in news\narticles,\u201d in Proceedings of the fourteenth workshop on semantic evaluation ,\npp. 1377\u20131414, 2020.\n[17] L. Wang, X. Shen, G. de Melo, and G. Weikum, \u201cCross-domain learning for clas-\nsifying propaganda in online contents,\u201d in Truth and Trust Online Conference ,\npp. 21\u201331, Hacks Hackers, 2020.\n[18] O. Balalau and R. Horincar, \u201cFrom the stage to the audience: Propaganda on\nreddit,\u201d EACL 2021 - 16th Conference of the European Chapter of the Associ-\nation for Computational Linguistics, Proceedings of the Conference , pp. 3540\u2013\n3550, 2021.\n[19] I. Vogel and M. Meghana, \u201cDetecting fake news spreaders on twitter from a mul-\ntilingual perspective,\u201d Proceedings - 2020 IEEE 7th International Conference\non Data Science and Advanced Analytics, DSAA 2020 , pp. 599\u2013606, 2020.\n[20] B. M. Sinno, B. Oviedo, K. Atwell, M. Alikhani, and J. J. Li, \u201cPolitical ideology\nand polarization of policy positions: A multi-dimensional approach,\u201d ArXiv ,\nvol. abs/2106.14387, 2021.\n[21] M. Mintz, S. Bills, R. Snow, and D. Jurafsky, \u201cDistant supervision for relation\nextraction without labeled data,\u201d in Proceedings of the Joint Conference of the\n47th Annual Meeting of the ACL and the 4th International Joint Conference\non Natural Language Processing of the AFNLP , (Suntec, Singapore), pp. 1003\u2013\n1011, Association for Computational Linguistics, Aug. 2009.\n[22] Y. Hua, \u201cUnderstanding BERT performance in propaganda analysis,\u201d pp. 135\u2013\n138, 2019.\n50\n[23] \u201cMetadata \u2014 Definition of Metadata by Merriam-Webster.\u201d https://www.\nmerriam-webster.com/dictionary/metadata . (Accessed on 2020-01-30).\n[24] A. Sardo, \u201cCategories, balancing, and fake news: The jurisprudence of the\neuropean court of human rights,\u201d Canadian Journal of Law & Jurisprudence ,\nvol. 33, no. 2, p. 435\u2013460, 2020.\n[25] P. Fortuna, J. Soler-Company, and L. Wanner, \u201cHow well do hate speech,\ntoxicity, abusive and offensive language classification models generalize across\ndatasets?,\u201d Information Processing & Management , vol. 58, no. 3, p. 102524,\n2021.\n[26] A. G\u00b4 eron, Hands-on Machine Learning with Scikit-Learn, Keras, and Tensor-\nFlow (2019, O\u2019reilly) . O\u2019Reilly Media, 2017.\n[27] R. Rehurek and P. Sojka, \u201cGensim\u2013python framework for vector space mod-\nelling,\u201d NLP Centre, Faculty of Informatics, Masaryk University, Brno, Czech\nRepublic , vol. 3, no. 2, 2011.\n[28] T. C. Rajapakse, \u201cSimple transformers.\u201d https://github.com/\nThilinaRajapakse/simpletransformers , 2019. (Accessed on 2021-04-22).\n[29] M. Abadi, A. Agarwal, P. Barham, E. Brevdo, Z. Chen, C. Citro, G. S. Corrado,\nA. Davis, J. Dean, M. Devin, S. Ghemawat, I. Goodfellow, A. Harp, G. Irving,\nM. Isard, Y. Jia, R. Jozefowicz, L. Kaiser, M. Kudlur, J. Levenberg, D. Man\u00b4 e,\nR. Monga, S. Moore, D. Murray, C. Olah, M. Schuster, J. Shlens, B. Steiner,\nI. Sutskever, K. Talwar, P. Tucker, V. Vanhoucke, V. Vasudevan, F. Vi\u00b4 egas,\nO. Vinyals, P. Warden, M. Wattenberg, M. Wicke, Y. Yu, and X. Zheng, \u201cTen-\nsorFlow: Large-scale machine learning on heterogeneous systems,\u201d 2015. Soft-\nware available from tensorflow.org.\n51\n[30] H. Kwak, C. Lee, H. Park, and S. Moon, \u201cWhat is Twitter, a social network\nor a news media?,\u201d Proceedings of the 19th International Conference on World\nWide Web, WWW \u201910 , pp. 591\u2013600, 2010.\n[31] J. C. Campbell, A. Hindle, and E. Stroulia, \u201cLatent Dirichlet Allocation: Ex-\ntracting Topics from Software Engineering Data,\u201d The Art and Science of An-\nalyzing Software Data , vol. 3, pp. 139\u2013159, 2015.\n[32] F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel,\nM. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Pas-\nsos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay, \u201cScikit-learn:\nMachine learning in Python,\u201d Journal of Machine Learning Research , vol. 12,\npp. 2825\u20132830, 2011.\n[33] L. Candillier and V. Lemaire, \u201cDesign and analysis of the nomao challenge\nactive learning in the real-world,\u201d 08 2013.\n[34] K. Aas and L. Eikvil, \u201cText categorisation: A survey.,\u201d 1999.\n[35] C. Aggarwal, Machine Learning for Text . Springer International Publishing,\n2018.\n[36] S. Marsland, Machine Learning: An Algorithmic Perspective . Chapman and\nHall/CRC, 2nd ed. ed., 2014.\n[37] T. Mitchell, Machine Learning . McGraw-Hill International Editions, McGraw-\nHill, 1997.\n[38] \u201cUnivariate Linear Regression - MuPAD.\u201d https://www.mathworks.com/\nhelp/symbolic/mupad_ug/univariate-linear-regression.html . (Accessed\non 2020-02-18).\n52\n[39] \u201cLOGISTIC REGRESSION CLASSIFIER - Towards\nData Science.\u201d https://towardsdatascience.com/\nlogistic-regression-classifier-8583e0c3cf9 . (Accessed on 2019-12-02).\n[40] D. Olson and D. Delen, Advanced Data Mining Techniques . Springer Berlin\nHeidelberg, 2008.\n[41] \u201cTweet object \u2014 Twitter Developers.\u201d https://developer.twitter.com/\nen/docs/tweets/data-dictionary/overview/tweet-object . (Accessed on\n2019-12-02).\n53", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "A Multidimensional Analysis of Text for Automated Detection of Computational Propaganda in Twitter Technical Report: CCC-22-003", "author": ["MEC Moreno", "M Montes-Y-G\u00f3mez", "LCG Gurrola"], "pub_year": "2022", "venue": "NA", "abstract": "Technology has changed the way in which people communicate with each other, giving rise  to new services such as social networks. Unfortunately, these services can be used to"}, "filled": false, "gsrank": 843, "pub_url": "https://ccc.inaoep.mx/archivos/2021/CCC-22-003.pdf", "author_id": ["", "DKpXXTgAAAAJ", ""], "url_scholarbib": "/scholar?hl=en&q=info:xzDY2B-jQWoJ:scholar.google.com/&output=cite&scirp=842&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D840%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=xzDY2B-jQWoJ&ei=n7WsaPbEK8DZieoPqdqh8QU&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:xzDY2B-jQWoJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://ccc.inaoep.mx/archivos/2021/CCC-22-003.pdf"}}, {"title": "I saw it on social media: Public opinion on race, crime, and immigration in the era of social media news consumption", "year": "2020", "pdf_data": "  \n \n \n \n \nI SAW IT ON SOCIAL MEDIA: PUBLIC OPINION ON RACE, CRIME, AND \nIMMIGRATION IN THE ERA OF SOCIAL MEDIA NEWS CONSUMPTION  \n \n \n \n \n \n \n \nBY \n \nMARISA ASHLEY SMITH  \n \n \n \n \n \n \n \nDISSERTATION  \n \nSubmitted in partial fulfillment of the requirements  \nfor the degree of Doctor of Philosophy in Communication  \nin the Graduate College of the  \nUniversity of Illinois at Urbana -Champaign, 2020  \n \n \n \nUrbana, Illinois  \n \n \n \nDoctoral Committee:  \n  \n Professor Travis L. Dixon, Chair  \n Associate Professor Cabral A. Bigman  \n Professor  David Tewksbury  \n Assistant Professor JungHwan Yang  \n Associate Professor Nikki Usher  \n \n \n \n ii ABSTRACT  \n \n Political polarization among the American electorate continuously grows (Iyengar, Sood, \n& Lelkes, 2012) , perniciously impeding political cohesion. Partisans refute policies simply \nbecause they do not align with their party\u2019s stance (Bechtel, Hainmueller, Hangartner, & \nHelbling, 2015)  and partisans distrust members of the opposing po litical party (Iyengar & \nKrupenkin, 2018; Iyengar, Lelkes, Levendusky, Malhotra, & Westwood, 2018) . As America \napproaches the 2020 presidential election, it is ever evident that identity drives politics (Kreiss, \n2018; Kreiss, Lawrence, & McGregor, 2020) .  \nGiven the growing chasm between Republicans and Democrats, scholarship often \nexamines how news available on s ocial media contributes to polarized opinions (e.g., Allcott & \nGentzkow, 2017; Freelon & Wells, 2020; Grinberg, Joseph, Friedland, Swire -Thompson, & \nLazer, 2019; Lewandowsky, Ecker, & Cook, 2017) . However, the majority of research \nexamining the implications of social media on sociopolitical attitudes omits the underlying cause \nof politica l polarization \u2013 racism. Racial resentment towards African Americans drive s \npolarization between Republicans and Democrats (Valentino & Zhirkov, 2017) , as well as, \nvoting behavior among White Americans (Reny, Collingwood, & Valenzuela, 2019) . \nFurthermore, attitudes towards immigration or the Black Lives Matter movem ent predicted \nsupport for Trump during the 2016 presidential election (Drakulich, Wozniak, Hagan, & \nJohnson, 2020; Reny et al., 2019) .  \nHolistic understanding of how social media impacts sociopolitical attitudes requires \nunderstanding whether news encountered during social media use i mpacts perceptions of African \nAmericans or Latinos. Drawing on framing theory, I examined how crime and immigration news \npotentially encountered during Twitter use influences stereotype endorsement, perceptions of \n \n iii immigrants as a threat, and support for pu nitive crime or immigration policies. Furthermore, I \npropose d the concept of  decentralized framing effects. This proposition contends that \nopportunities for news gatekeeping afforded by social media  shifts influential power away from \noffline and online news sources to the variety of sources users encounter during social media use . \nAs a result, audience opinions will be less contingent on the cable, print, or online news \naudiences directly select, and more so dependent on the news they incidentally  encounter on \nsocial media.  \n Study 1 recruited 244 adult Twitter users and content analyzed the crime and immigration \nnews participants potentially encountered on Twitter. Results indicated that crime news was \ntypically framed as relating to crime and jus tice, while immigration news emphasized the \npolitical and policy aspects of immigration. Surprisingly, explicit mentions of African Americans \nand Latinos were not prevalent in crime and immigration news. When present, however, African \nAmericans were repres ented as victims of crime and mentions of Latino immigrants ranged from \nauthorized immigrants (i.e., asylum seekers) to unauthorized immigrants (i.e., illegal alien). The \ntop shared news sources were legacy news outlets, such as CNN and the New York Times . \nFurthermore, left -leaning sources dominated participants\u2019 Twitter networks irrespective of the \nparticipant\u2019s party affiliation.  \n Study 2 (N = 141) expanded upon Study 1, examining relationships between the crime \nand immigration news in participants\u2019 Twit ter networks and participant attitudes. Analysis \ndemonstrated that partisanship was the greatest predictor of immigrant attitudes  and support for \nanti-immigrant policy. Interestingly, crime news participants potentially encountered on Twitter \nwas marginall y associated with depressed support for punitive crime policy. Furthermore, \n \n iv immigration news participants potentially encountered were associated with their thoughts on \nimmigration.  \nOverall, Study 2 found support for decentralized  framing effects. Partici pants\u2019 \nconsumption of offline (e.g., newspapers, cable news) and online (e.g., news websites) news was \nsignificantly associated with participants\u2019 endorsement of African American stereotypes. Heavy \nnews consumers reported greater endorsement in African Ame rican stereotypes. However, when \naccounting for the crime news users potentially encountered on Twitter, greater crime news \nreduced stereotype endorsement for heavy consumers of mainstream + liberal news. In other \nwords, the crime news participants potenti ally encountered on Twitter was capable of overriding \nthe impact of cable, print, or online news. These results suggest that social media are influential \nin reshaping perceptions of African Americans and suppressing stereotypes cultivated during \nmainstream  media use. The implications of these findings are discussed considering social media \nand activism, as well as immigration and political polarization.  \n \n \n \n \n \n \n \n \n \n \n \n v  \n \n \n \n \n \n \nTo my grandparents, Clifton and Juanita Simmons  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n vi TABLE OF CONTENTS  \n \nLIST OF TABLES   ................................ ................................ ................................ .......................  vii \nLIST OF FIGURES   ................................ ................................ ................................ ......................  ix \nCHAPTER 1: INTRODUCTION   ................................ ................................ ................................ ...1 \nCHAPTER 2: LITERATURE REVIEW  ................................ ................................ ........................ 6 \nCHAPTER 3: STUDY 1  ................................ ................................ ................................ ............... 32 \nCHAPTER 4: STUDY 2  ................................ ................................ ................................ ............... 69 \nCHAPTER 5: GENERAL DISCUSSION  ................................ ................................ ..................... 94 \nREFERENCES  ................................ ................................ ................................ ............................ 111 \nAPPENDIX A: NEWS FRAME AND THOUGH T LISTING CODEBOOK  ............................ 131 \nAPPENDIX B: FEATURE SELECTION FOR SUPERVISED MACHINE LEARNING  ........ 137 \nAPPENDIX C: SURVEY MEASURES  ................................ ................................ ...................... 140 \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n vii LIST OF TABLES  \n \nTable 3.1:  Reliability and Validity Tests for Crime and Immigration Supervised Machine \nLearning Classifiers   ................................ ................................ ................................ ...................... 46 \nTable 3.2:  Reliability and Validity Tests for News Frame Supervised Machine Learning \nClassifiers  ................................ ................................ ................................ ................................ ......48 \nTable 3.3: Analysis of Explicit Race Mentions in Crime News by Frame  ................................ .....53 \nTable 3.4: Analysis of Explicit Race Mentions in Immigration News by Frame  ........................... 53 \nTable 3.5: Top 2 0 Unigrams and Bigrams in News with Explicit Race Mentions ......................... 57 \nTable 3.6: Top Crime and Immigration News Sources  ................................ ................................ ..61 \nTable 3.7: Analysis of News Categories of Crime News by Partisanship  ................................ .....65 \nTable 3.8: Analysis of News Categories of Immigration News by Partisa nship  ........................... 66 \nTable 3.9: Analysis of News Categories and Outlet Lean for Crime and Immigration News by \nPartisanship  ................................ ................................ ................................ ................................ ...67 \nTable 4.1: Descriptives of Crime and Immigration News ................................ .............................. 70 \nTable 4.2: Principle Components Analysis for Support of Immigration Policies .......................... 72 \nTable  4.3: Factor Analysis of News Repertoires  ................................ ................................ ........... 75 \nTable 4.4: Correlation Matrix for Criterion and Control Variables  ................................ ............. 79 \nTable 4.5: Hierarchical Regression for Stereotype Endorsement  ................................ ................. 80 \nTable 4.6: Hierarchical Regression for Perceptions of Immigrants as a Threat  .......................... 81 \nTable 4.7: Hierarchical Regression for Punitive Crime Policy Support  ................................ .......82 \nTable 4.8: Hierarchical Regression for Support for Anti - and Pro -Immigration Policies  ............ 83 \nTable 4.9: Correlation Matrix for Crime News Frames and Issue Interpretations of Crime   .......85 \n \n viii Table 4.10: Correlation Matrix for Immigration News Frames and Issue Interpretations of \nImmigration ................................ ................................ ................................ ................................ ....85 \nTable 4.11: Moderation of Perceptions of News Credibility for Punitive Crime Policy Support . 86 \nTable 4.12: Correlation Matrix for News Repertoires and Cr iterion Variables   .......................... 90 \nTable 4.13: Moderation of Crime News for African American Stereotype Endorsement  ............. 91 \nTable B.1: List of Selected Features for Supervised Machine Learning of Crime Articles ......... 137 \nTable B.2: List of Selected Features for Supervised Machine Learning of Immigration  \nArticles  ................................ ................................ ................................ ................................ ......... 138 \nTable B.3: List of Selected Features for  Supervised Machine Learning of Crime and Immigration \nNews Frames \u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026\u2026.. 138 \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n ix LIST OF FIGURES  \n \nFigure 3.1:  Standardized Data Collection  Equation   ................................ ................................ .....35 \nFigure 3.2:  Example of Part -of-Speech Tagging  ................................ ................................ .......... 49 \nFigure 3.3:  Top Stemmed Noun Phrases in Crime News  ................................ ............................. 51 \nFigure 3.4:  Top Stemmed Noun Phrases in Immigration News  ................................ ................... 52 \nFigure 3.5:  Proportion of Crime News Sources by Partisanship ................................ ................... 62 \nFigure 3.6: Proportion of Immigration News Sources by Partisanship ................................ ......... 62 \nFigure 3.7:  Crime News Articles by News Category  ................................ ................................ ....63 \nFigure 3.8:  Immigration News Articles by News Cate gory ................................ .......................... 63 \nFigure 3.9:  Top 20 Digitally Native Crime News Articles  ................................ ........................... 64 \nFigure 3.10:  Top 20 Digitally Native Immigration News Articles  ................................ ............... 64 \nFigure 4.1:  Conditional Effect of Mainstream + Liberal Television News Consumption on \nAfrican American Stereotype Endorsement by Twitter Crime News  ................................ ........... 91 \n \n \n \n \n \n \n \n \n \n \n \n 1 CHAPTER 1: INTRODUCTION  \n \nIn 2008, the United States of America achieved a monumental moment and e lected its \nfirst African American president. The election of Barack Obama was indeed an extraordinary \nstep towards racial equality in the United States. Obama embodied the \u201cAmerican Dream;\u201d a \nmiddle -class man raised in a single -mother household achieving t he highest position in the \nnation. Unfortunately, the election of Barack Obama stoked long -festering racial resentment \namong the American public (Valentino & Brader, 2011) . Undeserving African Americans had \nsomehow cut ahead in the proverbial \u201cline\u201d towards American progress, most likely at the \nexpense of White Americans (Hochschild, 2016) .  \nRacial animosity permeated sociopolitical attitudes long before the election of Barack \nObama (Hutchings & Valentin o, 2004). Nevertheless , the contemporary political environment \nsignifies the blatant centrality of race in sociopolitical attitudes (see Abramowitz & McCoy, \n2019) . Republicans represent the \u201cpro -life\u201d party, united in their advocacy for anti -abortion \npolicies (Levendusky, 2009) . Yet, resentment towards Black Americans as opposed to \u201cpro -life\u201d \npositions explain Republicans\u2019 increasing fervor for their political party and disdain for \nDemocrats (Valentino & Zhirkov, 2017) . Evangelical Christians are commonly associated with \nthe Republican Par ty (Goggin, He nderson, & Theodoridis, 2019) . However, racial identity rather \nthan religious or class identity fosters growing polarization among the electorate (Valentino & \nZhirkov, 2017) . The staggering lack of political cohesion does not stem from diverging \nideological, religious, or class difference. Pol itical strife in the United States boils down to one \nelement \u2013 race.  \nThe current political success of the Republican Party resoundingly relies on the \nexploitation and manipulation of racial attitudes (Abramowitz & McCoy, 2019; Drakulich et al., \n \n 2 2020) . Republican politicians continuously, both implicitly and explicitly, communicate to voters \nthat they best represent White Americans (Kreiss et al., 2020; Sides, Tesler, & Vavreck, 2018) . \nNotably, Donald Trump constantly appeals to White racial identity, while demonizing out-\ngroups as inherent threats to American life (Kreiss et al., 2020) . Recent examples include a tweet \nthat \u201cpeople living the ir Suburban Lifestyle Dream \u201d would \u201cno longer be bothered or financially \nhurt by having low income housing built in their neighborhood,\u201d and a tweet  encouraging police \nto shoot protesters following the murder of George Floyd (Karni, Haberman, & Ember, 2020; \nRomm & Chiu, 2020) . These messages reaffirm stereotypes that African America ns pose a \nsignificant threat to White Americans, and that he is best suited for quashing the treat.  \nNews disseminated to audiences can echo these messages. Conservative news  often \ndiscounts the existence of racial discrimination (Mills, 2017)  and depicts protests demanding \njustice for African Americans or Latinos as reprehensible (Kilgo & Mour\u00e3o, 2019; Mills, 2017) . \nMainstream news sources also contribute to perceptions of African Americans and Latinos. \nHistorically, network and cable news sources have overrepresented African Americans as \ncriminals (Dixon & Linz, 2000a), and cu rrent crime news misrepresent the quantity of \nundocumented Latino immigrants who commit violent crime (Dixon & Williams, 2015) . \nMessages such as these note only propagate negative stereotypes associated with African \nAmericans or Latinos, but they are also especially influential in swaying Americans\u2019 voting \nbehavior (Drakulich et al., 2020; Valentino & Zhirkov, 2017) . Racial attitudes towa rd African \nAmericans and anti -immigrant attitudes explain why White voters engaged in vote switching \nduring the 2016 presidential election (i.e., voting for Obama in 2012 and voting for Trump in \n2016). Similarly, resentment towards African Americans and ne gative feelings toward the Black \nLives Matter movement predicted voting for Trump (Drakulich et al., 2020) .   \n \n 3 A growing number of American adults look to social media for news (Shearer & Grieco, \n2019) . As such, a n abundance of research examines the potential imp act of social media \ndisseminated news on American sociopolitical attitudes (Allcott & Gentzkow, 2017; Bail et al., \n2018; Grinberg et al., 2019) . However, few studies account for the undeniable centrality of race \nin the sociopolitical context (notable exception, Freelon et al., 2020)  and, to my knowledge, no \nresearch examines the impact of social media of racial attitudes . True e xamination of social \nmedia\u2019s role in shaping American perceptions necessitates the consideration of race.  Heavy \nexposure to crime or immigration news intensifies racial resentment (see Figueroa -Caballero & \nMastro, 2018)  and increases endorsement of negative ste reotypes (Dixon, 2006, 2008a, 200 8b). \nCrime and immigration news can exploit these racial attitudes, shaping the electorates\u2019 support \nof sociopolitical policies (Atwell Seate & Mastro, 2016; Dixon, 2006; Dragojevic, Sink, & \nMastro, 2017) . Reinforcement or manipulation of racial resentment via social media news \nexpos ure can contribute to mounting political fragmentation and, ultimately, perniciously affect \npolitical decision making. My  dissertation addresses this gap  and examines the influence of \nsocial media  news exposure  on racial attitudes towards African Americans and Latino s, as well \nas racialized policies associated with these groups \u2013 crime and immigration.   \nFirst, my dissertation examines crime and immigration news users encounter during their \nuse of Twitter. Tradit ional offline (e.g., television news) or online (e.g., news website) news \nemploy frames that intrinsically link African Americans to criminal behavior and Latinos to \nundocumented immigration (Dixon & Linz, 2000a; Dixon & Williams, 2015) . I exami ne whether \nthese depictions also entrench social media disseminated news. Second, I consider the sources \navailable within users\u2019 Twitter networks. Social media significantly reduces the barriers of news \ngatekeeping. On social media , legacy news organizatio ns distribute news from their site \n \n 4 (Rosenstiel, Sonderman, Loker, Ivancin, & Kjarval, 2015) , digitally native sources reach large \naudiences (\u201cDigital news fact sheet,\u201d 2019) , and everyday social media users share political \nnews (Thorson, Cotter, Medeiros, & Pak, 2019) . These changes to news dissemination may \nimpact which sources dominant the social media news environment and, subsequently, impact \nwho has the power to shape users\u2019 opinions. Third , my analys is considers the role of \ncontingencies; individual networked flows of content curated via social connections (Thorson & \nWells, 2016). That is, I consider how  news sources shared by users\u2019 social connections and the \nnews frames employed within these frames  impact users\u2019 beliefs in African American and Latino \nstereotypes, or support for harsh public policies.  \nLastly, I contextualize social media news consumption within the larger news ecology, \nconsidering how the effects of Twitter news consumption interact within users\u2019 news repertoires. \nAlthough social media serves as a primary news source for many adults (Shearer & Grieco, \n2019) , social media news consumption does not occur within a vacuum. Social media news \nexposure may complement  or attenuate effects due to exposure to other news sources (e.g., c able \nnews, newspapers) (Kleinnijenhuis, van Hoof, & v an Atteveldt, 2019) . I propose that if social \nmedia use attenuate s the effects of online and offline news exposure, social media decentralizes  \nframing effects, shifting  influence to  a wide variety of news users encounter during social media \nuse.  \nThe remaining chapters expand on these concepts and contentions. Chapter 2 describes \nthe racialization of crime and immigration in news media, the impact of exposure to these news \nframes, an d the potential implications of exposure to these frames in social media. Chapter 3 \ndescribes Study 1, where I content analyze news within users\u2019 Twitter networks. Chapter 4 \ndescribes Study 2, where I expand on Study 1, connecting the content available in users\u2019 Twitter \n \n 5 networks to their sociopolitical opinions. Lastly, Chapter 5 reiterates the major findings, \ndiscusses the implications and limitations of the findings, and offers suggestions for future \nresearch.  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n 6 CHAPTER 2: LITERATURE REVIEW  \n \nIn contemporary American society, attitudes towards African Americans and Latinos \ndrastically shape sociopolitical opinions. Racial animosity towards African Americans  contribute \nto ever -growing polarization among the American electorate  (Valentino & Zhirkov, 2017) . \nFurthermore , resentment towards African Americans and disdain for Latino immigrants cultivate \nsupport for politicians, especially when consider ing the results of the 2016 presidential election \n(Abramowitz & McCoy, 2019; Drakulich et al., 2020) . Given that race and racial attitudes are \nengrained in every aspect of American politics,  true examination of the impact of social media \nnews consumption on American sociopolitical attitudes requires the consideration of race and \nracial attitudes.   \nSocial media continuously grows as a prominent news source for many American adults \n(Shearer & Grieco, 2019). Scholar s and activists laud social media for its democratizing potential \n(S. J. Jackson & Foucault Welles, 2016) . Social media affords the opportunity to reframe \nprevalent narratives that suggest African Americans are inherently threatening or criminal \n(Foucault Welles & Jackson, 2019; S. J. Jackson & Foucault Welles, 2014) . Mere exposure to \nnews emphasizing the differential  treatment of African Americans due to institutional racism \ninforms audiences, particularly White Americans, that racism exists (Smith, Williamson, & \nBigman, 2020) . Furthermore, since heavy media exposure creates cognitive links between \nAfrican Americans and their depictions in the media (see Dixon, 2006) , exposure to sympathetic \nrepresentations may counter cognition connecting Black Americans wi th pathological behavior.  \nUnfortunately, social media also affords the easy spread of racist and manipulative \ncontent (Marwick, 2018) . The exploitation of Americans\u2019 racial attitudes operated as an effective \npolitical technique long before the emergence of social media (Hutchings & Valentino, 2004; \n \n 7 Mendelberg, 2001) . Nevertheless, social media can intensify the tactical employment of racial \nappeals. Members of the conservative right unceasingly demonstrate  their ability to amplify race -\ncentric news in social media (Faris et  al., 2017) . Hierarchal cohesion among conservative \npoliticians, news organizations, and publics easily bolster conservative narratives (Entman & \nUsher, 2018; Marwick, 2018) . Persistent exposure to racialized news via social media may \nestablish and reinforce negative racial attitudes (Marwick, 2018). As such , social media use may \ncreate a feedback loop, amplifying racial resentment cultivated during traditional news use \n(Kleinnijenhuis et al., 2019; Marwick, 2018) .   \nBelow, I discuss news organizations\u2019 historical racialization of crime and immigration, \nand the underlying cognitive processes explaining how these new s frames affect racial \nstereotypes and political decision -making. Next, I elaborate on current news habits exhibited by \nmany Americans. Americans increasingly report fragmented news consumption (Stroud, 2011; \nStroud & Curry, 2015) . News exposure via social media do es not occur in isolation from \naudiences\u2019  traditional offline and online (i.e., news website) media use. Considering audiences\u2019 \nnews repertoires provides insight into whether social media use merely a mplifies the effects of \ntraditional news exposure, or whether the effects of social media extends beyond that of \ntraditional news exposure. Lastly, I consider social media users\u2019 unique news experiences. Social \nconnections, user selection behavior, and soc ial media algorithms drive social media news \nexposure (Thorson & Wells, 2015) . Depending on the news curated fo r social media users  and \nhow it frames crime or immigration , audiences may encounter news that  lessens or  heightens \nnegative racial stereotypes .  \n \n 8 The Racialization of Crime and Immigration  \nNew s organizations help  audiences make sense of  crime and immigration within \nAmerican society.  Given the significant role news organizations play in  shaping public \nperceptions, many scholars investigate how news media frame crime and immigration. Early \nresearch examining news of violent crime  found tha t both local and network news primarily \nfocused on violent crime committed by Black suspects (Entman, 1992, 1994) . Relationships  \nbetween African Americans and violent crime were so prominently featured that the violent \ncrime news category accounted for 41% of all news featuring African Americans (Entman, \n1990) . Although both African American and White citizens committed violent cri me, news \ndepicted African Americans scowling in mug shots or restrained by White officers. White \ncriminals, on the other hand, received no such depiction (Entman, 1990). Entman (1990) argued \nthat news practices shun explicit anti -black racism, but uphold m odern versions of racism \nthrough their depictions of African Americans as violent criminals.  \nLater work, notably Dixon and Linz (2000a, 2000b) , found that news media consistently \ndepict African American perpetrators of violent crime in news. Local news especially portrayed \nAfrican Americans as perpetrators at rat es significantly greater than their actual arrest rates \n(Dixon & Linz, 2000a). Emphasis on violent African American perpetrators also intrinsically \nlinks African Americans with criminality, so much so that audiences cannot think about crime \nwithout conside ring African Americans  (e.g., Dixon, 200 6, 2008a; Domke, 2001) . Currently, \ntelevision depicts African American perpetrators at parity with their actual crime rates (Dixon, \n2017b; Dixon & Williams, 2015) . However, depictions of African American families re iterate \nviolent criminal stereotypes (Dixon, 2017a) . \n \n 9 Crime news has appended focus to another social group \u2013 Latino immigrants and \nundocumented Latino immigrants (Dixon & Williams, 2015). Immigrants represent a wide \nspectrum of ethnic or racial groups. However, news media suggests that audiences should link \nspecific groups with immigration. Such has become the case for immigration and Latinos \n(Valentino, Brader, & Jardina, 2013) . Mentions of Latinx populations in newspaper stories about \nimmigration drastically spiked in 1994, largely due to media coverage of California\u2019s \nProposition 187 (also known as the Save Our State (SOS) initiative) (Valentino et al., 2013). The \ncontroversial proposition proposed that public service organizations bar undocumented \nimmigrants from rece iving public benefits, such as non -emergency health care (ACLU, 1999) . \nAlthough Proposition 187 failed at the polls , its legacy continuously influences  news coverage of \nimmigratio n. From 1994 to 2011, mentions of Latinx populations in newspaper stories about \nimmigration continuously outpaced the proportion of mentions for other populations (i.e., Asian, \nAfrican, or Muslim) (Valentino et al., 2013).  \nNews media frame immigrant s as primarily  Latino and, more often than not, \nundocumented (Farris & Mohamed, 2018) . Additionally, news organizations bundle these \nundocumented i mmigration news frames with portrayals of undocumented immigrants as violent \ncriminals (Dixon & Williams, 2015; Farris & Mohamed, 2018; Kim, Carvalho, Davis, & \nMullins, 2011) . These unfavorable depictions suggest that audience s should think of immigration \n(and undocumented immigration) as synonymous with Latinos and violent crime (Farris & \nMohamed, 2018).  \nUnderstanding Group -Centered Frames  \nFraming theory sets the foundation for understanding the influential power of racialized  \ncrime and immigration  news frames (J. M. Jackson, 2019; T. E. Nelson & Kinder, 1996) . News \n \n 10 media frame issues or events by suggesting connections between concepts, making certain \nconsiderations applicable  to the issue (V. Price & Tewksbury, 1997; Scheufele & Tewksbury, \n2007) . For instance, news outlets may emphasize immigrants as car riers of infectious disease \n(Faris et al., 2017), thus promoting that audiences apply public health concerns to their \nevaluation of immigration. Recognizing the connections made or elements emphasized within \nnews frames are integral to understanding the po tential effects of frame exposure. Tewksbury \nand Scheufele (2019)  refer to these emphasized elements as information \u201cpackages\u201d containing \nwhat the news deems as information relevant to the matter. Relevant properties of issues include \nsocial groups, costs, arguments, metaphors, images, and so on.  \nNews frames that utilize explicit group cues when discussing crime or immigration are \nexceptionally influential on public perceptions of race and crime (J. M. Jackson, 2019; T. E. \nNelson & Kinder, 1996) . Nelson & Kinder (1996) refer to frames containing explicit cues to \nracial groups as group -centered frames . Group -centered frames signal that audiences should \nconne ct African Americans and undocumented Latino immigrants to crime or immigration. \nFurthermore, group -centered frames push audiences to make evaluations of crime and \nimmigration in light of their relevant, accessible attitudes of the racial group emphasized within \nthe frame (Domke, 2001; V. Price & Tewksbury, 1997). In the next section, I lay the framework \nfor understanding how these processes occur. Specifically, I connect chronic accessibility and \napplicability, arguing that both theoretical concepts are ne cessary for explicating framing effects \nin the context of group -centered news frames.  \nConnecting Chronic Accessibility and Applicability  \nPriming  and cognitive accessibility explain how audience s develop and maintain \ncognitive associations surrounding racial groups  (Dixon, 2006; Shrum, 2009) . According to this \n \n 11 paradigm, media depictions promote the construction and maintenance of schema, associative \nnetworks of nodes linked in memory (see, Fiske & Taylor, 2017) . Frequent  exposure to media \nthat prime  these connections make the associative network  chronically accessible  (i.e., more \neasily recalled from memory)  (Ewoldsen & Rhodes, 2019; Shrum, 2009 ). Exposure to news \nframes that prominently cast African Americans or undocumented Latino immigrants as \ncriminals make negative racial stereotypes of African Americans and Latinos accessible. \nAccordingly , heavy consumers of news , which often overrepresents Af rican Americans as \ncriminals (e.g., Dixon, 2017a),  endorse stereotypes of African Americans as intimidating and \nviolent (Dixon, 2008a, 2008b) . Similarly , heavy news consumption depresses support for \nimmigration (Gil de Z\u00fa\u00f1iga, Correa, & Valenzuela, 2012) , increases perceptions of immigrants \nas a threat (Watson & Riffe, 2013) , and supports negative cognition of Latinos (Mastro, \nTukachinsky, Be hm-Morawitz, & Blecha, 2014) .  \nResearch examining news consumption and the cognitive accessibility of racial \nstereotypes primarily focuses of how media use cultivates negative perceptions of African \nAmericans or Latinos (e.g., Dixon, 2006; 2008a; 2008b;  Figueroa -Caballero & Mastro , 2018). \nHowever, these same cognitive processes can also create cognitive linkages with positive or \ncounter -stereotypical characteristics (see Power, Murphy, & Coover, 1996) . For instance, \nexposure to news depicting African Americans in sympathetic positions, such as crime victims or \nas marginalized groups of people, may offset negative associations (e.g., African American s are \ncriminal or African Americans are lazy). Sympathetic depictions of African Americans \ncontradict notions that African Americans are inherently responsible for societal inequities (see \nPower et al., 1996; Smith et al., 2020).  \n \n 12   Priming  and cognitive accessibility are traditionally understood as theoretically divergent \nfrom effects associated with news frames ( Scheufele  & Tewksbury, 2007). Priming  effects are \nmemory -based, while framing is on -line and based on applicability  (Scheufele & Tewksbury, \n2007, p.15). However, since group -centered frames play on racial stereotypes held among \naudience members, largely due to prior exposure to racialized  news frames (see Dixon, 2006; \n2008a, 2008b), schema accessibility  is a necessary component for  explaining the  effects  of \nracialized crime and immigration  news  frames (Smith, Dixon, & Overbye, 2019) .  \nRecent expli cations of framing and framing effects support this suggestion that \naccessibility is a requisite for applicability (Lecheler & de Vreese, 2019) . News frames aff ect \naudiences\u2019 issue interpretations and attitudes to the extent that it resonates with existing, \naccessible schema (Cacciatore, Scheufele, & Iyeng ar, 2016; Lecheler & de Vreese, 2019; \nTewksbury & Scheufele, 2019) . In the case of group -centered frames, the accessibility of \nattitudes towards groups explicitly mentioned within the frame play a major role in shaping the \neffects of frame exposure. As previously discussed, group -centered frames exploit audiences\u2019 \nattitudes about the mentioned group ( Nelson & Kinder, 1996 ) and encourage audiences to make \ndecisions based on their attitudes about the group. This argument suggests that immigration \nframes, f or example, declaring crime a consequence of immigration while also depicting \nimmigrants as undocumented Latino immigrants will invite audiences to make decisions based \non their attitudes about Latinos. The more accessible the attitude  towards Latinx popul ations, the \ngreater the likelihood that such as frame will play on audiences\u2019 cognitive schema.  \nResearch examining the effects of group -centered news frames portraying  African \nAmericans or undocumented Latino immigrants as criminals support this contentio n (Figueroa -\nCaballero & Mastro , 2018; Smith et al., 2019). Smith and colleagues (2019) exposed participants \n \n 13 to news articles containing disinformation highlighting African Americans or undocumented \nLatino immigrants as criminals. Exposure to these news fra mes increased support for punitive \ncrime policy, but only among participants with chronically accessible stereotypes of African \nAmericans or Latinos (Smith et al., 2019). Frame exposure rendered participants\u2019 racial \nstereotypes (e.g., African Americans are  violent;  Latinos are uneducated) accessible and, once \naccessible, participants used accessible stereotypes in their decision making (Smith et al., 2019) . \nFraming Effects: Crime and Immigration  \nGroup -centered crime and immigration frames impact audiences\u2019 interpretations of and \nattitudes toward  crime and immigration policies (e.g., Dixon, 2006; Figueroa -Caballero & \nMastro, 2018 ; Smith et al., 2019 ). Exposure to frames connecting African Americans  and \ncriminality increase support for punitive crime policies, including the death penalty and three -\nstrikes laws (Dixon, 2 006; Gilliam & Iyengar, 2000) . Group -centered  immigration frames  \nproduce similar detrimental effects . Exposure to threatening undocumented Latino immigrant \ncriminals decrease support for immigration  (Brader, Valentino, & Suhay, 2008; Gil de Z\u00fa\u00f1iga et \nal., 2012)  and increase support for punitive immigration policy (Figueroa -Caballero & Mastro, \n2018 ; Smith et al., 2019 ). Furthermore, exposure to media that relies heavily on group -centered \nframes of immigration and crime decrease support for positive immigration policies, such as \nDACA or sanctuary cities, while simultaneously increasing support for punitive immigration \npolicies like building a border wall along the U.S. -Mexico border or increa sing deportations of \nundocumented immigrants (D. M. Price & Kaufhold, 2019) .  \nHeavy consumption of news media increases exposure to group -centered crime or \nimmigration frames. Traditionally, legacy news media has served as the primary conduit for \nracialized crime news frames and the facilitator for public opinions of crime and imm igration. In \n \n 14 an era with ample selection of news sources and opportunities for selection (Iyengar & Hahn, \n2009) , audiences can now also select new media sources. Ideally, the high choice media \nenvironment afforded by the shift of legacy news sources to online platforms (Tewksbury & \nRittenberg, 2012)  and the  popularity boom of digitally native news sources (\u201cDigital news fact \nsheet,\u201d 2019)  would motivate diverse  news consumption. Audiences would select news source s \ndiverse in origin and diverse in content.  Unfortunately, research unceasingly demonstrates that \naudiences often consume politically aligned news (Edgerly, 2015; Mour\u00e3o, Thorson, Chen, & \nTham, 2018) . Before elaborating on social media news consumption, I first describe audiences \nonline and offline news selection. Understanding audiences offline and online news selection \n(outside of social media) assists in understanding how social media news exposure may amplify \nor attenuate the effects of online/offline news use.  \nLegacy and New Medi a Repertoires: Red Media and Blue Media  \nNews repertoires  refer to audience\u2019s combination of online and offline news sources \nwithin their news diet (Edgerly, 2015; Mour\u00e3o et al., 2018).  Research indicates that political \nidentity often facilitates the constr uction of audiences\u2019 news repertoires (Edgerly, 2015). For \ninstance, conservative news sources, such as Rush Limbaugh\u2019s controversial radio show or the \nFox News cable network attract older, male, White, and Republican audiences (Edgerly, 2015). \nMainstream news sources and liberal news sources, like the Daily Kos  attract Democrat -leaning \naudiences (Edgerly, 2015). This does not suggest that audiences isolate themselves in perfect \necho chambers. A minority of Democrats and Republicans report news consumption  from outlets \nwith solely left -leaning or right -leaning audiences, respectively  (Jurkowitz, Mitchell, Shearer, & \nWalker, 2020) . Moreover, Democrats  report  consum ing mainstream media, national newspapers, \nand liberal sources (Mour\u00e3o et al., 2018; D. M. Price & Kaufhold, 2019) . Nevertheless, media \n \n 15 fragmentation permeates behavior amo ng the American electorate and Americans report \npolarized media consumption above other Western countries  (Fletcher, Cornia, & Nielsen, \n2020) . Furthermore, at least in the case of Republicans, research suggests a preference for party -\naligned news across all mediums (e.g., television, online news sites, and radio) (Mour\u00e3o et al., \n2018; D . M. Price & Kaufhold, 2019) .  \n These distinct news repertoires highlight the fears articulated by many communication \nscholars. Democrat -leaning audiences select \u201cblue\u201d or \u201cpurple\u201d media, while Republican -leaning \naudiences view \u201cred\u201d media (Edgerly, 2015; Iyengar & Hahn, 2009) . Blue media and red media \nlean towards liberal and conservative ideologies, respectivel y. Purple media reflect centric ideals  \n(Edgerly, 2015). A high-choice news ecology offer s diversity in the magnitude of options, \ndemonstrated by the ever -growing amount of digitally native sources available within digital \nmedia environments. However, this source diversity does not necessarily translate into content \ndiversity (Van Aelst et al., 2017) . Specifically, conservative (or red) media, regardless of its \nexistence as a cable news outlet or as  an online -only news source, may offer audiences the same \nor similar news frames (see Entman & Usher, 2018) .   \n One can gleam from the discussion of framing and framing effects offered above that the \nlack of ov erlap in news exposure supports diverging racial perceptions, and fragmented opinions \nabout crime and immigration. The conservative right selectively emphasizes narratives depicting \ntheir ideological argument as \u201cright\u201d and the sole \u201cauthentic\u201d voice of re ason (Jamieson & \nCapella, 2008; Marwick, 2018) . In the context of crime and immigration, this means reiterating \nthe pathological deviance of African Americans or Latinos to accentuate the absurdity of liberal \npolicies (e.g., immigration reform, criminal justice reform, or the Black Lives Matter movement ) \n(Abramowitz & McCoy, 2019; Drakulich et al., 2020; Kilgo & Mour\u00e3o, 2019 ). Republicans \n \n 16 consuming conservative media do not support DACA, sanctuary cities, or birth -right citizenship, \nyet support building a wall or maintaining immigration detention centers  (D. M. Price & \nKaufhold, 2019) . This does not mean that media exposure (absent of partisanship) is \nuninfluential. Consumers of Fox New s, regardle ss of partisanship, report depressed support for \nimmigration (Gil de Z\u00fa\u00f1iga et al., 2012).  Nevertheless, as partisans consume party -aligned \nmedia, partisans develop party -aligned perceptions  (Stroud, 2010) .  \n The entanglement of partisanship and media exposure provides a very interesting picture \nfor how news media may sow racial animosity. Thr ough emphasizing that criminal and \ndangerous African Americans or undocumented Latino immigrants receive excessive, favorable \nsupport from liberal political structures ( Abramowitz & McCoy, 2019) , conservative media not \nonly sway support for crime and immig ration policies, but also worsen  negative racial \nperceptions.  \nLegacy news and online news are indeed important in shaping public perceptions of \ncrime and immigration. However, these sources do not act in isolation of another important \nsource for news amon g American adults (Shearer & Grieco, 2019)  \u2013 social media. Mere \nexposure to news on social media can impact audiences\u2019 perceptions  (e.g., Feezell, 2018)  and it \ncan even amplify the effects of news encountered during other forms of media exposure (e.g., \nnewspapers, television, online news) (Kleinnijenhuis et al., 2019) .  \nThe addition of social media to the changing news landscap e begs the questions : (a) what \ncrime and immigration news  frames circulate within this digital space, (b) how the circulation of \nthese frames impact racial perceptions , and (c) whether social media accentuates the effects of \naudiences\u2019 news repertoires.  Social media also pose the question of what sources availab le \nwithin social media are more influential in shaping audiences\u2019 perspectives. Social media disrupt \n \n 17 traditional conceptions associated with news gatekeeping (Bennett & Pfetsch, 2018)  \u2013 allowing \nfor its digital boundaries to house legacy news sources and digitally na tive sources. Social media \nnews exposure diverges from individually constructed news repertoires (as discussed above) \nbecause exposure depends on networked flows; content curated by social contact \u2019s sharing \nbehavior  and algorithms ( via selection behavior) (Thorson et al., 2019; Thorson & Wells, 2015) . \nWhile these curated flows may contain news media from sources use rs encounter outside of \nsocial media, they are also responsible for funneling online visits towards sources  they may not \notherwise directly encounter, such as \u201cfake news\u201d (Benkler, Faris, & Roberts, 2018; J. L. Nelson \n& Taneja, 20 18) or disinformation  (Freelon & Wells, 2020) .  \nBelow, I expand on these concepts associated with the  social media news landscape, \nelaborating on social media as a news source. In doing so, I use a sociotechnical approach, \ndescribing how the social aspects of social media use accompanied with its technological \nfeatures guide news exposure (see Marwick, 20 18). This discussion helps set up the ultimate \nquestion addressed by my dissertation \u2013 how social media news consumption contributes  to \nattitudes concerning race, crime, and immigration.  \nSocial Media as a Source of News  \nBoyd  and Ellison (2008)  first defined social media as web -based services where users \ncould construct profiles, express connections with other users, and view connections made by \nothers within the system. So cial media maintains its status as a digital meeting ground for social \ninteractions, however the same affordances that allow for social connections have simultaneously \nconstructed a platform for news dissemination. Affordances are naturally existing attrib utes of a \nparticular object; the manner in which actors use the object (Gibson, 1979) . Affordances \n \n 18 associated with social media include, but are not limited to, interactivity , accessibility , visibility , \nand scalability  (Fox & McEwan, 2019; Treem & Leonardi, 2013) .  \nSocial media is highly interactive. Information shared within social media gain social \nfeedback in th e form of comments, shares, or \u201clikes\u201d from other users. Such feedback \nencourages engagement and further perpetuates information sharing (Fox & Moreland, 2014) . \nSocial media content is also accessible , so much so that audiences can access available content \non a continuous basis without time, place, or structural limitations (Fox & McEw an, 2019 ). \nSocial media also offers visibility of content disseminated through social media to large \naudiences. Sharing features, such as the ability to retweet, allows for information flow to \naudiences with minimal effort (Treem & Leonardi, 2013). Aligned  with the concept of visibility, \nsocial media messages can go viral, reaching millions of users almost instantaneously (Marwick \n& Lewis, 2017) .  \nSocial media users appropriate these affordances for a number of goal -oriented outcomes. \nFor instance, these affordances facilitate social support connections (Lu & Hampton, 2017)  and \nrelationship maintenance (Ellison, Vitak, Gray, & Lampe, 2014) . The utilization of social media \nfor these purposes are likely consistent with what the creators of popular social media sites \nenvisioned. However, the steady incre ase of social media news consumption among American \nadults (see Shearer & Grieco, 2019) also suggests that users recognize the opportunities for news \ndissemination and exposure. Fifty -four percent of American adults report getting news from \nsocial media in  some compacity and 28% of American adults report getting news on social \nmedia often (Shearer & Grieco, 2019).  \nTwitter ranks among the most used sources of social media news for American adults, \nwith 17% of American adults getting news on Twitter (Shearer & Grieco, 2019). Twitter allows \n \n 19 users to share short messages within a 280-character limit. Since its inception , Twitter\u2019s features \nhave set it apart from other social media platforms. For example, Twitter does not require \nreciprocal relationships , which affords greater amounts of one -way relationships reminiscent of \nan information source as opposed to an interpers onal digital environment  (Kwak, Lee,  Park, & \nMoon, 2010) . Journalists, politicians, and activists flock to Twitter to take advantage of the \ninformation sharing capabilities afforded by the site. Journalists from traditional news outlets, as \nwell as digitally native sources share links to their respective news organizations on Twitter \n(Russell, 2019) . Congressional representatives connect with constituents about political \ninitiatives or report their daily activities (Golbeck, Grimes, & Rogers, 2010) . Activists garner the \nattention of the public and political elites, as well as promote discussion of social issues (Freelon, \nMcIlwain, & Clark, 2018; S. J . Jackson & Foucault Welles, 2014) . Even the current President of \nthe United States uses Twitter as a conduit to the American public (Wells et al., 2016) . Twitter\u2019s \ninterface has shifted with time to reflect the prevalent utilization of the site as an information \nsource. Instead of prompting micro -blogs with the questions \u201cWhat are you doing? ,\u201d users are \nnow prompted to blog \u201cWhat is happening?\u201d It is evident that socia l media, specifically Twitter, \nhas morphed into a news source for a subset of American adults.  \nIdeally, these capabilities would lay the foundation for social media to easily live up to its \ndemocratizing potential (e.g., Smith et al., 2020). On social med ia, everyday social media users \ncan share news discussing crime or immigration in ways ignored by mainstream news sources \n(e.g., Foucault Welles & Jackson, 2019; S. J. Jackson & Foucault Welles, 2016) . As a result, \ndiscussions about racism are plentiful  (Neuman, Guggenheim, Jang , & Bae, 2014) . African \nAmericans and Latinos are not depicted as innately threatening criminals, but rather vulnerable \nvictims of police hostility (S. Jackson & Foucault Welles, 2015) and biased depictions by \n \n 20 mainstream news media  (R. Jackson, 2016) . Empl oying social media features, such as hashtags \nor tagging, users can reframe social issues, provoke public discourse, and influence the public \nand elites (e.g., mainstream media and politicians)  (Freelon et al., 2016).  \nSocial media is indeed celebrated for  its democratizing potential, especially considering \nthe momentum of the #BlackLivesMatter and #MeToo (Freelon, Lopez, Clark, & Jackson, \n2018) . However, the same t echnological features that allow for the construction of counter \npublics also create the perfect storm for racist, false, and manipulative information (Marwick, \n2018). Such problematic posts often lead to the amplifica tion of problematic content, especially \nfrom the conservative right (Entman & Usher, 2018; Marwick, 2018; Schradie, 2018) .  \nThe affordances of social media clearly situat e it as an additional news source. \nSpecifically, Twitter creates a news ecology where Americans are influenced by a combination \nof their offline (e.g., cable news) and online (e.g., news websites) news consumption, as well as \nthe news they encounter during  social media use (Kleinnijenhuis et al., 2019) . Social media also \nconverges exposure that typically occurs ac ross different online and offline mediums  (Chadwick, \n2017; Jenkins, 2006) . Legacy news sources of \u201cold\u201d media platforms like television (e.g., CNN ) \nor print (e.g., New York Times ) have transitioned into social media environments. At the same \ntime, news sources originating entirely in digital spaces have gained popularity wit hin social \nmedia platforms  (\u201cDigital news fact sheet,\u201d 2019) .  \nAlthough the intermingling of legacy and digitally native news sourc es within social \nmedia may imitate adults\u2019 news repertoires, the mechanisms underlying news exposure within \nsocial media differ. Thorson and Wells (2015)  argue that information encountered during social \nmedia use relies on the curated flow of content  regulated by a combination of social contacts, \nalgorithms, and selection behavior (Thorson et al., 2019) . Consequently, understanding frame \n \n 21 exposure within social media necessitates the recognition of the social and technological features \nof social media \u2013 namely social connections and algorithms (Thorson & Wells, 201 5; Thorson et \nal., 2019).   \nContingencies , which differs by social media user,  facilitate news e xposure on social \nmedia  (Thorson & Wells, 201 5). Adult social media users develop idiosyncratic social networks, \nselecting the users whom they will or will not follow ( Thorson & Wells, 201 5). These social \nconnections serve as news curator s, dictating the flow of information into social media users\u2019 \nindividual social networks (Bakshy, Messing, & Adamic, 2015; Thorson et al., 2019; Thorson & \nWells, 2015) . Journalists curate news that aids informed democracy (Thorson & Wells, 201 5). \nStrategic communicators, such as bots or purveyors of  disinformation, disseminate news for \nprofit or political gain (Entman & Usher, 2018; Thorson & Wells, 2016). Social connections \nwith family and friends curate news for social media users, and s ocial media algorithms curate \nnews consider ing users\u2019 previous  engagement  (e.g., \u2018liking\u2019 news s tories) and the political \ninterests of users\u2019 s ocial media connections (Lazer, 2015) . Together, these curating factors \ncollaborate to create a  contingent flow of news (Thorson et al., 2019). Just as political identity \ninfluences the construction of news repertoires, political identity can shape the contingent flow \nof social media content. Consequently, I also consider the impact of political identity on soc ial \nmedia news exposure.  \nConsidering Political Identity: Social Connections and Selection Behavior  \n Political identity within the United States has reached a familial status where one\u2019s \npolitical identity provides a sense of group belonging (Kreiss, 2018) . Americans report \ndiminished affective feelings toward out -party members  (Iyengar & Krupenkin, 2018) . Populist \nrhetoric stating that the Republican Party is under attack by liberal s manifested as Latino \n \n 22 immigrants or African Americans amplify these feelings  (Abramowitz & McCoy, 2019; \nMarwick, 2018, p. 497; Shafer, 2017) . Republicans dislike Democrats, Democrats dislike \nRepublicans and the chasm between in -group and out -group fe elings intensifies (Iyengar et al., \n2018). Greater racial resentment not only worsens this political fragmentation, but it is also \nassociated with stronger racialized party schema (Valentino & Zhirkov, 2017). Polarized \nRepublicans maintaining greater racia l resentment associate Democrats with African Americans \nand Republicans with Whites. In essence, racially resentful Republicans perceive the Republican \nParty as the party for White Americans (see Hochschild, 2016; Valentino & Zhirkov, 2017).  \nPolitical pola rization between  Republican s and Democrat s contribute to social media \nbehavior, including social connections and selection behavior. A continuous flow of scholarly \nwork examines the role of political identity in social media connections. Research in the ar ea of \nidentity and social media connections often warns of echo -chambers \u2013 the propensity to only \nconnect with like -minded individuals (Himelboim, Mccreery, & Smith, 2013) . While perfect \necho -chambers are far from the case (see Flaxman, Goel, & Rao, 2016)  research suggests that \nright-leaning social media users follow substantially more right -leaning accounts (Boutyline & \nWiller, 2017) .  \nSocial media affordances allow for the easy dissemination of information, including news \nwith varying levels of credi bility. Furthermore,  partisans tend to engage with attitude -consistent \ninformation in digital news environments (D. M. Price & Kaufhold, 2019; Wojcieszak, 2019) . \nPolitically aligned social connections and the preferential selection of identity confirming news, \nenable the curation of low -quality news sources (Lazer, 2015).  This was potentially at play \nduring the 2016 presidential election. During the 2016  presidential election , the majority o f low -\nquality news, such as \u201cfake news\u201d or disinformation favored then presidential candidate Donald \n \n 23 Trump (Faris et al., 2017) . Narayanan et al. (2018)  found that networked Twitter clusters of \nTrump supporters shared the largest amount of known \u201cfake\u201d news sources. Furthermore, during \nthis same time conservatives on Facebook shared and circulated  excessive amounts of fake news \nsources (Allcott & Gentzkow , 2017) .  \nConsidering the presence of low -quality news on social media, perceptions of news \ncredibility greatly influence the effects of news encountered during social media use (Metzger & \nFlanagin, 2015) . Perceptions of credibility in the context of digital news consumption \ncontinuously evolve. First of all, swelling polarization motivates credibility perceptions  less \nconcerned with news quality, and more fixated on attitude congruency (Kelly, 2019; Metzger, \nHartsell, & Flanagin, 2015; Smith et al., 2019) . Second, audiences have u pdated perceptions of \nwhat qualifies as news  (Edgerly & Vraga, 2019, 2020) . For in stance, a udiences view the New \nYork Times , a news organization possessing numerous years of journalistic expertise, as equally \na \u201cnews\u201d source as Mother Jones and the Drudge Report  (Edgerly & Vraga, 2019). \nConsequently, truly understanding the impact of social media news exposure on racial \nperceptions requires considering perceptions of credibility in the context of political identity.  \nConsidering Credibility  \nMetzger and Flanagin (2 015) describe credibility as a global, multidimensional construct, \nwhich includes subjective evaluations of news\u2019 believability, trustworthiness, accuracy, and \ncredibility. The subjective nature of credibility perceptions suggests that audiences can reach \ndiverging conclusions on news credibility (Metzger & Flanagin, 2015) . While assessing the \ncredibility of news, au diences look for credibility cues. Credibility cues may include the news \nsource  (Metzger et al., 2015) . Strong partisans, Republicans and Democrats alike, as cribe greater \ncredibility to congruent news sources  (Stroud, 2011; Stroud & Lee, 2013) . For instance, research \n \n 24 regarding dichotomous credibility perceptions consistently compare partisan perceptions of Fox \nNews and CNN. Strong Republicans view Fox News as more credible than CNN, while strong \nDemo crats view CNN as more credible than Fox News (Stroud & Lee, 2013).  \nPartisan differences in credibility perceptions of news sources also extends to social \nmedia. Edgerly and Vraga (2020) found that Democrats rate tweeted headlines from the \nAssociated Pres s or MSNBC as higher in news -ness (compared to Fox News ). Inversely, \nRepublicans view tweets from MSNBC as less newsworthy than headlines originating from Fox \nNews  (Edgerly & Vraga, 2020). Perceptions of social media content as \u201cnews\u201d reduces intention \nto verify the message (Edgerly & Vraga, 2020). The content of news stories serves as another \nrelevant cue for forming perceptions of news credibility (Kelly, 2019; Metzger et al., 2015) \nespecially in social media where users may encounter news sources they wo uld not otherwise \nencounter (J. L. Nelson & Taneja, 2018) .  \nPartisans are remarkably effective at recognizing party -aligned narratives in the presence \n(Metzger et al., 2015) or absence of source cues (Kelly, 2019) . Narratives that reiterate part isan \nbeliefs can serve as a credibility heuristic, motivating partisans to ascribe greater credibility to \nthese news frames (Kelly, 2019). Partisan differences in perceptions of credibility may also stem \nfrom partisanship in relation to media exposure. Con tinuous exposure to partisan media \nconstructs and reinforces cognitive schemas created by exposure to news frames (see Knobloch -\nWesterwick, 2012; Stroud & Curry, 2015) . When news upholds these schemas, audiences \nperceive them as credible (see Melican & Dixon, 2008; Shrum, 2009) . Perceptions of news \ncredibility, whether due to partisanship, prior media exposure, or other elements, predict how \nnews sways audiences\u2019 attitudes. In the context of social media news consumption, the greater \n \n 25 the perceptions o f news available on social media, the greater its influences on social media \nusers.  \nMass Media in the Era of Social Media  \nThe social media environment makes understanding f raming and framing effects less \nclean -cut, as audiences have individual media expe riences (Metzger, 2009) . Audiences encounter \nnews contingent on their social connections or their selection behavior (Thorson & Wells, 2015 ). \nFurthermore, partisanship and perceptions of credibility can greatly shape how audiences interact \nwith news encountered during social media use. Researchers assert that these niche experiences \nin an ever expand ing, high -choice news ecology, render the concept of mass media effects no \nlonger relevant  (Bennett & Iyengar, 2008; Metzger, 2009) . Mass media effects are essentially \nlimited because personalized  information flow constructs diverging, parallel po litical realities \n(Bennett & Iyengar, 2008; Bennett & Pfetsch, 2018; Metzger, 2009) . I contend that  mass media \neffects still occur and framing still helps inform  scholarship on  how news exposure shapes \naudiences\u2019 perception s. However, framing effects in the era of social media use stem from a \ncombination  of offline and online news consumption, as well as individual connections on social \nmedia.  \nIn a high -choice media environment, a udiences  can construct news repertoires , whi ch \ncombin es news from multiple offline (e.g., network news) or online (e.g., news websites) news \nsources. Additional exposure to news on social media can subsidize users\u2019 news use, amplifying \nensuing media effects (Kleinnijenhuis et al., 2019). Kleinnijenh uis et al.  (2019)  describes this \nprocess as a two -step flow akin to the traditional two -step communication model. Audiences\u2019 \nself-selected media choices facilitate consistent exposure to news frames that may  reinforce the \nframing effects of traditional news exposure. Similar two -step framing effects may occur when \n \n 26 considering reinforcement of crime or immigration frames. Although audiences maintain unique, \nindividual news repertoires, news audiences cluster by political ideology. Democrats attend to \nmainstr eam and liberal -leaning media, Republicans overwhelmingly select right -leaning news \nsources. Such ideological clustering lends itself to consistent exposure to ideologically aligned \nnews frames, especially for Republicans consuming conservative news source s. Specific sources \nmay differ (e.g ., Fox News  vs. Infowars ), but the frames presented within these conservative \nsources may prove highly consistent (Entman & Usher, 2018). Encountering ideologically \naligned content on social media due to social connection s or selection behavior will amplify  the \nimpact of news exposure.  If this occurs, social media merely amplif y framing effects that occur \nduring non -social media news exposure.  \nContrarily , social media news exposure may supersede the influence of television news, \nprint news, and news websites. Traditional television and print news organizations retain a \nsubstantial social media presence, evident by the amount of social media users who elec t to \nfollow these news organizations (Rosenstiel et al., 2015) . However, television news, print news, \nand news websites  do not control the flow of news on social media. First, d igitally native sources  \nthrive on social media (\u201cDigital news fact sheet,\u201d 2019) . Newly established digitally native news \nsources such as Breitbart or The Root  have found a proli fic following of readers on social media \n(\u201cDigital news fact sheet,\u201d 2019) . Second, social media users maintain more agency in soci al \nmedia environments via the news they share and the other users the y follow. These affordances \ncreate a contingent flow of news where content may diverge from that of non -social media \nsources  (see Russell Neuman et al., 2014) . For instance, social media discuss ion and news \nsharing on specific topics can potentially outnumber that of traditional news cycles.  \n \n 27 Framing effects due to social media facilitated encounters with  a variety of news sources \nmay outweigh that of non -social media news exposure. If this occurs, I propose that framing \neffects would be decentralized . Decentralized framing effects contend that opportunities for \nnews dissemination afforded within digital in formation environments shifts influential power \naway from (what was) a finite number of large news organizations and distributes it to various \nactors on social media. As a result, audience opinions that typically stem from heavy versus light \nmedia consumpt ion are outweighed by the content audiences encounter during social media use. \nFor instance, heavy media use typically results in increased stereotype endorsement or support \nfor punitive policy prescriptions (Dixon, 2006; Watson & Riffe, 2012). The occurre nce of \ndecentralized framing effects suggests that social media use would push framing effects in the \nopposite direction. In other words, the variety of sources on social media prove so influential that \naudience opinions are less of a \u201cmass media\u201d phenomen on, and more so contingent on individual \nexposure to a wide array of  news sources available on social media ( Bennett & Pfetsch, 2018 ). \nSocial Media News: Racialized Crime and Immigration News Frames  \n Given the potential framing effects described above, I p ropose a series of research \nquestions and hypotheses addressing the impact of social media news exposure on perceptions of \nviolent crime and immigration. Partisan sources  encountered during social media use  may \nemploy different  crime and immigration frames . The Republican Party \u201cowns\u201d the issues of \ncrime and immigration , so much as that the electorate views the Republican Party as best suited \nfor protecting Americans against violent criminals or immigrants  (Goggin et a l., 2019; \nValentino, 1999) . Political leverage  afforded by the connection between Republicans and a \n\u201ctough on crime or immigration\u201d ideology incentivizes conservative sources to focus on violent \n \n 28 crime and immigration  in a manner that depicts African Americans or Latinos as intrinsic threats \n(Abramowitz & McCoy, 2019; Ab ramowitz & Webster, 2018; see Baum & Groeling, 2008) .  \nThe Democratic Party, on the other hand, embraces racial inclusivity and tackles social \nissues, such as inequality or discrimination (Drakulich et al., 2020; Philpot & Miller, 2020) . \nConsequently, liberal news sources may appeal to these principles by sharing news in which \nAfrican Americans or Latinos are sympathetically depicted. The role of partisan identity in \ncurating social media content combined with right -leaning sources\u2019 prop ensity to invoke \nracialized crime or immigration news frames, places Republican -leaning social media users at \nrisk of high exposure crime or immigration news frames  that incorporate negative depictions of \nAfrican Americans or Latinos . Democrat -leaning user s, however, may encounter news with \nAfrican Americans or Latinos in more sympathetic roles. Consequently, I first consider the news \nframes present in participants\u2019 social media networks.  \nH1a: Republican -leaning participant networks will contain greater am ounts of race -centered, \nviolent crime frames depicting African Americans or Latinos as criminals than Democrat -leaning \nparticipant networks.  \nH1b: Republican -leaning participant networks will contain greater amounts of race -centered \nimmigration frames depi cting Latinos than Democrat -leaning participant networks.  \nRQ1: Are there  racial differences in the amount of race -centered  violent  crime frames depicting \nAfrican Americans or Latinos available in participant networks?  \nRQ2: Are there racial differences in t he amount of race -centered immigration frames depicting \nLatinos available in participant networks?  \nSecond, I consider the impact of exposure to these news frames on social media users. \nSocial media exposure to violent crime or immigration news can impact audiences\u2019 level of \n \n 29 stereotype endorsement . The inclusion of racial stereotypes  in news also influences public \nopinion on crime and immigration policy, such that audiences would support punitive policies \n(Dixon, 2008a; Figueroa -Caballero & Mastro, 2 018). Favorable depictions of African Americans \nor Latinos, on the other hand, promote opposing effects. Sympathetic depictions of African \nAmericans or Latinos are capable of decreasing stereotype endorsement or support for punitive \npolicy recommendations.   \nH2: Participants potentially exposed to greater amounts of race -centered, violent crime frames on \nsocial media will report greater African American and Latino stereotype endorsement.  \nH3: Participants potentially exposed to greater amounts of race -center ed immigration frames on \nsocial media will report greater perceptions of immigrants as a threat.   \nH4a: Participants potentially exposed to greater amounts of race -centered, violent crime frames \non social media will report greater support for punitive crim e policies.  \nH4b: Participants potentially exposed to greater amounts of race -centered immigration frames on \nsocial media will report greater support for punitive immigration policies.  \nH5: Participants will report issue interpretations consistent with frame s prevalent in individual \nsocial media news feeds.  \nThe above hypotheses consider the effects of news frames social media users may \nencounter during social media use. However, it does not account for the sources social media \nusers may encounter and the impa ct of exposure to these sources. While social media contain \nnews from popular legacy news sources,  the affordances of social also open the door to an \nabundance of digitally native news sources . Consequently, I consider  the news sources available \nin partici pants\u2019 social networks.  \nRQ3a: What news sources are present i n participants\u2019 social media networks?   \n \n 30 RQ3b: Are there partisan differences in the news sources present in participants\u2019 social media \nnetworks?  \nRQ4a: What types of news sources are present in p articipants\u2019 social media networks?  \nRQ4b: Are there partisan differences in the types of news sources present in participants\u2019 social \nmedia networks?  \nRQ4c: Are there partisan differences in the partisan lean of sources present in participants\u2019 social \nmedia  networks?  \nSocial media news consumption does not occur in isolation of other offline and online \nnews use. Understanding whether news encountered during social media use  amplifies  or \nattenuates the  effects of participants\u2019  offline and online news  use helps fit social media into the \nlarger news ecology. Thus, I ask the following.  \nRQ5: Do effects associated with news sources present in participants\u2019 social networks moderate \neffects associated with participants\u2019 news repertoi res?  \n Lastly, I consider the role of credibility perceptions in explaining the effects of social \nmedia news exposure. As previously discussed, news available on social media exhibit varying \nlevels of credibility. News disseminated on social media may pres ent overtly  biased depictions  of \ncrime and immigration . Politically motivated disinformation represents a  salient example of \ndetrimental content available on social media ( Freelon & Wells, 2020 ). Purveyors of \ndisinformation employ \u201cblack\u201d or \u201cgray\u201d propaganda techniques, such as subtlety blending \nfactual content with fabrications or illogical half -truths to mislead audiences for political gain \n(Benkler et al., 2018; Farris et al, 2017).  The fact th at both \u201cfake\u201d news sources and political \ndisinformation are more likely to present conservative -aligned news frames (Allcott & \nGentzkow, 2017; Mour\u00e3o & Robertson, 2019), suggests that such sources will weaponize \n \n 31 racialized crime or anti -immigrant discours e (Bennett & Livingston, 2018; Faris et al., 2017) . \nAlthough content users may encounter  on social media may lack explicit indicators of credibility, \nusers may find it credible. Perceptions of credibility impact how audiences process news, such \nthat news exposure produces a greater effect. Consequently, I propose the following.   \nH6: Percepti ons of credibility associated with social media news will moderate  the relationship \nbetween exposure to race-centered crime frames  depicting African Americans or Latinos and \nsubsequent attitudes.  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n 32 CHAPTER 3: STUDY 1  \n \nStudy 1 content analyzed crime and immigration news available within Twitter users\u2019 \nindividual social networks. Specifically, the study focused on the frames employed within crime \nand immigration news, as well  as the sources disseminating crime and immigr ation news. For \nthe content analysis, I utilized publicly available digital information of the participants\u2019 social \nconnections as trace evidence of the news participants encountered.  \nMethod  \nParticipants  \n 244 adult Twitter users over the age of 18 were r ecruited through a Qualtrics panel. \nQualtrics panel participants take part in various surveys for different amounts of remuneration. \nRecruitment was stratified by demographic characteristics to: (a) mirror the age and gender \ndemographics of Twitter users , and (b) provide an equal racial representation for comparison. \nResponses were collected between November 17, 2019 and January 6, 2020. The total sample (N \n= 244) reflects the demographics of Twitter users in terms of age  (M = 36.05, SD = 12.38), \ngender ( 47.13% female), education (32.37% high school or less, 22.54% some college or trade \nschool; 45.08% BA/BS or more), and income (60.25% $60,000 or less per year ). All respondents \nincluded in analysis consented and willingly provided their publicly available T witter IDs.  \nSurvey Procedure  \n Upon entering the survey, participants were informed that the purpose of the survey was \nto understand relationships between social media use and social/political opinions. Participants \nwere also informed that the survey would  request their Twitter ID. After providing their \ninformed consent, the online questionnaire prompted participants to provide their demographic \ninformation (i.e., race and ethnicity, age, gender, income, and education) and their Twitter ID. A \n \n 33 Twitter ID is as unique sequence of numbers assigned to each Twitter user. Unlike, Twitter \nusernames, Twitter IDs cannot be altered or changed. Furthermore, even when a user elects to \nchange their Twitter username, the Twitter ID remains the same. Consequently, this stu dy \nelected to use Twitter IDs as a more permanent digital trace indicator.  \n To obtain participants Twitter IDs, participants were first asked if they use Twitter. If the \nparticipant indicated that they use Twitter, they were directed to an external website  created for \nthe purpose of this dissertation. 1 The website instructed participants to provide their Twitter \nusername. Using a Twitter developer application, the website used the inputted Twitter username \nto provide the corresponding Twitter ID. 2 Partici pants were then instructed to copy and paste the \nTwitter ID into the Qualtrics survey. After providing their Twitter ID, participants completed \nmeasures for party lean, as well as additional measures discussed in Study 2.   \nSurvey Measures  \nRace. Participants indicated their ethnicity as either Hispanic (31.80%) or non -Hispanic \n(67.78%). After providing their ethnicity, participants specified their race using the following \ncategories: American Indian or Alaska Native, Asian, Black or African Americ an, Middle \nEastern, Native Hawaiian or other Pacific Islander or White. Participants  were only allowed to \nselect one of the provided racial categories, and the racial categories are consistent with the U.S. \ncensus racial categories. For analysis, the ethni c and racial categories were collapsed into the \nfollowing categories: American Indian or Alaska Native, Asian, Black or African American, \nMiddle Eastern, Native Hawaiian or other Pacific Islander, White, and Hispanic. The Hispanic \n \n1 https://getid.smresearchstudy.com   \n2 The website used Twitter API to convert participants\u2019 usernames into a Twitter ID. Twitter API only provides the \nTwitter ID for publicly available Twitter pages. I used a list of Twitter IDs produced by the website to crosscheck \nparticipants in the final sample, stratifying the sample to only include participants who provided a public and valid \nTwitter ID.  \n \n 34 category includes all par ticipants who indicated their ethnicity as Hispanic. The sample included \nthe following racial representations: .43% American Indian or Alaska Native, 9.13% Asian, \n27.83% Black or African American, .87% Middle Eastern, .43% Native Hawaiian or Another \nPacifi c Islander, 30.87% White, and 30.43% Hispanic. Given the low number of participants \nidentifying as American Indian or Alaska Native, Asian, Middle Eastern, or Native Hawaiian or \nother Pacific Islander, these racial groups were collapsed into one category ( i.e., \u201cOther\u201d).  \nParty lean. Participants were first asked whether they identify as a Democrat, \nRepublican, or Independent. If participants indicated identification as a Democrat or Republican, \nparticipants assessed the strength of their identification (i. e., \u201cstrong\u201d or \u201cnot very strong\u201d). If \nparticipants indicated identification as an Independent, participants designated whether their \nidentification was \u201cCloser to the Democratic Party,\u201d \u201cCloser to the Republican Party,\u201d or \u201cCloser \nto neither party.\u201d  \nSince predictions concerning partisan identification compare Democrat leaning to \nRepublican leaning participants, true independents (i.e., \u201ccloser to neither party\u201d) were excluded \nfrom analysis (n = 27) . Remaining partisans were coded as Democrat -leaning or Re publican -\nleaning. The sample of partisans included  70.50% Democrat -leaning participants and 29.49% of \nRepublican -leaning participants.  \nSample  \n Participants\u2019 Twitter IDs were used to obtain a list of Twitter users followed by survey \nparticipants. I obtaine d the list of Twitter users using the rtweet  package in R. The package \nincludes the function get_friends , which returns a list of user IDs for accounts followed by the \nspecified user s (Kearney, 2019). After removing participants who provided duplicate Twitter \nIDs, the final sample included 190 participants who followed at least one user on Twitter ( M = \n \n 35 594.85, SD = 1145.31, min = 1, max = 5000). The final sample consist s of the following \ndemographics: age (M = 36.83, SD = 12.71), gender ( 48.42 % female), education (30.53% high \nschool or less, 24.21% some college or trade school; 45.26% BA/BS or more), family income \n(57.37% $60,000 or less per year), and race (25.82% Black or African American; 34.07% White, \n30.77% Hispanic, and 9.34% Other). Addi tionally, the final sample contained a majority of \nDemocrat -leaning participants  (70.83%) .  \nAlthough the final sample contains a majority of Democrat -leaning participants and \nparticipants reporting higher levels of education, the high representation of edu cated participants \nreflects the actual demographics of Twitter users (Wojcik & Hughes, 2019) . According to the  \nPew Research Institute, 60% of adult Twitter users are Democrat -leaning, while only 35% of are \nRepublican -leaning. The demographics of Twitter users also skew towards a more educated \npopulation and 42% of Twitter users report being a college graduate (Woj cik & Hughes, 2019).  \nNews Sample  \n Before beginning the coding process, I first collected tweets shared by users followed by \nthe survey participants. Twitter data was collected in R using the rtweet  package (Kearney, \n2020) . Twitter API limits queries requesting user tweets to 3200 tweets per 15 -minute interval. \nGiven Twitter\u2019s API limitatio ns and the variance in the number of users the participants \nfollowed, I created a ratio to standardize the number of tweets collected for each survey \nparticipant. In the ratio, n represents the number of tweets requested in the Twitter API query \n(see Figur e 3.1).  \n \nFigure 3.1.  Standardized Data Collection Equation  \n \n \n 36  To illustrate, if a survey participant followed 120 users, the query requested a total of 25 \ntweets per user followed by the survey participant. As for participants following a large number \nof Twitter users (i.e., > 3000), the ratio proved inadequate. Cons equently, for these participants, I \nrandomly sampled a total of 3000 users followed by each survey participant. The random sample \nof 3000 Twitter users facilitated the use of the ratio to determine the n used in the query. The \nquery of tweets shared by use rs followed by the survey participants yielded 530,681 unique \ntweets.  \n Since the research questions and hypotheses focus on crime and immigration news, I first \nfocused on collecting potentially relevant news articles. For this process I reduced the sample  to \ntweets containing URLs ( N = 195,322). Next, I removed URLs linking to Twitter or other social \nmedia sites (e.g., Facebook, Instagram, YouTube, and Reddit). While many consider social \nmedia a valid source of news, social media posts do not qualify as a \u201cnews\u201d site. I removed \nadditional non -news content such as fashion, beauty sites, music, video game, book, movie, real \nestate, or giveaway sites. These exclusions were determined by considering keywords within the \ntweet or the URL. Example keywords include d sports , trailer , music , beauty , cosmetics , \ngiveaway , sweepstakes , hair, exercise , skin care , and eyeshadow . The keyword list was created \nusing an iterative process where I examined the top used words in the tweets for irrelevant \nkeywords and combined the se keywords with a dictionary created during previous research. \nLastly, I limited the sample to tweets dating back to 2016 -01-01. The sample included  46,673 \ntweets containing URLs.  \nThe next step required collecting the text from articles included in the fi nal sample. \nTextual data were collected using web -scrapping code written in R. Web -scrapping requires that \nthe written code consider the design of the website. For instance, Fox News and CNN  place the \n \n 37 article\u2019s text in a different position on their website . The written R code accounted for  different \nsite design s for the most shared news sources. 3 I employed generic web -scrapping code for \nobscure news sources (shared less than 15 times). This process helps avoid collecting \u201cmessy\u201d \ntextual data. Web -scrappin g proved successful in 76.35% of the scrapped sample ( N = 35,637). \nRemaining articles were unavailable due to broken or dead URLs (e.g., 404 Not Found HTTP \nstatus code). Textual data were cleaned by removing embedded URLs, embedded video html \ncode, special characters, white space, and non -English text.  \nFinall y, I employed a dictionary approach to select crime and immigration news. The \ndictionary was created during a previous content analysis pertaining to crime and immigration \nnews. In the previous research project, I collected tweets disseminated on Twitter i n the three \nmonths leading to the 2016 presidential election (2016 -08-08 to 2016 -11-08). The tweets \ncollected used the key words \u201ccrime\u201d and \u201cimmigration\u201d. Following data collection, I conducted \nLatent Dirichlet Allocation  (LDA) topic modeling to examine t he latent topics associated with \nthese keywords. I used the distribution of the words over the topics to expand the crime and \nimmigration dictionary. Crime keywords included crime , criminal , murder , robbery , mass \nshooting , attempted murder , manslaughter , assault , murderer , armed robbery , homicide , \nrobberies , sexual assault . Immigration keywords included immigration , immigrant , illegal \nimmigrant , undocumented  immigrant , illegal alien , immigration  and customs enforcement .  \nAdditionally, I also used a dictiona ry for excluding irrelevant news articles (also created \nduring the project discussed above). The exclusion dictionary removed entertainment news (i.e., \nNetflix, Hulu, Amazon Prime, streaming, IMBD, podcast ), news of cybercrime (i.e., cybercrime , \n \n3 Web scrapping code included CSS elements for the most shared news  sources. CSS elements point the web \nscrapping code to scape certain portions of the website (e.g., the body paragraph versus the headline). I used the \nselectorgadget  (https://selectorgadget.com ), a Chrome add -on to compile the  CSS element of interest.  \n \n 38 cybersecur ity). News articles from the timeframe selected for this project also include heightened \ndiscussion of Syrian migrants in international news. Given that immigration is discussed \ndifferently in countries outside of the United States, the inclusion of this t ext may prove \ndetrimental during the supervised machine learning process. Consequently, I used the keyword \ndictionary from previous research to exclude foreign news (e.g., Sweden, Iraq, Turkey, Brexit ). \nLastly, I excluded news about COVID -19 (i.e., covid  and coronavirus ). The final sample \nincluded 2,765 articles.  \nContent Analysis  \n The content analysis combines human coding, supervised machine learning, and natural \nlanguage processing. Supervised machin e learning is a semi -automatic coding method that uses \nhuman -coded documents to train a computer algorithm capable of classifying additional, similar \ndocuments  (Grimmer & Stewart, 2013; Pilny, McAninch, Slone, & Moore, 2019) . The initial \nsteps for supervised machine learning are similar to that of traditional content analyses (Pilny  et \nal., 2019). Th at is, humans must first classify a subset of documents from the sample of interest.  \nHuman Coding and Reliability  \nFour graduate students, including the primary researcher, classified articles to be used for \nsupervised machine learning. Coders were trained  using digital news articles outside the actual \nsample until acceptable levels of intercoder reliability were attained. Coders received 48 hours of \ntraining over a 16 -week period. Graduate student coders classified a random subset of news \narticles from the  sample of tweets ( n = 300). Researchers recommend classifying an additional \nvalidity sample to ensure the validity of the machine learning algorithm (Pilny  et al. , 2019). A \nvalidity sample ensures that the trained algorithm proves effective for generally classifying crime \nor immigration news, rather than only efficiently classifying the particular sample of articles.  \n \n 39 The validity sample (n = 100) was collected from the news website Media Cloud. 4 Media \nCloud is an open source, media ecosystem platform  (\u201cWhat We Do,\u201d n.d.) . Media Cloud tracks \nand aggregates news articles from various databases. Using a Boolean search containing \nkeywords from the crime and immigration dictionary, I collected a sample of 100 news  articles \npublished during the same timeframe of articles included in the sample collected from Twitter. \nTo ensure that the sample is as diverse as the Twitter sample, the validity sample includes \narticles from multiple Media Cloud databases: U.S. Top Digi tal Native Source 2018, U.S. Top \nNewspapers 2018, U.S. Top Online News 2017, Fake News, Left News, and Right News. 5 Total \nreliability was assessed using a subset of news articles from the sample ( n = 45) and 20% of the \nvalidity sample ( n = 20). Krippendor ff\u2019s alpha reached acceptable levels, ranging from .83 to .97. \nAfter subjecting the validity sample to the same screening process as described above, 82 articles \nremained.   \nCoding Scheme  \n The news articles obtained for the study served as the unit of analysis. Human coders \nclassified the topic of the news articles and the news frame of each news article (see Appendix \nA).    \nNews Topic. Coders assessed whether the news article was about crime, immigration , or \nundocumented immigration . To avoid noise during the supervised learning procedures, coders \nwere instructed to consider whether the entire article was about the topic of interest. This \n \n4 https://mediacloud.org  \n5 U.S. Top Digital Native Source 2018: Top U.S. digital native news sources of 2018 based on Pew Research \nCenter data published in August 2019; U.S. Top  Newspapers 2018:   Top U.S. newspapers of 2018 based on Pew \nResearch Center data published in August 2019; U.S. Top Online News 2017:  Top U.S. news websites of 2017 \naccording to comScore, Activate, and Alexa; Fake News:  List of fake news sites from Buzzfee d 2016 fake news \nreport; Left News:  Sources categorized as \u2018left\u2019 based on number of URLs shared in tweets by Clinton vs. Trump \nsupporters; Right News:  Sources categorized as \u2018right\u2019 based on number of URLs shared in tweets by Clinton vs. \nTrump supporters.   \n \n 40 procedure avoids including articles that mention the topic, but primarily focus on an irrelevant \nissue. Guidelines included considering the article\u2019s headline and the article\u2019s text, determine \nwhether the two combined elements presented a complete  crime, immigration, or undocumented \nimmigration narrative. To pic classification was not mutually exclusive.  \nThe crime  variable determined whether the article was about violent crime  (\uf061 = .89). The \nFBI Uniform Crime Report defines violent crime as offenses involving force or threat of force. \nConsequently, coders clas sified articles containing reports  of murder, nonnegligent \nmanslaughter, forcible rape, robbery, or aggravated assault (including hate crime) as a news \narticle about crime. The immigration  variable assessed whether the article reported on \nimmigration ( \uf061 = .98). Lastly, the undocumented immigration (\uf061 = .83) variable focused on \nwhether the article emphasized undocumented immigration. Undocumented immigration did not \ninclude asylum seekers unless the article explicitly questioned the legality of their immigra tion \n(e.g., referring to asylum seekers as \u201cillegals\u201d).   \nNews Frame . In addition to classifying the article\u2019s topic, human coders labeled the news \nframe  used when discussing the topic. News frames were adapted from the Policy Frames \nCodebook (Boydstun, Gross, Resnik, & Smith, 2013) . The Policy Frames Codebook lists \ngeneralized frame dimensions that can be applied to multiple issues ( Boydstun  et al., 2013 ). \nGeneral frame analysis, as opposed to news  frames primarily associated with crime or \nimmigration, allow for comparisons across topics. The codebook included the following frame \ncategories: 1) economic frame, 2) capacity and resources frame, 3) morality frame, 4) fairness \nand equality frame, 5) leg ality, constitutionality and jurisdiction frame, 6) security and \ndefense/law and order, crime, and justice frame, 7) health and safety frame, 8) quality of life \nframe, 9) cultural identity frame, 10) public opinion frame, 11) political frame, 12) policy \n \n 41 prescription and evaluation frame, 13) external regulation and reputation frame, and 14) legality, \nconstitutionality, and jurisdiction frame in a political context. News frames outside of these \ncriteria were coded as other.  \n Recognizing that news articles s eldom use a lone news frame, coders assigned each \narticle a primar y and secondary  news frame. Coders classified the dominant news frames used \nmost frequently throughout the text as the primary  news frame. Coders were instructed to \nconsider the frame that w ould come across most strongly to audiences and the frame most likely \nto stick in audiences\u2019 minds. Coders classified the second most prevalent news frame used within \nthe text as the secondary  news frame. The primary and secondary news frames assisted in \nobtaining inter -coder reliability. Specifically, before calculating inter -coder reliability, I \ndetermined the consensus between coders with respect to their choice of the primary frame \nversus the secondary frame. To illustrate: if three coders classified th e primary frame as a \npolitical frame and the fourth coder classified the secondary frame as a political frame, I re -\naligned the fourth coder\u2019s primary frame as a political frame. The frame classified by the \nmajority of the human coders served as the consen sus code. These processes resulted in adequate \ninter-coder reliability (\uf061 = .92).  \nSupervised Machine Learning  \nBefore beginning the supervised machine learning process, I created a ground -truth  \nvariable. Supervised machine learning necessitates a single -vector inference code for each \nclassified documented (Pilny et al., 2019, p. 4). Since the content analysis employed four human \ncoders, there were instances of coder disagreement within the reliability sample. 6 A single \n \n6 Articles in the reliability sample were collected from the broader sample of news articles. However, once I \ncompleted the selection method described above, a few articles from the reliability sample were not included in the \nfinal sample of crime and im migration articles.  \n \n 42 ground -truth variable was created for  each variable in all instances of coder disagreement \n(crime: n = 3; immigration: n = 1; news frame: n  = 1). Ground -truth variables were created \nselecting the classification agreed upon by the majority of the human coders. For example, if \nthree coders cla ssified the article as being about crime, the crime classification became the \nground -truth. The human coded sample included a small number of articles coded as pertaining \nto undocumented immigration ( n = 25), insufficient for the supervised machine learning process. \nConsequently, further analysis did not consider undocumented immigration.  \nTextual Analysis  \nMy approach to supervised machine learning  used a bag of word s approach (see Pilny et \nal., 2019). The first step required tokenization, splitting of the text into tokens  (Silge & \nRobinson, 2017) . Tokenization treated each word as the unit of ana lysis. During tokenization I \nremoved capitalization, hyphens, punctuation, symbols, URLs, and Twitter text (i.e., @username \nand #hashtag). Lowering the case of the text allows for the computer to recognize that the word \nis the same, despite its\u2019 letter cas e (e.g., Immigration versus immigration).  \nNext, I removed stop words and other irrelevant words from the list of tokens. Stop \nwords (e.g., \u201cand,\u201d \u201cof,\u201d \u201cthe\u201d, \u201cby\u201d, \u201csaid\u201d) are extremely common in the English language, and \nconsequently unhelpful in identifying unique words associated with specific  news topics and \nnews frames (see Silge & Robinson, 2017). The dictionary also removed the names of all news \nsites present in the sample (e.g., Fox News  or CNN ), days of the week (e.g., Monday), months in \nthe year (e.g., January), states (e.g., California or CA), regions (e.g., Southwest), and text \nreferring to social media engagement (e.g., subscribe, click, share). These words are prevalent in \nonline news articles, especially in the lead, and do not assist in classifying the topic of the news \n \n 43 article. Nex t, I created uni and bigrams. Unigrams are single tokens and bigrams refer to two \ntokens commonly used together (e.g., sexual assault or Donald Trump).  \nThe second step for supervised machine learning requires the creation of a document \nfrequency matrix (D FM). A DFM decomposes the data where each row represents a news article \nand each column contains a token within the document. During the creating of the DFM I \nstemmed the tokens. Stemming is a linguistic process of reducing a word to its base or root form \n(Pilny et al., 2019). For instance, the process of stemming would reduce immigrant, immigrants, \nand immigration to immigr . Stemming assists the computer in recognizing identical words, \nirrespective of tense use in the text.  \nDocument frequency matrices con tain the absolute frequency of each term in the \ndocument. However, frequent words are not necessarily important features of a document (see \nSilge & Robinson, 2017). Consequently, I weighed the words within the DFM considering the \nproportional term frequenc y (TF) and the inverse document frequency  (IDF). TF -IDF measures \nthe importance of each word by decreasing the weight of commonly used words (TF) and \nincreasing the weight of words that are not commonly used across the documents (IDF). This \nprocess extends  greater importance to words that prove significant to each article.  \nSupervised Machine Learning Algorithms  \n Supervised machine learning offers a number of algorithms that assist in the classification \nof documents, including na\u00efve Bayes  (NB), support vector machine  (SVM), and random forest  \n(RF) (Lantz, 2019) . NB applies Bayes Theorem to classify documents. NB calculates the \nprobability of a binary or nominal outcome or, in the instance of classifying documents, the \nprobability that a document belong s to a category. SVM classifies documents by creating a linear \nhyperplane, which separates the documents into categories. SVM uses prominent features of the \n \n 44 classified documents to create a hyperplane that best separates the available classifications (i.e. , \nmaximum margin hyperplane). When utilizing SVM, researchers can utilize kernels tricks for \nanalyzing non -linear data (e.g., polynomial, radial). Lastly, RF borrows from another machine \nlearning algorithm, decision trees. Decision trees use a top -down met hod to partition the data \nuntil each subdivided portion is highly populated by the one or more classes (Aggarwal, 2018, p. \n142). Word features, in this case TF -IDF, serve as the criteria for creating these subdivided \nportions and determining whether a document cont ains the words relevant to that subdivision (or \nbranch). RF randomizes the tree construction, creating multiple individual decision trees (i.e., a \nforest of decision trees). RF gathers information from the individual decision trees to select the \nbest featu res for splitting the data. I utilized all three algorithms during the supervised machine \nlearning process to determine which algorithm performed best in classifying the article\u2019s topic \n(i.e., crime or immigration) and news frame.  \nSupervised Machine Learn ing DFM and Feature Selection  \nTo help reduce noise during the supervised machine learning  process, I created separate \nweighted DFMs for each outcome variable of interest. Additionally, the crime and immigration \nweighted DFMs were created considering the ou tcome variables as mutually exclusive. That is, \nthe crime weighted DFM excluded articles classified as being about immigration, and the \nimmigration weighted DTM excluded articles classified as pertaining to crime. All articles with \nnews frame classificatio ns were included in the creation of the frame weighted D FM. \n Next, I first examined which features (i.e., unigrams and bigrams ) should be included in \nthe creation of the supervised machine learning  models. Feature selection increases the overall \naccuracy and interpretability of the supervised machine learning  model (Kuhn & Johnson, 2013; \nPilny et al., 2019) . Feature selection involves the process of removing non -informative features \n \n 45 that reduce the effectiveness of the model and redundant predictors that create multicollinearity \n(Kuhn & Johnson, 2013). The two primary methods of feature selection are filter  and wrapper  \nmethods. Filter methods are the most basic mechanism\u2019s for feature selection. Filter methods \nassist in ranking the importance of the model\u2019s features (Kuhn & Johnson, 2013). However, the \nfilter method does not consider relationships between the  variables (e.g., multicollinearity) \n(Kuhn & Johnson, 2013). Consequently, I used the latter feature selection method.  \n Wrapper methods perform an iterative search of the features to determine which features, \nwhen entered into the model, provide the best model performance (Kuhn & Johnson, 2013, p. \n491). Of the potential wrapper methods available, I used a correlation -based feature selection \nmethod (CFS). The CFS algorithm selects features that demonstrate strong correlations with the \noutcome variable, whil e concurrently selecting features with low between -predictor correlations \n(Kuhn & Johnson, 2013, p. 494).  \nI performed the CFS wrapper method in R using a fast correlation -based filter solution \n(FCFS) (Yu & Liu, 2003) . This \u201cfast\u201d method for CF  incorporates a filter method prior to the \nwrapper methods, which proves m ore time efficient for large, high -dimensional data (i.e., large \nDFM). The FCFS uses symmetrical uncertainty to determine the goodness of the available \nfeatures (Yu & Liu, 2003).  The first step of the FCFS requires examining the available features \nto deter mine a symmetrical uncertainty threshold with maximum correlation with the outcome \nvariable. The second step of the FCFS performs the wrapper method on these features. Appendix \nC reports the features selected for crime, immigration, and frame analysis, res pectively, as well \nas its corresponding symmetrical uncertainty  measures.  \n \n \n \n 46  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nTable 3.1 \nReliability and Validity Tests for Crime and Immigration Supervised Machine Learning Classifiers  \n \n  Reliability test  Validity test  \nClassifier  Accuracy  Precision  Recall  F-Measure  Accuracy  Precision  Recall  F-Measure  \nCrime          \nNa\u00efve Bayes  .80 .75 .75 .75 .79 .75 .60 .67 \nSupport Vector Machine  .82 .79 .75 .77 .77 .71 .60 .65 \nRandom Forest  .94 1.00 .78 .88 .91 .94 .79 .86 \nImmigration          \nNa\u00efve Bayes  .91 .92 .85 .88 .91 .85 .89 .87 \nSupport Vector Machine  .62 .00 .00 .00 .65 .00 .00 .00 \nRandom Forest  .91 1.00 .77 .87 .95 .94 .89 .92 \n \n \n 47 Supervised Machine Learning Reliability  \n \n Using the features selected during the process described above, I created na\u00efve Bayes  \n(NB), support vector machine  (SVM), and random forest  (RF) classification models. Each model \nwas trained using 80% of the relev ant news articles and tested using a 20% hold -out set. \nAdditionally, I tested each model  using the validation sample. Table 3.1 reports the reliability \nand validity tests for each model. Models created using RF provided the best performance in \nclassifying the crime  and immigration  news articles. Specifically, these models proved most \nprecise (i.e., the proportion of true positive classification). Precise models yield less false \npositive classifications, reducing Type 1 error in the classification of the rem aining data set.  \nInitial analysis of the news frames proved more difficult because the training set was \nsmall, and the coded sample did not represent all of the available frame classifications. \nConsequently, I collapsed the framing categories into three c ategories: (a) social frames: \nmorality frame, fairness and equality frame, health and safety frame, quality of life frame, and \ncultural identity frame , (b) political and policy frames : economic frame, capacity and resources \nframe, legality, constitutionality and jurisdiction frame, public opinion frame, political frame, \npolicy prescription and evaluation frame, and legality, constitutionality, and jurisdiction frame in \na political context , and (c) crime and justice  frames : security and defens e, and law and order, \ncrime, and justice frame. The RF model predicting these three classifications performed well (see \nTable 3.2). RF models were used to classify the remaining news articles ( n = 2311). Analysis \nyielded 706 and 143 unique crime and immigr ation articles, respectively. Furthermore, 15 news \narticles focused on both crime and immigration.   \n \n \n \n 48  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  Reliability test  Validity test  \nClassifier  Accuracy  Precision  Recall  F-Measure  Accuracy  Precision  Recall  F-Measure  \nSocial Frame          \nNa\u00efve Bayes  .35 .00 .00 .00 .00 .00 .00 .00 \nSupport Vector Machine  .44 .00 .00 .00 .00 .00 .00 .00 \nRandom Forest  .46 .00 .00 .00 .00 .00 .00 .00 \nPolitical and Policy Frame          \nNa\u00efve Bayes  .64 .70 .59 .58 .83 .93 .72 .81 \nSupport Vector Machine  .79 .90 .64 .75 .70 .69 .61 .65 \nRandom Forest  .86 .92 .79 .85 .86 .80 .89 .84 \nCrime and Justice Frame          \nNa\u00efve Bayes  .89 1.00 .79 .88 .80 .94 .67 .87 \nSupport Vector Machine  .91 .88 1.00 .93 .82 .90 .79 .84 \nRandom Forest  .96 .93 1.00 .95 .90 1.00 .79 .83 \n Table 3.2 \nReliability and Validity Tests for News Frame Supervised Machine Learning  Classifiers  \n \nNote . Overall accuracy for the classifiers in reliability tests: Na\u00efve Bayes = .62; Support Vector Machine = .79; \nRandom Forest = .86. Overall accuracy for classifiers in validity tests: Na\u00efve Bayes = .69; Support Vector \nMachine = .71; Random Forest = .83.   \n \n 49 Race -centered Crime and Immigration News  \nExplicit group mentions were  categorized using a combination of natural language \nprocessing (NLP) and a dictionary approach. Natural language processing is an automated \ncomputational technique, which recognizes the nuances and complexity of human language \n(Jurafsky & Martin, 2019) . To analyze race -centered crime and immigration news, I employed \npart-of-speech  (POS) tagging . POS tagging labels the parts of speech within text (e.g., nouns, \nverbs, adjectives, adverbs) (Jurafsky & Martin, 201 9). POS tags identify noun phrase s, a phrase \ncontaining a determiner (i.e., the modifier of a noun) and a noun. Verbs or verb phrases  (i.e., an \nadverb and/or more than one verb), typically follow a noun phrase. To illustrate, consider the \nsentence \u201c John, a Black man, brutally murdered  a Freeland man in 2015 .\u201d The modifier \u2018 a\u2019 \ninitiates the beginning of the noun phrase , and the nouns \u2018black\u2019 and \u2018man\u2019 serves as the middle \nand end root of the phrase. The verb phrase \u2018 brutally killed\u2019 follows the noun phrase \u2018 a black \nman\u2019 (see Figure 3.2).  \n \n \n \n \n Figure 3.2.  Example of Part -of-Speech Tagging  \nNote . NP = noun phrase; VP = verb phrase.   \n \nText describing racial groups as victims of crime use different syntactical structures. For \ninstance, consider the modified exam ple \u201c John, a Black man, who was killed by a Freeland man \nin 2015 .\u201d POS tagging still identifies the noun phrase  \u2018a black man\u2019  and the verb  \u2018killed \u2019, \nhowever the preposition \u2018by,\u2019 passes the action to another noun phrase  in the sentence (i.e., a \nFreeland man).  John, a Black man, brutally murdered  a Freeland man in 2015 . mid beg end root NP \nVERB  ADV  VP \n \n 50 I completed NLP using spaCy, an open source library for natural language processing 7. \nFirst, I parsed the text, labeling the noun phrases  and parts -of-speech (e.g., adv, verb). Next, I \nused regular expressions to e xtract syntactical patterns of noun phrases, and noun phrases \nfollowed by verb phrases (i.e., adverbs and verbs). I extracted noun phrases containing explicit \nracial mentions (e.g., Black, Latinos, African American, Hispanic) and corresponding violent \ncrime verbs (e.g., murder, kill, shot). 8 \n Identifying the sequence of noun phrases and verbs distinguished mentions of racial \ngroups as perpetrators of crime, as opposed to racial groups as victims of crime. Furthermore, \nnoun phrases  identify groups mentioned  in reference to immigration. Researchers have \nemployed similar methods when examining character mentions in immigration news (Card, \nGross, Boydstun, & Smith, 2016) .  \nResults  \nPreliminary Analysis  \nBefore reporting analysis pertaining to the proposed hypotheses and research questions, I \nfirst analy zed the prevalence of crime and immigration news. Participants\u2019 news feeds contained \ncrime ( M = 20.01, SD = 38.91, per participant) and immigration ( M = 4.58, SD = 9.10, per \nparticipant) news. Crime news employed crime and justice  frames (71.10%), social frames  \n(14.11%) and political and policy frames  (12.79%). Immigration news articles incorporated \npolitical and policy frames  (71.76%), social frames  (18.82%) and crime and justice  frames \n \n7 https://spacy.io  \n8 The violent crime dictionary includes the verb tense of crime keywords used to include crime news articles. \nFurthermore, the violent crime dictionary included words identified by three undergraduate coders as depic ting \ncrime perpetrators. The undergraduate students read crime news articles ( N = 35) and identified words depicting the \ncrime perpetrators.  \n \n 51 (9.41%). A small amount of news articles ( n = 18) were about both crime and immigration, and \nthese news stories also utilized political and policy frames  (61.11%).  \nPreliminary analysis of explicit mentions of race in noun phrases accompanied with \ncrime related verb phrases yielded a small number of phrases ( N = 12). Similarly, immigration \nnews articles only yielded eleven articles containing noun phrases  followed by verb phrases . \nGiven the lack of explicit racial mentions, analysis  focuses on examining noun phrases  with \nexplicit group mentions. The sample include 83 crime news articles containing 246 noun phrases \nwith explicit racial mentions of African Americans and Latinos (e.g., Black family; Mexican \nnational). Furthermore, 52 im migration news articles contained 208  noun phrases with explicit \nmentions of Hispanics or Latinos (e.g., Mexican asylum seekers).  \n \nFigure 3.3.  Top Stemmed Noun Phrases in Crime News  \n \nFrequency  \n \n 52  \n \nFigure 3.4.  Top Stemmed Noun Phrases in Immigration News  \n \nBefore proceeding with hypotheses testing, I conducted a series of \u03c72 test, examining \npotential differences in the proportion of explicit racial mentions by news frame. With respect to \ncrime news, there was a significant difference in mentions of Blacks or African Americans by \nnews frame, \u03c72 (2, N = 716) = 9.05, p < .01. The majority of explicit mentions of Blacks and \nAfrican Americans ( 63.16%) were present in crime and justice news frames. Analysis \ndemonstrated an overall difference in mentions of Hispanic and Latinos in crime news by news \nframe, \u03c72 (2, N = 716) = 12.61, p < .01. The majority of these mentions ( 50.00 %) were present in \ncrime and justice frames (see Table 3. 3). La stly, there was a marginal difference in explicit \nmentions of Hispanics and Latinos in immigration news by news frame, \u03c72 (2, N = 157) = 5.54, p \n= .06. Mentions of Hispanics and Latinos were most prevalent in political and policy frames \n(79.59 %) (see Table  3.4).  \nIn the next section , I discuss the results of the hypotheses and research questions. \nHypotheses and research questions were tested using a series of one-way and two -way analyses \nFrequency  \n \n 53 of variance, as well as \u03c72 tests. Analyses test ed for partisan and rac ial differences in the presence \nof crime and immigration news frames. Additionally, I included a series of post -hoc analysis \nfurther examining text used within the news articles and potential partisan differences in news \nexposure.  \nTable 3. 3 \n \nAnalysis of Explicit Race Mentions in Crime News by Frame  \n \nExplicit racial mentions  Social  \nframe  Political and  \npolicy frame  Crime and  \njustice  frame  \n\u03c72    n % n % n % \nBlack/African American mentions  3 5.26 18 31.58 36 63.16 9.04 * \nNo Black/African American \nmentions  39 5.92 105 15.93  515 78.15  \n        \nHispanic/Latino mentions  2 7.69 11 42.31 13 50.00  12.61** \nNo Hispanic/Latino mentions  40 5.80 112 16.23  538 77.97    \nNote . N = 716.  \na Given the small cell size for racial mentions in social frames , I performed a series of Fisher\u2019s \nExact Test (for 2 x 2 contingency tables and small sample sizes). Fisher\u2019s Exact Test did not \ndiffer from the \u03c72 test. \n\u2020p < .10. *p < .05. **p < .01. *** p < .001.  \n \nTable 3. 4 \nAnalysis of Explicit Race Mentions in Immigration News by Frame  \nExplicit racial mentions  Social  \nframe  Political and  \npolicy frame  Crime and  \njustice  frame  \u03c72 \n    n % n % n % \nHispanic/Latino mentions  5 10.20  39 79.59  5 10.20  5.54 \u2020 \nNo Hispanic/Latino mentions  26 24.07  66 61.11  16 14.82   \nNote . N = 157.  \na Given the small cell size for racial mentions in social frames , I performed a series of Fisher\u2019s \nExact Test (for 2 x 2 contingency tables and small sample sizes). Fisher\u2019s Exact Test did not \ndiffer from the \u03c72 test. \n\u2020p < .10. *p < .05. **p < .01. *** p < .001.  \n \n \n \n \n 54 Partisanship and News Exposure  \n H1a proposed that Republican -leaning participant networks would  contain greater \namounts of race -centered , violent crime frames depicting African Americans or Latinos  as \ncriminals  than Democrat -leaning participant networks. Unfortunately, as previously ment ioned, \nminimal instances where African Americans or Latinos we re explicitly mentioned as criminals \nlimited analysis to examine general, explicit mentions of race. Consequently, I first examined \ndifferences in potential exposure to crime news containing exp licit mentions of African \nAmericas or Latinos. A one -way analysis of variance demonstrated that there was a significant \ndifference in the amount of crime news articles containing explicit race mentions by partisanship, \nF(1, 142) = 5.43, p < .02. Networks o f Democrat -leaning participants ( M = 2.75, SD = 5.12) \ncontained more news with explicit mentions of racial groups than the networks of Republican -\nleaning participants ( M = .88, SD = 2.25). Again, since analysis could not compare explicit \nmentions of African Americans or Latinos as criminals, H1a was not supported. H1b proposed \nthat Republican -leaning participant networks would contain greater  amounts of race -centered \nimmigration frames depic ting Latinos  than Democrat -leaning participant networks . A one -way \nanalysis of variance demonstrated no significant difference in the amount of immigration news \ncontaining explicit race mentions by partisanship, F(1, 142) = 2.00, p = .16. H1b was not \nsuppo rted. \nTo further explore differences in partisanship and news exposure, I conducted post -hoc \nanalyses examining differences in news frame exposure by partisanship. A two -way analysis of \nvariance demonstrated that there was no interaction between partisansh ip and frame exposure \npertaining to crime news, F(2, 232) = 1.96, p = .14. Furthermore, there was no overall main \neffect for partisanship, F(1, 232) =  .47, p = .50. Analysis demonstrated, however, that there was \n \n 55 a significant main effect for the crime new s frame s, F(2, 232) = 15.24, p < .001. Post hoc  \ncomparisons using Tukey tests demonstrated that the majority of crime news utilized crime and \njustice frames. There were significant differences between the amount of crime news employing \ncrime and justice  frames  (M = 21.11, SD = 34.66)  versus political and policy frames (M = 5.88, \nSD = 6.94) , as well as crime news employing crime and justice  frames versus  social frames  (M = \n4.92, SD = 7.88) . However, there were no differences in the presence of crime news using \npolitical and policy frames  versus social frames .  \nWith respect to frame differences in immigration news by partisanship, a two -way \nanalysis of variance demonstrated no interaction be tween partisanship and frame exposure, F(2, \n139) = .31, p = .73. There was a main effect for partisan difference in overall exposure to \nimmigration news, F(1, 139) = 3.98, p < .05. Democrat -leaning participant networks ( M = 5.21, \nSD = 7.04) contained more immigration news than Republican -leaning networks ( M = 2.97, SD \n= 3.98). These results, however, most likely stem from the large percentage of Democrat -leaning \nparticipants . Specifically, of participants containing immigration news within their social \nnetw orks, 68.74% reported being Democrat -leaning. Similar to the crime news stories, there was \na significant main effect by the news frame, F(2, 139) = 11.57, p < .001. Post hoc comparisons \nusing Tukey tests demonstrated that the majority of immigration news u sed political and policy \nframes. There were significant differences between the amount of immigration  news employing \npolitical and policy  frames ( M = 7.61, SD = 8.64) versus crime and justice  frames  (M = 2.38, SD \n= 1.62), as well as immigration news employing political and policy frames  versus  social frames \n(M = 2.32, SD = 1.87). There was no significant difference between crime and justice  frames and \nsocial frames .  \n \n \n 56 Race and News Exposure  \nRQ1 asked whether racial differences emerge in the amount of race -centered violent \ncrime news depicting African Americans or Latinos in participants\u2019 networks. Furthermore, RQ2 \nasked whether racial differences emerge in the amount of race -centered immigrat ion frames \ndepicting Latinos in participants\u2019 networks. A one -way analysis of variance demonstrated no \nsignificant differences in the presence of crime news with explicit racial mentions by racial \ngroup, F(3, 153) = 1.19, p = .32. Furthermore, a one -way an alysis of variance demonstrated no \nsignificant differences in the presence of immigration news with explicit racial mentions by \nracial group, F(3, 153) = .15, p = .93. Overall, there were no racial differences in the presence of \nexplicit racial mentions in  crime news and immigration news.  \nFraming Crime and Immigration  \n As previously discussed, the majority of crime news employed crime and justice  frames, \nwhile immigration news heavily used political and policy  frames. These news frames also \nincorporated t he greatest amount of explicit race mentions in crime news and immigration news, \nrespectively. Considering these differences, I further explored these frames in a series of post -\nhoc textual analyses. First, I examined the top unigrams and bigrams present i n crime news \narticles that a) used a crime and justice  frame , and b) made explicit mentions of African \nAmericans or Latinos.  \nImportant words within these news articles (as measured by TF -IDF) included bank, \nrobbery, murder, suspect, attack, gun, and sexua l (see Table 3. 5). These terms explicitly \nreference violent crime, such as bank robberies or sexual assault. Interestingly, important words \nalso include mentions of African American susceptibility to violent crime. Emmett Till, a young \nAfrican American boy lynched in the 195 5, was prominently mentioned in these news articles. \n \n 57 Crime news articles also mentioned Trayvon Martin, another young, murdered African \nAmerican, and hate crimes committed against transgender African Americans. While African \nAmericans were mentioned in tan dem with violent crime, African Americans were also depicted \nas victims of violent crime. T he terms immigrant, border, and Mexico were also important in \ncrime news articles employing crime and justice  frames. Terms included mentions of \nChristopher Puente , an undocumented immigrant arrested for sexual assault. 9 The importance of \nterms associated with immigration in the crime news frames suggests that, when mentioned in \nreference to crime and justice , news frames may emphasize Mexican immigration.  \nTable 3. 5 \nTop 20 Unigrams and Bigrams in News with Explicit Race Mentions  \nCrime news with crime and justice  frames  Immigration news with p olitical and policy  \nframes  \nbank, bison, white, emmet, till, emmet till, \nblack, shabaab, smollett, kevin, edmond, \noffic, trayvo n, trayvon martin, mulder, puent, \norlean, murder, charg, suspect, klobuchar, \ncrash, attack, gun, myanmar, crime, robber, \nmartin, court, wood, matthew, univers, man, \nborder, church, immigr, mexico, stop, polic, \nmccormick, yellowston, attorney, hate, \ntransge nd, onwuachi, willig, till trayvon, \nonwuachi willig, monica, sexual  evangel, asylum, rule, elig, migrant, voter, \nperez, court, farmwork, illeg alien, elig voter, \nrefuge, alien, facial, facial recognit, black, \ndetain, carlo , republican, worker, democrat, \npew, school, effigi, technolog, recognit, \nappeal, program, illeg, seeker, asylum seeker, \nvote, charg, polici, campus, offici, wait, \nmexico, offic, ocasio, cortez, ocasio cortez, \nenforc, protest, endors, releas, remain, case,  \ntalk, bridg  \nNote.  Table contains stemmed tokens.  \nNext, I examined the top unigrams and bigrams present in immigration news articles that \na) used a political and policy  frame, and b) made explicit mentions of Latinos. Immigration \narticles classified as a political and policy frame included explicit mentions of Republicans and \nDemocrats, as well as political actors like Alexandria Ocasio Cortez. Political and policy  frame s \nwere conceptualized to include party politics. The importance of the terms Republican and \n \n9 https://www.foxnews.com/us/ice -chicago -released -previously -deported -felon -who-went -on-to-sexually -assault -\ntoddler   \n \n 58 Democrat in these news frames suggests that immigration news casted political parties as \nopposing entities within the immigration debate, and include explicit menti ons of Latino \nimmigrants within these debates. Numerous terms were used to refer to Latino immigrants: \nasylum seeker, migrant worker, illegal alien, and refugee.  \nDiverging connotations in these terms frame immigration along partisan lines.  \nConservative ne ws outlets typically promote news consistently depicting Latino immigrants as \n\u201cillegal aliens\u201d (see Conway et al., 2007). The term illegal alien emphasizes the unlawfulness of \nimmigrant behavior. Framing immigrants as unauthorized depicts immigrants as men acing . \nTerms such as a sylum seeker , refugee, or migrant worker , on the other hand, accentuate the \ndireness of their desire for immigration  (Murray & Marx, 2013) . The United Nations defines \nrefugees (along with asylum seekers) as persons forced to flee thei r native country because of \npersecution, war, or violence (\u201cWhat is a Refugee\u201d). Evoking the  term asylum seeker accentuates \nthe involuntary nature of the individual\u2019s migration  and emphasizes that refugees are in need of \nprotection from the victimization f aced in their home countries (see O\u2019Brien et al., 2019). \nMigrant workers refer to persons who migrate to another country for the purpose of employment \n(Kiss et al., 2015). While the term migrant worker may not summon feelings of sympathy, \nmigrant workers ( along with asylum seekers) fall into the category of authorized or \u201clegal\u201d \nimmigration ( Murray & Marx, 2013) .  \nCrime and Immigration News Sources  \nRQ3a asked w hat news sources are present participants\u2019 social media networks . The top \n10 crime news sources in the sample included PA Homepage , CNN , BBC, the New York  Times , \nthe Associated Press , Reuters, the Sun Herald, the Guardian, Breitbart , and NBC News . The top \n10 immigration news sources in the sample included the New York  Times , CNN , Reuters , NBC  \n \n 59 News , the Associated Press , BBC , Buzzfeed, Fox News, NPR, and the Guardian . These news \nsources accounted for 46.37% and 47.89% of the crime and immigration news sources, \nrespectively (see Table 3. 6).  \nI also examined the social med ia users who shared the most news within participant\u2019s \nsocial networks. Prominent sources for crime and immigration news were verified news \naccounts, such as CNN  (@cnnbrk), Reuters  (@reuters ), the New York Times  (@nytimes), and the \nAssociated Press (@ap). Other top sharers were non -news accounts such as Bernie Sanders \n(@sensanders ) and the Second Amendment Foundation (@ 2afdn ). Overall, the tops shared news \nsources, as well as the top sharers of crime and immigration news were prominent cable news, \nnewspaper , and digitally native sources.   \nRQ3b asked whether there are partisan differences in the news sources present in \nparticipants\u2019 social media networks. Figure 3.5 depicts proportional differences in crime news \nsources by partisanship (i.e., frequency of the  source by the total number of participants like -\npartisan  participants).  Crime  news originating from CNN, the second most shared source for \ncrime news, was present in equal proportions between Democrat -leaning and Republican -leaning \nparticipants, z = 1.73, p = .19, 95% CI [ -.01, .08]. Interestingly, crime news originating on Fox \nNews  diverged, with a greater p roportion being present in Democrat -leaning networks, z = 18.65, \np < .001, 95% CI [.04, .09]. With respect to immigration news (see Figure 3.6), there were no \npartisan differences in the proportion of news from CNN , z = 1.80, p = .18, CI 95% ( -.03, .13),  or \nnews from Fox News , z = .69, p = .41, CI 95% ( -.09, .03). Overall, crime and immigration news \nfrom highly shared legacy news sources (e.g., the NY Times, AP News ) were equally present in \nDemocrat -leaning and Republican -leaning networks. However, when con sidering the more niche \n \n 60 sources shared at lower overall proportions (e.g., Daily Caller , Breitbart , and Slate ), the  \nproportion visually diverged. 10 \nTypes of Crime and Immigration News Sources  \nRQ4a asked what types of news sources are present in participant s\u2019 social media \nnetworks. Crime and immigration articles were classified into one of the following groups: \nnewspaper, digitally native, cable news, network news, magazine, and radio. 11 As depicted in \nFigure 3.7 and Figure 3.8, digitally native sources were  a prominent source of crime and \nimmigration news. Although the top shared news sources (primarily traditional newspapers, \nnetwork news, or cable news) accounted for a substantial amount of crime and immigration new \nsources, a n assortment of digitally nati ve sources were shared at almost the same capacity as \nnewspapers, network news, and cable news combined . The top 20 digitally native sources are \ndepicted in Figure 3.9 and Figure 3.10.  \n \n \n \n \n \n \n \n \n \n10 The proport ion of these sources were too small for statistical comparison.  \n11 The list of news sources for each news category was created using the State of the News Media fact sheet \npublished by Pew Research Center ( https://www.journalism.org/2019/07/23/state -of-the-news -media -methodology/ ) \nand Amazon Alexa\u2019s list of top news sites ( https://www.alexa.com/topsites/ category/Top/News ). \n \n \n 61  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nTop crime news sources  Top immigration news sources  Top crime news sharers  Top immigration news sharers  \nNews outlet  n News outlet  n Screen name  n Screen name  n \npahomepage.com  83 nytimes.com  23 wbrewyou  88 homelanddems  16 \ncnn.com  60 cnn.com  10 cnnbrk  53 nytimes  9 \nbbc.com  42 reuters.com  7 2afdn  47 cnnbrk  7 \nnytimes.com  36 nbcnews.com  6 bbcnorthamerica  34 reuters  6 \napnews.com  21 apnews.com  5 nytimes  25 sensanders  6 \nreuters.com  12 bbc.com  5 ap 19 bbcnorthamerica  5 \nsunherald.com  12 buzzfeednews.com  3 sunherald  12 gemmaod1  4 \ntheguardian.com  12 foxnews.com  3 reuters  11 vahdatyeganeh  4 \nbreitbart.com  11 npr.org  3 foxnews  9 ap 3 \nnbcnews.com  11 theguardian.com  3 shareddotcom  8 guardian  3 \n \nTable 3. 6 \n \nTop Crime and immigration News Sources  \n \n 62  \nFigure 3.5.  Proportion of crime news sources by partisanship .  \n \n \nFigure 3.6.  Proportion of Immigration News Sources by Partisanship .  \n \n \n \napne ws.com\nbbc.combreitbar t.com\nbuzzfeedne ws.comchn.gecnn.com\ndailycaller .com\ndailymail.co .ukeed.comfbi.go vforums.battlefield.com\nfox.cofox6no w.comfoxnews.com\ngetpock et.com\nglobalcitiz en.orggo.shr.lcgo.wh.go v\nhrw.org independent.co .ukiwf.org\njustice .govkotaku.com\nkrem.comlatimes .comlocal.theonion.com\nmercur ynews.commiamiher ald.com\nmirror .co.uknbcne ws.com\nnewyorker.comnytimes .com\non.msnbc.compeople .com\nperezhilton.com\npolicehelpapps .compsychcentr al.comreuters .com\nrferl.orgsi.comtheajmendez.comtheguardian.com\ntheonion.com\ntmz.com\nvanityf air.comvirg.inwsj.com\n0.30%1.00%3.00%10.00%30.00%\n0.10% 1.00% 10.00%\nDemocrat\u2212leanRepublican\u2212lean\naclu.orgapne ws.combreitbar t.comcnn.com\ndailycaller .com\ndrd.shelizabethw arren.com\nelle.comfoxnews.com\nmirror .co.uk\nmsn.comnbcne ws.com\nnpr.org\nnydailyne ws.comnytimes .com\non.forbes .comreuters .com\nsfchronicle .com\nslate .comtheatlantic.comtheguardian.com\nunhcr .org\nusmagazine .comwashingtone xaminer .comwsj.com\n1.0%3.0%10.0%\n0.30% 1.00% 3.00% 10.00% 30.00%\nDemocrat\u2212leanRepublican\u2212lean\n \n 63   \nFigure 3.7.  Crime News Articles by News Category  \n \n \nFigure 3.8.  Immigration News Articles by News Category  \n \ndigitalnetw orknewspapercablemagazine\n0 100 200 300\nFrequencyNews category\ndigitalnewspapernetw orkcablemagazineradio\n0 20 40 60\nFrequencyNews category\nNews Category  \n News Category  \n \n 64  \nFigure 3.9.  Top 20 Digitally Native Crime News Articles  \n \n \nFigure 3.10.  Top 20 Digitally Native Immigration News Articles   \n  \ntheguardian.combreitbar t.coms.sho.comwlox.comfbi.go vchn.geindependent.co .uknewser.comshared.usbiogr aphy.comcrimeresearch.orgdailycaller .comjustice .govjustthene ws.comlife.shared.comlovebscott.comnola.comperezhilton.comrainn.orgtmz.com\n0.0 2.5 5.0 7.5 10.0 12.5\nDigital ne ws outletfrequency\nbuzzfeedne ws.comtheguardian.comaclu.orgbostone xperimentaltheatre .comelizabethw arren.comjustthene ws.compri.orgsplcenter .orgvox.comwashingtone xaminer .comamnestyusa.orgblog.samaltman.comborderrepor t.combreitbar t.combritannica.combuild.n yccdc.go vcolor lines.comconser vativereview.comcult.li\n0 1 2 3\nDigital ne ws outletfrequencyFrequency  \nFrequency  \nDigitally Native News Outlet  \n Digitally Native News Outlet  \n \n 65  RQ4b asked whether there are partisan differences in the types of news sources present in \nparticipants\u2019 social media networks.  The proportion of crime news originating from cable, \ndigitally native, magazine, and network news sources by partisanship differe d significantly, \u03c72 (3) \n= 65.28, p < .001. For Democrat -leaning participants, the majority of crime news originated from \ncable news sources (58.15%). However, for Republican -leaning participants, crime news \noriginated from digitally native sources (48.64%) (see Table 3. 7).  \nTable 3. 7 \nAnalysis of News Categories of Crime News by Partisanship  \n \nPartisanship  Cable  \nnews  Digitally native  \nnews  Magazine  Network  \nnews  \n \u03c72    n % n % n % n % \nDemocrat -lean 1010  58.15  467 26.89  14 0.81 246 14.16  65.28 *** \nRepublican -lean 130 44.22  143 48.64  5 1.70 16 5.44   \n Note . N = 2031  \n\u2020p < .10. *p < .05. **p < .01. *** p < .001.  \n  \n Similar trends emerged for immigration news. Overall, there was a significant difference \nin the proportion of news categories by partisanship, \u03c72 (3) = 18.46, p < .001. The majority of \nimmigration news present in Democrat -leaning participant networks origi nated from cable news \nsources (26.50%). For Republican -leaning participants, however, the majority of immigration \nnews originate from digitally native sources (38.39%) (see Table 3. 8). Taken together, there are \npartisan difference in the types of news sour ces present in participants\u2019 social media networks.  \n \n \n \n \n \n \n \n \n \n \n \n 66 Table 3. 8 \n \nAnalysis of News Categories of Immigration News by Partisanship  \n \nPartisanship  Cable  \nnews  Digitally native  \nnews  Magazine  Newspaper  \n \u03c72    n % n % n % n % \nDemocrat -lean 141 26.50  112 21.05  9 1.69 270 50.75  18.46 *** \nRepublican -lean 26 23.21  43 38.39  4 34.82  39 3.57   \n Note . N = 644  \n\u2020p < .10. *p < .05. **p < .01. *** p < .001  \n \nLastly,  RQ4c asked whether there are partisan differences in the partisan lean of sources \npresent in participants\u2019 social media network. News sources present in the sample were \ncategorized as follows: left, left center, center, right, or right center. Classifications were adopted \nfrom the Media Bias Fact Check, an independent media o utlet, which classifies the biases of \nnews sources. 1213 In the case of cable news, there was a significant difference in the outlet lean of \nthe source, \u03c72(1) = 9.26, p < .001 . For both Democrat -leaning and Republican -leaning \nparticipants, the majority of cable news originated from left -leaning sources, 77.13% and 88.00% \nrespectively. Left -leaning cable sources were the dominant cable news source for both \nDemocrat - and Republican -leaning participants.   \nWith respect to newspapers and outlet lean,  there were no significant differences by \npartisanship,  \u03c72(1) = .94, p = .63. Lastly, there were differences in the proportion of digitally \nnative sources by outlet lean, \u03c72(3) = 10.46, p < .05 . For both Democrat -leaning and Republican -\nleaning participant s, the majority of digitally native news originated from sources classified as \nleft center leaning (56.83% and 63.56%, respectively) (see Table 3. 9). Taken  together, these \n \n12 https://mediabiasfactcheck.com/about/  \n13 Data were validated using Pew Research Center data ( https://www.journalism.org/2014/10/21/political -\npolarization -media -habits/ ). There was a significant, moderate correlation between the sources partisans found \ntrustworthy and the media bias factcheck categorization, r (30) = .66, p < .01.  \n \n 67 results suggest that there were no partisan differences in the partisan lean of sour ces present in \nparticipants\u2019 social media networks. Crime and immigration news favored left -leaning ideology, \ndespite the participant\u2019s partisanship. The magnitude of left -leaning sources present in the most \nshared crime and immigration news sources (see T able 3. 6) underscores this finding.  \nTable 3. 9 \n \nAnalysis of News Categories and Outlet Lean for Crime and Immigration News by Partisanship  \n \n  Cable News    \nPartisanship  Left Left center  Center  Right  Right center  \n \u03c72    n % n % n % n % n % \nDemocrat -lean 877 77.13  --- --- --- --- 260 22.87  --- --- 9.24 ** \nRepublican -lean 132 88.00  --- --- --- --- 18 12.00  --- ---   \n Newspaper    \nPartisanship  Left Left center  Center  Right  Right center  \n \u03c72    n % n % n % n % n % \nDemocrat -lean --- --- 535 56.85  361 38.36  45 4.78 --- --- 0.94 \nRepublican -lean --- --- 83 55.33  62 41.33  5 3.33  ---  ---   \n Digitally native news    \nPartisanship  Left Left center  Center  Right  Right center  \n \u03c72    n % n % n % n % n % \nDemocrat -lean 41 22.40  104 56.83  10 5.46 28 15.30  --- --- 10.46 * \nRepublican -lean 2 3.85 33 63.46  5 9.62 12 23.08  --- ---   \n Note . N = 1041; N = 1091; N = 235  \n\u2020p < .10. *p < .05. **p < .01. *** p < .001.  \nDiscussion  \n \nStudy 1 examined the crime and immigration news available in participants\u2019 Twitter \nnetworks. Specifically, I examined the news frames used to describe crime and immigration, and \nexplicit group mentions within crime and immigration news. Overall, news organ izations \nfavored crime and justice  frames in crime news. Immigration news, however, more often \nincorporated political and policy  news frames. Explicit group mentions were not overtly \ncommon in crime and immigration news. When explicit group mentions were p resent, crime \n \n 68 news referenced violent crime (e.g., robbery, murder), emphasizing African Americans as \nvictims of crime or Mexican immigrants as perpetrators of crime.   \nWhen immigration news included explicit group mentions, political words (e.g., \nRepublic an, Democrat) were highly salient and accompanied with mentions of Latino \nimmigrants as asylum seekers, migrant workers, illegal aliens, and refugees. The emphasis of \nAfrican Americans as victims of violent crime  or political parties in reference to immigr ation \nwere most often incorporated in the prominent crime and immigration news frames (i.e., crime \nand justice, and political and policy, respectively).   \n As expected, digitally native news maintained a strong presence in the total amount of \ncrime and immigration news shared within participants Twitter networks. However, the majority \nof the top shared news sources originated from legacy news sources: cable news, network news, \nand newspapers. Lastly, it was expected that Twitter would make way for party -aligned news \nsources. Left leaning cable and digitally native news sources dominated participants\u2019 news feeds, \nirrespective of the participant\u2019s party identification .  \n \n \n \n \n \n \n  \n \n \n \n 69 CHAPTER 4: STUDY 2  \n \n Study 2 expanded on the previous study, examining relationships between news available \nwithin participants\u2019 news feeds and perceptions of race, crime, and immigration. Specifically, I \nexamined relationships between potential exposure to violent crime and i mmigration news \nduring social media use  and subsequent  endorsements of African American or Latino \nstereotypes. Additionally, I examined relationships between potential exposure to violent  crime \nand immigration news within participants\u2019 news feeds and perce ptions of immigrants as a threat, \npunitive crime policy support, and issue interpretation. Recognizing that social media operates \nwithin a larger news ecology, I considered the role of participants\u2019 offline news repertoires and \ngeneral perceptions of news credibility.  \nMethod  \n \nParticipants  \n Study 2 utilizes the same participant population as Study 1, specifically focusing on \nparticipants whose Twitter social networks contained crime or immigration news. The total \nsample ( N = 141) represented the following d emographics: age ( M = 38.42, SD = 13.11), gender \n(48.92%; female), education (33.81% high school or less, 21.58%  some college or trade school; \n44.60% BA/BS or more), and income (60.87% $60,000 or less per year).  \nSurvey Procedure  \n Study 1 content analyzed  crime and immigration news collected using participants\u2019 \nTwitter IDs. While completing the survey (see Study 1 Survey Procedure) participants also \nresponded to a number of criterion and moderating variables. Below, I discuss the predicting and \nmeasured va riables.  \n \n \n 70 Predict ing Variable  \n The crime and immigration news articles collected and analyzed during Study 1 served \nas the predicting variable. Coded items (i.e., article topic and news frame) were matched to each \nparticipant using the list of users followed by the participants . For eac h topic of interest (i.e., \ncrime and immigration ), accompanying news frames were  assigned a binary code;  1 (present) or \n0 (not present). For instance, if an article about immigration utilized the political and policy \nframe, the immigration \u2013 political and policy frame variable was coded as present . Table 4.1 \nreports the descriptives of crime and immigration news (with accompanying frames) present in \nparticipants\u2019 news feeds. The predicting variable signifies potential for exposure to crime and \nimmigration n ews during Twitter use.  \nTable 4.1  \n \nDescriptives of Crime and Immigration News  \n \nNews frame  Crime news  Immigration news  \n  M SD M SD \nSocial frame  4.92 7.88 2.32 1.87 \nPolitical and policy frame  5.88 6.94 7.61 8.64 \nCrime and justice frame  21.11  34.67  2.38 1.62 \n \nCriterion Variables  \nRacial Stereotype Endorsement.  Participants indicated  their level of agreement with 1 5 \nstereotypes associated with African Americans and Latinos on a 1 (strongly disagree) to 7 \n(strongly agree)  scale. Example items include d \u201cAfrican Americans (Latinos) are violent\u201d and \n\u201cAfrican Americans (Latinos) are uneducated \u201d (African American stereotype endorsement: \nCronbach\u2019s \uf061 = .96, M = 3.36, SD = 1.56; Latino stereotype endorsement: Cronbach\u2019s \uf061 = .94, \nM = 3.22, SD = 1.35.  \n \n 71 Perceptions of Immigrants as a Threat.  Participants indicated the extent to which \nimmigrants pose a symbolic threat to various aspects of society  (see Watson & Riffe, 2013 ). \nParticipants responded to five items on a scale from 1 (strongly disagree) to 7 (strongly agree) . \nExample items include d \u201cImmigrants take jobs away from American citizens\u201d and \u201cThe growing \nnumber of immigrants threatens traditional American customs and values \u201d (Cronbach\u2019s \uf061 = .92, \nM = 3.81, SD = 1.87).  \nPunitive Crime Policy  Support . Participants indicated  their level of sup port for five \npunitive policies from 1 (strongly oppose ) to 7 ( strongly favor ) (Cronbach\u2019s \uf061 = .77, M = 4.38, \nSD = 1.36) . Punitive policies include d three -strikes laws, mandatory minimums, sentence \nenhancements, trying juveniles as adults, and capital punishment. These items were  adapted from \nprevious research examining the effects of media exposure on punitive policy support (Simmons, \n2017 ).  \nSupport  for Immigration Policies.  Participants assessed their level of support on 13  \nimmigration policies from 1 ( strongly oppose ) to 7 ( strongly favor ) (Cronbach\u2019s \uf061 = .86) (see D. \nM. Price & Kaufhold, 2019) . As the listed policies included pro - and anti -immigration policies, I \nfurther analyzed the scale using principle components analysis (PCA) with varimax  rotation (see \nTable 4.2). Analysis yielded 2 components with an eigenvalue over 1, accounting for 6 4.72% of \nthe variance. Component 1 referred to anti -immigration policies (Cronbach\u2019s \uf061 = .92, M = 3.72, \nSD = 1.76) : 1) Building a border wall along the U.S. -Mexico border, 2) Immigrant detention \ncenters, 3) Deportation arrests at courthouses by immigration agents, 4) Raids at workplaces by \nimmigration agents, 5) Fines for U.S. businesses that hire undocumented workers, 6) Increased \ndeportations of undocumented immigrants. Component 2 referred to pro -immigration policies \n(Cronbach\u2019s \uf061 = .81, M = 4.56, SD = 1.31): 1) DAC A or Delayed Action for Childhood Arrivals, \n \n 72 2) Pathway for citizenship for Delayed Action for Childhood Arrivals, 3) Sanctuary cities, 4) \nBirthright citizenship, 5) Family reunification, and 6) Chain migration.   \nTable 4.2  \n \nPrinciple Components Analysis fo r Support of Immigration Policies  \n \n  Component  \n 1 2 \nAnti-immigration policies    \nBuilding a border wall along the U.S. -Mexico border  .84  \nImmigrant detention centers  .82  \nDeportation arrests at courthouses by immigration agents  .86  \nRaids at workplaces by immigration agents  .85  \nFines for U.S. businesses that hire undocumented workers  .76  \nIncreased deportations of undocumented immigrants  .89  \nIncreased border surveillance  .72  \nPro-immigration policies    \nDACA or Delayed Action for Childhood Arrivals   .74 \nPathway for citizenship for Delayed Action for Childhood Arrivals   .77 \nSanctuary cities   .67 \nBirthright citizenship   .73 \nFamily reunification   .69 \nChain migration   .61 \nNote. Principal Component Analysis using Varimax rotation with Kaiser normalization.  \naKaiser -Meyer -Olkin Measure of Sampling Adequacy = .85, Bartlett\u2019s test for sphericity, \uf0632 (78) \n= 1085.05, p < .001.  \n \n Issue interpretation . Participants separately listed thei r thoughts on immigration and \ncrime. Participants were instructed with the following prompt: \u201c Please list any and all thoughts \nthat come to mind when you think about [immigration , crime] . Please list one thought per box.  \nDo not worry about spelling, punct uation, or writing in complete sentences. \u201d The thought listing \nexercises allotted at most ten thoughts per topic; yielding 619 crime thought ( M = 4.99, SD = \n3.88, per participant) and 597 immigration thoughts ( M = 4.78, SD = 3.75, per participant). \n \n 73 Previou s researchers have utilized open -ended thought listings for measuring issue opinions \n(Riles  et al., 2015).  \nTwo undergraduate students and one graduate student (i.e., the primary researcher) \nclassified thoughts provided by the participants. Coders received  20 hours of training over an 8 -\nweek period. Individual thoughts served as the unit of analysis. Roughly 10% of each of the \nthought listing samples were used to assess intercoder reliability. All thought listings were \ncontent analyzed to determine salient frames within participants\u2019 thoughts (see Appendix A) and \nexplicit mentions of racial or ethnic groups (e.g., Black people, Mexicans). To mirror the frames \nconsidered in Chapter 3, the categories were collapsed into the following: 1 ) social frames, 2) \npolitical and policy frames , and 3) crime and justice  frames  (see Chapter 3). Krippendorff\u2019s \nalpha reached acceptable levels for salient frames in immigration thoughts ( \uf061 = .73) and crime \nthoughts ( \uf061 = .74), as well as explicit group mentions ( \uf061 = 1.00).   \nModerating Variables  \n Twitter News  Credibility . News credibility typically assesses audiences\u2019 perceptions of \nspecific news sources or news stories (see Metzger et al., 2015 ). However, given that lack of \nforesight of the news participants encounter, I mod ified the scale to examine general credibility \nperceptions for news encountered on Twitter. Participants responded to a series of adjectives \ndescribing news stories they view on Twitter on a scale from 1 ( not at all ) to 5 ( extremely ). \nAdjectives included complete , accurate , trustworthy , biased , and credible  (Cronbach\u2019s \uf061 = .84, \nM = 3.50, SD = .80) .  \nNews Repertoires . Participants were asked how often they watch or read television, \nonline, or radio news programming  on any device (e.g., phone, television, laptop, desktop, tablet) \nfrom 1 ( never ) to 5 ( daily ) (Mour\u00e3o et al., 2018). Participant responses were not mutually \n \n 74 exclusive. News programs included 1) national nightly news (i.e., CBS, ABC, or NBC), 2) The \nToday Show, Good Morning America or CBS This Morning , 3) CNN cable news programs (e.g., \nAnderson Cooper), 4) Fox cable news programs (e.g., Fox & Friends, Tucker Carlson Tonight, \nThe Ingraham Angle), 5) MSNBC  cable news programs (e.g., Rachel Maddow, Chris Matthews), \n6) news programming on N PR \u2013 live radio, podcasts, streaming (e.g. \u201cAll Things Considered\u201d) , \n7) conservative news websites (e.g., Infowars , Breitbart , the Blaze ), 8) liberal news websites \n(e.g., Daily Kos , Mother Jones ), 9) conservative talk radio \u2013 live radio, podcasts, streaming (e.g. \nRush Limbaugh) , 10) local newspapers (online or print) , 11) n ational newspapers (e.g., New York \nTimes , Washington Post ), 12) local television news , and 13) i nternational news websites ( e.g., \nBBC , The Guardian ).  \nIn order to classify the repertoires, I conducted a factor analysis on the 13 items with \noblimin rotation. Analysis yielded 4 factors  with an eigenvalue over .88, accounting for 77.23 % \nof the variance  (see Table 4.3) . Factor 1 included  CNN  cable news, MSNBC  cable news, NPR , \nand liberal news websites (Cronbach\u2019s \uf061 =.86 , M = 2.50, SD = 1.27) . Factor 2 included national \nnightly news, morning shows (e.g., the Today Show), and local television news (Cronbach\u2019s \uf061 = \n.81, M = 3.29, SD = 1.23) . Factor 3 included local and national newspapers (Cronbach\u2019s \uf061 = .80, \nM = 3.06, SD = 1.35) . Lastly, Factor 4 included Fox News , conservative news websites, and \nconservative talk radio (Cronbach\u2019s \uf061 = .87, M = 2.38, SD = 1.37) . Item 13 (i.e., international \nnews websites (e.g., BBC, The Guardian ) was removed from analysis because of low factor \nloading (< .50). I henceforth refer to the four factors as mainstream + liberal television news, \nlocal + national television news, newspapers, and conservative news, respectively.  \n \n \n 75 Table 4.3  \nFactor Analysis of News Repertoires  \n  Factor  \nNews  program  1 2 3 4 \nCNN  cable news programs (e.g. , Anderson Cooper, Don Lemon)  .72    \nMSNBC  cable news programs (e.g. , Rachel Maddow, Chris Matthews)  .79    \nNews programming on NPR \u2013 live radio, podcasts, streaming (e.g. , \u201cAll \nThings Considered\u201d)  .54    \nLiberal news websites (e.g. , Daily Kos , Mother Jones ) .52    \nNational nightly news (e.g., CBS, ABC , or NBC )  .71   \nThe Today Show, Good Morning America or CBS This Morning   .65   \nLocal television news about your viewing area   .61   \nLocal newspapers (online or print)    .70  \nNational newspapers (e.g. , The New York Times ; Washington Post ; \nonline or print)    .80  \nFOX cable news programs (e.g. , Fox & Friends, Tucker Carlson Tonight, \nThe Ingraham Angle)     .67 \nConservative news websites (e.g. , Instapundit, Infowars)     .76 \nConservative talk radio \u2013 live radio, podcasts, streaming (e.g. , Rush \nLimbaugh)     .86 \nNote. Principal Axis Factoring using Oblimin rotation with Kaiser normalization.  \naKaiser -Meyer -Olkin Measure of Sampling Adequacy = .89, Bartlett\u2019s test for sphericity, \uf0632 (78) \n= 1126.48, p < .001.  \n \nControl Variables   \nParty lean. Participants identified their p artisanship as a Democrat, Republican, or \nIndependent. If participants indicated identification as a Democrat or Republican, participants \nassessed the strength of their identification (i.e., \u201cstrong\u201d or \u201cnot very strong\u201d). If participants \nindicated identif ication as an Independent, participants designated whether their identification \nwas \u201cCloser to the Democratic Party,\u201d \u201cCloser to the Republican Party,\u201d or \u201cCloser to neither \nparty.\u201d Similar to study 1, true independents (i.e., \u201ccloser to neither party\u201d) we re excluded from \nanalysis (n = 15). Remaining partisans were coded as Democrat -leaning or Republican -leaning. \n \n 76 The sample of partisans included  67.46 % Democrat -leaning participants and 32.53 % of \nRepublican -leaning participants.  \nTwitter Use. Participants indicated how often they use Twitter from 1 ( never ) to 5 \n(daily ). (M = 4.39, SD = .97).  \nTwitter for News. First, participants indicated the frequency of their use of Twitter for \ngetting news  from 1 ( never ) to 5 ( daily ) (M = 4.14, SD = 1.20). Next , participants specified the \nnature of their news exposure on Twitter. Participants indicated their level of agreement from 1 \n(strongly disagree ) to 7 ( strongly agree ) with the following statements: \u201cI use Twitter to stay \ninformed about current events and public affairs,\u201d \u201cI use Twitter to get news about current events \nfrom mainstream media,\u201d and \u201cI use Twitter to get news from online news sites \u201d  (Cronbach\u2019s \uf061 \n= .90, M = 5.48, SD = 1.35)  (Gil de Z\u00fa\u00f1iga, Weeks, & Ard\u00e8vol -Abreu, 2017) .  \nResults  \nStudy 1 demonstrated that there were a small number of race -centered crime and \nimmigration frames (see Chapter 3). Consequently, I focused analysis on the total number of \narticles classified as  crime and immigration news . Additionally, I analyzed relationships between \nthe news frames used in the  crime and immigration news  article and the criterion variables . \nSecond, I corrected for the positive skew of these variables using log 10 transformation s. H2 \u2013 \nH4b were tested using a series of hierarchal regressions. H5 was tested using a series of \ncorrelations. The remaining hypotheses were tested using PROCESS macro version 3 for SPSS \n(Hayes, 2018) . Hayes PROCESS analyzes the conditional relationships between the variables of \ninterest. PROCESS models were created using percentile bootstrap confidence intervals with \n5000 bootstrap samples. Each model included controlled for age, gender, income, educati on, \n \n 77 race, partisanship,  media use,  and the nature of participants\u2019 use of Twitter for news  (i.e., Twitter \nnews use) .   \nPreliminary Analysis  \n Prior to testing the hypotheses and research questions, I examined correlations between \nthe criterion and control v ariables. Participants\u2019 Twitter use, frequency of using Twitter for news, \nand the nature of their news exposure on Twitter were strongly correlated. Participants reporting \ngreater Twitter use reported frequently using Twitter for news ( r = .72, p < .001), and using \nTwitter as a news source for  current events and public affairs , r = .40, p < .001. Participants\u2019 \nTwitter use was significantly correlated with the criterion variables of interests. Specifically, \nfrequent use of Twitter for news was significantly correlated with perceptions of immigrants as a \nthreat ( r = .21, p < .05) and support for anti -immigration policy ( r = .18, p < .05). Additional \ncorrelated relationships are reported in Table 4.4.  \nAfrican American and Latino Stereotype Endorsement  \nH2 predicted that participants potentially exposed to greater amounts of race -centered , \nviolent  crime frames on social media would  report greater  African American and Latino \nstereotype endorsement.  The results for the hierarchical regressions are reported in Table 4.5. \nRepublican -leaning participants endorsed African American stereotypes more than Democrat -\nleaning participants, \n  = .39, p < .001. Additionally, participants reporting grea ter news \nconsumption reported greater endorse ment of African American stereotypes, \n  = .22, p < .01. \nThe final step in the hierarchical regression demonstrated that the presence of crime news within \nparticipants\u2019 networks was not related to African American stereotype endorsement. \nComparably, Republican -lean and news use were related to Latino stereotype endorsement. \nRepublican -leaning participants endorsed Latino stereotypes more than Democrat -leaning \n \n 78 participants, \n  = .43, p < .001. Additionally, participants reporting heavier news consumption \nreported greater  endorse ment of Latino stereotypes, \n  = .28, p < .01. The presence of crime news \nwithin participants networks, however, was not related to Latino stereotype endorsement.  H2 \nwas not supported.  \nPerceptions of Immigrants as a Threat  \n H3 predicted that participa nts potentially exposed to greater amounts of race -centered \nimmigration frames  depicting Latinos w ould report greater perceptions of immigrants as a threat. \nRepublican -leaning participants reported greater perceptions of immigrants as a threat than \nDemocrat -leaning participants, \n  = .58, p < .001. Contrary to the hypothesis, the overall presence \nof immigration news was not related to participants\u2019 perceptions of immigrants as a threat. H3 \nwas not supported.  \nPunitive Crime Policy Support  \n H4a predicted that participants  potentially exposed to greater amounts of race -centered , \nviolent  crime frames  depicting African Americans or Latinos would report g reater support for \npunitive crime policies.  Similar to the previous analyses, Republican lean was significantly \nrelated to punitive crime policy support. Republican -leaning participants supported punitive \ncrime policies more than Democrat -leaning participa nts, \n  = .42, p < .001. Interestingly, the \nmagnitude of crime news present in participants\u2019 social networks was  marginally  negatively \nrelated to punitive crime policy support, \n  = -.18, p < .10. Participants whose Twitter networks \ncontained more crime news (as classified by the content analysis) reported less support for \npunitive crime policies. Although the model depicts a significant impact of potential exposure to \ncrime news on Twitter ( F (11, 109) = 2. 49, p < .01), the negative association contradicts the \nproposed relationship. H4a was not supported.  \n \n 79  \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nVariable  1 2 3 4 5 6 7 8 9 10 \n1.Twitter use  ----          \n2.Frequency of using Twitter for news  .72***  ----         \n3.Twitter for news  .40***  .60***  ----        \n4.Republican -lean .04 .02 -.02 ----       \n5.African American stereotype \nendorsement  .16\u2020 .15\u2020 .14 .33***  ----      \n6.Latino stereotype endorsement  .12 .12 .14 .37***  .79***  ----     \n7.Perceptions of immigrants as a threat  .13 .21* .15\u2020 .48***  .55***  .66***  ----    \n8.Punitive crime policy support  .04 -.03 .05 .32***  .32***  .38***  .40***  ----   \n9.Anti-immigration policy support  .07 .18* .07 .49***  .48***  .58***  .85***  .47***  ----  \n10.Pro-immigration policy support  -.04 .02 .02 -.20* -.22* -.11 -.30**  .03 -.23**  ---- \n \nTable 4.4  \nCorrelation Matrix for Criterion and Control Variables   \nNote. N = 126; Table reports Pearson correlations  \n\u2020p < .10. *p < .05. **p < .01. *** p < .001  \n \n \n \n 80  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  African American stereotype endorsement  Latino stereotype endorsement  \n Model 1  Model 2  \nVariable  \n 95% CI  adj. R2 R2 \n 95% CI  adj. R2 R2 \nStep 1: Demographics     -.01     -.01  \nAge .14 -.01 .04   .13 -.01 .03   \nFemale (reference male)  -.15 -1.11 .19   -.12 -.87 .25   \nIncome  .15 -.05 .26   .10 -.07 .20   \nEducation  -.12 -.33 .09   .03 -.16 .21   \nBlack  .06 -.62 1.02   .01 -.66 .75   \nHispanic  .07 -.54 1.01   -.04 -.78 .56   \nOther  -.01 -1.23 1.21   .02 -.99 1.15   \nStep 2: Partisanship     .11 .12***     .15 .15***  \nRepublican -lean .39***  .65 1.92   .43***  .72 1.79   \nStep 3: Media Use     .20 .09**    .20 .06**  \nNews consumption  .33**  .23 .76   .28**  .12 .58   \nStep 4: Twitter Use     .20 .01    .20 .00 \nTwitter news use  .08 -.13 .34   .05 -.15 .25   \nStep 5: News Exposure     .19 .00    .19 .01 \nTotal number of crime  \nnews articles  -.01 -.43 .37     -.07 -.49 .20     \n \nTable 4.5  \nHierarchical Regression for Stereotype Endorsement  \nNote. N = 121; Model 1:  F (11, 109) = 3.53, p < .001; Model 2: F (11, 109) = 3.63, p < .001 \naWhite is the reference group for each racial group  \n\u2020p < .10. *p < .05. **p < .01. *** p < .001.  \n \n \n 81 Table 4.6  \n \nHierarchical Regression for Perceptions of Immigrants as a Threat  \nVariable   \n 95% CI  adj. R2 \n R2 \nStep 1: Demographics     .06  \nAge .01 -.03 .04   \nFemale (reference male)  -.20 -1.83 .23   \nIncome  .28 -.00 .50   \nEducation  -.20 -.63 .11   \nBlack  .00 -1.38 1.39   \nHispanic  -.04 -1.38 1.05   \nOther  -.19 -3.22 .53   \nStep 2: Partisanship     .34 .26***  \nRepublican -lean .58***  1.55 3.36   \nStep 3: Media Use     .35 .12 \nNews consumption  .15 -.13 .71   \nStep 4: Twitter Use     .34 .00 \nTwitter news use  .12 -.22 .69   \nStep 5: News Exposure     .34 .00 \nTotal number of immigration \nnews articles  -.03 -.89 .68     \nNote. N  = 75; Final Model: F (11, 63) = 4.31, p < .001 \naWhite is the reference group for each racial group  \n\u2020p < .10. *p < .05. **p < .01. *** p < .001.  \n \nAnti - and Pro - Immigration Policy Support  \nH4b predicted that participants potentially exposed to greater amounts of race -centered \nimmigration frames  depicting Latinos would report greater support for punitive immigration \npolicies.  I tested this hypothesis considering relationships between immigration news and \nsupport for anti -immigration policies, as well as immigration news and support for pro -\nimmigration policies. The results for these analyses are depicted in Table 4.8. With respect to \nanti-immigration policies, Republican -leaning participants indicated greater support for anti -\nimmigration policies than Dem ocrat -leaning participants, \n  = .54, p < .001. The magnitude of \nimmigration news was not related support for anti -immigration policies.  \n \n 82 Female  participants  were more likely to support pro -immigration policies than males , \n = \n.34, p < .01. Income negatively related to  supported pro -immigration policies  with greater  \nincome depress ing support for pro -immigration policies , \n = -.41, p < .01 . Education positively \nrelated to pro-immigration policies, \n  = .37, p < .01. Lastly, racial identification was related to \nsupport for pro -immigration policies. Black participants were less likely to support pro -\nimmigration policies than White participants, \n  = -.35, p < .05, and Hispanic participants were \nless l ikely to support pro -immigration policies than White participants, \n  = -.29, p < .01. There \nwas no relationship between the presence of immigration news in participants\u2019 Twitter networks \nand pro -immigration policy support. H4b was not supported . \n \n \n \n \n \n \n \n \n \n \n \n \n \n Table 4.7  \n \nHierarchical Regression for Punitive Crime Policy Support  \n \nVariable   \n 95% CI  adj. R2 \n R2 \nStep 1: Demographics     -.05  \nAge .04 -.07 .03   \nFemale (reference male)  .04 -.33 .83   \nIncome  .00 -.14 .14   \nEducation  -.04 -.22 .16   \nBlack  -.04 -.84 .61   \nHispanic  .00 -.70 .68   \nOther  -.05 -1.37 .85   \nStep 2: Partisanship     .10 .15***  \nRepublican -lean .42***  .69 1.81   \nStep 3: Media Use     .10 .01 \nNews consumption  -.11 -.39 .11   \nStep 4: Twitter Use     .10 .00 \nTwitter news use  .06 -.15 .28   \nStep 5: News Exposure     .12 .03\u2020 \nTotal number of crime news \narticles  -.18\u2020 -.72 .01     \nNote. N  = 121; Final model: F (11, 109) = 2.49, p < .01 \naWhite is the reference group for each racial group  \n\u2020p < .10. * p < .05. ** p < .01. *** p < .001.  \n \n 83  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n  Anti-immigration policies  Pro-immigration policies  \n Model 1  Model 2  \nVariable  \n 95% CI  adj. R2 R2 \n 95% CI  adj. R2 R2 \nStep 1: Demographic variables     .19     .14  \nAge .06 -.03 .04   -.12 -.04 .01   \nGender (Female)  -.11 -1.36 .56   .34**  .25 1.66   \nIncome  .27 -.01 .45   -.41**  -.43 -.09   \nEducation  -.07 -.42 .26   .37**  .10 .61   \nBlack  -.06 -1.53 1.05   -.35* -2.14 -.24   \nHispanic  -.07 -1.42 .85   -.29* -1.75 -.08   \nOther  -.09 -2.35 1.15   .01 -1.22 1.36   \nStep 2: Partisanship     .27 .23***     .15 .02 \nRepublican -lean .54***  1.24 2.99   -.15 -1.21 .27   \nStep 3: Media Use     .26 .00    .16 .02 \nNews consumption  .07 -.29 .53   -.18 -.59 .10   \nStep 4: Twitter Use     .26 .01    .17 .02 \nTwitter news use  .14 -.17 .65   .15 -.14 .55   \nStep 5: News Exposure     .26 .00    .16 .00 \nTotal number of \nimmigration news articles  -.07 -1.00 .51     .05 -.51 .76     \n \nNote. N  = 75; Model 1: F (11, 63) = 3.30, p < .01; Model 2: F (11, 63) = 2.23, p < .05 \naWhite is the reference group for each racial group  \n\u2020p < .10. *p < .05. **p < .01. *** p < .001.  \n \nTable 4.8  \n \nHierarchical Regression for Support for Anti - and Pro -Immigration Policies  \n \n 84 Crime and Immigration Issue Interpretation  \n With respect to crime -related thoughts, the majority of thoughts utilized a crime and \njustice frame ( M = 1.01, SD = 1.86), followed by a political frame ( M = .40, SD = 1.05), and \nsocial fr ame ( M = .21, SD = .45). Explicit group mentions in relation to crime, however, were not \nas prevalent among participants\u2019 thoughts ( M = .06, SD = .28). The majority of participant \nthoughts on immigration referenced a political frame ( M = 1.09, SD = 1.48), followed by a social \nframe ( M = .54, SD = 1.06), and a crime and justice frame ( M = .17, SD = .53). Similar to \nparticipant thoughts on crime, explicit group mentions pertaining to immigration were not \nprevalent ( M = .12, SD = .45). Given the low number of explicit group mentions, I focused \nanalyses on comparing prevalent crime news frames and participants issue interpretations of \ncrime.  \nH5 predicted that participants would report issue interpretations consistent with frames \nprevalent in their individual social media feeds. To test this hypothesis, I conducted correlational \nanalysis comparing prevalent news frames and participants\u2019 issue interpretations. Results of the \ncorrelational analyses are reported in Table 4.9 and Table 4.10. Analysis dem onstrated no \nrelationship between  the presence of  crime news frames and issue interpretations of crime. \nParticipants did not report issue interpretations of crime that were consistent with the news \nframes they potentially encountered on Twitter.  \nWith resp ect to immigration, however, analysis demonstrated relationships between issue \ninterpretations of immigration and immigration news frames prevalent in participants\u2019 news \nfeeds. There was a positive relationship between social immigration news frames and po litical \nand policy thoughts ( r = .44, p < .01) . Additionally, there was a positive relationship between \ncrime and justice frames  and both political and policy thoughts ( r = .48, p < .01)  and social \n \n 85 thoughts ( r = .38, p < .05). Contrary to the hypothesis, p articipants\u2019 interpretations of \nimmigration did not unequivocally match the immigration news frames  they potentially \nencountered on Twitter  (e.g., social frames and social thoughts). Instead, participants\u2019 thoughts \nwere consistent with other news frames (e .g., social frames and political and policy thoughts). \nSince participants\u2019 thoughts did not align with the news frames prevalent in their news feeds, H5 \nwas not supported.  \nTable 4.9  \n \nCorrelation Matrix for Crime News Frames and Issue Interpretations of Cr ime \nVariable  1 2 3 4 5 6 \n1. Social frame  ----      \n2. Political and policy frame  .47** ----     \n3. Crime and justice frame  .44***  .82***  ----    \n4. Social thoughts  .16 .08 .08 ----   \n5. Political and policy thoughts  -.09 .08 -.02 .05 ----  \n6. Crime and justice thoughts  .32* -.14 -.05 .01 -.08 ---- \nNote . N = 126; Table reports Pearson correlations  \n\u2020p < .10. *p < .05. **p < .01. *** p < .001  \n \nTable 4.10  \n \nCorrelation Matrix for Immigration News Frames and Issue Interpretations of Immigration  \nVariable  1 2 3 4 5 6 \n1. Social frame  ----      \n2. Political and policy frame  .42* ----     \n3. Crime and justice frame  .57**  .62***  ----    \n4. Social thoughts  -.11 .05 .38* ----   \n5. Political and policy thoughts  .44**  .12 .48**  .27**  ----  \n6. Crime and justice thoughts  .02 -.08 .02 .12 .19* ---- \nNote . N = 126; Table reports Pearson correlations  \n\u2020p < .10. *p < .05. **p < .01. *** p < .001  \n \n \n \n \n 86 Credibility of News on Twitter  \n Next, I examined whether perceptions of the credibility of Twitter news moderated the \nrelationship between news exposure and subsequent attitudes pertaining to crime or immigration \n(H6). Previous analyses demonstrated that there was only a relationship bet ween the presence of \ncrime news and support for punitive crime policy. Consequently, I examined whether \nperceptions of news credibility moderated this relationship. Analysis demonstrated that \nperceptions of Twitter news credibility did not moderate the rel ationship between the presence of \ncrime news and support for punitive crime policies. H6 was not supported.  \nTable 4.11  \n \nModeration of Perceptions of News Credibility for Punitive Crime Policy Support  \nVariable  b 95% CI  \nAge .02 -.01 .04 \nGender (Female)  .31  -.23 .85 \nIncome  -.01  -.13 .11 \nEducation  -.01 -0.21 .12 \nBlack  .46 -.25 1.16 \nHispanic  .43 -.26 1.11 \nOther  .13 -.90 1.16 \nRepublican -lean 1.19*** .63 1.75 \nNews consumption  -.18 -.44 .08 \nTwitter news use  -.29 -1.03 .45 \nTotal number of crime news articles  -.31 -.68 .05 \nPerceptions of news credibility  -.14 -1.07 .79 \nTotal number of crime news articles  x perceptions of \nTwitter news credibility  .10 -.12 .33 \nR2 .23 \nNote. N  = 121; F (13, 107) = 2.40, p < .01 \naWhite  is the reference group for each racial group  \n\u2020p < .10. *p < .05. **p < .01. *** p < .001.  \n \n \n \n \n 87 News Repertoires and News on Twitter  \n RQ5 asked whether news present in participants\u2019 social networks moderate effects \nassociated with participants\u2019 news repertoires. This research question aims to contextualize \nsocial media news exposure within participants\u2019 news diet. As discussed in the literature review \n(see Cha pter 2) , social media can amplify media effects due to traditional media exposure (see \nKleinnijenhuis et al., 2019). Prior to examining potential moderations, I conducted preliminary \ncorrelation analysis to determine whether participants\u2019 news repertoires are related to the \ncriterion variables. Table 4.12 reports the results of the correlation analysis. Analysis \ndemonstrated that heavy consumers of local + national television, newspapers, and conservative \nnews reported greater African American stereotype en dorsement. There was also a marginal \nrelationship between consumption of mainstream + liberal television news and African American \nstereotype endorsement. Heavy consumers of local + national television, mainstream + liberal \ntelevision news, newspapers, and  conservative news reported greater Latino stereotype \nendorsement. Lastly, heavy conservative news consumption was associated with greater \nperceptions of immigrants as a threat, greater support for anti -immigration policies, and less \nsupport for pro -immigr ation policies.  \n Given these relationships, I analyzed whether the presence of crime or immigration news \nin participants Twitter networks intensify these associations. My report focuses on instances \nwhere news present in participants\u2019 news feeds moderated  the effects of participants\u2019 news \nrepertoires on the criterion variables. Overall, analysis demonstrated that news available on \nparticipants\u2019 news feeds moderated the relationship between mainstream + liberal television \nnews and African American stereotyp e endorsement, b = -.36, 95% CI [ -.67, -.05]. However, the \n \n 88 conditional effect of crime news within participants\u2019 news feeds was only significant at the 16 th  \n(b = .53, p  < .001, 95% CI [.19, .87]) and 50th percentile ( b = .31, p  < .05, 95% CI [.07, .55]) .  \nFigure 4.1 depicts the moderation of crime news on the relationship between participants\u2019 \nconsumption of mainstream + liberal television news and African American stereotype \nendorsement. Participants who reported light consumption of mainstream + libera l television \nnews and exhibited news feeds with low amounts of crime news reported lower African \nAmerican stereotype endorsement than light mainstream + liberal television news consumers \nwith moderate amounts of Twitter crime news. Contrarily, participants  reporting heavy \nmainstream + liberal television news consumption, while also demonstrating low potential \nexposure to crime news on Twitter, reported greater levels of African American stereotype \nendorsement than heavy consumers of mainstream + liberal tel evision news consumption with \nmoderate potential exposure to crime news on Twitter.  \nThese relationships demonstrated that, in the absence of potential Twitter crime news \nexposure, heavy mainstream + liberal television news consumption is related to greate r \nendorsements of African American stereotypes. The effects of heavy mainstream + liberal \ntelevision, however, were buffered when there was a presence of crime news in participants\u2019 \nnews feeds. This trend continues for heavy consumers of mainstream + liber al television news \nwith large amounts of Twitter crime news, however the moderation at this level was not \nsignificant.  \n Interestingly, this conditional relationship was inverse among light consumers of \nmainstream + liberal television news. For light mains tream + liberal television news consumers, \ngreater potential for exposure to Twitter crime news was associated with greater African \nAmerican stereotype endorsement. In other words, in the absence of mainstream + liberal \n \n 89 television news exposure Twitter cri me news may result in greater African American stereotype \nendorsement.  Overall, this analysis answers RQ4, demonstrating that in the case of mainstream + \nliberal television news exposure, Twitter crime news moderates the effect on African American \nstereoty pe endorsement.  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n 90  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \nTable 4. 12 \n \nCorrelation Matrix for News Repertoires and Criterion Variables  \nNote. N = 126; Table reports Pearson correlations  \n\u2020p < .10. *p < .05. **p < .01. *** p < .001  \n \n \nVariable  1 2 3 4 5 6 7 8 9 10 \n1.Local  + national television news  ----          \n2.Mainstream + l iberal television news  .58***  ----         \n3.Newspapers  .56***  .61***  ----        \n4.Conservative news  .45***  .65***  .52***  ----       \n5.African American  \nstereotype endorsement  .19* .16\u2020 .27**  .35***  ----      \n6.Latino stereotype endorsement  .21* .20* .18* .32***  .79***  ----     \n7.Perceptions of immigrant threat  .14 -.01 .06 .34***  .55***  .66***  ----    \n8.Punitive crime policy support  -.01 -.11 -.12 .06 .32***  .38***  .40***  ----   \n9.Support for anti -immigration policies  .10 -.04 .07 .28**  .48***  .58***  .85***  .47***  ----  \n10.Support for pro -immigration policies  .11 .07 -.06 -.28**  -.22* -.11 -.30**  .03 -.23**  ---- \n \n \n 91 Table 4.13  \n \nModeration of Crime News for African American Stereotype Endorsement  \nVariable  b 95% CI  \nAge .03** .01 .05 \nGender (Female)  -.45 -1.04 .14 \nIncome  .04 -.10 .18 \nEducation  -.18\u2020 -.38 .02 \nBlack  .57 -.20 1.35 \nHispanic  .25 -.59 1.00 \nOther  -.10 -1.23 1.03 \nRepublican -lean 1.23*** .63 1.85 \nTwitter news use  .21* .01 .42 \nTwitter crime news  .91** -.01 1.82 \nMainstream + liberal television news  .53* .19 .87 \nMainstream + liberal television news  x total number \nof crime news articles  -.36* -.67 -.05 \n R2 .28 \nNote. N  = 121; F (12, 108) = 3.43, p < .001 \naWhite is the reference group for each racial group  \n\u2020p < .10. * p < .05. ** p < .01. *** p < .001.  \n \n \n \nFigure 4.1 . Conditional Effect of Mainstream + Liberal Television News Consumption on \nAfrican American Stereotype Endorsement by Twitter Crime News  \n \n22.533.544.5\nLight Moderate HeavyAfrican American Stereotype Endorsement\nMainstream + Liberal Television News Consumption Low Crime News Articles\nModerate Crime News Articles\nHigh Crime News Articles\n \n 92 Discussion  \n \n Study 2 aimed to determine the implications of Twitter news exposure on participants\u2019 \nendorsements of racial stereotypes, policy opinions, and issue interpretations. Furthermore, study \n2 analyzed how Twitter news consumption fits into the effects of broade r news consumption \n(i.e., news repertoires). Overall, the sole presence of crime news in participants\u2019 Twitter feeds \nwas not related to African American or Latino stereotype endorsement. Instead, partisanship and \noverall news consumption  influenced stereot ype endorsement.  \nAlthough the presence of crime news did not directly affect stereotype endorsement, \nanalysis demonstrated that, in conjunction with mainstream + liberal news consumption, the \npresence of crime news in participants\u2019 Twitter feeds relates t o African American stereotype \nendorsement. For heavy mainstream + liberal news consumers, news available on Twitter acts as \na buffer, resulting in depressed endorsements of African American stereotypes. For participants \nwho consumed little to no mainstream  + liberal news, greater crime news yielded greater \nendorsements of African American stereotypes. Taken together, these results suggest that crime \nnews available on Twitter may not have a direct impact on stereotype endorsement, but instead \nbuffer the effe cts of mainstream media or produce effects among those who do not consume \nmainstream media.  \n Though Twitter crime news did not directly influence stereotype endorsements, analysis \ndemonstrated relationships between crime news on Twitter and punitive polic y support. \nInterestingly, the results were in the opposite of the predicted direction, with greater Twitter \ncrime news being associated with depressed support for punitive crime policy. Lastly, the \nimmigration news available in participants\u2019 Twitter feeds were related to participants \ninterpretations of immigration. Participants whose news feeds contained immigration news with \n \n 93 prominent social frames interpreted immigration as an issue of politics and policy. Among \nparticipants whose feeds contained immigrat ion news highlighting crime and justice, \nimmigration evoked political and policy thoughts, and social thoughts.  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n 94 CHAPTER 5: GENERAL DISCUSSION  \n \nRace entrenches American politics. American s\u2019 feelings toward Black  Americans  and \nLatinos  drive sociopolitical decision making, including public policy opinions (Dixon, 2006; \nDixon & Azocar, 2007)  and support for political candidates (Abramowitz & McCoy, 2019; \nDrakulich et al., 2020) . Despite the centrality of race in American politics, r esearch  examining \nthe sociopol itical impact of social media news consumption commonly  disregard s its importance. \nMore so, to my knowledge, no existing research examines the role social media may play in \ncontributing to prevailing perceptions of Black Americans and Latinos. M y dissertat ion filled  \nthis gap , investigating  social media disseminated crime and immigration  news and its impact on \nracial perceptions and policy opinions.  \n Study 1 content analyzed crime and immigration news available in participants\u2019 \nindividual Twitter networks.  Contrary to my anticipations, explicit mentions of African \nAmericans and Latino s in crime and immigration were not plentiful. However, when present, \ncrime news framed African Americans as victims and immigration news framed Latino \nimmigrants on a spectrum from authorized, asylum seeker to unauthorized, illegal alien. \nGenerally, crime news employed frames emphasizing the crime and justice elements of crime. \nImmigration news focused on the politics and policies surrounding the issue of immigration.  \nLegacy  news sources  (e.g., CNN , the New York Times ) were among the most shared news \nsources. Lastly, irrespective of partisanship, p articipants\u2019 Twitter networks were populated with \nleft or left center news sources .  \n Study 2 built upon the co ntent analysis, examining associations between the content \navailable  in participants\u2019 individual Twitter networks and participants\u2019 sociopolitical attitudes.  \nParticipants \u2019 news repertoires, as opposed to the presence of social media disseminated crime \n \n 95 news , predicted  participants\u2019 endorsement of African American and Latino stereotypes.  \nParticipants reporting heavy news consumption reported greater stereotype endorsement. \nAlthough the potential for crime news exposure on Twitter  did not directly relate to st ereotype \nendorsement, it did attenuate the effects of heavy news consumption. For heavy consumers of \nmainstream + liberal news, greater crime news in participants\u2019 Twitter feeds equated to lower \nendorsement of African American stereotypes. For participants  reporting light mainstream + \nliberal news consumption, however, more  crime news produced greater endorsement of African \nAmerican stereotypes. Surprisingly, the degree of crime news available in participants\u2019 \nindividual Twitter feeds predicted depressed su pport for punitive crime policies.  Perceptions of \nthe credibility of news available on Twitter did not moderate this relationship.  \nImmigration frames present in participants\u2019 Twitter networks were related to their \ninterpretations of immigration. Participants whose Twitter network contained immigration news \nwith social  frames reported more thoughts stressing politics and policy. Crime a nd justice frames \nconnected with thoughts related to politics and policy, as well as thoughts about social issues. In \nthis chapter, I discuss the implications of these findings . After reviewing the major findings, I \ndiscuss the limitations posed by these s tudies . Lastly, I offer suggestions for future research on \nsocial media news consumption and sociopolitical attitudes.  \nDecentralizing Frames and  Remedying African American Stereotypes  \nA foundational contention of my dissertation assumed that negative depi ctions of African \nAmericans  would pervade crime narratives  on Twitter.  The boundless potential for these \nnarratives to thrive on  Twitter would cultivate support for harsh crime sentences and beliefs in \nnegative African American stereotypes (see Chapter 2). Crime news articles present in \nparticipants\u2019 Twitter feeds most often utilized a crime and justice  frame. Crime and justice \n \n 96 frames were classified as articles that emphasized the breaking of laws, sentencing and \npunishment of crime, increa ses or reductions in crime, and threats to the security and welfare of a \nperson, group, or nation.  \nResearch indicates that c rime narratives preoccupied with punishment and threat promote \nfears of crime and victimization (Grabe & Drew, 2007; Romer, Jamieson, & Aday, 2003) . Heavy  \nconsumption of  crime new s such as these promote  fervorous  support for harsh crime sentences \n(Dixon, 2006; Dolliver, Kenney, Reid, & Prohaska, 2018)  and beliefs in the culpability of \nAfrican Americans (Dixon, 2008a; Dixon & Azocar, 2007). As such, it would be expected that \ncrime news available in participants\u2019 Twitter feeds would act as a conduit for r acial stereotypes \nand punitive crime policy support . Surprisingly , the degree of crime news available in \nparticipants\u2019 individual Twitter feeds motivated depressed support for punitive crime policies.  \nFurthermore, although overall media use was the primary  predictor of African American and \nLatino stereotype endorsement, for heavy consumers of mainstream + liberal news, greater crime \nnews in participants\u2019 Twitter feeds produced lower endorsement of African American criminal \nstereotypes.  \nThese findings are explainable considering the news sources that were prevalent in \nparticipants\u2019 feeds and the manner in which these articles framed Black Americans in relation to \ncrime. First, t he majority of crime news in participants\u2019 news feeds originat ed from left or left \ncenter ed news sources. Liberals are perceived as more racially inclusive (Drakulich et al., 2020; \nPhilpot & Miller, 2020) . Consequently, in an effort to appeal to liberal sentiment, news \ndisseminated by left and left center sources on social media would emphasize narratives that \naspire to uphold social justice. Liberal narratives also reframe dominant narratives, such as \nemphasizing crime committed by White nationalist movements  (see Mehta, 2019) . Second, when \n \n 97 the crime news included explicit mentions of African Americans, the nar ratives focused on the \nvictimization and vulnerability of African Americans.  Mentions of African Americans included \nwell-known victims such as Emmett Till and Trayvon Martin, as well as hate crimes committed \nagainst transgender Black Americans. Heavy expos ure to liberal crime news, which emphasizes \nAfrican American vulnerability, reframes crime and quells  the racist beliefs that link African \nAmericans to criminality or propel support for harsh crime policies.  \nThe impact of Twitter crime news in relation to  racial attitudes and crime policy paints  an \nenthralling picture of the effects of social media news exposure. Research examining social \nmedia and news often emphasize s the democratizing potential of social media (e.g., S. J. Jackson \n& Foucault Welles, 201 6; Smith et al., 2020). Social media removes the barriers of traditional \nnews dissemination, providing social media users and activists an opportunity to share and \nreshare news or focus on topics for longer periods of time than would be seen in traditional  news \ncycles (see Russell Neuman et al., 2014). This agency affords opportunit ies for reframing the \n\u201cAfrican  American criminal\u201d narrative that populates the news cycles of legacy news sources (S. \nJ. Jackson & Foucault Welles, 2016; LeFebvre & Armstrong, 2018) . These findings demonstrate \nthat social media users not only partake in sharing news that reframes pre vailing narratives of \nrace and crime , but also that t hese sharing behavior s impact social media users.   \nAt the beginning of my dissertation, I proposed the concept of decentralize d framing \neffects. The concept contends that framing effects due to contingen t, social media facilitated \nencounters with  a variety of news sources would outweigh the effects of traditional online and \noffline news exposure.  Research continuously indicates that heavy news use affects the cognitive \naccessibility of African American st ereotypes ( Dixon, 2006; 2008a, 2008b ). Furthermore, \nrelationships between heavy news exposure and African American stereotype endorsement were \n \n 98 supported by the results of the Study 2 (see Chapter 4). Nevertheless, c rime news participants \npotentially encountered on Twitter proved so impactful that it offset chronically accessible \nAfrican American criminal stereotypes developed during heavy exposure to non-social media \nnews  sources (see Dixon, 2006; 2008a, 2008b).  \nThe findings strongly support the concept of decentralize d framing effects . In this case, \nthe framing power of news sources present in participants\u2019 Twitter feeds superseded that of \nparticipants \u2019 news repe rtoires. Although the most shared news sources present  in partic ipants\u2019 \nnetworks originated from the same sources found in their news repertoires , the unique \ncombination of news available on social media outweighed non -social media news exposure . \nThe significant impact of crime news available on Twitter violate s previous contentions that \nonline and offline news sources  are the primary conduit s for shaping perceptions of African \nAmericans . Instead,  participants\u2019 social connections were afforded  framing power.  These \nfindings  underscore  the integral role of social media in understanding mass media effects.  \nFraming Immigration : Party Politics  \nParty politics were prevalent in the framing of immigration news available in participants \nTwitter networks . First, immigration news available in participants\u2019 Twitter feeds mo st often \nincorporated a political and policy  frame. Political and policy  frames referenced the legality and \nconstitutionality of government regulation, the economic benefits or costs of the issue, public \nopinion, or political actors/parties, or evaluated/prescribed potential policies. Second, e xplicit \nmentions of Latino immigr ants included references to Republicans and Democrats , and \ndiscussion s of Latino immigrants as asylum seekers, migrant workers, illegal aliens, or refugees.   \nThroughout the 2016 presidential election, then presidential candidate Donald Trump \ncampaigned wit h a focus on immigration, specifically undocumented immigration (Abramowitz \n \n 99 & McCoy, 2019) . In his campaign, Trump proclaimed that Mexican immigrants  were \u201crapists\u201d \nand chanted, along with his supporters, \u201cbuild the wall\u201d (Korte & Gomez, 2018) . Trump\u2019s \nrhetoric and p olicies  solidified Republicans\u2019 \u201cownership\u201d of immigration  (Faris et al., 2017; see \nGoggin et al., 2019) . The immigration frames available on Twitter echoed these partisan divides \nvia party politics and polarized immigration terms  (e.g., asylum seeker versus illegal alien) .  \nThe immigration frames available on Twitter potentially contributed to sustaining \nparticipants\u2019 polarized views of immigrants and immigration.  Political conflict -framed news, \nwhich establishes a battle between Republicans and Democrats, encourages partisans to develop \nmore extreme, polarized opinions on the issue (Han & Federico, 2017; Han & Wackman, 2017) . \nWhen continuously encountering immigration news emphasizing politics and policy  on Twitter, \nparticipants would engage in  partisan self-stereotyping ; the behavior of following the norms of \none\u2019s partisan group.  \nStudy 2 reflects the polarized views of immigrants and immigration  between Democrats \nand Republicans. Analysis demonstrated no relationship between potential exposure to \nimmigration news and  perceptions of immigrants as a threat or support for anti -immigrant \npolicies. Instead, partisanship was the sole predictor. Republican -leaning participants reported \ngreater perceptions of immigrants as a threat than Democrat -leaning participants. Additionally, \nRepublican -leaning parti cipants supported anti -immigration policy more than Democrat -leaning \nparticipants.  Republican -leaning participants adopted the anti -immigrant norm emphasized by \ntheir political party (D. M. Price & Kaufhold, 2019) . \nThese findings emphasize how party politics, especially in the context of immigration, \nfosters anti-immigrant sentiment (Abramowitz & McCoy, 2019) . Even more pernicious, t hese \nfindings demonstrate how  immigration news encountered during Twitter  use can contribute  to \n \n 100 the polarization of the American electorate. The chasm between Democrats and Republicans \ngrows and partisans of today are more divided than that of previous generations (Iyengar et al., \n2012) . Diverged partisan opinions on social issues like immigration prove detrimental , as it \nmotivates voting behavior that is solely motivated by partisan identity. Partisan divides on \nimmigration also lay the foundati on for  politicians to successfully engage in identity ownership  \n(Kreiss et al., 2020)  \u2013 the practice in which politicians employ rhetoric that leverage s party \nidentity (as well as racial identity) to rally vot ers. Such is currently the case during Donald \nTrump\u2019s reelection campaign, where he affirms that \u201creal\u201d Americans (i.e., White Americans) \nshould be protected against the threat of immigrants or Black Americans (Karni et al., 2020; \nWong, 2019) .  \nFraming Immigration: Spreading Activation and Issue Interpretation  \nConsidering the prevalence of political and policy  framed immigration news, I expected \nthat immigration news emphasizing politics and policy would yield issue interpretations \npertaining to politics and policy. Political and policy inter pretations of immigration existed, but \nnot with the anticipated relationships. Participants whose Twitter networks contained \nimmigration news with social  frames reported more thoughts stressing politics and policy. Crime \nand justice frames connected with thoughts related to politics and policy, as well as thoughts \nabout social issues. Framing theory posits that news frames affect how audiences think about \ncrime and immigration by implying that certain considerations are applicable to the issue (V. \nPrice & Tewksbury, 1997; Tewksbury & Scheufele, 2019) . As such, political and policy \nimmigration frames should evoke explicit political and policy interpretations. Nevertheless, the \nresults demonstrate a cognitive entanglement between politics and policy, and the social or crime \naspects of immigration.  \n \n 101 During the months included in  the sample of news articles, President Trump continuously \ndeclared (on Twitter or otherwise) that immigrants were criminals and rapists (see Reny et al., \n2019) . Also, during this period of time, images of the inhumane treatment of immigrant children \nin cages at an immigration detention center surfaced (Sacchetti, 2019)  and the Trump \nadministration implemented its family separation policy (Long, 2018) . Politics and policies such \nas these overlap with ideas of crime and justice or social issues (e.g., morality, fairness and \nequality, or quality of life). Furthermore, the criminalization of immigrants a nd their unequal \ntreatment in the American immigration system ensnares ideas of crime and justice with the social \ntreatment of immigrants.  \nThe ability for immigration news frames to evoke separate issue interpretations suggests \nthat elements of cognitive priming  and spreading activation may underlie the applicability  effect \nof news frames. Spreading activation suggests that activated nodes within an individual\u2019s schema \ncan \u201cspread\u201d to other related concepts within their existing schema ( see, Fiske & Taylor , 2017 ). \nPolitical and policy frames saturated immigration news on Twitter, rendering cognition \nconcerning connecting immigration to politics and policy especially salient. Exposure to social  \nor criminal and justice  framed immigration articles may activate  and spread to accessible \ncognitive nodes, evoking political and policy thoughts on the issue. Earlier in this dissertation, I \nargued that news frames affect audiences\u2019 issue interpretations to the extent that the frame \nresonates with existing, accessible schema (Cacciatore et al., 2016; Lecheler & de Vreese, 2019; \nTewksbury & Scheufele, 2019). With respect to a hotly  debated political issue , understanding \nframing effects necessitates considering salient schema connected to the issue.  \n \n 102 Partisan Differences in Twitter News Exposure  \n Another main contention of my dissertation posited that there would be partisan \ndifferences in the presence of race -centered crime and immigration news. Since Republicans \n\u201cown\u201d the issues of crime and immigration, right -leaning news would promote crime and  \nimmigration narratives imbued with racial cues for the purpose of promoting attitudes and \npolicies favorable to Republican elites (see Chapter 2 for review). Contrary to expectations, \nDemocrat -leaning participants contained more news with explicit mention s of racial groups than \nRepublican -leaning participants.  \nPartisan differences in racialized crime news may stem from the nature of the crime news \nthat explicitly mentioned racial groups. As previously mentioned, race -centered crime news in \nthe sample incl uded references to African Americans as victims. Specifically, these narratives \ndiscussed crimes in which African Americans fell victim to White perpetrators (as in the case of \nEmmett Till and Trayvon Martin). These narratives may have proved more prevalen t in \nDemocrat -leaning networks because they align with liberal -leaning contentions about crime (see \nValentino, 1999) . While  the hypotheses were not supported , the reasoning behind the hypothesis \nremained true; partisanship influenced the nature in which race was presented in crime news.  \nPartisanship and News Exposure on Twitter  \nEncountering news on social media depends on a combination of social curation and \npersonal curation (Thorson & Wells, 2015). In this context, legacy news organizations , digitally \nnative sources, and everyday social media users share news within their netwo rks (Bakshy et al., \n2015; Thorson et al., 2019; Thorson & Wells, 2015) . The ability for social media users to shape \ntheir social networks , combined with prevailing partisan news selection in other settings  \n(Edgerly, 2015; Mour\u00e3o et al., 2018) , suggests that partisanship would impact the contingent \n \n 103 flow of social media content. Furthermore, the popularity of  digitall y native news sources  in \nsocial media suggests that digitally native sources would be dominant sources of crime and \nimmigration news.  \nOverall, t he most shared crime and immigration  news  originated from prominent cable  \nand newspaper sources (e.g., CNN , the New York Times , the Associated Press ). Surprisingly, \npartisan networks contained equal proportions of crime and immigration news from these \nsources. Although digitally native sources did not account for the majority o f top shared news \narticles, a  variety of d igitally native sources summed to the  largest number of crime and \nimmigration news in participants\u2019 Twitter feeds. Partisan differences were more prominent  when \nconsidering these unique digitally native sources . For instance, Breitbart  and the Daily Caller  \nexisted largely in Republican -leaning networks, while sources like Slate , the Wall Street Journal , \nand Global Citizen , primarily existent in Democrat -leaning networks. Lastly, d espite the source \n(e.g., cable news, digitally native news) and irrespective of partisanship, the majority of news \npresented a left and l eft-center  ideological perspective .  \nThe lack of partisan d ifferences in the most shared news sources and the dominance of \nleft and left -center news sources among all participants was especially surprising. Scholars often \nvoice concern for growing distrust of mainstream news , especially among Republicans \n(Gramlich, 2020) . These findings sugge st that, even in the context of Twitter , legacy news \norganizations remain dominant sources of news  for all users. Second, the news available for \nTwitter users skews towards liberal ideologies. Left sources include liberally biased language \nthat appeal to e motion, publish misleading reports, or omit information considered uncongenial \nto liberal ideology (\u201cMedia bias/fact check,\u201d n.d.) . Left center demonstrates slight bias,  \npublish ing factual information but with language that favors liberal causes (\u201cMedia bias/fact \n \n 104 check,\u201d n.d.) . Research examining news bias, specifically in the context of social media, \nprominently focus on conservative news and con servative actors (Benkler et al., 2018). Although \nan abundance of research finds that biased or misleading sources more commonly align with \nright -leaning ideology (Marwick, 2018; Mour\u00e3o & Robertson, 2019) , the dominance of biased, \nright -leaning sources may depend on the platform.  \nThe Role of Credibility Perceptions  \nLastly, I  proposed that perceptio ns of the credibility of Twitter news would moderate \nrelationships between Twitter news and subsequent attitudes pertaining to crime or immigration. \nGiven that only a relationship between Twitter news and support for punitive crime policy \nexisted, I analyz ed whether perceptions of credibility moderated the relationship. Contrary to \nexpectations, participants\u2019 level of credibility ascribed to the news they encounter on Twitter did \nnot produce an effect.  \n Research in the context of digital news consumption o ften considers the role of \ncredibility in news effects. Digital news environments contain news that do not adhere to \ntraditional journalistic standards. Although it was surprising that credibility did not moderate the \neffects of news within participants\u2019 T witter networks, the lack of moderation may stem from the \nnews sources that dominated the shared crime news articles. Again , the most shared crime news \narticles were sourced from prominent cable, network, and newspaper sources. Although some of \nthese sourc es are distrusted by American adults (namely Republicans\u2019 distrust of CNN ) \n(Jurkowitz et al., 2020) , sources such as CNN , the New York Times ,  and the Associated Press  are \nconsidered credible and newsworthy ( Edgerly & Vraga, 2020; Stroud & Lee, 2013 ). Credible \nsources are more impactful on audiences\u2019 attitudes and political predispositions ( Flanagin & \nMetzger, 2017 ; Stroud & Lee, 2013 ).  \n \n 105 Limitations  \n My dissertation  provided insight into the crime and immigration news users may \nencounter on Twitter and  the potential effects of these news articles. Nevertheless, both studies \nexperienced methodological limitations. First of all, my dissertation limited analysis to Twitter. \nTwitter served a proxy for social media because Twitter API allows for levels of da ta collection \nprohibited by other social media sites (e.g., Facebook) ( Freelon, 2018 ). Many American adults \nuse Twitter as their source of social media news ( Shearer & Grieco, 2019 ), however, Twitter \nusers skew liberal ( Wojcik & Hughes, 2019 ). According to  the Pew Research Institute, \nDemocrat -leaning users account for the overwhelming majority (60%) of Twitter users (Wojcik \n& Hughes, 2019). Reliance on Twitter users as participants in these studies resulted in a sample \nof predominately Democrat -leaning part icipants.  \nThe predominantly Democrat -leaning sample may have impacted the content analyzed in \nStudy 1. Crime and immigration news in the sample primarily originated from liberal leaning \nsources. The sizeable  presence of liberal leaning sources possibly re sulted from the large number \nof Democrat -leaning participants who followed  liberal news sources. Nevertheless, the heavy \npresence of liberal news in Republican networks may also signal the propensity of Twitter to \ncontain liberal sources.  \n Limitations in the sample also hindered in -depth comparisons with respect to participants  \nnews consumption. Study 2 found that mainstream + liberal media use interacted with Twitter \ncrime news, impacting participants\u2019 endorsement of African American stereotypes. This same \ninteraction was not present among participants reporting conservative ne ws consumption. The \nlack of an interaction between conservative news consumption and Twitter news use was most \nlikely due to the fact that conservative news was most prevalent among Republican -leaning \n \n 106 participants . Republican -leaning participants ( M = 2.98, SD = 1.42) reported greater conservative \nnews consumption than Democrat -leaning participants ( M = 2.09, SD = 1.25), F (1, 124) = \n12.85, p < .001.  Imbalance in cell sizes (i.e., heavy versus light conservative news users) \nrestricted the statistical power needed for moderation analysis. As such, Study 2 could not draw \nbroader conclusions between participants\u2019 news repertoires and Twitter news consumption.  \nSecond of all, my dissertation was limited in the amount of crime and immigration news \narticles presen t for analysis. Twitter API allows for the collection of Twitter data;  however, the \nAPI limits the number  of tweets that can be collected within a certain time period. I managed \ndata collection by gathering  around 3 ,000 tweets from each user followed by ea ch participant. \nThe process yielded a sizable number  of tweets within a reasonable time period, but once I \nreduced the sample to solely crime and immigration news, the number of crime and immigration \nnews articles over the time span included ( 2016 -01-01 to 2020 -01-01) was ungenerous.  \nThe sample further diminished when considering crime and news articles containing \nexplicit group mentions. For instance, of the 706 news articles classified as crime news, only 12 \nexplicit mentions of a racial group committing  criminal action (as measured via natural language \nprocessing) emerged. I compensated for the lack of explicit group mentions (i.e., noun phrases) \nlinked with action (i.e., verb phrases), by expanding my analysis to general explicit group \nmentions. Analyse s yielded a larger number of explicit racial mentions (e.g., Black family, \nMexican asylum seekers), but still not enough for statistical analysis. Consequently, I pivoted \nand conducted analysis using the total number of Twitter crime or immigration news ar ticles in \nStudy 2.  \nThe lack of explicit racial mentions potentially resulted from the method used to detect \nexplicit mentions of race. Journalist s often reference racial groups, but signals to race can occur \n \n 107 in the form of images (e.g., Farris & Mohamed, 2018 ) or names that imply race (e.g., \nstereotypical African American or Latino names)  (see Dixon & Linz, 2000) . Natural language \nprocessing misses these forms of explicit racial cues. Although my analysis could not examine \nstatistical relationships with explicit group mentions and participants\u2019 attitudes, the findings still \npresented meaningful relationships .  \nLastly, through measuring the content available in participants\u2019 social networks, my \ndissertation could not deduce the content users actually encountered during their social media \nuse. A lgorithms curate the content users see ( Thorson & Wells, 2015 ). Furthe rmore, various \nelements, including user engagement and perceived preferences, drive a lgorithms  (Lazer, 2015 , \nsee Thorson et al., 2019).  Since social media companies do not publicly provide information on \nhow their algorithms  curate content, this element could not be accounted for in the analysis. \nHowever, given significant relationships with the presence of content on participants\u2019 feeds and \nattitudes, the data provided a general picture of what participants see when using Twitter.   \nFuture Research  \n My dis sertation provided a better understanding of the crime and immigration news \nTwitter users may encounter and the implications  of exposure to these news articles. However, \ngiven the limitations discussed above, there are plenty of opportunities  for future re search. Since \nmy dissertation recruited a large number  of Democrat -leaning participants, future research \nshould include a more balanced representation of partisanship. Partisan stratification during the \ndata collection process will allow for partisan and n ews consumption comparisons not afforded \nwithin these studies. With balanced partisan representation, researchers would be able to gleam \nwhether the associations found primarily apply to Democrats, or whether they are generalizable \nto partisans as a whole.   \n \n 108  Future research should also consider the social elements of social media news \nconsumption. News dissemination in social media  seldom occur s in isolation from  user \ngenerated comments. Online d iscussion of social media disseminated  news can further frame \ncrime and immigration by signifying public opinions on the issue  or stoking partisan divides on \nthe topic. Full examination of social media disseminated news must situate analysis in the full \ncontext of what make social media news consumption unique.  \n Additionally, research should  interrogate the findings of these studies using experimental \nanalysis. Study 2 found interesting relationships between Twitter crime news and depressed \nsupport for punitive crime policies. These results were explained by the news  classified during \nthe content analysis . However , this extrapolation does not answer how these news frames \ninduced  these  associations. Do portrayals of African Americans as victims reduce support for \npunitive crime policies? Does liberal language reduce su pport for punitive crime policies? An \nexperiment will help break through this \u201cblack -box\u201d relationship, e xamining  what specific news \nelements produce reduced support for punitive crime policies.  \n Likewise, Study 2 found relationships between immigration n ews and issue \ninterpretations. In my discussion I deduced that spreading activation may prove theoretically \nrelevant in understanding the effects of framing on issue interpretation. For instance, I argued \nthat exposure to social frames in immigration news was associated with political and policy \nthoughts because these thoughts were relevant and accessible. An experimental analysis isolating \nexposure to the immigration news frames examined in Study 2 would determine whether the \nproposed theoretical extension  proves valid.  \nLastly, future research should compare the crime and immigration news prevalent  on \nsocial media with larger, societal level factors. Research indicates that various forms of curation \n \n 109 influence the content available on social media, including social curation, algorithmic  curation, \nand personal curation ( Thorson & Wells, 2015 ). However, th ese approaches to understanding \nsocial media curation  does not account for the fact that societal ev ents may influence social \nmedia sharing behavior. Major societal or political events, such as a high -profile incident of \npolice  brutality, may inundate social media with crime news stories. Depending on the \nmotivations of those sharing such content, it may  support or undermine social justice efforts. \nRecognizing connections between social media content and societal events will not only help \npredict the news social media users may encounter, but will also further situate social media \nnews consumption within the larger news environment.   \nConclusion  \n Racism unceasingly plagues every aspect of American society. African Americans are \ndisproportionately affected by the criminal justice system (Franklin & Henry, 2020)  and \nimmigration policies intentionally bar immigration from Latin American countries ( Valentino et \nal., 2013 ). Racism  and racial animosity  fuels political decision making  among the el ectorate \n(Drakulich et al., 2020; Reny et al., 2019 ). My dissertation set out to understand the role social \nmedia, by way of widespread beliefs in racial stereotypes or support for harmful public policies, \nplay in upholding racist American systems. I found  that social media are capable of suppressing \nstereotype endorsement cultivated during mainstream media exposure .  \n As I conclude this dissertation, American society has reached a reckoning on the past and \ncurrent marginalization of African Americans. Foll owing the murders of Breonna Taylor and \nGeorge Floyd, protest ers flooded American streets demanding change to the American policing \nsystem. Social media meaningfully  fueled the demands for social justice (Auxier, 2020) . Social \nmedia users looked to social media as a platform for discussing social issues, encouraging others \n \n 110 to participate, and gaining information about upcoming rallies and protests (Auxi er, 2020). The \nmeaningful findings of my dissertation accompanied with current sociopolitical  events stress \nwhy examining social media effects are imperative and why these analyses should center on \nrace.  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n 111 REFERENCES  \n \nAbramowitz, A. I., & McCoy, J. (2019). United States: Racial resentment, negative partisanship, \nand polarization in Trump\u2019s America. Annals of the American Academy of Political and \nSocial Science , 681, 137 \u2013156. https://doi.org/10.1177/0002716218811309  \nAbramowitz, A. I., & Webster, S. W. (2018). Negative partisanship: Why Americans dislike \nparties but behave like rabid partisans. Political Psychology , 39, 119 \u2013135. \nhttps://doi.org/10.1111/pops.12479  \nACLU. (1999). C A\u2019s anti -immigrant proposition 187 is voided, ending state\u2019s five -year battle \nwith ACLU, rights groups. Retrieved from https://www.aclu.org/press -releases/cas -anti-\nimmigrant -proposition -187-voided -ending -states -five-year-battle -aclu-rights  \nAggarwal, C. C. (2018). Machine learning for text . Yorktown Heights: Springer.  \nAllcott, H., & Gentzkow, M. (2017). Social media and fake news in the 2016 election. Journal of \nEconomic Perspectives , 31(2), 211 \u2013236. https://doi.org/10.1257/jep.31.2.211  \nAtwell Seate, A., & M astro, D. (2016). Media\u2019s influence on immigration attitudes: An \nintergroup threat theory approach. Communication Monographs . \nhttps://doi.org/10.1080/03637751.2015.1068433  \nAuxier, B. (2020). Activism on social media varies by race and ethnicity, age, polit ical party. \nRetrieved from Pew Research Center website: https://www.pewresearch.org/fact -\ntank/2020/07/13/activism -on-social -media -varies -by-race-and-ethnicity -age-political -party/  \nBail, C. A., Argyle, L. P., Brown, T. W., Bumpus, J. P., Chen, H., Hunzaker,  M. B. F., \u2026 \nVolfovsky, A. (2018). Exposure to opposing views on social media can increase political \npolarization. Proceedings of the National Academy of Sciences of the United States of \nAmerica , 115(37), 9216 \u20139221. https://doi.org/10.1073/pnas.1804840115  \n \n 112 Bakshy, E., Messing, S., & Adamic, L. A. (2015). Exposure to ideologically diverse news and \nopinion on Facebook. Science , 348(6239), 1130 \u20136239. \nhttps://doi.org/10.7910/DVN/LDJ7MS  \nBaum, M. A., & Groeling, T. (2008). New media and the polarization of america n political \ndiscourse. Political Communication , 25(4), 345 \u2013365. \nhttps://doi.org/10.1080/10584600802426965  \nBechtel, M. M., Hainmueller, J., Hangartner, D., & Helbling, M. (2015). Reality bites: The limits \nof framing effects for salient and contested policy issues. Political Science Research and \nMethods , 3, 683 \u2013695. https://doi.org/10.1017/psrm.2014.39  \nBenkler, Y., Faris, R., & Roberts, H. (2018). Network propoganda: Manipulation, \ndisinformation, and radicalization in American politics . New York: Oxford Unive rsity \nPress.  \nBennett, W. L., & Iyengar, S. (2008). A new era of minimal effects? The changing foundations \nof political communication. Journal of Communication , 58, 707 \u2013731. \nhttps://doi.org/10.1111/j.1460 -2466.2008.00410.x  \nBennett, W. L., & Livingston, S. ( 2018). The disinformation order: Disruptive communication \nand the decline of democratic institutions. European Journal of Communication , 33(2), \n122\u2013139. https://doi.org/10.1177/0267323118760317  \nBennett, W. L., & Pfetsch, B. (2018). Rethinking political com munication in a time of disrupted \npublic spheres. Journal of Communication , 68, 243 \u2013253. https://doi.org/10.1093/joc/jqx017  \nBoutyline, A., & Willer, R. (2017). The social structure of political echo chambers: Variation in \nideological homophily in online ne tworks. Political Psychology . \nhttps://doi.org/10.1111/pops.12337  \n \n 113 Boyd, D. M., & Ellison, N. B. (2008). Social network sites: Definition, history, and scholarship. \nJournal of Computer -Mediated Communication , 13, 210 \u2013230. \nhttps://doi.org/10.1111/j.1083 -6101.2007.00393.x  \nBoydstun, A. E., Gross, J. H., Resnik, P., & Smith, N. A. (2013). Identifying media frames and \nframe dynamics within and across policy issues . Retrieved from \nhttp://www.policyagendas.org  \nBrader, T., Valentino, N. A., & Suhay, E. (2008). What triggers public opposition to \nimmigration? Anxiety, group cues, and immigration threat. American Journal of Political \nScience , 52(4), 959 \u2013978. https://doi.org/10.1111/j.1540 -5907.2008.00353.x  \nCacciator e, M. A., Scheufele, D. A., & Iyengar, S. (2016). The end of framing as we know \nit \u2026 and the future of media effects. Mass Communication and Society , 19(1), 7 \u201323. \nhttps://doi.org/10.1080/15205436.2015.1068811  \nCard, D., Gross, J. H., Boydstun, A. E., & Smit h, N. A. (2016). Analyzing framing through the \ncasts of characters in the news. Proceedings of the 2016 Conference on Empirical Methods \nin Natural Language Processing , 1410 \u20131420.  \nChadwick, A. (2017). The hybrid media system . New York: Oxford University Pr ess. \nDigital news fact sheet. (2019). Retrieved from https://www.journalism.org/fact -sheet/digital -\nnews/  \nDixon, T. L. (2006). Psychological reactions to crime news portrayals of black criminals: \nUnderstanding the moderating roles of prior news viewing and stereotype endorsement. \nCommunication Monographs , 73, 162 \u2013187. https://doi.org/10.1080/03637750600690643  \nDixon, T. L. (2008a). Crime news and racialized beliefs: Understanding the relationship between \nlocal news viewing and perceptions of African Americans  and crime. Journal of \n \n 114 Communication , 58, 106 \u2013125. https://doi.org/10.1111/j.1460 -2466.2007.00376.x  \nDixon, T. L. (2008b). Network news and racial beliefs: Exploring the connection between \nnational television news exposure and stereotypical perceptions of A frican Americans. \nJournal of Communication , 58, 321 \u2013337. https://doi.org/10.1111/j.1460 -2466.2008.00387.x  \nDixon, T. L. (2017a). A dangerous distortion of our families: Representations of families, by \nrace, in news and opinion media . Retrieved from \nhttps:// colorofchange.org/dangerousdistortion/  \nDixon, T. L. (2017b). Good guys are still always in White? Positive change and continued \nmisrepresentation of race and crime on local television news. Communication Research , \n44(6), 775 \u2013792. https://doi.org/10.1177/00 93650215579223  \nDixon, T. L., & Azocar, C. L. (2007). Priming crime and activating blackness: Understanding the \npsychological impact of the overrepresentation of blacks as lawbreakers on television news. \nJournal of Communication , 57, 229 \u2013253. https://doi.or g/10.1111/j.1460 -2466.2007.00341.x  \nDixon, T. L., & Linz, D. (2000a). Overrepresentation and underrepresentation of African \nAmericans and Latinos as lawbreakers on television news. Journal of Communication , 50, \n131\u2013154. https://doi.org/10.1111/j.1460 -2466.2 000.tb02845.x  \nDixon, T. L., & Linz, D. (2000b). Race and the misrepresentation of victimization on local \ntelevision news. Communication Research , 27(5), 547 \u2013573. \nhttps://doi.org/10.1177/009365000027005001  \nDixon, T. L., & Williams, C. L. (2015). The changin g misrepresentation of race and crime on \nnetwork and cable news. Journal of Communication , 65, 24\u201339. \nhttps://doi.org/10.1111/jcom.12133  \nDolliver, M. J., Kenney, J. L., Reid, L. W., & Prohaska, A. (2018). Examining the relationship \n \n 115 between media consumptio n, fear of crime, and support for controversial criminal justice \npolicies using a nationally representative sample. Journal of Contemporary Criminal \nJustice , 34(4), 399 \u2013420. https://doi.org/10.1177/1043986218787734  \nDomke, D. (2001). Racial cues and political ideology: An examination of associative priming. \nCommunication Research , 28(6), 772 \u2013801. https://doi.org/10.1177/009365001028006003  \nDragojevic, M., Sink, A., & Mastro, D. (2017). Evidence of linguistic intergroup  bias in U.S. \nprint news coverage of immigration. Journal of Language and Social Psychology . \nhttps://doi.org/10.1177/0261927X16666884  \nDrakulich, K., Wozniak, K. H., Hagan, J., & Johnson, D. (2020). Race and policing in the 2016 \npresidential election: Black  lives matter, the police, and dog whistle politics. Criminology , \n58(2), 370 \u2013402. https://doi.org/10.1111/1745 -9125.12239  \nEdgerly, S. (2015). Red media, blue media, and purple media: News repertoires in the colorful \nmedia landscape. Journal of Broadcasting  and Electronic Media , 59(1), 1 \u201321. \nhttps://doi.org/10.1080/08838151.2014.998220  \nEdgerly, S., & Vraga, E. K. (2019). News, entertainment, or both? Exploring audience \nperceptions of media genre in a hybrid media environment. Journalism , 20(6), 807 \u2013826. \nhttps://doi.org/10.1177/1464884917730709  \nEdgerly, S., & Vraga, E. K. (2020). That\u2019s not news: Audience perceptions of \u2018news -ness\u2019 and \nwhy it matters. Mass Communication and Society , 15205436.2020.1729383. \nhttps://doi.org/10.1080/15205436.2020.1729383  \nEllison, N. B., Vitak, J., Gray, R., & Lampe, C. (2014). Cultivating social resources on social \nnetwork sites: Facebook relationship maintenance behaviors and their role in social capital \nprocesses. Journal of Computer -Mediated Communication , 19(4), 855 \u2013870. \n \n 116 https: //doi.org/10.1111/jcc4.12078  \nEntman, R. M. (1990). Modern racism and the images of blacks in local television news. Critical \nStudies in Mass Communication , 7(4), 332 \u2013345. \nhttps://doi.org/10.1080/15295039009360183  \nEntman, R. M. (1992). Blacks in the news: T elevision, modern racism and cultural change. \nJournalism Quarterly , 69(2), 341 \u2013361. https://doi.org/10.1177/107769909206900209  \nEntman, R. M. (1994). Representation and reality in the portrayal of blacks on network television \nnews. Journalism Quarterly , 71(3), 509 \u2013520. https://doi.org/10.1177/107769909407100303  \nEntman, R. M., & Usher, N. (2018). Framing in a fractured democracy: Impacts of digital \ntechnology on ideology, power and cascading network activation. Journal of \nCommunication , 68, 298 \u2013308. https://d oi.org/10.1093/joc/jqx019  \nFaris, R. M., Roberts, H., Etling, B., Bourassa, N., Zuckerman, E., & Benkler, Y. (2017). \nPartisanship, propaganda, and disinformation: Online media and the 2016 U.S. \npresidential election . Retrieved from \nhttps://cyber.harvard.edu /publications/2017/08/mediacloud  \nFarris, E. M., & Mohamed, H. S. (2018). Picturing immigration: How the media criminalizes \nimmigrants. Politics, Groups, and Identities , 6, 814 \u2013824. \nhttps://doi.org/10.1080/21565503.2018.1484375  \nFeezell, J. T. (2018). Agenda setting through social media: The importance of incidental news \nexposure and social filtering in the digital era. Political Research Quarterly , 71, 482 \u2013494. \nhttps://doi.org/10.1177 /1065912917744895  \nFigueroa -Caballero, A., & Mastro, D. (2018). Examining the effects of news coverage linking \nundocumented immigrants with criminality: Policy and punitive implications. \n \n 117 Communication Monographs , 1\u201322. https://doi.org/10.1080/03637751.2018. 1505049  \nFlaxman, S., Goel, S., & Rao, J. M. (2016). Filter bubbles, echo chambers, and online news \nconsumption. Public Opinion Quarterly . https://doi.org/10.1093/poq/nfw006  \nFletcher, R., Cornia, A., & Nielsen, R. K. (2020). How polarized are online and off line news \naudiences? A comparative analysis of twelve countries. International Journal of \nPress/Politics , (2), 169 \u2013195. https://doi.org/10.1177/1940161219892768  \nFoucault Welles, B., & Jackson, S. J. (2019). The battle for #Baltimore: Networked \ncounterpublics and the contested framing of urban unrest. International Journal of \nCommunication , 13, 1699 \u20131719. Retrieved from \nhttps://ijoc.org/index.php/ijoc/article/view/ 8244  \nFox, J., & McEwan, B. (2019). Social media. In M. B. Oliver, A. A. Raney, & J. Bryant (Eds.), \nMedia effects: Advances in theory and research  (4th ed., pp. 373 \u2013388). New York: \nRoutledge.  \nFox, J., & Moreland, J. J. (2014). The dark side of social networ king sites: An exploration of the \nrelational and psychological stressors associated with Facebook use and affordances . \nhttps://doi.org/10.1016/j.chb.2014.11.083  \nFranklin, T. W., & Henry, T. K. S. (2020). Racial disparities in federal sentencing outcomes: \nClarifying the role of criminal history. Crime & Delinquency , 66(1), 3 \u201332. \nhttps://doi.org/10.1177/0011128719828353  \nFreelon, D., Bossetta, M., Wells, C., Lukito, J., Xia, Y., & Adams, K. (2020). Black trolls matter: \nRacial and ideological asymmetries in soc ial media disinformation. Social Science \nComputer Review . https://doi.org/10.1177/0894439320914853  \nFreelon, D., Lopez, L., Clark, M. D., & Jackson, S. J. (2018). How Black Twitter and other \n \n 118 social media communities interact with mainstream news . Retrieved from https://kf -site-\nproduction.s3.amazonaws.com/media_elements/files/000/000/136/original/TwitterMedia -\nfinal.pdf  \nFreelon, D., McIlwain, C., & Clark, M. (2018). Quantifying the power and consequences of \nsocial media protest. New Media & Society , 20, 990 \u20131011. \nhttps://doi.org/10.1177/1461444816676646  \nFreelon, D., & Wells, C. (2020). Disinformation as political communication. Political \nCommunication . https://doi.org/10.1080/10584609.2020.1723755  \nGibson, J. J. (1979). The theory of affordances. In The ecologic al approach to visual perception  \n(pp. 119 \u2013136). New York: Taylor & Francis Group.  \nGil de Z\u00fa\u00f1iga, H., Correa, T., & Valenzuela, S. (2012). Selective exposure to cable news and \nimmigration in the U.S.: The relationship between FOX news, CNN, and attitudes to ward \nMexican immigrants. Journal of Broadcasting & Electronic Media , 56, 597 \u2013615. \nhttps://doi.org/10.1080/08838151.2012.732138  \nGil de Z\u00fa\u00f1iga, H., Weeks, B., & Ard\u00e8vol -Abreu, A. (2017). Effects of the news -finds -me \nperception in communication: Social media use implications for news seeking and learning \nabout politics. Journal of Computer -Mediated Communication , 22(3), 105 \u2013123. \nhttps://doi.org/10.1111/jcc4.12185  \nGilliam, F. D., & Iyengar, S. (2000). Prime suspects: The influence of local television news on \nthe viewing public. American Journal of Political Science , 44, 560. \nhttps://doi.org/10.2307/2669264  \nGoggin, S. N., Henderson, J. A., & Theodoridis, A. G. (2019). What goes with red and blue? \nMapping partisan and ideological associations in the minds of voter s. Political Behavior . \n \n 119 https://doi.org/10.1007/s11109 -018-09525 -6 \nGolbeck, J., Grimes, J. M., & Rogers, A. (2010). Twitter use by the U.S. Congress. Journal of \nthe American Society for Information Science and Technology , 61(8), n/a -n/a. \nhttps://doi.org/10. 1002/asi.21344  \nGrabe, M. E., & Drew, D. G. (2007). Crime cultivation: Comparisons across media genres and \nchannels. Journal of Broadcasting and Electronic Media , 51(1), 147 \u2013171. \nhttps://doi.org/10.1080/08838150701308143  \nGramlich, J. (2020). 5 facts about F ox News. Retrieved from https://www.pewresearch.org/fact -\ntank/2020/04/08/five -facts -about -fox-news/  \nGrimmer, J., & Stewart, B. M. (2013). Text as data: The promise and pitfalls of automatic \ncontent analysis methods for political texts. Political Analysis , 21(3), 267 \u2013297. \nhttps://doi.org/10.1093/pan/mps028  \nGrinberg, N., Joseph, K., Friedland, L., Swire -Thompson, B., & Lazer, D. (2019). Fake news on \nTwitter during the 2016 U.S. presidential election. Science , 363(6425), 374 \u2013378. Retrieved \nfrom http://science.sciencemag.org/  \nHan, J., & Federico, C. M. (2017). Conflict -framed news, self -categorization, and partisan \npolarization. Mass Communication and Society , 20(4), 455 \u2013480. \nhttps://doi.org/10.1080/15205436.2017.1292530  \nHan, J., & Wackman, D. B. (2017). Partisan self -stereotyping: Testing the salience hypothesis in \na prediction of political polarization. International Journal of Communication , 11, 603 \u2013625. \nHayes, A. F. (2018). Introduction to mediation, moderation, and conditional process analysis : A \nregression -based approach  (2nd ed.). New York: The Guilford Press.  \nHimelboim, I., Mccreery, S., & Smith, M. (2013). Birds of a Feather Tweet Together: Integrating \n \n 120 Network and Content Analyses to Examine Cross -Ideology Exposure on Twitter. Journal of \nComputer -Mediated Communication . https://doi.org/10.1111/jcc4.12001  \nHochschild, A. R. (2016). Strangers in their own land: Anger and mourning on the American \nright . New York: The New Press.  \nHutchings, V. L., & Valentino, N. A. (2004). The centrality of race in American politics. Annual \nReview of Political Science , 7, 383 \u2013408. \nhttps://doi.org/10.1146/annurev.polisci.7.012003.104859  \nIyengar, S., & Hahn, K. S. (2009). Red media, blue media: Evi dence of ideological selectivity in \nmedia use. Journal of Communication , 59, 19\u201339. https://doi.org/10.1111/j.1460 -\n2466.2008.01402.x  \nIyengar, S., & Krupenkin, M. (2018). The strengthening of partisan affect. Advances in Political \nPsychology , 39, 201 \u2013218. h ttps://doi.org/10.1111/pops.12487  \nIyengar, S., Lelkes, Y., Levendusky, M., Malhotra, N., & Westwood, S. J. (2018). The origins \nand consequences of affective polarization in the United States affective polarization: An \noutgrowth of partisan social identity.  Annual Review of Political Science , 1\u201335. \nIyengar, S., Sood, G., & Lelkes, Y. (2012). Affect, not ideology: A social identity perspective on \npolarization. Public Opinion Quarterly . https://doi.org/10.1093/poq/nfs038  \nJackson, J. M. (2019). Black Americans and the \u201ccrime narrative\u201d: Comments on the use of news \nframes and their impacts on public opinion formation. Politics, Groups, and Identities , 7, \n231\u2013241. https://doi.org/10.1080/21565503.2018.1553198  \nJackson, R. (2016). If they gunned me down and criming while White: An examination of \nTwitter campaigns through the lens of citizens\u2019 media. Cultural Studies \u2194 Critical \nMethodologies , 16(3), 313 \u2013319. https://doi.org/10.1177/1532708616634836  \n \n 121 Jackson, S. J., & Foucault Welles, B. (2014). Hijacking #myNYPD: Socia l Media Dissent and \nNetworked Counterpublics . https://doi.org/10.1111/jcom.12185  \nJackson, S. J., & Foucault Welles, B. (2016). #Ferguson is everywhere: initiators in emerging \ncounterpublic networks. Information, Communication & Society , 19, 397 \u2013418. \nhttps: //doi.org/10.1080/1369118X.2015.1106571  \nJamieson, K. H., & Capella, J. N. (2008). Echo chamber: Rush Limbaugh and the conservative \nmedia establishment . New York: Oxford University Press.  \nJenkins, H. (2006). Convergence culture: Where old and new media coll ide. New York: New \nYork University Press.  \nJurafsky, D., & Martin, J. H. (2019). Speech and language processing: An introduction to \nnatural language processing, computational linguistics, and speech recognition  (3rd ed.). \nRetrieved from https://web.stanford .edu/~jurafsky/slp3/edbook_oct162019.pdf  \nJurkowitz, M., Mitchell, A., Shearer, E., & Walker, M. (2020). U.S. media polarization and the \n2020 election: A nation divided. Retrieved from Pew Research Center website: \nhttps://www.journalism.org/2020/01/24/u -s-media -polarization -and-the-2020 -election -a-\nnation -divided/  \nKarni, A., Haberman, M., & Ember, S. (2020, July 29). Trump plays on racist fears of terrorized \nsuburbs to court White voters. New York Times . Retrieved fr om \nhttps://www.nytimes.com/2020/07/29/us/politics/trump -suburbs -housing -white -voters.html  \nKearney, M. W. (2020). Package \u2018rtweet.\u2019 Retrieved from https://cran.r -\nproject.org/web/packages/rtweet/rtweet.pdf  \nKelly, D. (2019). Evaluating the news: (Mis)percepti ons of objectivity and credibility. Political \nBehavior , 41, 445 \u2013471. https://doi.org/10.1007/s11109 -018-9458 -4 \n \n 122 Kilgo, D., & Mour\u00e3o, R. R. (2019). Media effects and marginalized ideas: Relationships among \nmedia consumption and support for Black Lives Matter . International Journal of \nCommunication , 13, 4287 \u20134305. Retrieved from \nhttps://ijoc.org/index.php/ijoc/article/view/10518  \nKim, S., Carvalho, J. P., Davis, A. G., & Mullins, A. M. (2011). The view of the border: News \nframing of the definition, causes, and solutions to illegal immigration. Mass Communication \nand Society , 14, 292 \u2013314. https://doi.org/10.1080/15205431003743679  \nKleinnijenhuis, J., van Hoof, A. M. J., & van Atteveldt, W. (2019). The combined effects of \nmass media and social media on political pe rceptions and preferences. Journal of \nCommunication , 69, 650 \u2013673. https://doi.org/10.1093/joc/jqz038  \nKnobloch -Westerwick, S. (2012). Selective exposure and reinforcement of attitudes and \npartisanship before a presidential election. Journal of Communication , 62, 628 \u2013642. \nhttps://doi.org/10.1111/j.1460 -2466.2012.01651.x  \nKorte, G., & Gomez, A. (2018, May 17). Trump ramps up rhetoric on undocumented \nimmigrants: \u201cThese aren\u2019t people. These are animals.\u201d USA Today . Retrieved from \nhttps://www.usatoday.com/story/ne ws/politics/2018/05/16/trump -immigrants -animals -\nmexico -democrats -sanctuary -cities/617252002/  \nKreiss, D. (2018). The networked self in the age of identity fundamentalism. In Z. Papacharissi \n(Ed.), A networked self and platforms, stories, connections  (pp. 12 \u201328). New York: \nRoutledge.  \nKreiss, D., Lawrence, R. G., & McGregor, S. C. (2020). Political identity ownership: Symbolic \ncontests to represent members of the public. Social Media and Society , 6(2). \nhttps://doi.org/10.1177/2056305120926495  \n \n 123 Kuhn, M., & Johns on, K. (2013). Applied predictive modeling . New York: Springer.  \nKwak, H., Lee, C., Park, H., & Moon, S. (2010). What is Twitter, a social network or a news \nmedia? Proceedings of the 19th International Conference on World Wide Web , 591 \u2013600. \nRetrieved from h ttp://bit.ly  \nLantz, B. (2019). Machine learning with R: Expert techniques for predictive modeling  (3rd ed.). \nBirmingham: Packt Publishing.  \nLazer, D. (2015). The rise of the social algorithm: Does content curation by Facebook introduce \nideological bias? Science , 348(6239), 1090 \u20131091. https://doi.org/10.1126/science.aab1422  \nLecheler, S., & de Vreese, C. H. (2019). News framing effects . New York : Routledge.  \nLeFebvre, R. K., & Armstrong, C. (2018). Grievance -based social movement mobilization in the \n#Ferguson Twitter storm. New Media & Society , 20(1), 8 \u201328. \nhttps://doi.org/10.1177/1461444816644697  \nLevendusky, M. (2009). The partisan sort: How libe rals became Democrats and conservative \nbecame Republicans . Chicago: The University of Chicago Press.  \nLewandowsky, S., Ecker, U. K. H., & Cook, J. (2017). Beyond misinformation: Understanding \nand coping with the \u201cpost -truth\u201d era. Journal of Applied Research  in Memory and \nCognition . https://doi.org/10.1016/j.jarmac.2017.07.008  \nLong, C. (2018, December 6). Family separations at border down, but dozens still affected. \nAssociated Press . Retrieved from \nhttps://apnews.com/dcb05d02726e4d4c9b6de2a31944ba81  \nLu, W., & Hampton, K. N. (2017). Beyond the power of networks: Differentiating network \nstructure from social media affordances for perceived social support . 19(6), 861 \u2013879. \nhttps://doi.org/10.1177/1461444 815621514  \n \n 124 Marwick, A. E. (2018). Why do People Share Fake News? A Sociotechnical Model of Media \nEffects. In Georgetown Law Technology Review  (Vol. 2).  \nMarwick, A. E., & Lewis, R. (2017). Media manipulation and disinformation online . Retrieved \nfrom https:// datasociety.net/output/media -manipulation -and-disinfo -online/  \nMastro, D., Tukachinsky, R., Behm -Morawitz, E., & Blecha, E. (2014). News coverage of \nimmigration: The influence of exposure to linguistic bias in the news on consumer\u2019s \nracial/ethnic cognitions . Communication Quarterly , 62(2), 135 \u2013154. \nhttps://doi.org/10.1080/01463373.2014.890115  \nMedia bias/fact check. (n.d.). Retrieved from https://mediabiasfactcheck.com  \nMehta, D. (2019, August). Americans are more worried about White Nationalism after El Paso.  \nRetrieved from FiveThirtyEight website: https://fivethirtyeight.com/features/americans -are-\nmore -worried -about -white -nationalism -after-el-paso/ %09  \nMelican, D. B., & Dixon, T. L. (2008). News on the net: Credibility, selective exposure, and \nracial prejudic e. Communication Research , 35, 151 \u2013168. \nhttps://doi.org/10.1177/0093650207313157  \nMendelberg, T. (2001). The race card . Princeton, N.J.: Princeton University Press.  \nMetzger, M. J. (2009). Media effects in the era of Internet communication. In R. L. Nabi & M . \nB. Oliver (Eds.), The sage handbook of media processes and effect  (pp. 561 \u2013576). \nThousand Oaks: SAGE Publications, Inc.  \nMetzger, M. J., & Flanagin, A. J. (2015). Psychological approaches to credibility assessment \nonline. In S. S. Sundar (Ed.), The Handbo ok of the Psychology of Communication \nTechnology  (pp. 445 \u2013466). Malden, MA: John Wiley & Sons, Inc.  \nMetzger, M. J., Hartsell, E. H., & Flanagin, A. J. (2015). Cognitive dissonance or credibility?: A \n \n 125 comparison of two theoretical explanations for selective exposure to partisan news. \nCommunication Research , 1\u201326. https://doi.org/10.1177/0093650215613136  \nMills, C. E. (2017). Framing Ferguson: Fox News and the construction of US racism. Race & \nClass , 58(4), 39 \u201356. https://doi.org/10.1177/0306396816685030  \nMour\u00e3o , R. R., & Robertson, C. T. (2019). Fake news as discursive integration: An analysis of \nsites that publish false, misleading, hyperpartisan and sensational information. Journalism \nStudies , 1\u201319. https://doi.org/10.1080/1461670X.2019.1566871  \nMour\u00e3o, R. R., Thorson, E., Chen, W., & Tham, S. M. (2018). Media repertoires and news trust \nduring the early Trump administration. Journalism Studies , 19(13), 1945 \u20131956. \nhttps://doi.org/10.1080/1461670X.2018.1500492  \nNarayanan, V., Barash, V., Kelly, J., Kollanyi, B., Ne udert, L. -M., & Howard, P. N. (2018). \nPolarization, partisanship and junk news consumption over social media in the US . 6. \nNelson, J. L., & Taneja, H. (2018). The small, disloyal fake news audience. New Media & \nSociety , 20(10), 3720 \u20133737. https://doi.org/1 0.1177/1461444818758715  \nNelson, T. E., & Kinder, D. R. (1996). Issue frames and group -centrism in American public \nopinion. The Journal of Politics , 58, 1055 \u20131078. Retrieved from \nhttp://www.journals.uchicago.edu/t -and-c \nNeuman, W. R., Guggenheim, L., Jang, S. M., & Bae, S. Y. (2014). The dynamics of public \nattention: Agenda -setting theory meets big data. Journal of Communication , 64, 193 \u2013214. \nhttps://doi.org/10.1111/jcom.12088  \nPhilpot, T. S., & Miller, K. M. (2020). A new face to the race card? Campaigns, racial cues, and \ncandidate credibility. Social Science Quarterly , 101(1), 73 \u201390. \nhttps://doi.org/10.1111/ssqu.12723  \n \n 126 Pilny, A., McAninch, K., Slone, A., & Moore, K. (2019). Usin g supervised machine learning in \nautomated content analysis: An example using relational uncertainty. Communication \nMethods and Measures , 13(4), 287 \u2013304. https://doi.org/10.1080/19312458.2019.1650166  \nPower, G. J., Murphy, S. T., & Coover, G. (1996). Primin g prejudice: How stereotypes and \ncounter -stereotypes influence attribution of responsibility and credibility among ingroups \nand outgroups. Human Communication Research , 23(1), 36 \u201358. \nhttps://doi.org/10.1111/j.1468 -2958.1996.tb00386.x  \nPrice, D. M., & Kaufhold, K. (2019). Bordering on empathy: The effect of selective exposure \nand border residency on immigration attitudes. Journal of Broadcasting & Electronic \nMedia , 63(3), 494 \u2013511. https://doi.org/10.1080/08838151.2019.1659089  \nPrice, V., & Tewksbury, D. (1997). News values and public opinion: A theoretical account of \nmedia priming and framing. Progress in Communication Sciences , 173 \u2013212. \nReny, T. T., Collingwood, L., & Valenzuela, A. A. (2019). Vote switching in the 2016 election: \nHow raci al and immigration attitudes, not economics, explain shifts in White voting. Public \nOpinion Quarterly , 83(1), 91 \u2013113. https://doi.org/10.1093/poq/nfz011  \nRomer, D., Jamieson, K. H., & Aday, S. (2003). Television news and the cultivation of fear of \ncrime. Journal of Communication , 53, 88\u2013104. https://doi.org/10.1111/j.1460 -\n2466.2003.tb03007.x  \nRomm, T., & Chiu, A. (2020, May 29). Twitter flags Trump, White House for \u2018glorifying \nviolence\u2019 after tweeting Minneapolis looting will lead to \u2018shooting.\u2019 The Washingto n Post . \nRetrieved from https://www.washingtonpost.com/nation/2020/05/29/trump -minneapolis -\ntwitter -protest/  \nRosenstiel, T., Sonderman, J., Loker, K., Ivancin, M., & Kjarval, N. (2015). Twitter and the \n \n 127 News: How people use the social network to learn about t he world. Retrieved from \nhttps://www.americanpressinstitute.org/publications/reports/survey -research/how -people -\nuse-twitter -news/  \nRussell, F. M. (2019). Twitter and news gatekeeping: Interactivity, reciprocity, and promotion in \nnews organizations\u2019 tweets. Digital Journalism , 7(1), 80 \u201399. \nhttps://doi.org/10.1080/21670811.2017.1399805  \nSacchetti, M. (2019, July 10). \u2018Kids in cages\u2019: House hearing examines immigration detention as \nDemocrats push for more information. The Washington Post . Retrieved from \nhttps:// www.washingtonpost.com/immigration/kids -in-cages -house -hearing -to-examine -\nimmigration -detention -as-democrats -push -for-more -information/2019/07/10/3cc53006 -\na28f-11e9 -b732 -41a79c2551bf_story.html  \nScheufele, D. A., & Tewksbury, D. (2007). Framing, agenda sett ing, and priming: The evolution \nof three media effects models. Journal of Communication , 57, 9\u201320. \nhttps://doi.org/10.1111/j.1460 -2466.2006.00337.x  \nSchradie, J. (2018). The revolution that wasn\u2019t . Cambridge: Harvard University Press.  \nShafer, J. G. (2017). Donald Trump\u2019s \u201cpolitical incorrectness\u201d: Neoliberalism as frontstage \nracism on social media. Social Media and Society , 3(3). \nhttps://doi.org/10.1177/2056305117733226  \nShearer, E., & Grieco, E. (2019). Americans are wary of the role social media sites play in \ndelivering the news. Retrieved from https://www.journalism.org/2019/10/02/americans -are-\nwary -of-the-role-social -media -sites-play-in-delivering -the-news/  \nShrum, L. J. (2009). Media consumption and perceptions of social reality: Effects and underlying \nprocesses. In J. Bryant & M. B. Oliver (Eds.), Media effects: Advances in theory and \n \n 128 research  (3rd ed., pp. 50 \u201373). New York: Routledge.  \nSides, J., Tesler, M., & Vavreck, L. (2018). Identity crisis: The 2016 presidential campaign and \nthe battle for the meanin g of America . New Jersey: Princeton University Press.  \nSilge, J., & Robinson, D. (2017). Text mining with R: A tidy approach  (1st ed.). Sebastopol: \nO\u2019Reilly.  \nSmith, M. A., Dixon, T. L., & Overbye, H. (2019). The perils of disinformation: Racial \nstereotyping, continued influence effect, and affective political polarization. National \nCommunication Association Annual Meeting . Baltimore, MD.  \nSmith, M. A., Williamso n, L. D., & Bigman, C. A. (2020). Can social media news encourage \nactivism? The impact of discrimination news frames on college students\u2019 activism \nintentions. Social Media + Society , 1\u201310. https://doi.org/10.1177/2056305120921366  \nStroud, N. J. (2010). Pola rization and partisan selective exposure. Journal of Communication , \n60, 556 \u2013557. https://doi.org/10.1111/j.1460 -2466.2010.01497.x  \nStroud, N. J. (2011). Niche News: The politics of news choice . New York: Oxford University \nPress, Inc.  \nStroud, N. J., & Curry,  A. (2015). The polarizing effects of partisan and mainstream news. In J. \nA. Thurber & A. Yoshinaka (Eds.), American gridlock: The sources, characters, and impact \nof political polarization  (pp. 337 \u2013354). https://doi.org/10.1017/cbo9781316287002.017  \nStroud,  N. J., & Lee, J. K. (2013). Perceptions of cable news credibility. Mass Communication \nand Society , 16, 67\u201388. https://doi.org/10.1080/15205436.2011.646449  \nTewksbury, D., & Rittenberg, J. (2012). News on the internet: Information and citizenship in the \n21st century . New York: Oxford University Press.  \nTewksbury, D., & Scheufele, D. A. (2019). News framing theory and research. In M. B. Oliver, \n \n 129 A. A. Raney, & J. Bryant (Eds.), Media effects: Advances in theory and research  (4th ed., \npp. 51 \u201368). New York: Routl edge.  \nThorson, K., Cotter, K., Medeiros, M., & Pak, C. (2019). Algorithmic inference, political \ninterest, and exposure to news and politics on Facebook. Information, Communication & \nSociety , 1\u201318. https://doi.org/10.1080/1369118x.2019.1642934  \nThorson, K., & Wells, C. (2015). Curated flows: A framework for mapping media exposure in \nthe digital age. Communication Theory , 26, 309 \u2013328. https://doi.org/10.1111/comt.12087  \nTreem, J. W., & Leonardi, P. M. (2013). Social media Use in organizations: Exploring the \naffordances of visibility, editability, persistence, and association. Annals of the International \nCommunication Association , 36(1), 143 \u2013189. \nhttps://doi.org/10.1080/23808985.2013.11679130  \nValentino, N. A. (1999). Crime news and the priming of racial attitudes  during evaluations of the \npresident. Public Opinion Quarterly , 63(3), 293 \u2013320. https://doi.org/10.1086/297722  \nValentino, N. A., & Brader, T. (2011). The sword\u2019s other edge perceptions of discrimination and \nracial policy opinion after Obama. Public Opinion Quarterly , 75(2), 201 \u2013226. \nhttps://doi.org/10.1093/poq/nfr010  \nValentino, N. A., Brader, T., & Jardina, A. E. ( 2013). Immigration opposition among U.S. \nWhites: General ethnocentrism or media priming of attitudes about Latinos? Political \nPsychology , 34(2), 149 \u2013166. https://doi.org/10.1111/j.1467 -9221.2012.00928.x  \nValentino, N. A., & Zhirkov, K. (2017). Blue is black  and red is white? Affective polarization \nand the racialized schemas of US Party coalitions. Annual Meeting of the Midwest Political \nScience Association . \nVan Aelst, P., Str\u00f6mb\u00e4ck, J., Aalberg, T., Esser, F., de Vreese, C., Matthes, J., \u2026 Stanyer, J. \n \n 130 (2017) . Political communication in a high -choice media environment: A challenge for \ndemocracy? Annals of the International Communication Association , 41(1), 3 \u201327. \nhttps://doi.org/10.1080/23808985.2017.1288551  \nWatson, B. R., & Riffe, D. (2013). Perceived threat, immigration policy support, and media \ncoverage: Hostile media and presumed influence. International Journal of Public Opinion \nResearch , 25(4), 459 \u2013479. https://doi.org/10.1093/ijpor/eds032  \nWells, C., Shah, D. V., Pevehouse, J. C., Yang, J., Pelled, A., Boe hm, F., \u2026 Schmidt, J. L. \n(2016). How Trump drove coverage to the nomination: Hybrid media campaigning. \nPolitical Communication , 33(4), 669 \u2013676. https://doi.org/10.1080/10584609.2016.1224416  \nWhat We Do. (n.d.). Retrieved from https://mediacloud.org/about  \nWojcieszak, M. (2019). What predicts selective exposure online: Testing political attitudes, \ncredibility, and social identity. Communication Research , 1\u201330. \nhttps://doi.org/10.1177/0093650219844868  \nWojcik, S., & Hughes, A. (201 9). Sizing up Twitter news. Retrieved from Pew Research Center \nwebsite: https://www.pewresearch.org/internet/2019/04/24/sizing -up-twitter -users/  \nWong, J. C. (2019, August 5). Trump referred to immigrant \u201cinvasion\u201d in 2,000 Facebook ads, \nanalysis reveals. The Guardian . Retrieved from https://www.theguardian.com/us -\nnews/2019/aug/05/trump -internet -facebook -ads-racism -immigrant -invasion  \nYu, L., & Liu, H. (2003). Feature selection for high -dimensional data: A fast correlation -based \nfilter solution. Proceedings o f the Twentieth International Conference on Machine \nLearning . Washington, DC.  \n \n \n \n 131 APPENDIX A: NEWS FRAME AND THOUGH T LISTING CODEBOOK  \n \nCrime and Immigration News Frames  \n \n1. (crime ) \u2013 Is the story about a violent  crime (includes general mentions of violent  crime such \nas associations between a group of people and crime)?  \n \nIn the FBI\u2019s Uniform Crime Reporting (UCR) Program, violent crime is composed of four \noffenses: murder and nonnegligent manslaughter, forcible rap e, robbery, and aggravated assault \n(including hate crime). Violent crimes are defined in the UCR Program as those offenses which \ninvolve force or threat of force.  \n \nRules:   \no Consider the headline. Does the article match the headline? (i.e., do these two elem ents \npresent a complete  crime narrative)?  \no If the article mentions violent crime and the person is mentioned as being innocent of the \ncrime, the violent crime is still mentioned.  \no If the article details a hoax crime (e.g., Jussie Smollett), code as being a bout a violent \ncrime.  \n \nExample: \u201cIn the past six years, criminal aliens have been charged with more than 560,000 \ncrimes in Texas including kidnapping, homicide, burglary, and more.\u201d  \n \nExample: \u201cBlack -on-black crime data reveals that African Americans are often the perpetrators \nof violence.\u201d  \n \n1 = Yes  \n0 = No  \n \n2. (immigration ) - Is the story about immigration in the United States?  \n \n1 = Yes  \n0 = No  \n \n3. (undocumented_immigration ) - Is the story about undocumented immigration in the United \nStates?  \n \n1 = Yes  \n0 = No  \n    \nRules:   \no Consider the headline. Does the article match the headline? (i.e., do these two elements \npresent a complete  immigration narrative)?  \n \n 132 o Asylum seekers are considered documented unless the article explicitly  states that they \nare \u201cillegal\u201d .  \n \n4. (frame ) \u2013 If the story is about crime, immigration or undocumented immigration, how is the \nissue described? Please select  a primary  and secondary  frame from the options below.   \n \nPrimary Frame: The primary frame is the dominant frame featured in the article. If a text \ncontains multiple frame cues, the primary frame is simply the one that comes across most \nstrongly; that is, the one that wi ll likely stick the most in the audience\u2019s mind. (ask \nyourself: what is the lasting impression on the audience? What did the author want to \nconvey? What are the author\u2019s motivations?)  \n \nSecondary Frame: Often the primary frame will be the one used the most frequently throughout \na text, but not always. If the article contains a frame that does not come across as the \nprimary frame, but it is still present, it qualifies as the secondary frame. This will be the \nsecond most prevalent frame that will likely stick with audiences.  \n  \n1. Economic Frame: The costs, benefits, or any monetary/financial implications of the \nissue (to an individual, family, organization, community or to the economy as a whole).  \n  \n2. Capacity and Resources Frame: The lack of or availability of phy sical, geographical, \nspatial, human, and financial resources, or the capacity of existing systems and resources \nto implement or carry out policy goals.  \n \n3. Morality Frame:  Any perspective \u2014or policy objective or action (including proposed \naction) \u2014 that is co mpelled by religious doctrine or interpretation, duty, honor, \nrighteousness or any other sense of ethics or social responsibility.  \n \n4. Fairness and Equality Frame: Equality or inequality with which laws, punishment, \nrewards, and resources are applied or distr ibuted among individuals or groups. Also, the \nbalance between the rights or interests of one individual or group compared to another \nindividual or group.  \n  \n5. Legality, Constitutionality and Jurisdiction Frame: The constraints imposed on or \nfreedoms granted t o individuals, government, and corporations via the Constitution, Bill \nof Rights and other amendments, or judicial interpretation. This deals specifically with \nthe authority of government to regulate, and the authority of individuals/corporations to \nact in dependently of government.  \n \n6. Security and Defense Frame/Law and Order, Crime and Justice Frames:  Specific \npolicies in practice and their enforcement, incentives, and implications. Includes stories \nabout enforcement and interpretation of laws by individuals and law enforcement, \nbreaking laws, loopholes, fines, sentencing and punishment. Increases or reductions in \ncrime. Security, threats to security, and protection of one\u2019s person, family, in -group, \nnation, etc. Generally, an action or a call to action that c an be taken to protect the welfare \nof a person, group, nation sometimes from a not yet manifested threat.  \n \n 133  \n7. Health and Safety Frame: Healthcare access and effectiveness, illness, disease, \nsanitation, obesity, mental health effects, prevention of or perpetua tion of gun violence, \ninfrastructure and building safety.  \n \n8. Quality of Life Frame:  The effects of a policy on individuals\u2019 wealth, mobility, access \nto resources, happiness, social structures, ease of day -to-day routines, quality of \ncommunity life, etc.  \n \n9. Cultural Identity Frame:  The social norms, trends, values and customs constituting \nculture(s), as they relate to a specific policy issue  \n  \n10. Public Opinion Frame:  References to general social attitudes, protests, polling and \ndemographic information, as well as implied or actual consequences of diverging from or \n\u201cgetting ahead of\u201d public opi nion or polls. References to a party's base or constituency \n(would usually overlap with Politics).  \n  \n11. (Party Politics) Political Frame: Any political considerations surrounding an issue. \nIssue actions or efforts or stances that are political, such as partis an filibusters, lobbyist \ninvolvement, bipartisan efforts, deal -making and vote trading, appealing to one\u2019s base, \nmentions of political maneuvering. Explicit statements that a policy issue is good or bad \nfor a particular political party or politician. Relat ing to a specific political party (e.g., \n\u201cThe Democrats are wrong because of \u2026.\u201d; \u201cThe Republicans are wrong because\u2026\u201d).  \n \n12. Policy Prescription and Evaluation Frame:  Particular policies proposed for addressing \nan identified problem, and figuring out if certa in policies will work, or if existing policies \nare effective. The article provides an explicit argument for or against the proposed policy \n(claims/evidence/reasoning).  \n \n13.  External Regulation and Reputation Frame:  The United States\u2019 external relations \nwith another nation; the external relations of one state with another; or relations between \ngroups. This includes trade agreements and outcomes, comparisons of policy outcomes or \ndesired policy outcomes.  \n \n14. Legality, Co nstitutionality and Jurisdiction Frame in a (Party Politics) Political \nFrame Context: Any discussion of politicians or political parties surrounding how they \nenact laws with questionable legality, constitutionality, or jurisdiction . Includes issue \nactions or efforts or stances that are political, such as partisan filibusters, lobbyist \ninvolvement, bipartisan efforts, deal -making and vote trading, appealing to one\u2019s base, \nmentions of political maneuvering. Explicit statements that a policy issue is good or b ad \nfor a particular political party.  \n \n15. Other : Any frame cue that does not fit in the first 14 dimensions.  \n \n \n \n \n 134 Crime and Immigration Thought Listing Codebook  \n \n1. (frame ): Participants were asked to list their thoughts about crime and immigration. We will \ncode  each individual thought to determine which frame best fits each individual thought. Please \nselect one frame per thought. Select the frame that comes across most strongly. Also, consider \nthe explicitness of the frame. Avoid interpreting the participant\u2019s r esponse based on your \npersonal beliefs. Note: If the thought lacks contextual clues, code as 13: Other.  \n \n1. Economic Frame: The costs, benefits, or any monetary/financial implications of the \nissue (to an individual, family, organization, community or to the economy as a whole).  \n \n2. Capacity and Resources Frame: The lack of or availability of physical, geographical, \nspatial, human, and financial resources, or the capacity of existing systems and resources \nto implement or carry out policy goals. (e.g., at capa city, \u201coverflowing\u201d).  \n \n3. Morality Frame:  Any perspective \u2014or policy objective or action (including proposed \naction) \u2014 that is compelled by religious doctrine or interpretation, duty, honor, \nrighteousness or any other sense of ethics or social responsibility  \n \n4. Fairness and Equality Frame: Equality or inequality with which laws, punishment, \nrewards, and resources are applied or distributed among individuals or groups. Also, the \nbalance between the rights or interests of one individual or group compared to anoth er \nindividual or group. Explicit mentions comparing two groups of people. Also, mentions \nof \u201cjustice,\u201d  \u201cfairness,\u201d \u201cunfair\u201d, \u201ccivil rights\u201d.  \n \n5. Legality, Constitutionality and Jurisdiction Frame/ Policy Prescription and \nEvaluation Frame: The legality frame includes the constraints imposed on or freedoms \ngranted to individuals, government, and corporations via the Constitution, Bill of Rights \nand other amendments, or judicial interpretation. This deals specifically with the \nauthority of government to regulate , and the authority of individuals/corporations to act \nindependently of government. Think about the legality of a law. The policy prescription \nframe includes policies proposed for addressing an identified problem, and figuring out if \ncertain policies will work, or if existing policies are effective. Explicit mentions that a \nproposed crime or immigration policy should be enacted, is effective, is ineffective, or is \nunconstitutional (e.g., \u201cbuild the wall\u201d, \u201cthe wall is stupid\u201d, \u201cDACA works\u201d, \u201csanctuary \ncities are illegal\u201d, \u201copen borders,\u201d \u201ckick them out\u201d). Examples for crime (e.g., \u201charsher \npunishment\u201d, \u201ckeep them in jail\u201d, \u201cmandatory minimum\u201d, \u201cthe death penalty\u201d, \u201cban \nguns\u201d). NOTE: Needs to be a prescription that can be legislated through policy change \nOR n eeds to include information about how it can be implemented.  \n \nExamples for Legality:  A) Opponents of laws targeting undocumented immigrants in \nArizona and Alabama are quoted as saying only the federal government, not individual \nstates, are entitled to reg ulate immigration and enforce immigration laws. B) Stories \ndiscussing legal challenges, from the federal government, to Arizona\u2019s immigration laws  \n \n \n 135 6. Security and Defense Frame/Law and Order Crime Frames:  Specific policies in \npractice and their enforcement, incentives, and implications. Includes stories about \nenforcement and interpretation of laws by individuals and law enforcement, breaking \nlaws, loopholes, fines, sentencing and punishment. Increases or reductions in crime. \nExplicit mentions about crime, cri minal behavior, or punishing criminals (e.g., \ndeath penalty, jail, prison etc.).  Also, the breaking of laws (i.e., illegals, illegal \nimmigration, undocumented, \u201cthey\u2019re illegal\u201d, \u201cthey\u2019re murderers\u201d, \u201cmurder\u201d, \n\u201ckilling\u201d, \u201cdrugs\u201d). Think of the breaking of laws as explicit  mentions of criminal \nbehavior.  \n \nSecurity, threats to security, and protection of one\u2019s person, family, in -group, nation, etc. \nGenerally,  an action or a call to action that can be taken to protect the welfare of a person, \ngroup, nation sometimes from a not yet manifested threat.  \n \n7. Health and Safety Frame: Healthcare acc ess and effectiveness, illness, disease, \nsanitation, obesity, mental health effects, prevention of or perpetuation of gun violence, \ninfrastructure and building safety.  \n \n8. Quality of Life Frame:  The effects of a policy on individuals\u2019 wealth, mobility, access  \nto resources, happiness, social structures, ease of day -to-day routines, quality of \ncommunity life, etc.  \n \n9. Cultural Identity Frame:  The social norms, trends, values and customs constituting \nculture(s), as they relate to a specific policy issue. Explicit mentions of cultural norms, \ntrends, or customs. For instance, \u201cIn America, we \u2026.\u201d  \n \n10. Public Opinion Frame:  References to general social  attitudes, protests, polling and \ndemographic information, as well as implied or actual consequences of diverging from or \n\u201cgetting ahead of\u201d public opinion or polls. References to a party's base or constituency \n(would usually overlap with Politics).  \n \n11. Polit ical Frame: Any political considerations surrounding an issue. Issue actions or \nefforts or stances that are political, such as partisan filibusters, lobbyist involvement, \nbipartisan efforts, deal -making and vote trading, appealing to one\u2019s base, mentions o f \npolitical maneuvering. Explicit statements that a policy issue is good or bad for a \nparticular political party. Explicit mention of a politician or a political party (e.g., \n\u201cRepublicans believe this is a problem\u201d or \u201cTrump is \u2026. \u201d).  \n \n12. External Regulation and Reputation Frame:  The United States\u2019 external relations with \nanother nation; the external relations of one state with another; or relations between \ngroups. This includes trade agreements and outcomes, comparisons of policy outcomes or \ndesired policy ou tcomes.  \n \n13. Other : Any frame cue that does not fit in the first 14 dimensions.  \n \n \n 136 2. (group cue ): Does the thought explicitly  mention a specific racial or ethnic group?  \n \n1 = Yes  \n0 = No  \n \nExplicit race  \u2013 In order to be considered an explicit mention, the actual race or some synonym \nmust be present. Mentions of a country (e.g., Mexico or the United States) does not equate to a \nracial or ethnic group mention.  \n \nFor classifying characters or groups into a racial category, we will be using the US Census \nCategory system, which describes race in the following manner:  \n \nSynonyms and Derogatory Slang Words for Blacks, Whites, and Latinos  \n \nBlack  White  Latino  \nAfrican American  \nAfrican (other countries?)  \nColored  \nNegro (and variations)  \nDarkies  Caucasian  \nEuropean American  \n(other countries?)  \nPale \nCrackers  Latino/Latina  \nMexican (other countries?)  \nSpic \nWetback  \n \n \nExample:  Black people, Mexicans, Latinos, etc.   \n \n3. (undocumented ): Does the thought explicitly  mention undocumented (or illegal) immigration?  \n \n1 = Yes  \n0 = No  \n \n \n \n \n \n \n \n \n \n \n 137 APPENDIX B: FEATURE SELECTION FOR SUPERVISED MACHINE LEARNING  \n \nTable B.1 \nList of Selected Features for  Supervised Machine Learning of Crime Articles  \nStemmed unigram and bigram  Symmetrical uncertainty  \nkill 0.20 \ndegre murder  0.11 \npolic  0.10 \ncharg  0.10 \npresid  0.09 \nvictim  0.08 \nbuilt 0.08 \nblood  0.08 \ntie 0.07 \nshooter  0.07 \nmoney  0.07 \njuri 0.06 \nterm 0.06 \ndeclar  0.06 \nintens  0.06 \ntax 0.06 \nuniqu  0.06 \nphysic evid  0.06 \nheinous  0.06 \nballot  0.05 \nproper  0.05 \nviolent  0.05 \nmove  0.05 \nagreement  0.04 \nrealiti  0.04 \nimmigr  0.04 \nqualiti  0.04 \nfoundat  0.04 \ntradit  0.04 \nfourth  0.04 \nfatal 0.03 \ngun 0.03 \n \n \n 138 Table B.2 \nList of Selected Features for  Supervised Machine Learning of Immigration Articles  \nStemmed unigram and bigram  Symmetrical uncertainty  \nimmigr  0.51 \nasylum  0.34 \nhomeland  0.30 \nborder  0.28 \ndetent  0.26 \nadministr  0.24 \ninjunct  0.19 \ndeport  0.19 \nimmigr polici  0.18 \ncitizenship  0.14 \nperman  0.14 \neffect  0.11 \ntrump offic  0.11 \nliberti  0.10 \nenforc immigr  0.08 \nbegin  0.07 \npopul  0.07 \nconvers  0.07 \nconnect  0.06 \nprosecutor  0.05 \nprimari  0.05 \nworld  0.05 \n \nTable B.3 \nList of Selected Features for  Supervised Machine Learning of Crime and Immigration News  \nFrames  \nStemmed unigram and bigram  Symmetrical uncertainty  \nadministr  0.24 \npolic  0.17 \ncharg  0.15 \npresid donald  0.12 \nman 0.11 \n \n \n 139 Table B.3 (cont.)  \nList of Selected Features for  Supervised Machine Learning of Crime and Immigration News \nFrames  \ndetent  0.10 \nevid 0.10 \noverwhelm  0.09 \nport 0.09 \naction  0.09 \ntrial 0.09 \noppos  0.08 \ndemocrat  0.08 \napprov  0.08 \nhighlight  0.07 \nprocedur  0.07 \npackag  0.07 \nadvanc  0.07 \ndark 0.07 \nyouth  0.07 \nattorney general  0.07 \nqualifi  0.07 \namerican  0.07 \nhomicid  0.06 \nplead guilti  0.06 \nblood  0.06 \nsearch  0.06 \nhandgun  0.06 \nchristian  0.05 \ncomplex  0.05 \njoin 0.05 \nstatist  0.05 \ndoubt  0.05 \ncount  0.04 \nconfid  0.04 \nexecut  0.04 \ncompens  0.03 \ncop 0.03 \n \n \n 140 APPENDIX C: SURVEY MEASURES  \n \n(age). What is your age in years?   \n \n(ethnicity). Please specify your ethnicity.  \n \n1 = Hispanic  \n2 = Not Hispanic  \n3 = Don\u2019t know/Decline  \n \n(race). Please specify your race.  \n \n1 = American Indian or Alaska Native  \n2 = Asian  \n3 = Black or African American  \n4 = Middle Eastern  \n5 = Native Hawaiian or Other Pacific Islander  \n6 = White  \n7 = Don\u2019t know/Decline  \n \n(gender). To which gender do you most i dentify?  \n \n1 = Male  \n2 = Female  \n \n(income). What is your total family income?  \n \n1 = less than $30,000 per year  \n2 = $30,000 - $40,000 per year  \n3 = $40,001 - $60,000 per year  \n4 = $60,001 - $80,000 per year  \n5 = $80,001 - $90,000 per year  \n6 = $90,001 - $100,000 per year  \n7 = more than $100,000 per year  \n8 = Don\u2019t know/Decline  \n \n1 = less than $30,000 per year  \n2 = $30,000 - $40,000 per year  \n3 = $40,001 - $60,000 per year  \n4 = $60,001 - $80,000 per year  \n5 = $80,001 - $90,000 per year  \n6 = $90,001 - $100,000 per year  \n7 = more than $100,000 per year  \n8 = Don\u2019t know/Decline  \n \n \n \n 141 (education). What is your highest level of school completed?  \n1 = 8th grade or less  \n2 = Some high school  \n3 = High school graduate  \n4 = Trade or Vocational School  \n5 = AA or AS degree  \n6 = College graduate BA or BS  \n7 = Master\u2019s degree  \n8 = Graduate work past Master\u2019s degree (e.g., /PhD/MD/JD)  \n9 = Don\u2019t know/Decline  \n \n(Media Use). Please respond to the following questions about your media viewing habits. Use \napplies to any device, for example your phone, television, laptop, desktop, tablet, etc.  \n \nQ19_1. How often do you watch national nightly news (e.g., CBS, ABC, or NBC)?  \nQ19_2. How often do you watch The Today Show, Good Morning America or CBS This \nMorning?  \nQ19_3. How often do you watch CNN cable news programs (e.g. Anderson Cooper, Don \nLemon)?  \nQ19_4. How often do you watch FOX cable news programs (e.g. Fox & Friends, Tucker Ca rlson \nTonight, The Ingraham Angle)?  \nQ19_5. How often do you watch MSNBC cable news programs (e.g. Rachel Maddow, Chris \nMatthews)?  \nQ19_6. How often do you watch News programming on NPR \u2013 live radio, podcasts, streaming \n(e.g. \u201cAll Things Considered\u201d)?  \nQ19_7. How often do you use conservative news websites (e.g. Instapundit, Infowars)?  \nQ19_8. How often do you use liberal news websites (e.g. Daily Kos, Mother Jones)?  \nQ19_9. How often do you listen to conservative talk radio \u2013 live radio, podcasts, streamin g (e.g. \nRush Limbaugh)?  \nQ19_10. How often do you read local newspapers (online or print)?  \nQ19_11. How often do you read national newspapers (e.g. The New York Times; Washington \nPost; online or print)?  \nQ19_12.  How often do you watch local television new s about your viewing area?  \nQ19_13. How often do you use international news websites (e.g. BBC, The Guardian)?  \n \nQ20. How often do you use Twitter?  \n1 = Never  \n2 = Less than once a week  \n3 = Once a week  \n4 = 2 -3 times a week  \n5 = Daily  \n \nQ22. How often you use Twitter [via computer, tablet, mobile, or any device] for getting news? \n(M = 4.06, SD = 1.27)  \n \n1 = Never  \n \n 142 2 = Less than once a week  \n3 = Once a week  \n4 = 2 -3 times a week  \n5 = Daily  \n \n(Social Media News Use). Please select your level of agreement/disagreement with the following \nstatements.  \n \n1 = Strongly disagree  \n2 = Disagree  \n3 = Somewhat disagree  \n4 = Neither agree nor disagree  \n5 = Somewhat agree  \n6 = Agree  \n7 = Strongly agree  \n \nQ21_1. I use Twitter to stay inform ed about current events and public affairs.  \nQ21_2. I use Twitter to get news about current events from mainstream media.  \nQ21_3. I use Twitter to get news from online news sites.  \n \n(News Credibility). Q40_1. How  complete  do you find  the news stories you vi ew on Twitter?  \n \n1 = Not at all  \n5 = Extremely  \n \n(News Credibility). Q41_1. How  accurate  do you find  the news stories you view on Twitter?  \n \n1 = Not at all  \n5 = Extremely  \n \n(News Credibility). Q42_1. How  biased  do you find  the news stories you view on Twitter? \n(reverse coded)  \n \n1 = Not at all  \n5 = Extremely  \n \n(News Credibility). Q43_1. How  trustworthy  do you find  the news stories you view on Twitter?  \n \n1 = Not at all  \n5 = Extremely  \n \n(News Credibility). Q44_1. How  credible  do you find  the news stories you view on Twitter?  \n \n1 = Not at all  \n5 = Extremely  \n \n \n 143 Q27. Generally speaking, do you think of yourself as a Democrat, a Republican, or an \nIndependent?  \n \n1 = Democrat  \n2 = Republican  \n3 = Independent  \n \nQ28. [If D/R:] Would you call yourself a strong  [Democrat], or a not very strong [Democrat]?  \n \n1 = Strong [Democrat]   \n2 = Not Very Strong [Democrat]   \n \nQ29. [If D/R:] Would you call yourself a strong [Republican], or a not very strong [Republican]?  \n \n1 = Strong [Republican]   \n2 = Not Very Strong [Republican]   \n \nQ30. [If Independent:] Do you think of yourself as closer to the Democratic Party or the \nRepublican Party?  \n \n1 = Closer to the Democratic Party  \n2 = Closer to the Republican Party  \n3 = Closer to neither party  \n \nQ31. Gene rally speaking, do you think of yourself as a liberal, a conservative, or a moderate?  \n \n1 = Liberal  \n2 = Conservative  \n3 = Moderate  \n \nQ32. [If L/M:] Would you call yourself a strong [Liberal], or a not very strong [Liberal]?  \n \n1 = Strong [Liberal]  \n2 = Not Ver y Strong [Liberal]  \n \nQ33. [If L/M:] Would you call yourself a strong [Conservative], or a not very strong \n[Conservative]?  \n \n1 = Strong [Conservative]  \n2 = Not Very Strong [Conservative]  \n \n \nQ34. [If Moderate:] Do you think of yourself as closer to the Democrat ic Party or the Republican \nParty?  \n \n1 = Closer to a Liberal  \n \n 144 2 = Closer to a Conservative  \n3 = Closer to neither  \n \nQ23. Using the thermometer, please \"slide\" to indicate how favorably or unfavorably you feel \nabout the  Democratic Party.   \n \nScore of 0 means you feel \u201ccold\u201d towards the group, a score of 50 means you do not \nfeel  \u201cparticularly warm or cold toward\u201d the group, and a score of 100 implies that you feel \n\u201cwarm\u201d towards the group.  \n \nQ24. Using the thermometer, please \"slide\" to indicate how favor ably or unfavorably you feel \nabout the  Republican Party.   \n \nScore of 0 means you feel \u201ccold\u201d towards the group, a score of 50 means you do not \nfeel  \u201cparticularly warm or cold toward\u201d the group, and a score of 100 implies that you feel \n\u201cwarm\u201d towards the gr oup. \n \nQ25. Using the thermometer, please \"slide\" to indicate how favorably or unfavorably you feel \nabout  liberals.   \n \nScore of 0 means you feel \u201ccold\u201d towards the group, a score of 50 means you do not \nfeel  \u201cparticularly warm or cold toward\u201d the group, and a score of 100 implies that you feel \n\u201cwarm\u201d towards the group.  \n \nQ26. Using the thermometer, please \"slide\" to indicate how favorably or unfavorably you feel \nabout  conservatives.   \n \nScore of 0 means you feel \u201ccold\u201d towards the group, a score of 50 means you do not \nfeel  \u201cparticularly warm or cold toward\u201d the group, and a score of 100 implies that you feel \n\u201cwarm\u201d towards the group.  \n \n(Punitive Policy Support). Please select your level of support for the following criminal justice \npolicies.   \n \n1 = Strongly oppose  \n2 = Oppose  \n3 = Somewhat oppose  \n4 = Neither oppose nor favor  \n5 = Somewhat favor  \n6 = Favor  \n7 = Strongly favor  \n \nQ8_1. Three -strikes laws  \nQ8_2. Mandatory minimums  \nQ8_3. Trying juveniles as adults  \nQ8_4. Sentence enhancements  \n \n 145 Q8_5. Capital punishment  \n \n(Support for Immigration Policies). Please select your level of support for the following \nimmigration policies.   \n \n1 = Strongly oppose  \n2 = Oppose  \n3 = Somewhat oppose  \n4 = Neither oppose nor favor  \n5 = Somewhat favor  \n6 = Favor  \n7 = Strongly favor  \n \nQ9_1. Buildin g a border wall along the U.S. -Mexico border  \nQ9_2. DACA or Delayed Action for Childhood Arrivals  \nQ9_3. Pathway for citizenship for Delayed Action for Childhood Arrivals  \nQ9_4. Sanctuary cities  \nQ9_5. Immigrant detention centers  \nQ9_6. Deportation arrests  at courthouses by immigration agents  \nQ9_7. Raids at workplaces by immigration agents  \nQ9_8. Fines for U.S. businesses that hire undocumented workers  \nQ9_9. Increased deportations of undocumented immigrants  \nQ9_10. Birthright citizenship  \nQ9_11. Increased border surveillance  \nQ9_12. Family reunification  \nQ9_13. Chain Migration  \n \n(Perceptions of Immigrant Threat). Please select your level of agreement/disagreement with the \nfollowing statements.   \n \n1 = Strongly disagree  \n2 = Disagree  \n3 = Somewhat disagree  \n4 = Neither agree nor disagree  \n5 = Somewhat agree  \n6 = Agree  \n7 = Strongly agree  \n \nQ10_1. Immigrants take jobs away from American citizens.  \nQ10_2. Immigrants create a strain on social services and schools.  \nQ10_3. The growing number of immigrants th reatens traditional American customs and values.  \nQ10_4. The government has allowed illegal immigration to get out of control.  \nQ10_5. If the number of immigrants moving into my community reached a certain point, I would \nconsider moving.  \n \n \n 146 (Latino Stereotyp e). Please select your level of agreement/disagreement with the following \nstatements.  \n \n15 = Strongly disagree  \n16 = Disagree  \n17 = Somewhat disagree  \n18 = Neither agree nor disagree  \n19 = Somewhat agree  \n20 = Agree  \n21 = Strongly agree  \n \nQ13_1. Latinos are intimi dating.  \nQ13_2. Latinos are hostile.  \nQ13_3. Latinos are uneducated.  \nQ13_4. Latinos are violent.  \nQ13_5. Latinos are loud.  \nQ13_6. Latinos do not like Whites.  \nQ13_7. Latinos tend to grow up in households in which the father is absent.  \nQ13_8. Latinos are sexually aggressive.  \nQ13_9. Latinos are lazy.  \nQ13_10. Latinos are streetwise.  \nQ13_11. Latinos are poor.  \nQ13_12. Latinos prefer to live off welfare.  \nQ13_13. Latinos are hardworking. (reverse code)  \nQ13_14. Latinos are likely to commit crime.  \nQ13_15. Latinos are drug dealers.  \n \n(African American Stereotype). Please select your level of agreement/disagreement with the \nfollowing statements.  \n \n15 = Strongly disagree  \n16 = Disagree  \n17 = Somewhat disagree  \n18 = Neither agree nor disagree  \n19 = Somewhat agree  \n20 = Agree  \n21 = Strongly agree  \n \nQ12_1. African Americans are intimidating.  \nQ12_2. African Americans are hostile.  \nQ12_3. African Americans are uneducated.  \nQ12_4. African Americans are violent.  \nQ12_5. African Americans are loud.  \nQ12_6. African Americans do not like Wh ites. \nQ12_7. African Americans tend to grow up in households in which the father is absent.  \nQ12_8. African Americans are sexually aggressive.  \n \n 147 Q12_9. African Americans are streetwise.  \nQ12_10. African Americans are poor.  \nQ12_11. African Americans prefer to live off welfare.  \nQ12_12. African Americans are hardworking. (reverse code)  \nQ12_12. African Americans are likely to commit crime.  \nQ12_14. African Americans are drug dealers.  \nQ12_15. African Americans are lazy.  \n ", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "I saw it on social media: Public opinion on race, crime, and immigration in the era of social media news consumption", "author": ["MA Smith"], "pub_year": "2020", "venue": "NA", "abstract": "Political polarization among the American electorate continuously grows (Iyengar, Sood, &  Lelkes, 2012), perniciously impeding political cohesion. Partisans refute policies simply"}, "filled": false, "gsrank": 844, "pub_url": "https://www.ideals.illinois.edu/items/117259", "author_id": [""], "url_scholarbib": "/scholar?hl=en&q=info:-cVF7R-9rHwJ:scholar.google.com/&output=cite&scirp=843&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D840%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=-cVF7R-9rHwJ&ei=n7WsaPbEK8DZieoPqdqh8QU&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:-cVF7R-9rHwJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://www.ideals.illinois.edu/items/117259/bitstreams/384854/data.pdf"}}, {"title": "Detecting Extreme Ideologies in Shifting Landscapes: An Automatic & Context-Agnostic Approach", "year": "2022", "pdf_data": "Practical Guidelines for Ideology Detection Pipelines and Psychosocial Applications\nRohit Ram1,2, Emma Thomas3, David Kernot4, Marian-Andrei Rizoiu2\n1Thaum\n2University of Technology Sydney\n3Flinders University\n4Defence Science and Technology Group\nrohit@thaum.io,marian-andrei.rizoiu@uts.edu.au,\nemma.thomas@flinders.edu.au,david.kernot@defence.gov.au\nAbstract\nOnline ideology detection is crucial for downstream tasks,\nlike countering ideologically motivated violent extremism and\nmodeling opinion dynamics. However, two significant issues\narise in practitioners\u2019 deployment. Firstly, gold-standard train-\ning data is prohibitively labor-intensive to collect and has\nlimited reusability beyond its collection context (i.e., time,\nlocation, and platform). Secondly, to circumvent expense, re-\nsearchers employ ideological signals (such as hashtags shared).\nUnfortunately, these signals\u2019 annotation requirements and con-\ntext transferability are largely unknown, and the bias they\ninduce remains unquantified. This study provides guidelines\nfor practitioners requiring real-time detection of left, right, and\nextreme ideologies in large-scale online settings. We propose\na framework for pipeline constructions, describing ideology\nsignals by their associated labor and context transferability.\nWe evaluate many constructions, quantifying the bias associ-\nated with signals and describing a pipeline that outperforms\nstate-of-the-art methods ( 0.95AUC ROC). We showcase the\ncapabilities of our pipeline on five datasets containing more\nthan 1.12 million users. We set out to investigate whether\nthe findings in the psychosocial literature, developed for the\noffline environment, apply to the online setting. We evalu-\nate at scale several psychosocial hypotheses that delineate\nideologies concerning morality, grievance, nationalism, and\ndichotomous thinking. We find that right-wing ideologies use\nmore vice-moral language, have more grievance-filled lan-\nguage, exhibit increased black-and-white thinking patterns,\nand have a greater association with national flags. This re-\nsearch empowers practitioners with guidelines for ideology\ndetection, and case studies for its application, fostering a safer\nand better understood digital landscape.\nCode \u2014 github.com/behavioral-ds/ideology prediction\n1 Introduction\nIdeologies are the collection of beliefs and opinions about\nthe ideal arrangement of society (Cohrs 2012). Tracking ex-\ntreme ideologies is particularly important in detecting ex-\ntreme voices that can spread harmful and false information,\nleading to dangerous and even deadly outcomes. Ideology is\ncanonically (and inexactly) projected onto a left-right spec-\ntrum, where the left is associated with equality and reform,\nCopyright \u00a92025, Association for the Advancement of Artificial\nIntelligence (www.aaai.org). All rights reserved.and the right is associated with authority and tradition. There\nhas been a recent increase in fringe and extreme-leaning\nworldviews, including the far-right \u2013 a prominent archetype\nof extreme ideologies associated with ultranationalism and\nopposition to multiculturalism. Worryingly, this has increased\nIdeologically Motivated Violent Extremism (IMVE) (Carr\net al. 2022) \u2013 a term coined to encompass religious, political\nand nationalist extremism. Ideology detection is a lead indi-\ncator for IMVE, fortifying individual and collective security.\nIt facilitates understanding these ideological groups\u2019 values\nand beliefs, which helps design interventions, build political\nbridges and tackle radicalization.\nRadicalization can occur in a matter of weeks (McCauley\nand Moskalenko 2008; Booth et al. 2024), both offline (face-\nto-face) and online (forums and social media platforms). To\ncombat this, practitioners \u2013 such as law enforcement and\nnational security agencies \u2013 need practical, real-time ideol-\nogy detection tools that minimize human effort and can be\napplied across diverse contexts. Despite the significant ex-\nisting literature, practical and effective detection guidelines\nremain scarce. This study establishes a framework for ideol-\nogy detection pipelines, examining diverse constructions and\ndemonstrating practical implementations using off-the-shelf\ncomponents. Our first aim is to identify practical pipelines\nthat reduce annotation efforts while maintaining transferabil-\nity across different contexts. Our second aim is to validate\ninsights into the psychosocial asymmetries of ideologies. We\nleverage five large datasets, totaling 1.12 million profiles,\nand test several hypotheses from the psychosocial literature\nat scale, mainly developed in offline laboratory setups. We\nanswer two specific research questions.\nThe first question involves ideological proxies \u2013 measur-\nable user behavior signals correlating with \u201ctrue\u201d ideology\n\u2013 that minimize annotation labor and are transferable across\ncontexts. We define a context as the tuple (topic, time, ge-\nography, platform). Prior works rely on various sources of\nideological knowledge, including manually labeling users,\nlabeling ideological proxies, and detecting group behavior\ndifferences. However, these approaches have limitations: the\nformer two require extensive expert labeling \u2013 an expensive\nresource \u2013 and often fail to transfer across contexts. The latter\noften lacks robustness. Of the three, ideological proxies are\nthe most common approach to reducing labor; however, they\nvary in reusability. See Section 2 for a complete discussion.arXiv:2208.04097v4  [cs.CY]  9 Aug 2025\nFurthermore, few users partake in direct ideological activ-\nity, and some actively avoid disclosure. Consequently, many\nproxies reveal only the vocal subset of users, biasing down-\nstream analyses (Alkiek, Zhang, and Jurgens 2022; Cohen\nand Ruths 2013). Despite this, prior works commonly use\nproxies as ground truth (Darwish et al. 2020; Rashed et al.\n2021; Xiao et al. 2020) without quantifying the bias this en-\ntices. Our first research question is: Which ideological prox-\nies minimize annotation labor, maximize context transfer-\nability, and reduce bias?\nThe second question involves the psychosocial asymme-\ntries of ideologies. Understanding the values and beliefs of\nideological groups is instrumental in modeling their polariza-\ntion and user radicalization. Ideological asymmetry studies\nare abundant in relevant disciplines (Tomkins 1963; Jost\n2017); often shown via offline surveys. For example, moral\nvalues delineate left-from-right ideologies (Graham, Haidt,\nand Nosek 2009); and grievance/grudge language delineate\nmoderate-from-extreme ideologies (Stankov 2021; Van der\nVegt et al. 2021). Many of these hypotheses were developed\nwith offline populations, and there is limited evidence for\nonline populations. We know online and offline populations\ndiffer demographically (Auxier and Anderson 2021), but we\ndo not understand their psychosocial differences. We ask\ncan we build psychosocial profiles of ideological groups\nand employ them to evaluate hypotheses related to the\npsychosocial traits of these groups?\nSolution Outline. First, we evaluate ideological proxies. We\nmake the widely adopted assumption that homophily \u2013 the\ntendency of similar individuals to associate \u2013 propagates\nideology. We build a framework to construct ideology de-\ntection pipelines. We qualitatively evaluate proxies, by their\nminimization of labelling efforts and how readily they trans-\nfer to new contexts, and quantitatively evaluate proxies on\ntheir prediction of human-annotated ground truth. We show\nthat a pipeline constructed through a proxy based on media\nconsumption and a lens based on text, is both qualitatively\nadvantageous and quantitatively performant. Second, we use\na pipeline to test hypotheses of the psychosocial asymme-\ntries of ideology at scale. We address the first question in\nSection 4. We introduce our pipeline framework, consisting\nof four components: dataset, ideological proxy, homophilic\nlens, and inference architecture. We use five social media\ndatasets , collected from three platforms (Parler, Facebook\nand Twitter), containing 1.12 million users, and spanning\nsocial domains such as TV shows, elections, climate change,\nantivaccination and the January 6th US Capitol Insurrection.\nWe frame the problem as user classification: the left-right\ndetection as ternary classification (left, right, and neutral),\nand the far-right detection as binary classification. We limit\nour scope to Anglo-centric, English-speaking contexts with a\ndominant uniaxial political spectrum1. We explore four left-\nright and two far-right ideology proxies , leveraging behaviors\nsuch as posting politically-charged hashtags, following politi-\n1This is not to discount the need for ideology detection in other\nregions, like the Global South. Nor to suggest that a uniaxial spec-\ntrum is sufficient to encompass the complex politics of global com-\nmunities. See Section 8 for a discussion.\nDataset Proxies Homophilic Lenses Inference\n#QandA, \n#Ausvotes, \n#Socialsense,\n....Hashtags,\nParty Followers,\nPolitician Endorsers,\nMedia Publication ProxyLexical \n[USE (Cichocka et al. 2016)],\nHashtag [TF-IDF],\nResharing [Multi-hot]LightGBM (Ke et al. 2017)\n#MAGA #OBAMA...\n......\n...Figure 1: The schema conceptualizes the four components\nof the pipeline ; (1) the datasets contain information about\nusers (two examples are shown), (2) the ideological proxies\nassign labels on some of the users based on external informa-\ntion (here #MAGA indicates right-leaning, while #OBAMA\nindicates left-leaning), (3) the homophilic lenses build nu-\nmeric descriptions for user and a way to measure their simi-\nlarity, and (4) inference architecture predicts the likely labels\nof all other users in the dataset.\ncal parties, endorsing politicians, and sharing media websites.\nWe build three homophilic lenses based on language, en-\ndorsements, and topics. We use the ideology proxies and\nhomophily lenses to build ideology pipelines with an off-the-\nshelf classifier . See Fig. 1.\nIn Section 6 we evaluate the performance of ideology de-\ntection pipelines. We construct gold-standard benchmarks for\nleft-right and far-right classification via human annotation\nand use them to evaluate bias introduced by ideological prox-\nies. Furthermore, we assess various combinations of ideology\nproxy and homophilic lens to observe interaction effects and\nfind the best performing combination. Finally, we compare\nthis pipeline to state-of-the-art baselines: TIMME (Xiao et al.\n2020), UUS (Darwish et al. 2020), and UUS+ (Samih and\nDarwish 2021) and achieve the best area-under-the-receiver-\noperating-curve (AUC ROC) of 0.95, an improvement of\n6.7%over the next best, TIMME.\nWe address the second question in Section 7. We evalu-\nate psychosocial hypotheses relating to morality, grievance,\nnationalism, and dichotomous thinking. For morality , we eval-\nuate the seminal Moral Foundations Theory (Graham, Haidt,\nand Nosek 2009) hypotheses, operationalized via FrameAxis\n(Kwak et al. 2021) (see Section 3). In its two subsets of\nhypotheses, individualizing and binding; we find relatively\nmore support for the prior. However, only 46% of hypotheses\nare supported overall. As alternative hypotheses, we find that\nthe right uses the language of vice more than the left, with\nstatistical significance. For grievance , following literature\nthat theorized that grudges and grievances are requirements\nfor radicalization (Stankov 2021), we find large-scale proof\nthat the far-right uses grievance language more than moder-\nates. We operationalize via the Grievance Dictionary threat-\nassessment tool (Van der Vegt et al. 2021) (see Section 3).\nFornationalism , we show that the right exhibit nationalism\nvia flag emojis, adding validity to our inferred grouping. Fi-\nnally, for dichotomous thinking , we apply a dictionary-based\napproach, showing that the far-right, followed by the right,\nexhibits more black-and-white thinking (supporting prior\nwork).\nThe main contributions of this work are as follows:\n\u2022An ideology detection pipeline applicable in large-scale\nonline setups, that minimizes labor requirements and im-\nproves transferability to multiple contexts.\n\u2022The most comprehensive discussion and analysis of ideo-\nlogical proxies (to our knowledge); quantifying their bias\nindependently and jointly with homophilic lenses. One\nconstruction outperforms state-of-the-art methods.\n\u2022Evaluation of psychosocial hypotheses concerning ideolo-\ngies in a large-scale online setting.\nGlossary. For readability, we collocate and define terms here.\nIdeological Proxy : measurable user behaviors correlating\nwith ideology (e.g., emitting hashtags, following ideological\nusers, sharing ideological media, etc.). Homophilic Lens : a\nrepresentation of users highlighting specific behaviors under\nthe homophilic assumption (users who act similarly are likely\nto share similar ideological beliefs). Inference Architecture :\na classifier used to infer user connections in a latent space.\n2 Related Work\nTwo corpora relate to our study; ideology detection and psy-\nchosocial asymmetries. Our primary concern, for the prior,\nis pipeline delineation criteria and, for the latter, is evidence\nbases for hypotheses.\n2.1 Ideology Detection Delineation\nIdeology detection is becoming popular and relevant for re-\nsearchers and practitioners across the computer, social, and\npolitical sciences. We delineate prior work by population\nscope, homophilic lenses, and ideological proxies.\nPopulation Scope describes who the technique applies to?\nMany works limit their scope to a population subset: legisla-\ntors, elites (Xiao et al. 2020), the politically active (Darwish\net al. 2020), or everyone (Samih and Darwish 2021). Subsets\noffer clearer ground truth and easier inference, but lack rep-\nresentativeness of the population, leading to biases when ap-\nplied broadly (Alkiek, Zhang, and Jurgens 2022; Cohen and\nRuths 2013) and constraining the representativeness of corre-\nlational analyses (Alizadeh et al. 2019). This work applies to\nall users, providing representative downstream analysis.\nHomophilic Lenses describe which features are utilized to\ninfer ideology? Underlying detection is the homophilic as-\nsumption \u2013 people who act similarly are likely to share similar\nideological beliefs. Prior works operationalize this via several\nlenses: content (including metadata, images (Xi et al. 2020),\nand text (Preo t \u00b8iuc-Pietro et al. 2017)), network (such as fol-\nlowership and resharing (Xiao et al. 2020)), or a combination\n(Chakraborty, Goyal, and Mukherjee 2022). In political sci-\nence, the modus operandi is Ideal Point Estimation (Poole\nand Rosenthal 1985) using homophily via legislator voting\nbehavior. Ideal Point Estimation techniques are largely unsu-\npervised and rely on distinct behavioral patterns but are used\nin most political science ideology measurement work (Gu\net al. 2016; O\u2019Hagan and Schein 2023). In particular, Barber \u00b4a(2015) utilize the following of politicians on Twitter to esti-\nmate user ideal points, and their work is employed in correla-\ntion analysis (Badaan et al. 2023). Given the host of behaviors\nthat portray ideology, novel lenses continue to emerge, in-\ncluding media sharing (Cann, Weaver, and Williams 2021;\nEady et al. 2020), and community participation (Ravi, Vela,\nand Ewetz 2022). Prior works commonly engineer salient\nlenses and seek their optimal combination (Darwish et al.\n2020; Aldayel and Magdy 2019); however the complexity of\ndata context, inference architecture, and ideological proxy\nchoices often make the conclusions unclear. For example,\nDarwish et al. (2020) recommend a retweet lens, while Al-\ndayel and Magdy (2019) recommend a network and lexical\nlens combination. The ideological salience of lenses and their\ncombinations is not our work\u2019s focus. We implement three ho-\nmophilic lenses previously shown to be ideologically salient,\nto limit interaction effects with ideological proxies concerns.\nIdeological Proxy describes what is the source of ideological\nknowledge? Prior work utilizes three paradigms for detec-\ntion: supervised, unsupervised, and weak supervision. Each\nemploys distinct ideological knowledge sources\u2013 dubbed ide-\nological proxies . In this study, we focus on both the proxies\u2019\nperformance and their expert annotation labor requirement\nwhen used across multiple contexts. We delineate proxies by\n(1) the extent to which they require expert annotation, (2) are\ntransferable to different contexts, and (3) how well they rep-\nresent trueideology. These criteria describe how well proxies\ngeneralize to arbitrary datasets and how much manual effort\nis required for switching contexts.\nDirect user annotation for supervised learning (Thomas\net al. 2022; Xiao et al. 2020) is simple, the most representa-\ntive, and accommodates fine-grained distinctions between ide-\nologies (Liu et al. 2023); however, it is also the most restric-\ntive, requiring laborious expert evaluation of users, across ev-\nery new context. Conversely, unsupervised approaches need\nlittle annotation and, in theory, are applicable in any context.\nSome apply embedding and clustering techniques (Darwish\net al. 2020; Samih and Darwish 2021; Rashed et al. 2021).\nOthers utilize matrix factorization to jointly learn represen-\ntations of users and their behaviors (Lai et al. 2022; Lahoti,\nGarimella, and Gionis 2018). These methods are not robust\nin practice, require highly polarized contexts, fail on homoge-\nnous user sets, and depend heavily on lenses. Furthermore,\nthey require expert knowledge in post-analysis (e.g., identify-\ning clusters) (Darwish et al. 2020), and clusters do not always\nalign with ideology. Weak supervision trades-off between the\nhigh labor of supervised and the instability of unsupervised\nmethods. It employs an ideological proxy, a user behavior\nstrongly correlated with ideology. Prior work utilizes a range\nof ideological proxies, including; politically-charged hash-\ntags (Rizoiu et al. 2018), political party relationships (Eady\net al. 2020), politician relationships, community participa-\ntion (Lai et al. 2022), and news media sharing (Jiang, Ren,\nand Ferrara 2023; Badawy, Lerman, and Ferrara 2019; Bailo,\nJohns, and Rizoiu 2023). We assess proxies\u2019 labor minimiza-\ntion and context transferability qualitatively in Section 4.2\nand assess their representativity quantitatively in Section 6.2.\nRelated Ideology Detection. Jiang, Ren, and Ferrara (2023)\nuse text and retweet features, and a combined media-hashtag\nproxy which they validate. However, they limit scope to\nactive users who retweet and require hashtag proxy labeling.\n2.2 Psychosocial Profiling of Ideological Groups.\nMany social science works detail the nuanced profiles of fine-\ngrained ideological groups and highlight the asymmetries\nbetween ideologies (Tomkins 1963; Jost 2017; Rao 2017;\nRao, Morstatter, and Lerman 2022), often requiring painstak-\ning surveys and ethnographic inquiry. In this work, we supply\nlarge-scale online evidence for hypotheses surrounding psy-\nchosocial asymmetries of ideologies, relating to morality,\ngrievance, nationalism, and dichotomous thinking.\nMorality. Moral Foundations Theory (Graham, Haidt, and\nNosek 2009) is an explanation of moral values variations\nbetween liberals and conservatives (see Section 3). Despite\nits support in psychological survey data (Graham, Haidt, and\nNosek 2009), and a handful of online studies (Reiter-Haas,\nKopeinik, and Lex 2021; Mokhberian et al. 2020), online\nsocial data inconsistently supports this explanation (Wang\nand Inbar 2021; Alizadeh et al. 2019).\nGrievance and Grudge are linked to extreme ideologies in\npsychological theory;Van der Vegt et al. (2021) link grievance\nto extremism, and Stankov (2021) link grudge to the far-right.\nNationalism is definitionally associated with right-wing\npoliticians. Prior work has shown that flags are associated\nwith nationalism (Kemmelmeier and Winter 2008), emojis\nhold identity and semantics information (Li et al. 2020), and\nthat flag emojis are significant in right-leaning political com-\nmunication (Kariryaa et al. 2022). However, this research is\nlimited to politicians in a US context.\nDichotomous Thinking is a cognitive distortion in people\nwith internalizing disorders, is tied to language (Bathina et al.\n2021), and is associated with the right (Meyer 2020).\nOur concern is evaluating hypotheses in large-scale online\npopulations in various contexts. Accordingly, we limit our\nscope to automated techniques using online metadata alone.\nPrior work, online, analyses left-right (Reiter-Haas, Kopeinik,\nand Lex 2021) or extremist asymmetries, but rarely both\n(Alizadeh et al. 2019). Additionally, they analyze small and\nnon-representative samples. This work analyzes left, right,\nand far-right ideologies in several large-scale online contexts.\n3 Preliminaries\nOur study relies on several techniques from prior work.\nEncoding Techniques are employed to implement ho-\nmophilic lenses; the Universal Sentence Encoder (USE) (Cer\net al. 2018) for our lexical lens (a mature, off-the-shelf,\ntransformer-based model), Term-Frequency Inverse Docu-\nment Frequency (TF-IDF) for our hashtag lens, and a multi-\nhot encoding for our resharing lens. We utilize simple encod-\ning techniques, as they are not our work\u2019s main focus.\nInference Architecture Implementation. We use Light-\nGBM (Ke et al. 2017) \u2013 an efficient tree-based classifier\n\u2013 and FlaML (Wang et al. 2021), a system that infers hyperpa-\nrameters based on dataset characteristics in pipelines.\nMoral Foundations Theory (MFT) (Graham, Haidt, and\nNosek 2009) explains variations in moral reasoning through\nfive modular foundations.It espouses that liberals expressindividualizing foundations (care and fairness) while conser-\nvatives express binding foundations (loyalty, authority, and\nsanctity) relatively more. We characterize users\u2019 language\nwith FrameAxis (Kwak et al. 2021), a dictionary embed-\nding technique, to identify a user\u2019s value for each founda-\ntion. It supplies measures, bias andintensity . Importantly,\ndictionary-embeddings are generally a refinement over dic-\ntionaries alone, particularly for smaller documents, however\nthey do not capture the complexities of human language.\nFor example, such approaches will not handle negations\n(for example, \u201cI do not care\u201d) and do not consider the con-\ntext around word usage. Large-language model (LLM) ap-\nproaches may improve these deficits; however, LLMs in-\ntroduce their own complexities (Liscio et al. 2023) and the\ndictionary/embeddings approaches are better validated.\nGrievance Dictionary (Van der Vegt et al. 2021) is curated\nfor threat assessment, including categories such as fixation,\nviolence, and paranoia. It is validated on social media data,\nand provides features for distinguishing extremist texts.\nState-Of-The-Art Baselines. In Section 6, we compare our\napproach to three state-of-the-art detection approaches. UUS\n(Darwish et al. 2020) encodes the kmost active users, applies\ndimensionality reduction, clusters these embeddings, and\nassigns clusters stances via expert annotation. The authors\ntune parameters including; k, features (based on retweets,\nretweeted accounts, and hashtags), dimensionality reduction\nschemes, and clustering schemes. They recommend encoding\n1000 users via retweets, then applying UMAP and Mean-\nShift. UUS+ (Samih and Darwish 2021) extends UUS by\nfinetuning BERT with UUS -labels; applying it to remaining\nusers. Finally, TIMME (Xiao et al. 2020) is a supervised\nmulti-task multi-relation deep graph method using five user\nrelationships to embed and classify users.\n4 Ideology Framework and Implementation\nIn this section, we describe our ideology pipeline frame-\nwork in two parts; Section 4.1 partitions pipelines into four\ncomponents and Sections 4.2 and 4.3 provides component\nimplementation details.\n4.1 Pipeline Constructions Framework\nIn this section, we abstract four components of ideology\ndetection, shown in Fig. 1: the dataset, ideological proxy,\nhomophilic lens, and inference architecture.\nThe Dataset is a set of unlabelled users and their activity\nmetadata within a context. It has an underappreciated effect\non observed pipeline performance. Section 5 discusses clas-\nsification difficulty and introduces our evaluation datasets.\nThe Ideological Proxy infuses ideological knowledge via\nweak supervision. A user subset is labeled (left, right, or\nfar-right) via ideology-correlated behaviors, such as sharing\nhashtags, following political parties, endorsing politicians, or\nsharing news media. See Section 4.2 for details.\nThe Homophilic Lens characterises ideologically salient\nuser similarity. Section 4.3 describes three homophilic lenses:\nthe lexical lens, the hashtag, and the resharing lens.\nThe Inference Architecture propagates labels from a user\nsubset to the remaining unlabelled users. We train a clas-\nsifier on the ideology-proxy-labeled users represented via\nProxy AL CT A V\nHASHTAGS * * *\nCOMMUNITY PARTICIPATION ** ** *\nPOLITICIAN ENDORSERS ** ** **\nPARTY FOLLOWERS *** ** ***\nMEDIA *** **** ****\nTable 1: Ideology Proxy Qualitative Comparison for appli-\ncation by practitioners based on three-part criteria; annotation\nlabor minimization (AL), context transferability (CT), and\nAvailability (A V). Criteria are rated out of four-stars.\nhomophilic lenses. We use LightGBM with FlaML as our\nclassifier2. The remainder of this section enumerates the ide-\nological proxies (Section 4.2) and homophilic lenses (Sec-\ntion 4.3) evaluated, and their implementations.\n4.2 Implementating Ideological Proxies\nHere, we qualitatively compare proxies and describe the im-\nplementations of the proxies evaluated in our study.\nProxy Qualitative Comparison. We conduct an assessment\nof proxies, based on their utility for practitioners. Based on\nour reading of the thematic review presented in Section 2,\nwe qualitatively build three criteria to assess each proxy. The\ncriteria are designed to partially order proxies as a guide to\npractitioners. Therefore, we apply a four-star rating (one star\nis lower) for each criterion, as shown in Section 4.2.\nThe first criterion we construct is labor minimization (AL)\ndefined as the extent to which expert labor is required to\ngenerate the proxy. Proxies which require human experts to\nperform the entire contruction will score one star, whereas an\napproach with no human intervention scores four stars. The\nsecond criterion is context transferability3(CT), defined as\nthe number and diversity of contexts in which a proxy can\nbe applied. If a proxy is only available in a given context\nit will score one star, whereas if the proxy is available with\nno restrictions, it will score four stars. The third criterion is\navailability to practitioners4(A V), defined as the extent to\nwhich a proxy or its ingredients are openly available, either\nfor ideology detection or independent tasks.\nHASHTAGS shared is commonly used as a proxy, but re-\nquires domain knowledge and is time-consuming to generate\n(one star on AL), and generally requires reannotation for\nevery dataset (* for CT). Furthermore, not all social media\nplatforms use hashtags therefore it has a low availability (*\nfor A V). COMMUNITY PARTICIPATION uses user activity in\nideological communities (e.g., subreddit posting). The com-\nmunities tend to be fewer and more persistent (** on AL) and\n2The hyperparameter nestimators is inferred for the far-\nright detection due to the sparsity of labeled users; it is fixed\nto200 for left-right detection to prevent overfitting. We set the\nisunbalance flag due to label imbalance.\n3Note that context transferability has a multiplier effect on anno-\ntation labor since a failure to transfer requires reannotation.\n4We do not discount prior work labor. However, we recognize\nthat availability differs, independently of ideology tasks, and proxies\u2019\nmaintenance should be considered in practitioner guidelines.there is some detectable overlap of the communities between\nplatforms (** on CT). However, they are unavailable on some\nplatforms (e.g., Twitter/X) and are inconsistent across coun-\ntries (* on A V). Furthermore, it requires experts for anno-\ntation, and datasets linking communities to ideologies are\nfew. PARTY FOLLOWERS andPOLITICIAN ENDORSERS\nleverage databases of political parties and politicians with\ntheir online profiles, which are intermittently available (** on\nA V). Such databases are usually country- and period-specific\n\u2013 political parties emerge, change, and become relegated in\ntime. The advantage of these proxies is their stability and\nnon-ambivalent nature during the studied context (** on CT).\nFurthermore, databases do not encode all ideologically rel-\nevant information, such as the lean of parties or specific\npoliticians, requiring an expert instead (** and *** on AL,\nrespectively). MEDIA proxies utilize users sharing news me-\ndia, which often have known political slants. They leverage\navailable and well-maintained data on media slants (*** on\nAL), which have intrinsic value in communication studies,\nthe news ideology detection task, and general consumer value.\nThere is strong evidence linking news readership (Garimella\net al. 2021; Bakshy, Messing, and Adamic 2015) and sharing\n(An, Quercia, and Crowcroft 2014) to ideology. Media slants\nare fairly consistent across time, media-sharing behaviors\noccur on most platforms (**** on A V), and media tend to be\nideologically consistent across topics (**** on CT). There\nare limitations to the media proxy (see Section 8), but it out-\nperforms its alternatives in terms of annotation labor, context\ntransferability, and general availability.\nLeft-Right ideological proxies. We build four proxies.\nHASHTAGS proxy requires experts to code hashtags. We\nqualitatively inspect the 1,000most common hashtags in our\ndatasets and label their political lean; \u22121if left-leaning, 0\nif non-partisan, and 1if right-leaning. We quantify a user\u2019s\npolitical lean as the mean of the labeled hashtags they emit\nand their ideology label as the sign of this lean.\nPARTY FOLLOWERS proxy requires collecting the follow-\ners of the major political parties\u2019 online accounts for each\ntarget country (i.e., Australia and USA). We code the political\nparties by their ideology. The users in the dataset who follow\na single party receive the party\u2019s ideology label.\nPOLITICIAN ENDORSERS proxy requires a dataset of\npoliticians, their political affiliations, and social media han-\ndles. We use the Twitter Parliamentarian Database (van Vliet,\nT\u00a8ornberg, and Uitermark 2020). We code the politicians us-\ning their party\u2019s ideology (where independents are excluded).\nNote that independents\u2019 exclusion reduces the proxy rep-\nresentativity, but this is preferable to manually labeling all\nindependents. We label users who retweet politicians using\nthe majority vote of the politicians\u2019 ideologies.\nLEFT-RIGHT MPP (Media Publication Proxy) requires\na dataset of media websites with their political slants. We\nutilize an extensive survey (Park et al. 2021; Newman\net al. 2021) of news consumption behavior within English-\nspeaking countries (Australia, New Zealand, UK and the\nUSA), collected in 2020 and 2021 by Reuters. Participants\nindicated the news media they read and self-reported their po-\nlitical leaning ranging from \u22123(extreme left) to 3(extreme\nright). We compute a publication\u2019s slant as the weighted\nmean political lean of the participants who consume that pub-\nlication, where each participant is weighted by the inverse\nnumber of publications they consume. Since countries\u2019 per-\nspectives on what constitutes left- and right-leaning differ,\nwe calibrate scores across countries with the AllSides Media\nBias Ratings (AllSides 2022). We encode the ratings\u2019 five-\npoint scale onto a numerical scale from \u22121to1. We align\neach country\u2019s scores, minimizing the sum of squared dif-\nferences between a country\u2019s scores and AllSides scores for\noverlapping publications. Finally, we generate slant scores\nfor each publication as the average slant over all countries and\nyears. We associate publications (and their slants) with their\nwebsite domains, averaging where a domain is shared. We\npresent the media organizations and their constructed slant\nscores in online appendix (Appendix 2024). We compute a\nuser\u2019s political lean as the average lean of the media domains\nthey share and their ideology label as the sign of this lean.\nFar-Right ideology proxies. We build two proxies.\nFAR-RIGHT MPP is constructed from the media slant\nscores of mainstream media built for LEFT-RIGHT MPP .\nNext, we label users \u2018far-right\u2019 if their political lean exceeds\n0.5or as \u2018moderate\u2019 otherwise.\nMBFC MPP is constructed from the Media Bias Fact Check\n(Zandt 2022) dataset, including both media slant and veracity,\nand containing conspiratorial and fake news sources. We label\nusers sharing the right-most media category as \u2018far-right\u2019.\n4.3 Homophilic Lenses\nHomophily is the tendency of similar users to be similar\n(McPherson, Smith-Lovin, and Cook 2001) and is commonly\nassumed in ideology detection. A homophilic lens is a user\nembedding that encodes ideologically relevant information.\nHere we convert content about user behavior into numerical\nvectors. This section details three lenses.\nLexical Lens (USE). Language is a strong indicator of one\u2019s\npolitical ideology (Cichocka et al. 2016); since a sociolect is\nformed through associations with others.\nHashtag Lens (HT). Hashtags signal users\u2019 interests and the\ndiscussion topics they participate in (Bode et al. 2013).\nResharing Lens (RT). Resharing is a signal of endorsement\n(Metaxas et al. 2015). We assume users endorsing the same\npeople likely share similar ideologies (Van Vliet, T \u00a8ornberg,\nand Uitermark 2021).\nImplementation. For the lexical lens , we preprocess text, to\nprevent potential data leaks, by removing URLs, hashtags,\nand mentions. We concatenate each user\u2019s tweets and encode\nthem as 512dimensional vectors via the universal sentence\nencoder (USE) (Cer et al. 2018). The encoder choice is arbi-\ntrary and based on its prior user in literature for social media-\noriginating text (Rashed et al. 2021). For the hashtag lens ,\nwe use the Term-Frequency Inverse Document Frequency\n(TF-IDF) of users (i.e., documents) via hashtags (i.e., words)\nthey use if used at least 10times. TF-IDF is a refinement\nover the bag-of-words model that weights terms used by their\noccurrence within a corpus, providing a simple but salient\nvector representation. Finally, for the resharing lens , we gen-\nerate a multi-hot encoding for users based on the 1000 mostDataset #Users #Posts Country Hopkins\n#QandA 103,074 768,808 AUS 0.2624\n#Ausvotes 273,874 5,033,982 AUS 0.2445\n#Socialsense 49,442 358,292 AUS 0.2591\nRiot 574,281 1,067,794 US 0.1490\nParler 120,048 603,820 US 0.3016\nTable 2: The datasets used in this work: source, profiling,\nand country of origin (AUS and US refer to Australia and\nUSA, respectively). The last column represents the Hopkins\nstatistics (Hopkins and Skellam 1954) for the lexical lens.\nreshared posts. We represent a user uiashi\u2208R1000, where\nhi[j] = 1 ifuireshares the jth most reshared post ( hi[j] = 0\notherwise). In summary, there are three representations of\nusers; lexical R512, hashtag R|#hashtags |, reshare R1000.\n5 Contexts, Datasets, and Ideology Labels\nThis section introduces datasets and their contexts. Sec-\ntion 5.1 describes the five datasets, and Section 5.2 shows\nhow we qualitatively construct ideology ground truth, used\nto evaluate proxies and pipelines\u2019 performance.\n5.1 Contexts and Datasets\nSection 5.1 summarizes the datasets; there are three Aus-\ntralian and two American datasets; one originates from Par-\nler, another is a mixture of Facebook and Twitter, and the\nremainder are Twitter-based. In prior work datasets, ideology\ncorrelates with explicit user behavior (e.g., discussion topics);\nthis simplifies detection but rarely holds in practice. Here,\nwe use data where detection is difficult, as one would likely\nencounter in the wild. We quantify the detection difficulty\nusing Hopkin\u2019s statistics (Hopkins and Skellam 1954) of the\nlexical lens, indicating the clustering tendency of data, rang-\ning from 1 (highly clustered, easy detection) to 0 (uniformly\ndistributed, difficult detection). Hopkin\u2019s statistic is common\nmeasure of clustering tendency, effectively characterizing the\nprobability that embeddings are drawn from a uniform distri-\nbution. We assume that embeddings with a high clustering\ntendency are easier to classify. Note clusters do not necessar-\nily align with classes, however they often do in real-world\ndata; baselines, like UUS and UUS+, directly employ this\naxiom to infer labels (relying heavily on the underlying clus-\ntering tendency of the data). Quantifying detection difficulty\nof datasets is uncommon in literature and prior work often\nvary dataset difficulty be construction (Maci `a, Orriols-Puig,\nand Bernad \u00b4o-Mansilla 2008) or require class labels to infer\nit (Lorena et al. 2019). We employ Hopkin\u2019s Statistic as a\nsimple quantification of difficulty (which is not the focus of\nour work). It is likely related to the decision boundary aspect\nof classification complexity (Lorena et al. 2019). Section 5.1\nshows values \u2208[0.14,0.3]indicating no clustering tendency.\nBriefly, the datasets are: #QandA [Twitter/X] surrounding\na political panel show with audience questions; #Ausvotes\n[Twitter/X] surrounding the 2022 Australian Federal Elec-\ntion; #Socialsense [Twitter/X and Facebook] (Calderon, Ram,\nand Rizoiu 2024) surrounding the Australian Black Summer\nBushfires; Riot [Twitter] (Kerchner and Wrubel 2021) and\nParler [Parler] (Aliapoulios et al. 2021) both surrounding the\nUS capitol insurrection. See (Appendix 2024) for details.\n5.2 Build a Ground Truth\nWe qualitatively annotate a subset of #QandA users to gener-\nate both a left-right and far-right ground truth.\nLeft-Right Ground Truth. Due to the imbalance and spar-\nsity of some ideological classes5, we employ the proposed\npipeline to construct a candidate set of users for manual an-\nnotation. Platforms such as X/Twitter have been shown to\nlean-left, and the imbalance in datasets (such as Q+A which\nattracts a left-leaning audience) can be substantial. While it\ncan be argued that using the pipeline to generate a ground\ntruth to train future pipelines may skew the data selection, it\nhas advantages over the alternatives. For example, (1) con-\nducting a manual search through a random candidate set and\ngenerating a proportionately low-volume of right-leaning\nusers is prohibitively expensive, and (2) employing a proxy\ndirectly as our ground truth (following the baselines we com-\npare against) defeats the purpose of evaluating the proxies\nand introduces significant biases.\nWe generate the candidate set using the following\nfour components; (1) we select each of the four prox-\nies ( HASHTAGS ,PARTY FOLLOWERS ,POLITICIAN EN-\nDORSERS ,LEFT-RIGHT MPP ), (2) using labels derived from\nthe selected proxy, we train the classifier to predict user labels\n(since even proxy do not necessarily produce sufficient vol-\numes of right-leaning users), (3) we apply to proxy-trained\nclassifier to the entire #QandA dataset (including those al-\nready labelled), (4) finally, we extract the 100left- and 100\nright-leaning users with the highest classifier confidence (es-\ntimated through the classifier sigmoid scores). We collect the\npool of 800users in one set, deduplicate, shuffle it, and re-\nmove users who are unavailable (either private or suspended).\nThis results in 695users; we sample 200users, inspect their\nprofiles and categorize them as left-leaning, right-leaning,\nfar-right, or indeterminable.\nNext, two experts manually labeled each profile. The ex-\nperts both had extensive knowledge of the Australian political\ncontext, and were native English speakers. They were given\nexamples of left, right, far-right, and indeterminable user\nprofiles for context. They were instructed to use any signals\nof ideological-alignment they observed to make their assess-\nments (see (Appendix 2024) for details). Finally, they were\ngiven links to each user profile and instructed to categorize\nthem. They achieved moderate inter-annotator agreement i.e.,\nCohen\u2019s \u03baof0.515As a result, our left-right ground truth\ncontains 103left- and 74right-leaning users.\nFar-Right Ground Truth. Bailo, Johns, and Rizoiu (2023)\nsnowball sample Australian far-right users, starting with a\n\u2018seed\u2019 user and recovering \u2018lists\u2019 (a Twitter feature document-\ning similar users) they belong to. They intersected the sample\nwith their dataset, manually validated their far-right status,\ncrawled this validated set\u2019s followers, and manually coded\nthese too. They obtained 1,496users, of which 686are in\n#QandA, and serve as our far-right ground truth.\n5Predicted label counts show this imbalance (Appendix 2024).Left-Right Far-right\nHashtagsParty\nFollow.Pol.\nEndors.L.R.\nMPPF.R.\nMPPMBFC\nMPP\nUSE 0.881 0.868 0.788 0.946 0.691 0.773\nHT 0.873 0.876 0.812 0.849 0.559 0.633\nRT 0.840 0.844 0.752 0.879 0.538 0.668\nUSE+HT 0.949 0.879 0.870 0.939 0.715 0.785\nUSE+RT 0.880 0.821 0.785 0.953 0.666 0.762\nHT+RT 0.904 0.914 0.799 0.937 0.570 0.632\nall 0.950 0.875 0.854 0.929 0.713 0.785\nPrec. 0.889 0.873 0.797 0.892 0.516 0.530\nRecall 0.857 0.820 0.794 0.902 0.540 0.557\nF1 0.855 0.821 0.766 0.893 0.636 0.720\nTable 3: Determine the optimal proxy and lens combina-\ntion. (top) AUC ROC for each combination of lenses (rows)\nand proxy (columns). The underlines show the best lens for\na given proxy. (bottom) The precision, recall and macro-F1\nfor each proxy averaged over all lens combinations. The bold\nshow the best-performing proxy.\n6 Proxy Bias, Baselines, and Validation\nIn this section, we first quantify proxy bias (i.e., representativ-\nity) and homophilic lens interaction effects, by enumerating\nall pipeline constructions, in Section 6.1. Next, we present a\npipeline construction that outperforms three state-of-the-art\nmethods in Section 6.2. Finally, we evaluate transfer learning\nacross contexts, illustrating \u2018in-context\u2019 training superiority,\nand test cross-proxy performance in Section 6.3.\nTo avoid confusion, Section 6.1 employs both ground-truth\nand Section 6.2 uses the left-right ground-truth constructed\nin Section 5.2 for the #QandA dataset. Section 6.3 does not\nutilize the constructed ground truth. In its first segment it\ntrains on labels derived from one proxy and tests on labels\nderived from another, with fixed dataset #QandA. In its sec-\nond segment it trains on users from one dataset and tests on\nusers from another, with fixed proxy L EFT-RIGHT MPP.\n6.1 Quantifying Proxy Bias\nHere we jointly assess ideological proxy and homophilic\nlens combinations and their performance against our ground\ntruths, to infer proxy representativity. The top section of\nSection 6 shows all combinations. The columns represent\nproxies, and the rows show the seven possible concatenations\nof our lens implementations. We use the respective ground\ntruth for validation and testing in a 50% : 50% split, employ-\ning the validation set for threshold calibration (for converting\ncontinuous scores to discrete predictions), and removing neu-\ntral ideologies from training, as they do not appear in testing.\nCells show AUC ROC scores for pipelines trained with re-\nspective proxy and lens combinations. A higher AUC ROC\nscore is better with a maximum score of 1and a random\nbaseline of 0.5. The bottom section of Section 6 shows the\nprecision, recall and F1, averaged over all lens combinations.\nThe purpose is to quantify how well proxies represent \u2018true\u2019\nideology, approximated via our ground truth.\nResults. There are two main conclusions. First, Section 6\n0.86 0.53 0.51 0.690.69 0.61 0.74 0.620.57 0.55 0.87 0.530.7 0.56 0.54 0.820.62 0.830.94 0.7\nHashtagsParty\nFollowersPolitician\nEndorsersLeft\u2212\nRight\nMPPFar\u2212\nRight\nMPPMBFC\nMPP\nHashtags Party\nFollowersPolitician\nEndorsersLeft\u2212\nRight\nMPPFar\u2212\nRight\nMPPMBFC\nMPP\nTested OnTrained On\n0.000.250.500.751.00Figure 2: Self- and cross-proxy generalization. The AUC\nROC of ideology detection on #QandA when trained on one\nproxy (y-axis) and tested on another (x-axis) for left-right\nfar-right proxies.\nMethod UUS UUS+ TIMME Ours\nMacro-F1 0.60\u00b10.230.61\u00b10.260.88 0.92\nAUC ROC \u2013 0.76\u00b10.150.89 0.95\nTable 4: Baselines. Left-right classification performance of\nbaselines vs. our pipeline on the ground truth. We report the\nmean and standard deviation over all setup combinations for\nUUS andUUS+ . Note that UUS does not produce a score,\nonly labels; therefore, AUC ROC cannot be computed for it.\n(bottom) shows that MPP consistently outperforms other\nproxies for left-right detection. In order of representativity,\nwe have LEFT-RIGHT MPP ,HASHTAGS ,PARTY FOLLOW -\nERS, and POLITICIAN ENDORSERS . The MBFC MPP is\nthe most performant for far-right ideology. This is signifi-\ncant, as we have shown that media-based proxies are both\nqualitatively advantageous and optimal for representativity;\nproviding clear guidelines for practitioners. Second, Section 6\n(top) shows that no homophilic lens dominates all others and\nthe best-performing lens combination changes for each proxy.\nThis may explain unclear conclusions within the literature,\nwhere lens optimization is performed in isolation of other\npipeline components (e.g., proxies). Despite the lack of a\ndominating lens, we observe that pipelines containing the\nlexical lens generally outperform their peers, and USE by\nitself (first row) has competitive performances. In addition,\nUSE is the only platform-independent lens.\n6.2 Prediction Performance Against Baselines\nBaselines. We evaluate a pipeline construction against three\nstate-of-the-art stance detection techniques: UUS (Darwish\net al. 2020), UUS+ (Samih and Darwish 2021), and TIMME\n(Xiao et al. 2020) \u2013 detailed in Section 2. For UUS , the\nauthors\u2019 recommended setup (UMAP+Mean-Shift, retweet\nfeatures, and 1000 active users) does not produce any clusters\non #QandA. To render UUS competitive, we enumerate the\n0.82 0.66 0.66 0.61 0.630.7 0.73 0.64 0.6 0.570.66 0.59 0.81 0.57 0.560.69 0.6 0.67 0.75 0.640.68 0.56 0.61 0.62 0.73\nqandaausvotessocialsenseriotparler\nqanda\nausvotes\nsocialsenseriotparler\nTested OnTrained On\n0.50.60.70.80.91.0Figure 3: Context generalization. AUC ROC of LEFT-\nRIGHT MPP trained on one dataset (y-axis) and tested on\nanother (x-axis).\nsetups similarly to their work. We fix the dimensionality re-\nduction to UMAP and clustering to Mean-Shift following\ntheir recommended setup. We use the default scikit-learn\nsettings ( nneighbors=15 ,mindist=0.1 ,ncomponents=2 ,\nmetric=cosine ), and do not enumerate different hyperparam-\neters to (1) faithfully replicate their work, and (2) simulate\nthe experience of a time-poor practitioner. Furthermore, we\nimplement setups for every combination of features (retweets,\nretweeted accounts, and hashtags) and number of active users\n(500,1000 , and 5000 ). In addition, UUS only reports the\nmost active users\u2019 labels; however, our ground truth users\nare not the most active. Instead, we use UMAP and Mean-\nShift inference methods to acquire labels for these users. For\nUUS+ , we use the same set of UUS setups. Following the\nauthors, we utilize BERT base multilingual , using the Hugging-\nFace implementations with PyTorch. We fine-tune BERT by\nadding a fully-connected dense layer followed by a softmax\noutput layer. We minimize the cross-entropy loss over the\ntraining data. As it is not specified by the authors, we choose\nto fine-tune for 10epochs (a sufficient quantity for our data\nvolume). Finally, for TIMME , we use all relations except the\nfollowership network, which is prohibitive to acquire.\nPredicting Human-Annotated Ideology. We evaluate per-\nformance using the left-right ground truth (see Section 5.2)\nwith a 5-fold cross-validation (where applicable). For this\ntask, we use the pipeline constructed from the LEFT-RIGHT\nMPP and the USE+RT homophilic lens (the best-performing\ncombination from Section 6). Section 6.2 shows the F1-macro\nand AUC ROC scores for each technique. We make several\nobservations. First, our approach consistently outperforms\nall baselines, with the next best being TIMME . Second, UUS\nandUUS+ show low mean performance and high standard\ndeviation. Most setups failed to cluster users and were re-\nmoved before computing the mean and standard deviation.\nFurthermore, the clusters required an expert for labeling. Our\npipeline construction has practical advantages over these\nbaselines and outperforms them.\n6.3 Cross Proxy and Context Generalization\nCross Proxy Generalization. Here, we characterize the ro-\nbustness of ideological proxies through their self- and cross-\nconsistency. Self-consistency indicates how well the pipeline\npredictions trained with a given proxy align with the same\nproxy on a test set. We evaluate self-consistency using a 5-\nfold cross-validation. Cross-consistency indicates that two\nproxies capture similar ideological signals. We evaluate the\ndirected cross-consistency of a source \u2212\u2192target proxy by\ndeploying a pipeline with the source proxy to predict the\nideology of every user in the #QandA dataset and testing\nagainst the ideology labels set by the target proxy. We report\nthe performance over users whom the target proxy labels, and\nuse a one-vs-one scheme to adjust to the multiclass setting.\nFor a given proxy, we deploy the pipeline with the best lens\ncombination as per Section 6.\nSection 6.2 shows the AUC ROC performance for every\npair of source \u2212\u2192 target proxy for both left-right and far-\nright ideology detection. The self-consistency (main diagonal)\nis high for all left-right pipelines, except PARTY FOLLOW -\nERS. It is worth noting, POLITICIAN ENDORSERS has high\nself-consistency but a low prediction performance against\nthe ground truth (see Section 6). This suggests that politi-\ncian endorsement behavior is distinct from prototypical ideo-\nlogical behavior. Note, far-right proxies have relatively low\nself-consistency, perhaps due to the sparsity of far-right users.\nSection 6.2 shows cross-consistency of left-right pipelines\nis relatively low, except for LEFT-RIGHT MPP andHASH-\nTAGS . This supports prior work (Cohen and Ruths 2013;\nAlkiek, Zhang, and Jurgens 2022) arguing that different prox-\nies confer diverse ideology prototypes. The LEFT-RIGHT\nMPP andHASHTAGS proxies generalize well to each other\nand the ground truth (see Section 6), suggesting they accu-\nrately represent true ideology . Both far-right proxies general-\nize well on each other, but their performance on the ground\ntruth is relatively weak. This indicates they represent similar\nbehaviors not fully aligned with ideology.\nIn-Context Dominance. Researchers often implicitly sug-\ngest political signals from one context transfer to others. Here\nwe demonstrate the importance of \u2018in-context\u2019 training. Each\ndataset is typically associated with a distinct context (see\nSection 4.1). We evaluate transfer-learning across contexts by\ntraining a pipeline (constructed with the LEFT-RIGHT MPP\nproxy and the USE+RT lenses) on one dataset and testing on\nanother dataset. Section 6.2 shows the 5-fold cross-validation\nAUC ROC performance of left-right ideology detection for\nevery pair of datasets. Intuitively, models perform best when\ntrained and tested on the same dataset (i.e., in-context). How-\never, we observe a significant performance drop-off with\ntransfer learning (off-diagonal). Despite this, we see rela-\ntively better transfer learning between contexts that share\ntraits. Models trained in Australian contexts perform better\nwhen tested within the Australian context, and noticeably\nunderperform when tested in US contexts. Moreover, a fur-\nther reduction is observed when training or testing with the\nParler dataset (i.e., a different social platform context). These\nobservations indicate that signals of ideology differ between\ncontexts. While transfer learning performs better in similar\ncontexts, \u2018in-context\u2019 training is significantly more effective.\n#QandA\n#Ausvotes\n#Socialsense\nRiot\nParler Total\nFairness 2 2 2 2 210/20\nCare 2 4 3 1 313/20\nLoyalty 2 0 1 1 26/20\nAuthority 2 1 2 2 29/20\nSanctity 2 0 1 2 38/20\nTotal10/207/209/208/2012/2046/100\nTable 5: Moral Foundations Hypotheses testing. The num-\nber of times the MFT hypotheses tests are significant for each\nfoundation (rows) and dataset (columns).\n7 Psychosocial Analysis of Ideology Cohorts\nIn this section, we test four hypothesis sets for psychosocial\nasymmetries of ideologies, relating to morality, grievance,\nnationalism, and dichotomous thinking. This serves two pur-\nposes: an application case study for practitioners and to sup-\nply online evidence bases for conclusions of prior work. We\nuse pipelines constructed from the MBFC MPP andLEFT-\nRIGHT MPP proxies, alongside the USE lens for its appli-\ncability across all datasets. The first pipeline labels users\nas \u2018far-right\u2019. If users are not labeled \u2018far-right\u2019, the second\npipeline assigns them as \u2018left\u2019, \u2018neutral\u2019, or \u2018right\u2019. For most\nanalysis below, we highlight results on a single dataset, how-\never we produce the relevant plots for all datasets and label\ndistributions in the supplementary material (Appendix 2024).\nTesting Moral Foundations. We begin by evaluating MFT\nhypotheses. There are five hypotheses relating to individu-\nalizing (liberal) and binding (conservative) foundations. We\nuse a Wilcox Rank Sign Test (95%), with Holm adjustment\nfor family-wise error, to evaluate the support for each moral\nfoundations hypothesis in each dataset. We test these hy-\npotheses with the bias andintensity measures and both \u201cleft\nvs. right\u201d and \u201cleft vs. far-right\u201d (i.e., each combination has\nfour hypotheses). Section 7 shows the number of statistically\nsignificant tests for each moral foundations hypothesis in\neach dataset. Overall, only 46% of hypotheses are supported,\nmarginally favoring the individualizing over the binding hy-\npotheses. This inconsistency, seen in prior work (Wang and\nInbar 2021; Thomas et al. 2022), suggests MFT applies dif-\nferently online than it does offline.\nNext, given the lack of support for MFT, we test an alter-\nnative hypothesis, that right-leaning users, relative to left-\nleaning users, exhibit vice over virtue foundations . For each\nmoral foundation, we assign each user a virtue/vice score\nequal to their intensity, if their bias is positive/negative, re-\nspectively. This segregates the population into vice or virtue\nusers. In Fig. 4a, we plot each foundation\u2019s mean vice and\nvirtue scores for each ideological group in the #QandA\ndataset. We observe that a significant proportion of right-\nleaning users partake in the language of vice rather than virtue\ncompared to left-leaning users. We apply the Wilcox Rank\nSign Test (95%) between the means of ideological groups,\n0.000 0.005 0.010\nMean Difference (from neutral)Moral Foundations Vice/Virtue\nIdeological Group L N R FRloyalty .virtue\ncare.virtue\nfairness.virtue\nauthority .virtue\nsanctity .virtue\nloyalty .vice\nauthority .vice\nsanctity .vice\ncare.vice\nfairness.vice(a)\n\u22122 0 2\nSigned\u2212KL Divergence (from neutral)Grievance\nIdeological Group L N R FRhonour\ngod\njealousy\nimposter\nfrustration\ngrievance\nparanoia\n\ufb01xation\nhate\nthreat\ndesperation\nmurder\nviolence\nloneliness\nplanning\nsuicide\nhelp\nsoldier\nsurveillance\nrelationship\ndeadline (b)\n (c)\n (d)\nFigure 4: (a)(b) Distribution of psychosocial properties for ideological groups for #QandA and #Ausvotes, respectively. Line\ncolor represents ideological groups, and the y-axis shows psychosocial categories. (a) Vices-Virtues. The x-axis is the mean\ndifference for each ideological group from neutral, for Moral Foundations vice and virtue categories. (b) Grievances. The x-axis\nis the signed-KL divergence of each group ideological group from neutral for grievance categories. (c) Emoji Nationalism.\nThe odds (y-axis) of observing an emoji (x-axis) for a user given their ideological group (color), for #QandA. The odds are\ndetermined via logistic regression with no reference group. (d) Dichotomous Thinking. The bootstrapped prevalence distribution\nof dichotomous thinking CDS (y-axis) in tweets by users from ideological groups (x-axis), for #QandA.\nfor each category, and find all are significantly different6. We\nshow that this is relatively consistent across all datasets in the\nonline appendix (Appendix 2024), This provides a consistent\nmoral asymmetry in the online context.\nTesting Extremists\u2019 Association With Grievance. Early\nsignals of extremism are of particular concern to national\nsecurity and law enforcement practitioners. Prior work sug-\ngests that extreme ideologies hold more grievance and grudge\nbeliefs than moderates. We use the Grievance dictionary\n(Van der Vegt et al. 2021) to quantify users\u2019 grievance and\ngrudge language. In Fig. 4b, we plot the Kuller-Leibach diver-\ngence (signed by mean difference) between the distribution of\neach ideological group from the neutral group for each cate-\ngory with the #Ausvotes dataset. We apply the Kruskal-Wallis\nTest (95%) between ideological groups, for each category,\nand find all are significantly different. We observe that the\nfar-right users differ significantly from the other ideologies in\nall categories and generally use more grievance language. No-\ntably, in the #Ausvotes dataset, the far-right users use honor\nandgodtype language less than other groups. In the online\nappendix (Appendix 2024), we show that this hypothesis\nholds for most datasets. A takeaway for practitioners is that\nfar-right language and threat assessment indicators overlap,\nsuggesting a method to build effective public safety tools.\nTesting Nationalism Via Emoji. Here we add online evi-\ndence that the right-wing are associated with nationalism via\nemojis. This hypothesis is widely accepted (and definitional),\nand supporting it validates our inferred ideologies.\nFig. 4c shows the odds of observing an emoji, given a\nuser\u2019s ideological group in #QandA. Point ranges indicate\n6Except between the right and far-right in the care-virtue cate-\ngory, which is irrelevant to our conclusionsthe 95% confidence interval. The significance of the emoji in\npredicting ideological groups, via the Wald Test, is indicated\nwith stars. We make several observations. First,\n is used\nmore by ideological groups than neutral users. Second, the\nright (and far-right) use\n and\n significantly more than\nthe left. Third,\n is used marginally more by the left than\nother groups. Finally, we include\n as a control (showing\nno associations with any ideology). We conclude that na-\ntionalism, via national flags, is associated with our inferred\nright-leaning ideologies. The use of\n could be evidence\nof imported ideology from America to Australia.\n is only\nmarginally associated with the left.\nTesting Dichotomous Thinking. Recent work suggests the\nright-ideologies applying black-and-white thinking relatively\nmore than left-wing ideologies . Following (Bathina et al.\n2021), we match n-grams relating to cognitive distortions\nschema (CDS) in user tweets in #QandA. We measure the\nprevalence \u2013 the empirical probability of observing a CDS\nn-gram in a tweet given an ideological group. Addition-\nally, we utilize 100bootstrap samples (i.e., repeated sam-\npling of tweets) to estimate the prevalence distributions.\nFig. 4d shows that all non-neutral ideologies exhibit a sig-\nnificantly higher prevalence of dichotomous thinking, with\nright-leaning higher than left-leaning and far-right higher\nthan right-leaning. We perform T-Tests (95%) to compare\ngroup means and find all differ significantly from each other.\nThese findings support prior literature (Meyer 2020), and\nextend it by showing that the far-right might engender an\neven greater extent of dichotomous thinking. Other cogni-\ntive distortions\u2019 prevalences are summarized in the online\nappendix (Appendix 2024).\n8 Conclusion\nThis work proposes a framework for ideology detection\npipelines and quantifies biases introduced by ideological\nproxies. It tests hypotheses of the psychosocial asymmetries\nof ideological groups, in the online space. We present an\nevaluation of ideological proxies; qualitatively, indicating\nproxies that minimize labor, are transferable across multiple\ncontexts, and are available; and, quantitatively, indicating the\nrepresentativity and robustness of proxies. We find the media\nproxy advantageous, and a pipeline constructed from it and\nthe lexical lens to be optimal, outperforming state-of-the-art\napproaches. Such research is essential for furnishing practi-\ntioners with actionable guidelines for ideology detection and\nits practical applications.\nLimitations. The media proxy has several limitations. Firstly,\nit relies on the availability of up-to-date media slant data. Pub-\nlication slant can shift over time, and publication emergence,\nacquisition and closure can hold significance (particularly\non ideological fringes). Secondly, some users share media to\nrefute it. Thirdly, article slants may differ from publication\nslants. Finally, it will not produce a perfectly representative\nuser subset, although media sharing ubiquity makes it rel-\natively competitive. Furthermore, our conceptualization of\nideology is simplistic, and some political systems are com-\nplex requiring complex ideological proxies (which are largely\nunavailable).\nFuture Work. We limit our scope to English-speaking Anglo-\ncentric countries due to the expertise and language profi-\nciency of the author team. However, the study could be ap-\nplied broadly. Newman et al. (2021) provides data annually\nfor46diverse countries, including segments of the Global\nSouth. Our study could be extended to any other uniaxial\npolitical setting with little amendment.\nReferences\nAldayel, A.; and Magdy, W. 2019. Your stance is exposed! analysing\npossible factors for stance detection on social media. CSCW .\nAliapoulios, M.; Bevensee, E.; Blackburn, J.; Bradlyn, B.; Cristo-\nfaro, E. D.; Stringhini, G.; and Zannettou, S. 2021. A Large Open\nDataset from the Parler Social Network.\nAlizadeh, M.; Weber, I.; Cioffi-Revilla, C.; Fortunato, S.; and Macy,\nM. 2019. Psychology and morality of political extremists: evidence\nfrom Twitter language analysis of alt-right and Antifa. EPJ DS .\nAlkiek, K.; Zhang, B.; and Jurgens, D. 2022. Classification without\n(Proper) Representation: Political Heterogeneity in Social Media\nand Its Implications for Classification and Behavioral Analysis. In\nACL.\nAllSides. 2022. AllSides Media Bias Ratings. https://www.allsides.\ncom/media-bias/ratings. Accessed: 2022-04-08.\nAn, J.; Quercia, D.; and Crowcroft, J. 2014. Partisan sharing: Face-\nbook evidence and societal consequences. In COSN .\nAppendix, O. 2024. Supplementary Material: Practical Guidelines\nfor Ideology Detection Pipelines and Psychosocial Applications.\nhttps://bit.ly/ideology detection.\nAuxier, B.; and Anderson, M. 2021. Social media use in 2021. Pew\nResearch Center .\nBadaan, V .; Hoffarth, M.; Roper, C.; Parker, T.; and Jost, J. T. 2023.\nIdeological asymmetries in online hostility, intimidation, obscenity,\nand prejudice. Scientific reports .Badawy, A.; Lerman, K.; and Ferrara, E. 2019. Who falls for online\npolitical manipulation? In WWW .\nBailo, F.; Johns, A.; and Rizoiu, M.-A. 2023. Riding information\ncrises: the performance of far-right Twitter users in Australia during\nthe 2019\u20132020 bushfires and the COVID-19 pandemic. Information,\nCommunication & Society .\nBakshy, E.; Messing, S.; and Adamic, L. A. 2015. Exposure to\nideologically diverse news and opinion on Facebook. Science .\nBarber \u00b4a, P. 2015. Birds of the same feather tweet together: Bayesian\nideal point estimation using Twitter data. Political analysis .\nBathina, K. C.; Ten Thij, M.; Lorenzo-Luaces, L.; Rutter, L. A.; and\nBollen, J. 2021. Individuals with depression express more distorted\nthinking on social media. Nature Human Behaviour .\nBetz, M. 2016. Constraints and opportunities: what role for media\ndevelopment in countering violent extremism?\nBode, L.; Hanna, A.; Sayre, B.; Yang, J.; and Shah, D. V . 2013.\nMapping the political Twitterverse: Finding connections between\npolitical elites.\nBooth, E.; Lee, J.; Rizoiu, M.-A.; and Farid, H. 2024. Conspiracy,\nmisinformation, radicalisation: understanding the online pathway\nto indoctrination and opportunities for intervention. Journal of\nSociology .\nCalderon, P.; Ram, R.; and Rizoiu, M.-A. 2024. Opinion Market\nModel: Stemming Far-Right Opinion Spread using Positive Inter-\nventions. In ICWSM .\nCann, T. J.; Weaver, I. S.; and Williams, H. T. 2021. Ideological\nbiases in social sharing of online information about climate change.\nPlos one .\nCarr, H. J.; Dancho, R.; Michaud, K.; Chiang, P.; Damoff, P.; Lloyd,\nD.; MacGregor, A.; McKinnon, R.; Noormohamed, T.; Schiefke, P.;\nShipley, D.; Popta, T. V .; and Zuberi, S. 2022. Rise of Ideologically\nMotivated Violent Extremism in Canada. Technical report.\nCer, D.; Yang, Y .; Kong, S.-y.; Hua, N.; Limtiaco, N.; John, R. S.;\nConstant, N.; Guajardo-Cespedes, M.; Yuan, S.; Tar, C.; et al. 2018.\nUniversal sentence encoder. arXiv preprint arXiv:1803.11175 .\nChakraborty, S.; Goyal, P.; and Mukherjee, A. 2022. Fast Few Shot\nSelf-attentive Semi-supervised Political Inclination Prediction. In\nICADL .\nCichocka, A.; Bilewicz, M.; Jost, J. T.; Marrouch, N.; and\nWitkowska, M. 2016. On the grammar of politics\u2014or why conser-\nvatives prefer nouns. Political Psychology .\nCohen, R.; and Ruths, D. 2013. Classifying political orientation on\nTwitter: It\u2019s not easy! In ICWSM .\nCohrs, J. C. 2012. Ideological bases of violent conflict.\nDarwish, K.; Stefanov, P.; Aupetit, M.; and Nakov, P. 2020. Unsu-\npervised user stance detection on twitter. In ICWSM .\nEady, G.; Bonneau, R.; Tucker, J. A.; and Nagler, J. 2020. News\nsharing on social media: Mapping the ideology of news media\ncontent, citizens, and politicians.\nGarimella, K.; Smith, T.; Weiss, R.; and West, R. 2021. Political\npolarization in online news consumption. In ICWSM .\nGraham, J.; Haidt, J.; and Nosek, B. A. 2009. Liberals and con-\nservatives rely on different sets of moral foundations. Journal of\npersonality and social psychology .\nGu, Y .; Chen, T.; Sun, Y .; and Wang, B. 2016. Ideology detection\nfor twitter users with heterogeneous types of links. arXiv preprint\narXiv:1612.08207 .\nHopkins, B.; and Skellam, J. G. 1954. A New Method for deter-\nmining the Type of Distribution of Plant Individuals. Annals of\nBotany .\nJiang, J.; Ren, X.; and Ferrara, E. 2023. Retweet-BERT: Politi-\ncal Leaning Detection Using Language Features and Information\nDiffusion on Social Networks. ICWSM .\nJost, J. T. 2017. Asymmetries abound: Ideological differences in\nemotion, partisanship, motivated reasoning, social network structure,\nand political trust. Journal of Consumer Psychology .\nKariryaa, A.; Rund \u00b4e, S.; Heuer, H.; Jungherr, A.; and Sch \u00a8oning,\nJ. 2022. The role of flag emoji in online political communication.\nSocial Science Computer Review .\nKe, G.; Meng, Q.; Finley, T.; Wang, T.; Chen, W.; Ma, W.; Ye, Q.;\nand Liu, T.-Y . 2017. Lightgbm: A highly efficient gradient boosting\ndecision tree. NeurIPS .\nKemmelmeier, M.; and Winter, D. G. 2008. Sowing patriotism, but\nreaping nationalism? Consequences of exposure to the American\nflag. Political Psychology .\nKerchner, D.; and Wrubel, L. 2021. U.S. Capitol Riot and\n#TrumpRally Tweet IDs.\nKwak, H.; An, J.; Jing, E.; and Ahn, Y .-Y . 2021. FrameAxis: charac-\nterizing microframe bias and intensity with word embedding. PeerJ\nComputer Science .\nLahoti, P.; Garimella, K.; and Gionis, A. 2018. Joint non-negative\nmatrix factorization for learning ideological leaning on twitter. In\nWSDM .\nLai, A.; Brown, M. A.; Bisbee, J.; Tucker, J. A.; Nagler, J.; and\nBonneau, R. 2022. Estimating the ideology of political youtube\nvideos. Political Analysis .\nLi, J.; Longinos, G.; Wilson, S.; and Magdy, W. 2020. Emoji and\nself-identity in Twitter bios. In NLP+CSS .\nLiscio, E.; Araque, O.; Gatti, L.; Constantinescu, I.; Jonker, C. M.;\nKalimeri, K.; and Murukannaiah, P. K. 2023. What does a text\nclassifier learn about morality? An explainable method for cross-\ndomain comparison of moral rhetoric. In ACL.\nLiu, S.; Luo, Z.; Xu, M.; Wei, L.; Wei, Z.; Yu, H.; Xiang, W.; and\nWang, B. 2023. Ideology Takes Multiple Looks: A High-Quality\nDataset for Multifaceted Ideology Detection. In EMNLP .\nLorena, A. C.; Garcia, L. P.; Lehmann, J.; Souto, M. C.; and Ho,\nT. K. 2019. How complex is your classification problem? a survey\non measuring classification complexity. CSUR .\nMaci `a, N.; Orriols-Puig, A.; and Bernad \u00b4o-Mansilla, E. 2008.\nGenetic-based synthetic data sets for the analysis of classifiers be-\nhavior. In HAIS .\nMcCauley, C.; and Moskalenko, S. 2008. Mechanisms of Political\nRadicalization: Pathways Toward Terrorism. Terrorism and Political\nViolence .\nMcPherson, M.; Smith-Lovin, L.; and Cook, J. M. 2001. Birds of a\nfeather: Homophily in social networks. Annual review of sociology .\nMetaxas, P.; Mustafaraj, E.; Wong, K.; Zeng, L.; O\u2019Keefe, M.; and\nFinn, S. 2015. What do retweets indicate? Results from user survey\nand meta-review of research. In ICWSM .\nMeyer, P. H. 2020. Political Ideology and Black-and-White Think-\ning.\nMokhberian, N.; Abeliuk, A.; Cummings, P.; and Lerman, K. 2020.\nMoral framing and ideological bias of news. In SocInfo .\nNewman, N.; Fletcher, R.; Schulz, A.; Andi, S.; Robertson, C. T.;\nand Nielsen, R. K. 2021. Reuters Institute digital news report 2021.\nReuters Institute for the Study of Journalism .\nO\u2019Hagan, S.; and Schein, A. 2023. Measurement in the Age of\nLLMs: An Application to Ideological Scaling. arXiv preprint\narXiv:2312.09203 .Park, S.; Fisher, C.; McGuinness, K.; Lee, J. Y .; and McCallum,\nK. 2021. Digital news report: Australia 2021 . News and Media\nResearch Centre.\nPoole, K. T.; and Rosenthal, H. 1985. A spatial model for legislative\nroll call analysis. American journal of political science .\nPreot \u00b8iuc-Pietro, D.; Liu, Y .; Hopkins, D.; and Ungar, L. 2017. Be-\nyond binary labels: Political ideology prediction of Twitter users. In\nACL.\nRadsch, C. 2016. Media Development and Countering Violent\nExtremism: An Uneasy Relationship, a Need for Dialogue. Center\nfor International Media Assistance .\nRao, A.; Morstatter, F.; and Lerman, K. 2022. Partisan asymmetries\nin exposure to misinformation. Scientific reports .\nRao, A. R. 2017. Red, blue and purple states of mind: Segmenting\nthe political marketplace. Journal of Consumer Psychology .\nRashed, A.; Kutlu, M.; Darwish, K.; Elsayed, T.; and Bayrak, C.\n2021. Embeddings-Based Clustering for Target Specific Stances:\nThe Case of a Polarized Turkey. In ICWSM .\nRavi, K.; Vela, A. E.; and Ewetz, R. 2022. Classifying the Ideo-\nlogical Orientation of User-Submitted Texts in Social Media. In\nICMLA .\nReiter-Haas, M.; Kopeinik, S.; and Lex, E. 2021. Studying Moral-\nbased Differences in the Framing of Political Tweets. In ICWSM .\nRizoiu, M.-A.; Graham, T.; Zhang, R.; Zhang, Y .; Ackland, R.; and\nXie, L. 2018. # DebateNight: The Role and Influence of Socialbots\non Twitter During the 1st 2016 US Presidential Debate. In ICWSM .\nSamih, Y .; and Darwish, K. 2021. A few topical tweets are enough\nfor effective user stance detection. In ACL.\nStankov, L. 2021. From social conservatism and authoritarian pop-\nulism to militant right-wing extremism. Personality and Individual\nDifferences .\nThomas, E. F.; Leggett, N.; Kernot, D.; Mitchell, L.; Magsarjav, S.;\nand Weber, N. 2022. Reclaim the Beach: How Offline Events Shape\nOnline Interactions and Networks Amongst Those Who Support\nand Oppose Right-Wing Protest. Studies in Conflict & Terrorism .\nTomkins, S. 1963. Left and right: A basic dimension of ideology\nand personality.\nVan der Vegt, I.; Mozes, M.; Kleinberg, B.; and Gill, P. 2021. The\ngrievance dictionary: Understanding threatening language use. Be-\nhavior research methods .\nvan Vliet, L.; T \u00a8ornberg, P.; and Uitermark, J. 2020. The Twit-\nter parliamentarian database: Analyzing Twitter politics across 26\ncountries. PLoS one .\nVan Vliet, L.; T \u00a8ornberg, P.; and Uitermark, J. 2021. Political Sys-\ntems and Political Networks: The Structure of Parliamentarians\u2019\nRetweet Networks in 19 Countries. International Journal of Com-\nmunication .\nWang, C.; Wu, Q.; Weimer, M.; and Zhu, E. 2021. FLAML: A fast\nand lightweight automl library. MLSys .\nWang, S.-Y . N.; and Inbar, Y . 2021. Moral-language use by US\npolitical elites. Psychological Science .\nWikipedia. 2023. Q+A (Australian talk show). https://en.wikipedia.\norg/wiki/Q \\%2BA (Australian talkshow). Accessed: 2023-04-27.\nXi, N.; Ma, D.; Liou, M.; Steinert-Threlkeld, Z. C.; Anastasopou-\nlos, J.; and Joo, J. 2020. Understanding the political ideology of\nlegislators from social media images. In ICWSM .\nXiao, Z.; Song, W.; Xu, H.; Ren, Z.; and Sun, Y . 2020. TIMME:\nTwitter ideology-detection via multi-task multi-relational embed-\nding. In KDD .\nZandt, D. 2022. Media Bias/Fact Check. https://mediabiasfactcheck.\ncom/about. Accessed: 2022-04-08.\nEthics Checklist\n1. For most authors...\n(a)Would answering this research question advance sci-\nence without violating social contracts, such as violat-\ning privacy norms, perpetuating unfair profiling, exac-\nerbating the socio-economic divide, or implying disre-\nspect to societies or cultures? Yes, see the Ethics and\nBroader Impact Statement at the end of this checklist.\n(b)Do your main claims in the abstract and introduction\naccurately reflect the paper\u2019s contributions and scope?\nYes.\n(c)Do you clarify how the proposed methodological ap-\nproach is appropriate for the claims made? Yes.\n(d)Do you clarify what are possible artifacts in the data\nused, given population-specific distributions? Yes, see\nContexts, Datasets, and Ideology Labels.\n(e)Did you describe the limitations of your work? Yes, see\nthe Conclusion.\n(f)Did you discuss any potential negative societal impacts\nof your work? Yes, see the Ethics and Broader Impact\nStatement at the end of this checklist.\n(g)Did you discuss any potential misuse of your work?\nYes, see the Ethics and Broader Impact Statement at\nthe end of this checklist.\n(h)Did you describe steps taken to prevent or mitigate po-\ntential negative outcomes of the research, such as data\nand model documentation, data anonymization, respon-\nsible release, access control, and the reproducibility of\nfindings? Yes.\n(i)Have you read the ethics review guidelines and ensured\nthat your paper conforms to them? Yes.\n2. Additionally, if your study involves hypotheses testing...\n(a)Did you clearly state the assumptions underlying all\ntheoretical results? Yes.\n(b)Have you provided justifications for all theoretical re-\nsults? Yes.\n(c)Did you discuss competing hypotheses or theories that\nmight challenge or complement your theoretical re-\nsults? Yes.\n(d)Have you considered alternative mechanisms or ex-\nplanations that might account for the same outcomes\nobserved in your study? Yes.\n(e) Did you address potential biases or limitations in your\ntheoretical framework? Yes.\n(f)Have you related your theoretical results to the existing\nliterature in social science? Yes.\n(g)Did you discuss the implications of your theoretical\nresults for policy, practice, or further research in the\nsocial science domain? Yes.\n3. Additionally, if you are including theoretical proofs...\n(a)Did you state the full set of assumptions of all theoreti-\ncal results? NA\n(b)Did you include complete proofs of all theoretical re-\nsults? NA4. Additionally, if you ran machine learning experiments...\n(a)Did you include the code, data, and instructions needed\nto reproduce the main experimental results (either in\nthe supplemental material or as a URL)? No, we will\ninclude our git repository once the paper gets accepted.\nThe repository will include the code and instructions.\n(b)Did you specify all the training details (e.g., data splits,\nhyperparameters, how they were chosen)? Yes.\n(c)Did you report error bars (e.g., with respect to the ran-\ndom seed after running experiments multiple times)?\nYes, where applicable.\n(d)Did you include the total amount of compute and the\ntype of resources used (e.g., type of GPUs, internal\ncluster, or cloud provider)? No, our study does not\nrequire significant compute resources.\n(e)Do you justify how the proposed evaluation is sufficient\nand appropriate to the claims made? Yes.\n(f)Do you discuss what is \u201cthe cost\u201c of misclassification\nand fault (in)tolerance? Yes.\n5.Additionally, if you are using existing assets (e.g., code,\ndata, models) or curating/releasing new assets, without\ncompromising anonymity ...\n(a)If your work uses existing assets, did you cite the cre-\nators? Yes.\n(b) Did you mention the license of the assets? NA\n(c)Did you include any new assets in the supplemental\nmaterial or as a URL? Yes.\n(d)Did you discuss whether and how consent was obtained\nfrom people whose data you\u2019re using/curating? NA.\n(e)Did you discuss whether the data you are using/curating\ncontains personally identifiable information or offen-\nsive content? NA\n(f)If you are curating or releasing new datasets, did you\ndiscuss how you intend to make your datasets FAIR?\nNA\n(g)If you are curating or releasing new datasets, did you\ncreate a Datasheet for the Dataset? NA\n6.Additionally, if you used crowdsourcing or conducted\nresearch with human subjects, without compromising\nanonymity ...\n(a)Did you include the full text of instructions given to\nparticipants and screenshots? NA\n(b)Did you describe any potential participant risks, with\nmentions of Institutional Review Board (IRB) ap-\nprovals? NA\n(c)Did you include the estimated hourly wage paid to\nparticipants and the total amount spent on participant\ncompensation? NA\n(d)Did you discuss how data is stored, shared, and deiden-\ntified? NA\nEthical Statement\nThis work introduces a powerful tool for inferring user ide-\nology based on covert cues such as language patterns. We\ndemonstrate our tool for detecting far-right ideologies; how-\never, it could, in theory, be used by oppressive regimes to\ninfer the true ideologies of their citizens and expose their op-\nponents (Radsch 2016). The Countering Violent Extremism\n(CVE) literature (Betz 2016) explores the ethical concerns of\ndeveloping tools that can be used for oppressive ends and pro-\nposes mitigation strategies. There are also privacy concerns,\nas one\u2019s ideology can be viewed as an intimate and private\ntrait that our tool can expose. Additionally, we show how to\nuse our pipeline to profile entire online populations based on\ntheir psychosocial characteristics. We argue that the pipeline\npredictions are not prescriptive; they should be treated as an\nearly warning system, requiring human expert investigation.\nWe further note that we only use expert-inferred political af-\nfiliation as our ground truth, not private self-reported political\nindicator data.\nAppendices\nThis document accompanies the submission. The informa-\ntion in this document complements the submission and is\npresented here for completeness reasons. It is not required to\nunderstand the main paper or reproduce the results.\nA Dataset Collection Details\n#QandA. We collect discussions related to the Australian\npanel show Q+A (Wikipedia 2023), where panelists (pub-\nlic figures, politicians, and experts) answer curated audi-\nence questions. Twitter participation is encouraged in airings.\nWe collect #QandA using the filter keyword qanda during\nJanuary-December 2020.\n#Ausvotes. We collect discussions about the 2022 Australian\nFederal election, tracking the lead-up and aftermath. It fol-\nlows the major parties and their leaders: the left-leaning Aus-\ntralian Labor Party led by Anthony Albanese and the right-\nleaning Liberal-National Coalition led by Scott Morrison. We\ncollect #Ausvotes using the keywords auspol andausvotes ,\nand for mentions of @ScottMorrisonMP ,@AlboMP , and\n@AusElectoralCom , between 9 May and 15 June 2022 (the\nelections occurred on 21 May).\n#Socialsense (Calderon, Ram, and Rizoiu 2024) features\ndiscussions related to the Australian Black Summer bushfires,\nwhich gathered discourse concerning climate change, and\ncontains far-right opinions. #Socialsense contains 90days of\nTwitter and Facebook discussions, from 1 November to 29\nJanuary 2020.\nRiot (Kerchner and Wrubel 2021) features discussions about\nthe January 6th US Capitol Insurrection, including election\nfraud and insurrection topics. The dataset spans 6 January to\n1 February 2021 and was collected with the filter keywords\nTrumpRally ,Democracy ,USCapitol ,Capitol ,DCProtests ,\nandAshliBabbit .\nParler (Aliapoulios et al. 2021) features discussions about\nthe US Capitol Insurrection from Parler. We collect all posts\nemitted during the day of 6 January 2021.\nB All UUS/UUS+ Metrics\nThi section shows all possible runs for the UUS andUUS+ .\nWe notice that in many instances UUS fails to seperate clus-\nters, and even in instances where seperation can be achieved\nmany suffer from poor performance. This shows that these\ntechniques lack robustness for more difficult datasets.\nC Left-Right Annotation Procedure\nIdeology is the subject of considerable subjectivity, not only\nbecause experts have their own ideology, but because anno-\ntators are often unclear as to what evidence is permissible\nfor use. For this task we issued the following guidelines to\nannotators:\nIt is not always clear what should count as an ideo-\nlogical signal. For our purposes, we will include the\nfollowing as signals of ideology:\n\u2022If a target user promotes/retweets someone or an\norganisation with a known ideological affiliation,\nyou may assume that the target endorse them. ForTable 6: All Baseline Performances. The table shows to\nperformances for all combinations of the UUS andUUS+\nbaselines.\nRepresentation Active\nUsersF1-\nMacroAUC\nROCUUS\nF1-\nMacro\nH 500 0.37 0.68 0.37\nH 1000 - - -\nH 5000 0.37 0.54 0.37\nHR 500 - - -\nHR 1000 - - -\nHR 5000 0.89 0.92 0.85\nR 500 - - -\nR 1000 - - -\nR 5000 0.93 0.93 0.87\nT 500 - - -\nT 1000 - - -\nT 5000 - - -\nTH 500 0.4 0.58 0.54\nTH 1000 - - -\nTH 5000 0.92 0.91 0.87\nTR 500 - - -\nTR 1000 - - -\nTR 5000 - - -\nTRH 500 - - -\nTRH 1000 - - -\nTRH 5000 0.41 0.75 0.36\nexample, if a target user retweets a labor MP then\nyou can label the user as \u2019left\u2019.\n\u2022If a target user, has a stance against someone with a\nknown ideological affiliation, then you might infer\nthat the target user\u2019s ideology is the opposing ideol-\nogy. For example, if a target user calls a labor MP\nan insult, then you can label the user as \u2019right\u2019.\n\u2022If a target user expresses a view about a issue related\nto an ideology, you can infer the user\u2019s ideology. For\nexample, if a user supports LGBTQ or environmen-\ntal issues, then (if there is enough evidence) you\nmay label them as \u2019left\u2019.\nThese guidelines aim to increase the clarity of the anno-\ntation task. In countries where political affiliation is obvert\n(e.g. the united states), this labelling task is often unam-\nbiguous; however, in Australia ideological signals are of-\nten implicit. The full annotation briefing material is avail-\nable in the code repository [https://github.com/behavioral-\nds/ideology prediction].\nContext-Transfer Illustration\nFig. 5 further illustrates the difficulty with utilizing particular\nproxies as ground truth. We observe that some ideological\nproxies are consistent across only some contexts (represented\nby the dashed green boxes). For example, #RoboDebt (in\nrelation to an Australian incident) is not relevant to the USA\nand did not exist before 2016; and, although @MittRomney\nsignaled right-wing ideology in 2012, the right has shifted\nParty\nFollowers\nPolitician\nEndorsers\nHashtags\nMedia\n( T 1,\n , ) ( T 1, , )\n ( T2 , , ) ( T2 , , )\n Context@UserA\n@UserB\n@UserC\n@UserD\n@JoeBiden\n@KamalaHarris\n@realDonaldT rump\n@Mike_Pence\n#BLM\n#DefundThePolice\n#MAGA\n#AllLivesMatter\nNYT\nVOX\nFOX\nSKY@User1\n@User2\n@User3\n@User4\n@JoeBiden\n@KamalaHarris\n@realDonaldT rump\n@Mike_Pence\n#BLM\n#DefundThePolice\n#MAGA\n#AllLivesMatter\nNYT\nVOX\nFOX\nSKY@User1\n@User2\n@User3\n@User4\n@BarackObama\n@HillaryClinton\n@MittRomney\n@PRyan\n#W earAMask\n#MaskUp\n#MyBodyMyChoice\n#MasksDontW ork\nNYT\nVOX\nFOX\nSKY@UserE\n@UserF\n@UserG\n@UserH\n@AlboMP\n@billshortenMP\n@ScottMorrisonMP\n@PeterDuttonMP\n#RoboDebt\n#SportsRorts\n#DefundABC\n#DictatorDan\nNYT\nVOX\nFOX\nSKYFigure 5: Most ideology proxies do not generalize across\ncontexts. The x-axis shows four contexts that vary in time ( T1\nandT2), country (Australia and USA), and platform (Twitter\nand Facebook). The y-axis show four proxies: endorsing\npolitical parties or political figures, using politically charged\nhashtags and the consumed media slant. The green dashed\nboxes indicate whether a proxy is applicable across contexts.\nsince Trump\u2019s election.\nPrior ideology detection techniques fail to easily context-\nswitch and cannot be readily applied to multiple distinct\ndomains.\nMedia Publication Slants\nThe media slant scores are shown in Fig. 6, where we ob-\nserved publications like Breitbart andFox News are extremely\nright-leaning, and VoxandNYTimes are left-leaning.\nCognitive Distortions Schemata Prevalence\nFig. 7 shows the prevalence of all twelve cognitive distor-\ntions in each of the ideological groups, for #QandA. Note\nthat many CDS n-grams are extremely rare (or do not appear),\nnamely; emotional reasoning andmental filtering . In several\nCDS the left exhibit higher prevalence, such as catastrophiz-\ning,fortune-telling ,disqualifying the positive , and should\nstatements .\nFlag Emoji Hurdle Model\nFor completeness, we present the results of the hurdle model\n(used to model zero-inflated count data, such a tokens in a\ncorpus). The hurdle model is a mixed model, comprised of a\nlogistic regression to model the presense of no emoji, and a\ntruncated poisson with log linkage, to model the count of the\nemoji. Fig. 8 shows the coefficients for each model, including\nthe reference groups.\n is observed more for far-right users\nin both the zero and the count models. The count models for\nthe other flags show mixed results and not significant.\nPrecision-Recall of Pipelines\nFig. 9 shows precision and recall for every lens combinations\nand proxy.Table 7: Distribution of Predicted Labels. The number of\nusers predicted to be in each class (rows) for each dataset\n(columns). Note that for many datasets there is a signifi-\ncant imbalance toward the left (except Parler hich is a right-\nleaning platform).\n#QandA\n#Ausvotes\n#Socialsense\nRiot\nParler\nLeft 80,375 189,233 48,056 339,095 293\nNeutral 21,176 79,221 604 227,839 48,829\nRight 777 3,689 464 3,624 68,104\nFar-right 746 1,731 318 3,723 2,822\nPredicted Label Distribution\nTable 7 shows the distribution of predicted labels, to provide\ncontext for the psychosocial analysis.\nDataset Profiling\nActivity levels are often a concern for ideology detection\nframeworks, given that low-activity users reveal few signals\nof ideology. Fig. 10 shows the distribution of activity for users\nfor each dataset. It shows long-tailed activity distributions and\nthe proportion of low-activity users. Riot hows a significant\nproportion of low-activity users, who\u2019re often difficult to\nclassify.\nExhaustive Psychosocial Analysis\nGrievance\nThis section shows the difference between ideological groups\nin terms of grievance categories for all available datasets.\nMFT\nThis section shows the difference between ideological groups\nin terms of moral foundations for all available datasets.\nFigure 6: Media Publication Slants. The plot shows the slants of Media Publications, as averaged over the year, country, and\nsource point estimates.\nFigure 7: CDS Prevalence\nFigure 8: Hurdle Model\nPrecision\nRecall0.5 0.6 0.7 0.8 0.9 1.0 0.5 0.6 0.7 0.8 0.9 1.0Far\u2212Right \nMPPMBFC \nMPPPolitician \nEndorsersParty \nFollowersHashtagsLeft\u2212Right\nMPP\nFeaturesht ht+rt rt\nuse use+ht use+ht+rtuse+rt\nFigure 9: Precision-Recall. The plot shows the macro-\naveraged precision and recall of pipelines, trained with each\nproxy (y-axis) and each feature set (colors), probability cali-\nbrated with the hold-out validation set for F1-macro scores.\n100101102103104105\ncounts106\n105\n104\n103\n102\n101\n100Proportiondataset\nqanda\nausvotes\nsocialsense\nriot\nparlerFigure 10: Activity Distribution. The log-log ECCDF distri-\nbution of activity (number of posts per user) for each dataset.\nsoldiersuicidemurderviolencethreathatejealousyimpostorfrustrationgrievancehonourparanoiagodfixationlonelinessdesperationdeadlineplanningsurveillancehelprelationship\n\u22121.0 \u22120.5 0.0 0.5 1.0\nSigned\u2212KL Divergence (from neutral)Grievance\nIdeological Group LNRFR\nFigure 11: Grievance #QandA\ndeadlinerelationshipsurveillancesoldierhelpsuicideplanninglonelinessviolencemurderdesperationthreathatefixationparanoiagrievancefrustrationimpostorjealousygodhonour\n\u22122 0 2\nSigned\u2212KL Divergence (from neutral)Grievance\nIdeological Group LNRFR\nFigure 12: Grievance #Ausvotes\nplanningrelationshipviolencethreatmurdersurveillancehelpdesperationsoldierdeadlineparanoiasuicideimpostorhategodgrievancefrustrationlonelinessjealousyfixationhonour\n\u22122 0 2\nSigned\u2212KL Divergence (from neutral)Grievance\nIdeological Group LNRFRFigure 13: Grievance #Socialsense\nthreatjealousyviolenceimpostormurderfrustrationhonoursoldierdeadlinefixationdesperationlonelinessgodgrievanceparanoiahelpsurveillancesuiciderelationshiphateplanning\n\u22120.25 0.00 0.25 0.50\nSigned\u2212KL Divergence (from neutral)Grievance\nIdeological Group LNRFR\nFigure 14: Grievance Riot\nsurveillancemurderdeadlinesoldierhelpviolenceplanningthreatsuicidehatefixationparanoiajealousyfrustrationgrievanceimpostorlonelinessdesperationhonourgodrelationship\n\u22122 \u22121 0 1 2\nSigned\u2212KL Divergence (from neutral)Grievance\nIdeological Group LNRFR\nFigure 15: Grievance Parler\nfairness.vicecare.vicesanctity.viceauthority.viceloyalty.vicesanctity.virtueauthority.virtuefairness.virtuecare.virtueloyalty.virtue\n0.000 0.005 0.010\nMean Difference (from neutral)Moral Foundations Vice/Virtue\nIdeological Group LNRFR\nFigure 16: MFT #QandA\nfairness.vicecare.virtueauthority.vicesanctity.viceloyalty.viceauthority.virtueloyalty.virtuesanctity.virtuecare.vicefairness.virtue\n\u22120.0025 0.0000 0.0025\nMean Difference (from neutral)Moral Foundations Vice/Virtue\nIdeological Group LNRFRFigure 17: MFT #Ausvotes\ncare.vicefairness.viceauthority.viceloyalty.vicesanctity.vicesanctity.virtueauthority.virtuefairness.virtueloyalty.virtuecare.virtue\n\u22120.005 0.000 0.005 0.010\nMean Difference (from neutral)Moral Foundations Vice/Virtue\nIdeological Group LNRFR\nFigure 18: MFT #Socialsense\nfairness.viceauthority.vicecare.viceloyalty.vicesanctity.vicesanctity.virtueloyalty.virtuecare.virtueauthority.virtuefairness.virtue\n0.000 0.005 0.010\nMean Difference (from neutral)Moral Foundations Vice/Virtue\nIdeological Group LNRFR\nFigure 19: MFT Riot\ncare.vicefairness.viceauthority.viceloyalty.vicesanctity.vicefairness.virtueauthority.virtuesanctity.virtuecare.virtueloyalty.virtue\n\u22120.006 \u22120.003 0.000 0.003\nMean Difference (from neutral)Moral Foundations Vice/Virtue\nIdeological Group LNRFR\nFigure 20: MFT Parler", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Detecting Extreme Ideologies in Shifting Landscapes: An Automatic & Context-Agnostic Approach", "author": ["R Ram", "E Thomas", "D Kernot", "MA Rizoiu"], "pub_year": "2022", "venue": "arXiv preprint arXiv:2208.04097", "abstract": "In democratic countries, the ideology landscape is foundational to individual and collective  political action; conversely, fringe ideology drives Ideologically Motivated Violent Extremism ("}, "filled": false, "gsrank": 848, "pub_url": "https://arxiv.org/abs/2208.04097", "author_id": ["", "U3JInqYAAAAJ", "", "J9sjxXYAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:dTXXSCKHSn0J:scholar.google.com/&output=cite&scirp=847&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D840%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=dTXXSCKHSn0J&ei=n7WsaPbEK8DZieoPqdqh8QU&json=", "num_citations": 2, "citedby_url": "/scholar?cites=9028176984338281845&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:dTXXSCKHSn0J:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2208.04097"}}, {"title": "A survey on computational propaganda detection", "year": "2020", "pdf_data": "A Survey on Computational Propaganda Detection\nGiovanni Da San Martino1\u0003,Stefano Cresci2,Alberto Barr \u00b4on-Cede \u02dcno3,\nSeunghak Yu4,Roberto Di Pietro5and Preslav Nakov1\n1Qatar Computing Research Institute, HBKU, Doha, Qatar\n2Institute of Informatics and Telematics, IIT-CNR, Pisa, Italy\n3DIT, Alma Mater Studiorum\u2013Universit `a di Bologna, Forl `\u0131, Italy\n4MIT Computer Science and Arti\ufb01cial Intelligence Laboratory, Cambridge, MA, USA\n5College of Science and Engineering, HBKU, Doha, Qatar\nfgmartino, rdipietro, pnakov g@hbku.edu.qa, s.cresci@iit.cnr.it, a.barron@unibo.it,\nseunghak@csail.mit.edu\nAbstract\nPropaganda campaigns aim at in\ufb02uencing people\u2019s\nmindset with the purpose of advancing a speci\ufb01c\nagenda. They exploit the anonymity of the Internet,\nthe micro-pro\ufb01ling ability of social networks, and\nthe ease of automatically creating and managing\ncoordinated networks of accounts, to reach millions\nof social network users with persuasive messages,\nspeci\ufb01cally targeted to topics each individual user\nis sensitive to, and ultimately in\ufb02uencing the out-\ncome on a targeted issue. In this survey, we review\nthe state of the art on computational propaganda de-\ntection from the perspective of Natural Language\nProcessing and Network Analysis, arguing about\nthe need for combined efforts between these com-\nmunities. We further discuss current challenges and\nfuture research directions.\n1 Introduction\nThe Web makes it possible for anybody to create a website or\na blog and to become a news medium. Undoubtedly, this is a\nhugely positive development as it elevates freedom of expres-\nsion to a whole new level, giving anybody the opportunity to\nmake their voice heard. With the rise of social media, every-\none can reach out to a very large audience, something that\nuntil recently was only possible for major news outlets.\nHowever, this new avenue for self-expression has brought\nalso unintended consequences, the most evident one being\nthat the society has been left unprotected against potential\nmanipulation from a multitude of sources. The issue be-\ncame of general concern in 2016, a year marked by micro-\ntargeted online disinformation and misinformation at an un-\nprecedented scale, primarily in connection to Brexit and the\nUS Presidential campaign; then, in 2020, the COVID-19 pan-\ndemic also gave rise to the \ufb01rst global infodemic. Spread-\ning disinformation disguised as news created the illusion that\nthe information was reliable, and thus people tended to lower\ntheir natural barrier of critical thinking compared to when in-\nformation came from different types of sources.\n\u0003Contact AuthorWhereas false statements are not really a new phenomenon\n\u2014e.g., yellow press has been around for decades\u2014 this time\nthings were notably different in terms of scale and effective-\nness thanks to social media, which provided both a medium to\nreach millions of users and an easy way to micro-target spe-\nci\ufb01c narrow groups of voters based on precise geographic,\ndemographic, psychological, and/or political pro\ufb01ling.\nAn important aspect of the problem that is often largely\nignored is the mechanism through which disinformation\nis being conveyed, which is using propaganda techniques .\nThese include speci\ufb01c rhetorical and psychological tech-\nniques, ranging from leveraging on emotions \u2014such as us-\ningloaded language ,\ufb02ag waving ,appeal to authority ,slo-\ngans , and clich \u00b4es\u2014 to using logical fallacies \u2014such as straw\nmen (misrepresenting someone\u2019s opinion), red herring (pre-\nsenting irrelevant data), black-and-white fallacy (presenting\ntwo alternatives as the only possibilities), and whataboutism .\nMoreover, the problem is exacerbated by the fact that propa-\nganda does not necessarily have to lie; it could appeal to emo-\ntions or cherry-pick the facts. Thus, we believe that speci\ufb01c\nresearch on propaganda detection is a relevant contribution in\nthe \ufb01ght against online disinformation.\nHere, we focus on computational propaganda , which is\nde\ufb01ned as \u201cpropaganda created or disseminated using com-\nputational (technical) means\u201d [Bolsover and Howard, 2017 ].\nTraditionally, propaganda campaigns had been a monopoly\nof state actors, but nowadays they are within reach for\nvarious groups and even for individuals. One key ele-\nment of such campaigns is that they often rely on coordi-\nnated efforts to spread messages at scale. Such coordina-\ntion is achieved by leveraging botnets (groups of fully au-\ntomated accounts) [Zhang et al., 2016 ], cyborgs (partially\nautomated) [Chu et al., 2012 ]and troll armies (human-\ndriven) [Linvill and Patrick, 2018 ], known as sockpuppets\n[Kumar et al., 2017 ],Internet water army [Chen et al., 2013 ],\nastroturfers [Ratkiewicz et al., 2011 ], and seminar users\n[Darwish et al., 2017 ]. Thus, a promising direction to thwart\npropaganda campaigns is to discover such coordination; this\nis demonstrated by recent interest by Facebook1and Twitter2.\n1newsroom.fb.com/news/2018/12/inside-feed-coordinated-inauthentic-behavior/\n2https://help.twitter.com/en/rules-and-policies/platform-manipulationarXiv:2007.08024v1  [cs.CL]  15 Jul 2020\nIn order for propaganda campaigns to work, it is critical\nthat they go unnoticed. This further motivates work on de-\ntecting and exposing propaganda campaigns, which should\nmake them increasingly inef\ufb01cient. Given the above, in the\npresent survey, we focus on computational propaganda from\ntwo perspectives: ( i) the content of the propaganda messages\nand ( ii) their propagation in social networks.\nFinally, it is worth noting that, even though there have been\nseveral recent surveys on fake news detection [Shu at al.,\n2017; Zhou et al., 2019 ], fact-checking [Thorne and Vlachos,\n2018 ], and truth discovery [Li et al., 2016 ], none of them fo-\ncuses on computational propaganda. There has also been a\nspecial issue of the Big Data journal on Computational Pro-\npaganda and Political Big Data [Bolsover and Howard, 2017 ],\nbut it did not include a survey. Here we aim to bridge this gap.\n2 Propaganda\nThe term propaganda was coined in the 17th century, and ini-\ntially referred to the propagation of the Catholic faith in the\nNew World [Jowett and O\u2019Donnell, 2012, p. 2 ]. It soon took\na pejorative connotation, as its meaning was extended to also\nmean opposition to Protestantism. In more recent times, back\nin 1938, the Institute for Propaganda Analysis [Ins, 1938 ],\nde\ufb01ned propaganda as \u201c expression of opinion or action by in-\ndividuals or groups deliberately designed to in\ufb02uence opin-\nions or actions of other individuals or groups with reference\nto predetermined ends \u201d.\nRecently, Bolsover et. al [2017 ]dug deeper into this def-\ninition identifying its two key elements: ( i) trying to in\ufb02u-\nence opinion, and ( ii) doing so on purpose. In\ufb02uencing opin-\nions is achieved through a series of rhetorical and psycho-\nlogical techniques. Clyde R. Miller in 1937 proposed one\nof the seminal categorizations of propaganda, consisting of\nseven devices [Ins, 1938 ], which remain well accepted to-\nday[Jowett and O\u2019Donnell, 2012, p.237 ]:name calling ,glit-\ntering generalities ,transfer ,testimonial ,plain folks ,card\nstacking , and bandwagon . Other scholars consider catego-\nrizations with as many as eighty-nine techniques [Conserva,\n2003 ], and Wikipedia lists about seventy techniques.3How-\never, these larger sets of techniques are essentially subtypes\nof the general schema proposed in [Ins, 1938 ].\nPropaganda is different from disinformation4, in particular\nwith reference to the truth value of the managed information\nand its goal, which in disinformation are ( i)false , and ( ii)in-\ntending to harm , respectively. The (often-neglected) intention\nto harm popped up in 2016, due to both the Brexit referendum\nand the US Presidential elections, when society and academia\ndiscovered that the news cycle got weaponized by disinforma-\ntion. Contrarily, propaganda can hook to claims that are either\ntrue or false, and its intended objectives can be either harmful\nor harmless (even good5). In practice, propaganda and dis-\ninformation are used synergetically to achieve speci\ufb01c objec-\ntives, effectively turning social media into a weapon. Another\nrelated concept is that of \u201cfake news\u201d, where the focus is on\na piece of information being factually false.\n3http://en.wikipedia.org/wiki/Propaganda techniques\n4http://eeas.europa.eu/topics/countering-disinformation en\n5Think of Greta Thunberg\u2019s highly propagandistic speech at the UN in 2019.Although lying and creating fake stories is considered as\none of the propaganda techniques (some authors refer to it as\n\u201cblack propaganda\u201d [Jowett and O\u2019Donnell, 2012 ]), there are\ncontexts where this course of actions is often done without\npursuing the objective to in\ufb02uence the audience, as in satire\nand clickbaiting. These special cases are of less interest when\nit comes to \ufb01ghting the weaponization of social media, and\nare therefore considered out of the scope for this survey.\n3 Text Analysis Perspective\nResearch on propaganda detection based on text analysis has\na short history, mainly due to the lack of suitable annotated\ndatasets for training supervised models. There have been\nsome relevant initiatives, where expert journalists or volun-\nteers analyzed entire news outlets, which could be used for\ntraining. For example, Media Bias/Fact Check (MBFC)6\nis an independent organization analyzing media in terms of\ntheir factual reporting, bias, and propagandist content, among\nother aspects. Similar initiatives are run by US News &\nWorld Report7and the European Union.8Such data has been\nused in distant supervision approaches [Mintz et al., 2009 ],\ni.e., by assigning each article from a given news outlet the\nlabel propagandistic/non-propagandistic using the label for\nthat news outlet. Unfortunately, such coarse approximation\ninevitably introduces noise to the learning process, as we dis-\ncuss in Section 5.\nIn the remainder of this section, we review current work on\npropaganda detection from a text analysis perspective. This\nincludes the production of annotated datasets, characterizing\nentire documents, and detecting the use of propaganda tech-\nniques at the span level.\n3.1 Available Datasets\nGiven that existing models to detect propaganda in text are\nsupervised, annotated corpora are necessary. Table 1 shows\nan overview of the available corpora (to the best of our knowl-\nedge), with annotation both at the document and at the frag-\nment level.\nRashkin et al. [2017 ]released TSHP-17 , a balanced cor-\npus with document-level annotation including four classes:\ntrusted ,satire ,hoax , and propaganda .TSHP-17 belongs to\nthe collection of datasets annotated via distant supervision: an\narticle is assigned to one of the classes if the outlet that pub-\nlished it is labeled as such by the US News & World Report .\nThe documents were collected from the English Gigaword\nand from seven unreliable news sources.\nAccording to Barr \u00b4on-Cede \u02dcno et al. [2019 ]the low amount\nof sources considered per class is a downside of TSHP-17 ,\nas the systems trained on it might be modeling the news out-\nlets, rather than propaganda itself (or any of the other three\nclasses). To cope with this limitation, Barr \u00b4on-Cede \u02dcno et al.\nreleased QProp a twice-as-big binary imbalanced dataset in\nwhich\u001810% of the articles belong to class propaganda .\n6http://mediabiasfactcheck.com\n7www.usnews.com/news/national-news/articles/2016-11-14/avoid-these-fake-\nnews-sites-at-all-costs\n8www.usnews.com/news/national-news/articles/2016-11-14/avoid-these-fake-\nnews-sites-at-all-costs; http://euvsdisinfo.eu/\nCorpus Level Sources Classes Articles Prop.\nTSHP-17 document 11 (2) 4 22,580 5,330\nQProp document 104 (10) 2 51,294 5,737\nPTC text span 49 (13) 18 451 7,385\nTable 1: Textual datasets available to train supervised propaganda\nidenti\ufb01cation models at different granularity levels.\nOnce again, the annotation in QProp is obtained by distant\nsupervision; this time with information from MBFC. Aside\nthe binary propaganda vs.trustworthy annotation, in QProp\neach article has associated metadata from its source such as\nthe bias level (e.g., left,center ,right ) from MBFC and ge-\nographical information, average sentiment, publication date,\nidenti\ufb01er, author, and of\ufb01cial source name from GDELT.9\nHowever, both TSHP-17 andQProp lack information about\nthe precise location of a propagandist snippet within a doc-\nument. Since propaganda is conveyed by using speci\ufb01c\nrhetoric and psychological techniques, a separate line of\nresearch recently aimed to identify the use of such tech-\nniques. In particular, Da San Martino et al. [2019b ]pro-\nposed a dataset with assets that previously available resources\nlacked. First, their PTC corpus is manually judged by pro-\nfessional annotators, rather than using distant supervision.\nSecond, the annotation is at the fragment level: speci\ufb01c text\nspans are \ufb02agged, rather than full documents. Third, it goes\ndeeper into the types of propaganda, considering 18 propa-\nganda techniques, rather than the binary propaganda vs. non-\npropaganda setting. The curated list of techniques is summa-\nrized in Table 2. Whereas the volume of PTC is way lower\nthan that of TSHP-17 andQProp \u2014a few hundred articles\nagainst thousands\u2014 it contains more than 7,000 propagandist\nsnippets. See Figure 1 for an example with annotations.\nAnother relevant line of research is on computational argu-\nmentation, which deals with some logical fallacies considered\nto be propaganda techniques. Habernal et al. [2017 ]described\na corpus with 1:3karguments annotated with \ufb01ve fallacies\nsuch as ad hominem ,red herring , and irrelevant authority .\n3.2 Text Classi\ufb01cation\nEarly approaches to propaganda identi\ufb01cation are fairly\naligned to the produced corpora. Rashkin et al. [2017 ]de\ufb01ned\na classical four-classes text classi\ufb01cation task: propaganda vs\ntrusted vshoax vssatire, using the TSHP-17 dataset. Us-\ning word n-gram representation with logistic regression, they\nfound that their model performed well only on articles from\nsources that the system was trained on.\nBarr\u00b4on et al. [2019 ]used a binary classi\ufb01cation setting: de-\ntecting propaganda vsnon-propaganda and experimented on\nTSHP-17 andQProp corpora. They ran a massive set of ex-\nperiments, investigating various representations, from writing\nstyle and readability level to the presence of certain keywords,\ntogether with logistic regression and SVMs, and con\ufb01rmed\nthat using distant supervision, in conjunction with rich repre-\nsentations, might encourage the model to predict the source,\nrather than to discriminate propaganda from non-propaganda.\n9https://www.gdeltproject.org/Technique De\ufb01nition\nName calling attack an object/subject of the propa-\nganda with an insulting label\nRepetition repeat the same message over and over\nSlogans use a brief and memorable phrase\nAppeal to fear support an idea by instilling fear against\nother alternatives\nDoubt questioning the credibility of some-\none/something\nExaggeration/minimizat. exaggerate or minimize something\nFlag-Waving appeal to patriotism or identity\nLoaded Language appeal to emotions or stereotypes\nReduction ad hitlerum disapprove an idea suggesting it is pop-\nular with groups hated by the audience\nBandwagon appeal to the popularity of an idea\nCasual oversimpli\ufb01ca-\ntionassume a simple cause for a complex\nevent\nObfuscation, inten-\ntional vaguenessuse deliberately unclear and obscure ex-\npressions to confuse the audience\nAppeal to authority use authority\u2019s support as evidence\nBlack&white fallacy present only two options among many\nThought terminating\nclich \u00b4esphrases that discourage critical thought\nand meaningful discussions\nRed herring introduce irrelevant material to distract\nStraw men refute argument that was not presented\nWhataboutism charging an opponent with hypocrisy\nTable 2: List of the 18 propaganda techniques and their de\ufb01nitions.\nFigure 1: Text excerpt with annotated propaganda techniques.\nThey advocated for providing assurance that test data come\nfrom news sources that were not used for training, and inves-\ntigated what representations remain robust in such a setting.\n3.3 Detecting the Use of Propaganda Techniques\nDa San Martino et al. [2019b ]de\ufb01ned two tasks, based on\nannotations from the PTCdataset: ( i) binary classi\ufb01cation \u2014\ngiven a sentence in an article, predict whether any of the 18\ntechniques has been used in it; ( ii) multi-label multi-class\nclassi\ufb01cation and span detection task \u2014given a raw text,\nidentify both the speci\ufb01c text fragments where a propaganda\ntechnique is being used as well as the type of technique. Such\na \ufb01ne-grained level of analysis may provide support and ex-\nplanations to the user on why an article has been judged as\npropagandistic by an automatic system. The authors pro-\nposed a multi-granularity deep neural network that modulates\nthe signal from the sentence-level task to improve the predic-\ntion of the fragment-level classi\ufb01er.\nA shared task was held within the 2019 Workshop on\nNLP4IF: censorship, disinformation, and propaganda10,\nbased on the PTC corpus and the task de\ufb01nitions above.\nThe best-performing models for both tasks used BERT-\nbased contextual representations. Other approaches used\ncontextual representations based on RoBERTa, Grover, and\nELMo, or context-independent representations based on lex-\nical, sentiment-based, readability, and TF-IDF features. En-\nsembles were also popular. Further details are available in the\nshared task overview paper [Da San Martino et al., 2019a ].\n4 Network Analysis Perspective\nAs seen in Section 3, the rhetoric techniques used for in-\n\ufb02uencing readers\u2019 opinions can be detected directly in the\ntext. Contrarily, identifying the intent behind a propaganda\ncampaign requires analysis that goes beyond individual texts,\ninvolving (among others) classi\ufb01cation of the social media\nusers that contributed to injecting and spreading propaganda\nwithin a network. Thus, a necessary condition to detect\nthe intention to harm implies detecting malicious coordina-\ntion (i.e., coordinated inauthentic behavior). Throughout the\nyears, this high-level task has been tackled in different ways.\n4.1 Early Approaches\nEarly approaches for detecting malicious coordination were\nbased on classifying individual nodes in a network as either\nmalicious orlegitimate . Then, clusters of malicious nodes\nwere considered to be acting in coordination. In other words,\nthe concept of coordination was not embedded within the\nmodels, but it was added \u201ca posteriori\u201d. The vast majority of\nthese approaches are based on supervised machine learning\nand each account under investigation was analyzed in isola-\ntion. That is, given a group of accounts to analyze, the super-\nvised technique was separately applied to each account of the\ngroup, that in turn received a label assigned by the detector.\nThe key assumption of this body of work is that each mali-\ncious account has features that make it clearly distinguishable\nfrom legitimate ones. This approach to the task also revolved\naround the application of off-the-shelf, general-purpose clas-\nsi\ufb01cation algorithms. Widely used algorithms include deci-\nsion trees and random forests, SVMs, boosting and bagging\n(e.g., Adaptive Boost and Decorate) and, more recently, deep\nneural networks [Kudugunta and Ferrara, 2018 ].\nThe most widely known example of this kind of detectors,\nis Botometer [Yang et al., 2019 ], a social bot detection sys-\ntem. By leveraging more than 1,200 features for a social me-\ndia account, it evaluates pro\ufb01le characteristics, social network\nstructure, the produced content (including sentiment expres-\nsions), and temporal features. Botometer simultaneously ana-\nlyzes multiple dimensions of suspicious accounts for spotting\nbots. Instead, other systems solely rely on network character-\nistics [Yang et al., 2015 ], textual content [Rangel and Rosso,\n2019 ], or pro\ufb01le information [Lee and Kim, 2014 ]. These\nlatter systems are typically easier to game, since they only\nanalyze a single facet of the complex, evolving behavior of\nbad online actors.\n10http://www.netcopia.net/nlp4if/2019/4.2 Evolving Threats\nDespite having achieved promising initial results, these early\napproaches had several limitations. First, the performance\nof a supervised detector strongly depends on the availabil-\nity of a ground truth (training) dataset. In most cases, a real\nground truth is lacking and the labels are manually given by\nhuman operators. Unfortunately, as of 2020, we still have\ndiverse and con\ufb02icting de\ufb01nitions of what a malicious ac-\ncount really is [Grimme et al., 2017 ], and humans have been\nproven to suffer from annotation biases and to largely fail at\nspotting sophisticated bots and trolls [Cresci et al., 2017 ].\nTo make matters worse, it has been demonstrated that ma-\nlicious accounts \u201cevolve\u201d (i.e., they change their characteris-\ntics and behaviors) in an effort to evade detection by estab-\nlished techniques [Cresci et al., 2017 ]. Nowadays, sophis-\nticated malicious accounts are using the same technological\nweapons as their hunters \u2014such as powerful AI techniques\u2014\nfor generating credible texts (e.g., with GPT-2), pro\ufb01le pic-\ntures (e.g., with StyleGAN)11, and videos (e.g., using deep-\nfakes), thus dramatically increasing their capabilities of im-\npersonating real people, and hence of escaping detection.\n4.3 Modern Approaches\nThe dif\ufb01culties at detecting sophisticated bots and trolls with\nearly approaches lead to a new research trend whose primary\ncharacteristic is to target groups of accounts as a whole, rather\nthan focusing on individual accounts. In recently proposed\ndetectors, coordination is considered a key feature to ana-\nlyze, and it is modeled within the detectors themselves. The\nrationale for this choice is that malicious accounts act in co-\nordination (e.g., sbots are often organized in botnets, trolls\nform so-called troll armies) to amplify their effect [Zhang et\nal., 2016 ]. Moreover, by analyzing large groups of accounts,\nmodern detectors also have more data to exploit for fueling\npowerful AI algorithms [Sun et al., 2017 ]. The shift from\nindividual to group analysis was accompanied by another\nshift from general-purpose machine learning algorithms, to\nad-hoc algorithms speci\ufb01cally designed for detecting coor-\ndination. In other words, the focus shifted from feature en-\ngineering to learning effective feature representations and of\ndesigning brand-new and customized algorithms [Cai et al.,\n2017 ]. Many modern detectors are also unsupervised or semi-\nsupervised, to overcome the generalization de\ufb01ciencies of su-\npervised detectors that are severely limited by the availability\nof exhaustive training datasets [Echeverr `\u0131a et al., 2018 ].\nExamples of such systems implement network-based tech-\nniques, aiming at detecting suspicious account connectivity\npatterns [Liu et al., 2017; Chetan et al., 2019; Pacheco et al.,\n2020 ]. Coordinated behavior appears as near-fully connected\ncommunities in graphs, dense blocks in adjacency matrices,\nor peculiar patterns in spectral subspaces [Jiang et al., 2016 ].\nOther techniques adopted unsupervised approaches for spot-\nting anomalous patterns in the temporal tweeting and retweet-\ning behaviors of groups of accounts \u2014e.g., by computing\nmetrics of distance out of the accounts activity time series and\nby subsequently account clustering [Chavoshi et al., 2016;\nMazza et al., 2019 ].\n11https://www.wired.com/story/facebook-removes-accounts-ai-generated-photos/\nThe rationale behind such approaches is based on evidence\nsuggesting that human-driven and legitimate behaviors are in-\ntrinsically more heterogeneous than automated and inauthen-\ntic ones [Cresci et al., 2020 ]. Consequently, a large cluster\nof accounts with highly similar behavior might serve as a red\n\ufb02ag for coordinated inauthentic behavior. Distance (or simi-\nlarity) between account activity time series was computed via\ndynamic time warping [Chavoshi et al., 2016 ], or as the Eu-\nclidean distance between the feature vectors computed by an\nLSTM autoencoder [Mazza et al., 2019 ]. More recently, other\nauthors investigated the usefulness of Inverse Reinforcement\nLearning (IRL) for inferring the intent that drives the activity\nof coordinated groups of malicious accounts. Inferring in-\ntent and motivation from observed behavior has been exten-\nsively studied in the framework of IRL, with the main goal\nof \ufb01nding the rewards behind an agent\u2019s observed behavior.\nThe inferred rewards can then be used as features in super-\nvised learning systems aimed at detecting malicious and co-\nordinated agents.\nThe switch from early to modern detectors demonstrated\nthat the approach (e.g., individual vsgroup-based, supervised\nvsunsupervised) to the task of propaganda and malicious ac-\ncounts detection can have serious repercussions on detection\nperformance. However, some scienti\ufb01c communities natu-\nrally tend to favor a speci\ufb01c approach. For example, the ma-\njority of techniques that perform network analysis (e.g., by\nconsidering the social or interactions graph of the accounts)\nare intrinsically group-based. More often than not, they are\nalso unsupervised. Contrarily, all techniques based on textual\nanalyses, such as those that solely rely on natural language\nprocessing, are supervised detectors that analyze individual\naccounts [Rangel and Rosso, 2019 ]. As a consequence, some\ncombinations of the cited approaches \u2014above all, text-based\ndetectors that perform unsupervised group analysis\u2014 are al-\nmost unexplored. For the future, it would thus be advisable to\nput efforts along the highlighted research directions that have\nbeen mostly overlooked until now.\n5 Lessons Learned\nThe main lesson from our analysis is that there is a disconnec-\ntion between NLP and Network Analysis communities when\nit comes to \ufb01ghting Computational Propaganda, and therefore\ncombined approaches may lead to systems signi\ufb01cantly out-\nperforming the current state of the art. A detailed analysis is\nreported in the following.\n5.1 Text Analysis Lessons\nFrom a text analysis perspective, we see that there is a lack of\na suitable dataset for document-level propaganda detection.\nThe attempts to use distant supervision as a substitute, by\nprojecting labels from media to all the articles they have pub-\nlished is problematic in many aspects, even when done care-\nfully. Indeed, distant supervision inevitably introduces noise\nin the learning process, as it is based on the wrong assump-\ntion that all articles from a given source would be either pro-\npaganda or non-propaganda. In reality, a propagandist source\ncould periodically post objective non-propagandist informa-\ntion to boost its credibility.Similarly, sources that are generally recognized as objec-\ntive might occasionally post information that promotes a par-\nticular agenda. One way to deal with this issue might be to\ndevise advanced learning algorithms, such as Generative Ad-\nversarial Networks (GANs), which can be trained to avoid\nspeci\ufb01c biases, i.e., modelling the article source. Another is-\nsue with distant supervision is that while it is acceptable for\ntraining, it cannot give a fair assessment of a system at testing\ntime, something that previous work has ignored.\nAnother lesson is that it seems more promising to focus\non detecting the use of \ufb01ne-grained propaganda techniques in\ntext. Propaganda techniques are well-de\ufb01ned and well-known\nin the literature, and thus it makes sense to focus on them, as\nthey are the very device on which propaganda is built. No-\ntably, a proper dataset is already available for this new task,\nit is of reasonable size (350K tokens, which compares well\nto datasets for the related task of named entity recognition,\nwhose typical size is 200K tokens), and covers a wide range\nof 18 commonly accepted techniques, comprising both vari-\nous kinds of appeal to emotions as well as logical fallacies.\n5.2 Network Analysis Lessons\nTypically, when scholars and OSN administrators identify\nnew coordinated behavior that goes undetected by existing\ntechniques, as a reaction they start the development of new\ndetectors. The implication of this reactive approach is that\nimprovements occur only some time after having collected\nevidence of a new mischievous behavior. Bad actors thus\nbene\ufb01t from a large time span \u2014the time needed to design,\ndevelop, and deploy a new detector\u2014 during which they are\nfree to tamper with our online environments.\nA second lesson learned is related to the use of machine\nlearning algorithms, the vast majority of which are designed\nto operate in environments that are stationary and neutral.\nUnfortunately, in the task of propaganda campaign detection\nboth assumptions are easily violated, yielding unreliable pre-\ndictions and severely decreased performance [Goodfellow et\nal., 2014 ]. Stationarity is violated by the mechanism of evo-\nlution of malicious accounts, resulting in accounts exhibiting\ndifferent behavior and characteristics over time. Neutrality is\nviolated as well, since propaganda spreaders and bot masters\nare actively trying to fool detectors. Consequently, the excep-\ntional results in malicious accounts detection that we reported\nin our papers might be actually largely exaggerated.\nAdversarial machine learning may however mitigate both\nprevious issues, since the existence of adversaries is ac-\ncounted for by design. We could thus apply adversarial ma-\nchine learning to study vulnerabilities of existing detectors\nand the possible attacks the cited vulnerabilities could lead to,\nbefore they have been exploited by the adversaries. Interest-\ningly, this paradigm has recently been applied for improving\nbot detection as well as for fake news detection [Wu et al.,\n2020; Zellers et al., 2019 ]. Finally, it is worth noting that all\ntasks related to the detection of online deception, manipula-\ntion, and automation \u2014including, but not limited to, propa-\nganda campaign detection\u2014 are intrinsically adversarial.\n6 Challenges and Future Forecasting\n6.1 Major Challenges\nComputational propaganda detection is still in its early stages\nand the following challenges need to be addressed:\n1. Text is not the only way to convey propaganda. Some-\ntimes, pictures convey stronger messages than texts, as for\ncertain political memes. Thus, it is becoming increasingly\nnecessary to analyze multiple modalities of data (e.g., im-\nages, videos, speech). This is challenging because, even if\nsome research was conducted on how to effectively under-\nstand cross-modal information in various domains, little\nhas been done on what information (provided by a given\nmodality) can be leveraged to detect propaganda.\n2. Explainability is a desirable feature of propaganda detec-\ntion systems in order to make them accepted at large. In\nfact, it is crucial to be able to motivate decisions, espe-\ncially controversial ones (e.g., banning of OSN accounts\nor removal of posts/news). However, most of the recent\ndevelopments in propaganda and coordination detection\nare based on deep learning, which lacks explanability \u2014\nfor the short and medium term, at least.\n3. In addition to being able to classify individual doc-\numents as propaganda or single accounts as decep-\ntive/coordinated, it would be useful to also provide infor-\nmation towards understanding the goals and the strategy\nof propaganda campaigns [Atanasov et al., 2019 ]. This\nproblem currently stands as largely unsolved and calls for\njoint efforts in propaganda and coordination detection.\n4. Recent advances in neural language models have made it\ndif\ufb01cult even for humans to detect synthetic text. Zellers\net al. [2019 ]showed that a template system helps manip-\nulate the output format of a language model, while Yang\net al. [2018 ]suggested how to transfer the style of the lan-\nguage model to the target domain. With all building blocks\nalready in place, it is likely that automatically-generated\npropaganda will surface in the near future.\n5. The vast majority of existing detectors are evaluated only\non a single annotated dataset. Often, the dataset is col-\nlected and annotated for a speci\ufb01c study, and is subse-\nquently disregarded. As such, we currently lack the ability\nto evaluate detectors\u2019 capability of generalizing the perfor-\nmance obtained in silico , also when applied in-the-wild.\nFor the future, it is advisable to devote additional efforts\nto curate large annotated datasets. Extensive data sharing\ninitiatives \u2014such as that of Twitter related to recent infor-\nmation operations12\u2014 are thus particularly welcome.\n6. When dealing with user-generated data, ethical considera-\ntions are also important. We should thus guarantee that all\nanalysis and potential sharing of datasets are conducted\nrespecting the privacy of the involved users. This can\nalso affect data availability, as demonstrated by the Face-\nbook/Social Science One URL dataset13, whose release\nwas postponed for almost two years due to the need to\nimplement robust privacy-preserving mechanisms.\n12http://transparency.twitter.com/en/information-operations.html\n13http://socialscience.one/blog/unprecedented-facebook-urls-dataset-now-\navailable-research-through-social-science-one6.2 Forecasting\nGiven the above challenges and the existence of some previ-\nously remarked under-explored directions, we highlight the\nfollowing research directions:\n1. There is growing motivation for jointly tackling the tex-\ntual and the network aspects of propaganda detection, as\nrelying on a single paradigm is a recipe for failure. For\ninstance, if a pre-trained language model such as GPT-2\nis used as an automated propaganda generation method, it\nmay become ineffective to detect propaganda when focus-\ning on linguistic features alone, since it would take longer\nto detect propaganda than to generate it. Thus, in the fu-\nture it will be necessary to go beyond texts and to also\nanalyze the network nodes and the connectivity patterns\nthrough which propaganda spreads.\n2. Spreading propaganda through multiple modalities is in-\ncreasingly popular. Maliciously crafted images or videos\ncan be more effective than articles when targeting the\nmillennial generation, who is more familiar with watch-\ning than reading. Again, research in detecting propa-\nganda needs to move beyond text analysis, and to embrace\nmore comprehensive analyses that span over various data\nmodalities.\n7 Conclusion\nAmong the contributions of our work, we surveyed state-of-\nthe-art computational propaganda detection methodologies.\nWe also showed how the rapid pace of evolution of the tech-\nniques adopted by an adversary are impairing current pro-\npaganda detection solutions. Further, we justi\ufb01ed our call\nfor moving beyond textual analysis and we argued for the\nneed of combined efforts blending Natural Language Pro-\ncessing, Network Analysis, and Machine Learning. Finally,\nwe showed concrete promising research directions in the \ufb01eld\nof computational propaganda detection.\nReferences\n[Atanasov et al., 2019 ]Atanasov et al. Predicting the role of\npolitical trolls in social media. In CoNLL , pages 1023\u2013\n1034, 2019.\n[Barr\u00b4on-Cede \u02dcno et al., 2019 ]Barr\u00b4on-Cede \u02dcno et al. Proppy:\nOrganizing the news based on their propagandistic con-\ntent. Inf. Process. Manag. , 56(5):1849\u20131864, 2019.\n[Bolsover and Howard, 2017 ]Bolsover and Howard. Com-\nputational propaganda and political big data: Toward a\nmore critical research agenda. Big Data , 5(4):273\u2013276,\n2017.\n[Cai et al., 2017 ]Cai et al. Detecting social bots by jointly\nmodeling deep behavior and content information. In\nCIKM , pages 1995\u20131998, 2017.\n[Chavoshi et al., 2016 ]Chavoshi et al. DeBot: Twitter bot\ndetection via warped correlation. In ICDM , pages 817\u2013\n822, 2016.\n[Chen et al., 2013 ]Chen et al. Battling the internet water\narmy: Detection of hidden paid posters. In ASONAM ,\npages 116\u2013120, 2013.\n[Chetan et al., 2019 ]Chetan et al. Corerank: Ranking\nto detect users involved in blackmarket-based collusive\nretweeting activities. In WSDM , pages 330\u2013338, 2019.\n[Chu et al., 2012 ]Chu et al. Detecting automation of Twit-\nter accounts: Are you a human, bot, or cyborg? TDSC ,\n9(6):811\u2013824, 2012.\n[Conserva, 2003 ]Conserva. Propaganda Techniques . Au-\nthorHouse, 2003.\n[Cresci et al., 2017 ]Cresci et al. The paradigm-shift of so-\ncial spambots: Evidence, theories, and tools for the arms\nrace. In WWW Companion , pages 963\u2013972, 2017.\n[Cresci et al., 2020 ]Cresci et al. Emergent properties, mod-\nels, and laws of behavioral similarities within groups of\nTwitter users. Comput. Commun. , 150:47\u201361, 2020.\n[Da San Martino et al., 2019a ]Da San Martino et al. Find-\nings of the NLP4IF-2019 shared task on \ufb01ne-grained pro-\npaganda detection. In NLP4IF@EMNLP , pages 162\u2013170,\n2019.\n[Da San Martino et al., 2019b ]Da San Martino et al. Fine-\ngrained analysis of propaganda in news articles. In\nEMNLP , pages 5640\u20135650, 2019.\n[Darwish et al., 2017 ]Darwish et al. Seminar users in the\nArabic Twitter sphere. In SocInfo , pages 91\u2013108, 2017.\n[Echeverr `\u0131a et al., 2018 ]Echeverr `\u0131a et al. LOBO: Evaluation\nof generalization de\ufb01ciencies in Twitter bot classi\ufb01ers. In\nACSAC , pages 137\u2013146, 2018.\n[Goodfellow et al., 2014 ]Ian Goodfellow et al. Generative\nadversarial nets. In NIPS , pages 2672\u20132680, 2014.\n[Grimme et al., 2017 ]Grimme et al. Social bots: Human-\nlike by means of human control? Big Data , 5(4):279\u2013293,\n2017.\n[Habernal et al., 2017 ]Habernal et al. Argotario: Compu-\ntational argumentation meets serious games. In EMNLP ,\npages 7\u201312, 2017.\n[Ins, 1938 ]How to detect propaganda. In Publications of the\nInstitute for Propaganda Analysis , pages 210\u2013218. 1938.\n[Jiang et al., 2016 ]Jiang et al. Inferring lockstep behavior\nfrom connectivity pattern in large graphs. Knowledge and\nInformation Systems , 48(2):399\u2013428, 2016.\n[Jowett and O\u2019Donnell, 2012 ]Jowett and O\u2019Donnell. Pro-\npaganda and Persuasion . SAGE, 2012.\n[Kudugunta and Ferrara, 2018 ]Kudugunta and Ferrara.\nDeep neural networks for bot detection. Information\nSciences , 467:312\u2013322, 2018.\n[Kumar et al., 2017 ]Kumar et al. An army of me: Sockpup-\npets in online discussion communities. In WWW , pages\n857\u2013866, 2017.\n[Lee and Kim, 2014 ]Lee and Kim. Early \ufb01ltering of\nephemeral malicious accounts on Twitter. Comput. Com-\nmun. , 54:48\u201357, 2014.\n[Li et al., 2016 ]Li et al. A survey on truth discovery.\nSIGKDD Explor. Newsl. , 17(2):1\u201316, 2016.[Linvill and Patrick, 2018 ]Linvill and Patrick. Troll facto-\nries: The Internet Research Agency and state-sponsored\nagenda building. Resource Centre on Media Freedom in\nEurope , 2018.\n[Liu et al., 2017 ]Liu et al. HoloScope: Topology-and-spike\naware fraud detection. In CIKM , pages 1539\u20131548, 2017.\n[Mazza et al., 2019 ]Mazza et al. RTbust: Exploiting tem-\nporal patterns for botnet detection on Twitter. In WebSci ,\npages 183\u2013192, 2019.\n[Mintz et al., 2009 ]Mintz et al. Distant supervision for re-\nlation extraction without labeled data. In ACL\u2013AFNLP ,\npages 1003\u20131011, 2009.\n[Pacheco et al., 2020 ]Pacheco et al. Unveiling coordinated\ngroups behind White Helmets disinformation. In WWW\nCompanion , pages 611\u2013616, 2020.\n[Rangel and Rosso, 2019 ]Rangel and Rosso. Overview of\nthe 7th author pro\ufb01ling task at PAN 2019: Bots and gender\npro\ufb01ling in Twitter. In CLEF , 2019.\n[Rashkin et al., 2017 ]Rashkin et al. Truth of varying shades:\nAnalyzing language in fake news and political fact-\nchecking. In EMNLP , pages 2931\u20132937, 2017.\n[Ratkiewicz et al., 2011 ]Ratkiewicz et al. Truthy: Mapping\nthe spread of astroturf in microblog streams. In WWW ,\npages 249\u2013252, 2011.\n[Shu at al., 2017 ]Shu at al. Fake news detection on so-\ncial media: A data mining perspective. SIGKDD Explor.\nNewsl. , 19(1):22\u201336, 2017.\n[Sun et al., 2017 ]Sun et al. Revisiting unreasonable effec-\ntiveness of data in deep learning era. In ICCV , pages 843\u2013\n852, 2017.\n[Thorne and Vlachos, 2018 ]Thorne and Vlachos. Auto-\nmated fact checking: Task formulations, methods and fu-\nture directions. In COLING , pages 3346\u20133359, 2018.\n[Wu et al., 2020 ]Wu et al. Using improved conditional gen-\nerative adversarial networks to detect social bots on Twit-\nter.IEEE Access , 8:36664\u201336680, 2020.\n[Yang et al., 2015 ]Yang et al. V oteTrust: Leveraging friend\ninvitation graph to defend against social network sybils.\nTDSC , 13(4):488\u2013501, 2015.\n[Yang et al., 2018 ]Yang et al. Unsupervised text style trans-\nfer using language model discriminators. In NIPS , pages\n7287\u20137298, 2018.\n[Yang et al., 2019 ]Yang et al. Arming the public with arti-\n\ufb01cial intelligence to counter social bots. Human Behavior\nand Emerging Technologies , 1(1):48\u201361, 2019.\n[Zellers et al., 2019 ]Zellers et al. Defending against neural\nfake news. In NIPS , pages 9051\u20139062, 2019.\n[Zhang et al., 2016 ]Zhang et al. The rise of social botnets:\nAttacks and countermeasures. TDSC , 15(6):1068\u20131082,\n2016.\n[Zhou et al., 2019 ]Zhou et al. Fake news: Fundamental the-\nories, detection strategies and challenges. In WSDM , pages\n836\u2013837, 2019.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "A survey on computational propaganda detection", "author": ["GDS Martino", "S Cresci", "A Barr\u00f3n-Cede\u00f1o", "S Yu"], "pub_year": "2020", "venue": "arXiv preprint arXiv \u2026", "abstract": "Propaganda campaigns aim at influencing people's mindset with the purpose of advancing  a specific agenda. They exploit the anonymity of the Internet, the micro-profiling ability of"}, "filled": false, "gsrank": 850, "pub_url": "https://arxiv.org/abs/2007.08024", "author_id": ["URABLy0AAAAJ", "Jsd83JgAAAAJ", "0q0QVG4AAAAJ", "ayy2eo0AAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:KJ2QxRsrlEgJ:scholar.google.com/&output=cite&scirp=849&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D840%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=KJ2QxRsrlEgJ&ei=n7WsaPbEK8DZieoPqdqh8QU&json=", "num_citations": 241, "citedby_url": "/scholar?cites=5229852465562688808&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:KJ2QxRsrlEgJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2007.08024"}}, {"title": "Leadership Studies", "year": "NA", "pdf_data": "https://johepal.com  \n \nCite article  as: \n \nMyers Bartell, S.  (2025). PhDead: The erosion of academic freedom by \nignorance . Journal of Higher Education Policy and Leadership Studies, 6(1), 9-\n33. https://dx.doi.org/10.61186/johepal.6.1.9  Journal of  \nHigher Education Policy  \n And  \nLeadership Studies  \nJHEP ALS (E -ISSN: 2717 -1426 ) \n \n \n \n \n \nPhDead: The Erosion of \nAcademic Freedom by \nIgnorance  \n \n \n \n \n \n Sherrie Myers Bartell           \nDepartment of Business Administration , \nUniversity of the People , California, USA   \n \nEmail: sherrie.bartell@uopeople.edu                            \n https://orcid.org/0009 -0007 -6319 -8973   \nArticle  Received  Article  Accepted  Published Online  \n2024/11/08 2025/03/10 2025/03/31 \n [ DOI: 10.61186/johepal.6.1.9 ]  [ Downloaded from johepal.com on 2025-08-25 ] \n                             1 / 26\nMyers Bartell, S.  \n \n \n E-ISSN: 2717 -1426  Volume: 6 Issue: 1 DOI:  10.61186 /johepal. 6.1.9 9 PhDead: The Erosion of Academic Freedom by \nIgnorance  \n Journal of Higher Education \nPolicy And Leadership \nStudies (JHEP ALS) \n \nE-ISSN: 2717 -1426  \nVolume: 6 Issue: 1 \npp. 9-33 \nDOI:  \n10.61186 /johepal. 6.1.9 \nAbstract  \nThis article explores the gradual erosion of academic \nfreedom in contemporary educational institutions, \nattributing this decline to the pervasive influence of \nignorance. Through examination of both historical and \ncontemporary examples, this piece highlights how \nignoran ce\u2014manifested through censorship, lack of critical \nthinking, and the suppression of diverse viewpoints \u2014\nundermines the foundational principles of academic \nfreedom. The paper argues that when academic freedom is \ncompromised, there are detrimental effects on educators, \nstudents, and society at large. It is essential to foster an \nenvironment of open inquiry and intellectual rigor to \npreserve the integrity of academia. Furthermore, \nintellectual freedom and critical thought are requisite for a \nthriving society an d a secure union between democracy and \neducation. Recommendations for policy changes and \neducational reforms are proposed to counteract these \ndetrimental trends and promote a culture of knowledge, \ntolerance, inclusion, and understanding. Ultimately, this \npaper underscores the critical importance of combating \nignorance to safeguard the future of academic freedom and \nto ensure the continued progress and vitality of educational \ninstitutions.  \n \n \n \n  \n \n \nSherrie Myers Bartell  * \n \n \n \n \n \n \n \n \n \n \nKeywords: Anti-intellectualism; Ignorance; Academic Freedom; Critical Thinking; Higher \nEducation; Free Speech; Illiberalism ; Agnotology  \n \n  \n                                                           \n*Corresponding author\u2019s email:  sherrie.bartell@uopeople.edu                 \n [ DOI: 10.61186/johepal.6.1.9 ]  [ Downloaded from johepal.com on 2025-08-25 ] \n                             2 / 26\nPhDead?  \n  \n \n Journal of Higher Education Policy And Leadership Studies (JHEP ALS) 10 Introduction  \nThe question of what counts as knowledge and who counts as its producers is confounded \nby ignorance. The exaltation of anti -intellectualism (Niose, 2015) and its manifestations as \nanti-science fervor (Hotez, 2020), rejection of critical thinking (Burbules, 2022; Garry, 2023), \ncensorship and book banning (Scussel, 2024), \"truth decay\" (Roy, 2024), moral tribal ism \n(Bocian et al., 2021), cancel culture (Dholakia, 2020; Garry, 2023), fake news, alternative \nfacts, conspiracy theories, and the spread of dis - and misinformation (Ordway, 2017; Renze, \n2021; Zadronzy, 2024) undermine traditionally accepted ideas of know ledge and expertise. \nEach trend supports the notion that \"We live in an age of ignorance\u2026\" (Proctor & \nSchiebinger, 2008, p. vii, as cited in Barbier et al., 2021). A major casualty of ignorance is \nacademic freedom, threatened by growing authoritarianism, s tate overreach, geopolitical \nconflict, and the onslaught of right -wing populism and religious nationalism globally (Berg \net al., 2023; Douglass, 2023; Goodman, 2024; Klein & Norris, 2022; Lerch et al., 2024; Pap, \n2021; Schofer et al., 2022; Unal, 2024).  \nAcademic institutions face increasing attacks from groups seeking to shut down \nintellectual inquiry and discourse (Kirstein, 2004; Sultana, 2018 ) that disagrees with their \nworldview. Ideologically driven efforts to censor, silence, and intimidate faculty t hreaten \nacademic freedom. Dependency on philanthropic support has weakened academic \ninstitutions, leading administrators to potentially yield to donors' demands (Benn, 2015; \nMoody, 2023) \u2013even when conflicting with institutional values and interests \u2014result ing in \nuniversities violating standards of academic freedom and free speech rights (Sultana, 20 18). \nLast April, a New York Times opinion piece asked, \"Is this the end of academic \nfreedom?\" (Chakravartty & Nesiah, 2024). The article examined censorship duri ng a pro -\nPalestinian demonstration at New York University's Bobst Library atrium, where a poetry \nreading was interrupted. University administrators halted the recitation of a poem by \nPalestinian poet and scholar Refaat Alareer, killed weeks earlier in an I sraeli offensive. The \npoem, \"If I Must Die,\" concludes with \"If I must die, let it bring hope \u2014 let it be a tale.\"  \nShortly after these lines were read, the university administration intervened to stop the \nreading. Students and faculty participants were sum moned to disciplinary meetings, and \nwritten warnings were issued (Chakravartty & Nesiah, 2024).  \nAlthough this paper does not take sides on the horrific genocidal conflict in Gaza or \nthe vile rise of anti -Semitism on U.S. college campuses, a commitment to d emocratic values \nenabling free speech should not be used to harm or devalue another human being. This is \nespecially true in a collegiate environment where open -mindedness and freedom of \nexpression are imperative for constructive learning and research. The disruption of a \npeaceful poetry reading at NYU by campus officials to quash free speech illustrates \nrestrictions on academic freedom, manufactured ignorance, and anti -intellectualism. \nCensorship of faculty and student -organized events is not beneficial \"if  one believes that \nuniversities should be open spaces for civil and informed discussion and debate\" (Douglass, \n2023, p. 8). Encouraging constructive debate can bridge ideological rifts and promote \nintellectual engagement (Sterling, 2024b, para. 9). The con sequences of constraining \nacademic freedom are dire, including loss of scholarly knowledge, intellectual community, \ncareer curtailment, uncertainty, self -censorship and detachment.  \n [ DOI: 10.61186/johepal.6.1.9 ]  [ Downloaded from johepal.com on 2025-08-25 ] \n                             3 / 26\nMyers Bartell, S.  \n \n \n E-ISSN: 2717 -1426  Volume: 6 Issue: 1 DOI:  10.61186 /johepal. 6.1.9 11 Freedom and enlightenment share an inextricable bond; the pursuit of one is  \ninseparable from the other. For knowledge to grow in the spaces between rival ideas \n(Bartell, 2007, p. 147), freedom of expression and tolerance for opposing views is needed. \nThe discovery of truth depends on unrestricted speech, making the individual and  \nintellectual right to free speech a cornerstone of academic freedom (Kabasakal Badamchi, \n2022). However, an important qualification must be made: While \u201cfree speech makes no \ndistinction about quality; academic freedom does\u201d (Scott, 2017, p. 14; Sultana, 2 018, p. \n232). Unlike free speech, academic freedom demands the pursuit of truth; it is informed, \nreasoned, intellectually -driven and knowledge -based, founded on principles of scholarly \nrigor and verification (Sultana 20 18), not a license to incite intolera nce, hate or violence, \nspread propaganda, or stifle dissenting voices or the right of speech by minorities, the \noppressed, and marginalized groups.  \nThis article will illustrate how academic freedom is enveloped in a haze of \"unknowing\" \n(Sultana , 2018), wh ere radical ideologies and baseless assertions by pseudo -intellectuals \nhave infiltrated higher education, posing as genuine discourse. This situation is partly self -\ninflicted and threatens its own downfall without organized opposition, resistance, and a pl an \nto combat illiberalism and support democracy (Douglass, 2023).  \nWith ignorance as our departure point and anti -intellectualism as the modus operandi, \nwe consider the confluence of these developments to make sense of it all; foreseeing its \nimpact on highe r education (HE) and what this may portend for the future of academic \nfreedom, academe, and their role in knowledge creation. Though not intended as political \nscreed, we ignore the ramifications of politics at our peril. Partisan polarization is a \nsignific ant factor with a multiplier effect on antecedents affecting HE. As an open system, \nthe academy is not immune to its external environs. As political divisions deepen within the \nsurrounding landscape (Kelly, 2021; Kleinfeld, 2023); these phenomena can signi ficantly \nimpact policies, funding, and academic discourse in universities. The growing conflation of \npartisanship, populism and polarization (Kelly, 2021; Mudde, 2004, 2018) necessitates \nconsideration of political dynamics, which is woven throughout the di scussion where useful \nor instructive.  \nWorking Definitions  \nDefinitional diversity pervades the literature informing this article, shaped by prevailing \nvalues and standards of the time, place, and socio -political -cultural processes from which it \nemerges (Hof stede, 1993; Pinto, 2019; Stel, 2019). While variety may be appealing when \nexploring options or trying new activities, it complicates analysis here. Definitional variety \ndoes not negate the necessity of defining terms for shared understanding. Establishing  an \nunambiguous meaning is an essential first step in scholarly work, providing a foundation for \nmutual understanding (Dholakia, 2020), leading to clarity and insight. The following \nparagraphs offer working definitions for key concepts, curated from variou s scholarly \nsources.  \nMany Shades of Ignorance   \nThe Merriam -Webster (n.d. -b) online dictionary defines ignorance as \"the state of lacking \nknowledg e, education, or awareness \". Ignorance has been a major research topic for over \n [ DOI: 10.61186/johepal.6.1.9 ]  [ Downloaded from johepal.com on 2025-08-25 ] \n                             4 / 26\nPhDead?  \n  \n \n Journal of Higher Education Policy And Leadership Studies (JHEP ALS) 12 twenty years with abundant lite rature in fields like science, technology, sociology, \nphilosophy, history, and anthropology (Barbier et al., 2021). The study of ignorance shifts \nthe question from \"how do we know what we know\" to \"how or why we don't know\" \n(Proctor & Schiebinger, 2008, p.  vii as cited in Barbier et al., 2021).  \nPinto (2019) submits, \"We seek knowledge because we are ignorant\" (p. 196), from \nwhich we could infer, ignorance is \"the opposite of knowledge, [a state of] not knowing\" \n(Stel, 2019, para. 2). While this makes intuit ive sense, such a definition is too open -ended to \nbe practical.  \nContrary to Pinto's perspective, Peels (2010) argues that \"being ignorant is not \nequivalent to failing to know,\" and contends that \"one's definition of ignorance crucially \ndepends on one's acc ount of belief\" (p. 57). Pritchard (2021) describes this alternate view \nas the \"state of lacking a true belief in the target facts\" (p. 225). Other treatments view \nignorance as epistemic insouciance or \"bullshit\" in Frankfurtian parlance (Cassam, 2018, p. \n1; Frankfurt, 2005), a matter of professional levels (Abbott, 2010), and as a survival strategy \nand tool for oppression, e.g., racialized ignorance in the context of racial bigotry and white \nprivilege (Sullivan & Tuana, 2007).  \nGiven the growing and varied literature associated with ignorance, it is unsurprising \nthat ignorance as a knowledge domain is not within the purview of any one discipline. As \nSmithson (2015) so aptly puts it,  \n[The study of ignorance] splatters across disciplines without any respect for \ndisciplinary boundaries. From astrophysics to zoology, most disciplines have \nperspectives for dealing with the unknown, employing methods from \nmathematics to discourse analysis. These perspectives have, understandably, \ntheir own specialized linguistic -conceptual frameworks and usually are \ndisconnected from one another (p. 385).  \n \nConsequently, the study of ignorance can be interdisciplinary, multidisciplinary, or \ntransdisciplinary (Smithson, 2015). Interdisciplinary research involves collaboration \nbetween disciplines for knowledge transfer. Multidisciplinary research addresses a common \nproblem from multiple perspectives. Transdisciplinary research develops knowledge \nsimultaneously across and beyond all disciplines (Dodig -Crnkovic et al., 2017).  \nHere , we focus on a specific type of ignorance \u2014deliberately fabricated and spread for \nunscrupulous ends. Agnotology, a subfield studying ignorance, examines its origin (Scussel, \n2024). Described as \"the new political sociology of science\" (Barbier et al., 2021 , par. 1), \nagnotology explores how ignorance is manufactured, shaped, and culturally provoked \n(Proctor & Schiebinger, 2008; Scussel, 2024, p.  12). Knowledge is manipulated to create \nignorance (Jalonen, 202 4). The concept has been used to illuminate connect ions between \nignorance and power, explain climate change non -acceptance, reveal how political discourse \ndiscounts science, weaponize critical race theory (CRT), foment election denialism, and \nuncover industry practices designed to mislead and foster uncert ainty (Barbier et al., 2021; \nJalonen, 202 4; Scussel & Norris, 2023). By examining the dynamics underlying purposive \nignorance production, researchers can discover its contextual dimensions and exponents' \nintentions.  \n [ DOI: 10.61186/johepal.6.1.9 ]  [ Downloaded from johepal.com on 2025-08-25 ] \n                             5 / 26\nMyers Bartell, S.  \n \n \n E-ISSN: 2717 -1426  Volume: 6 Issue: 1 DOI:  10.61186 /johepal. 6.1.9 13 Proctor differentiates three types of ma nufactured ignorance: ignorance as a native \nstate, ignorance as a lost realm, and ignorance as a strategic ploy (Scussel & Norris, 2023, \np.51). For this paper, our working definition focuses on \"strategic ignorance\" (Barbier et al., \n2021), defined as delib erate actions created and sustained through social interactions, \nsymbolic processes, organizational structures, or institutional mechanisms to sow doubt, \nmisinformation, disinformation, and other forms of not knowing (Jalonen, 202 4; Proctor & \nSchiebinger, 2008; Scussel, 2024).  \nAnti -Intellectualism, It\u2019s the American Way  \nOver the past 60 years, anti -intellectualism has become a fashionable, \"recurrent \ninterpretive lens to make sense of society and politics\" (Lecklider, 2014, para. 2). Aaron \nLecklider (2014),  a cultural historian and professor of American Studies at the University of \nMassachusetts, describes the depiction of Americans as anti -intellectual as a \"relatively \nrecent phenomenon,\" exploding after the publication of Hofstadter's \"Anti -Intellectualism  \nin American Life\" in 1963. Lecklider found that \"anti -intellectual\" has appeared in the New \nYork Times over 650 times since 1870, with about 75% occurring after Hofstadter's book \nrelease. However, history suggests anti -intellectualism has been part of Ame rica's heritage \nsince the nation's infancy, rooted in 17th -century Puritan ideology (Hofstadter, 1963; Huang \net al., 2021; Kang, 2009). Deeply rooted in the framework of modern culture (D\u00edaz  Villarreal , \n2021, p. 2), American anti -intellectualism has histor ically influenced current public dialogue, \npolicy -making, societal health (Huang et al., 2021; Niose, 2015), and the venerated \ninstitution of higher education. While we cannot trace the full lineage of anti -intellectualism \nin the U.S. here, we begin with a  paradox and brief discussion of historic precedents to \ndemonstrate its long -standing tradition in American society.  \nHistory as Destiny and Paradox   \nAmerica is the only nation on earth founded on an idea (Galen et al., n.d.), a nation conceived \nin liberty.  This lofty idea, borne in the minds of America\u2019s founding fathers, is enshrined in \nthe Declaration of Independence.  \nIntellectualism is an endeavor founded on ideas that embody the \u201ccapacity to ponder \nin detail about things\u201d (\u0160rol & Galasov\u00e1, 2022, para. 1 ). With ideas as its currency and critical \nthinking as its method of engagement, intellectualism involves imagining, reflecting, \ninterpreting, evaluating, and analyzing circumstances to enrich our understanding of the \nworld. Through the ages, ideas \u2014the pro duct of exercising the intellect \u2014have sparked \nrevolutions, reshaped societies, and spawned innovations. When cultivated with purpose, \nideas can be an inspiring force driving positive change.  \nParadoxically, anti -intellectualism is part of America's DNA, not withstanding the \ncountry's origin as a nation spawned from an idea. Generally understood as hostility toward \nintellectual pursuits (Merriam -Webster, n.d. -a), anti -intellectualism refers to mistrust of \nintellectuals and experts (Barker et al., 2022; Lunz Tr ujillo, 2022; Merkley, 2020; Motta, \n2018), who are perceived as elitist and out -of-touch with mainstream society (Huang et al., \n2021; Long, 1996). Following Huang et al. (2021), anti -intellectualism is defined as \"a social \nattitude that systematically unde rmines science -based facts, academic authorities, and the \npursuit of theory and knowledge\" (p. 3). Pervasive in American culture (Hofstadter, 1963), \n [ DOI: 10.61186/johepal.6.1.9 ]  [ Downloaded from johepal.com on 2025-08-25 ] \n                             6 / 26\nPhDead?  \n  \n \n Journal of Higher Education Policy And Leadership Studies (JHEP ALS) 14 anti-intellectualism advances an implosion of truth that provides a structure for alternative \nfacts; to bel ieve things based on personal opinions with little or no supporting evidence \n(Huang et al., 2021, p. 15).  \nAmerican anti -intellectualism is grounded in \u201cthe framework of our religious history\u201d \n(Hofstadter, 1963, p. 47), dating back to the early days of Euro pean colonization in America \n(Long et al., 1996) and the confluence of Evangelical \u2013Puritanical Protestant * beliefs of \nAmerica\u2019s first European colonists (Huang et al., 2021, Kang, 2009).  \nPuritanism reached North America during the Great Puritan Migration o f the 1620s \nand 1630s, when English Puritans sought refuge in the New World to escape religious \npersecution and spread the Christian gospel (Kang, 2009). Puritanism is a strict form of \nProtestantism that aimed to \"purify\" the Anglican Church of Catholic in fluence following the \n16th -century English Reformation (Kang, 2009, p.  148). The term \"Puritans\" was initially a \nderisive label, later describing reformers who opposed Anglican hierarchy and sought a \npurer form of worship based on biblical literalism (Hist ory.com Editors, 202 5; Online \nEtymology Dictionary, n.d.). In America, Puritanism influenced culture beyond religion, \nshaping values like individualism, egalitarianism, and the sanctity of hard -work (Kang, 2009).  \nKang (2009) submits that the Puritans' \"zeal for education\" significantly shaped \npedagogy in the United States. Upon reaching the New World, they prioritized establishing \ncolleges and public schools where the main goal was \"Christian nurture and growth\" (p. 151). \nThe Puritans considered functio nal literacy necessary for people to read and understand the \nBible themselves, rather than blindly accepting church doctrine and depending on clerics \n(AHEF, 2017; Kang, 2009; Shipton, 1958). An educated citizenry was viewed as necessary for \na virtuous life . \nThe Puritans created the first free public schools for children, passed education laws \nmandating basic literacy skills, and founded many early American colleges, including \nHarvard, Yale, and Dartmouth (AHEF, 2017; Kang, 2009). These advances were built o n \nChristian purpose and values. Kang (2009) notes that while Puritans emphasized Bible \nliteracy, they also recognized the importance of a broader, liberal arts education with \nreligious and classical elements to prepare learners for \"all God's truth\" (p.  151) through a \ncurriculum including language studies in English, Greek, and Latin as well as Greek and Latin \nclassics (Lytle, 2018). Puritan education, while religious in intent, reflected Renaissance \nhumanism, emphasizing a \"Christian liberal arts\" educatio n (Chambers College, n.d.) to \ncultivate an educated clergy and promote an educated populace (AHEF, 2017; Kang, 2009; \nLytle, 2018).  \nThe Puritans' devotion to education presents a paradox, as their focus on practical \npiety often conflicted with intellectual exploration, creating a battle between faith and \nreason (Worthen, 201 4). The first \"Great Awakening\" in America, circa 1730s and 1740s, \nmarked a shift from Puritanism's self -restraint and intellectual rigor toward religious \nemotionalism (e.g., ecstatic exp eriences, speaking in tongues, emotional healing) (Berg, \n2019). The secularization of U.S. higher education evolved over time, influenced by historical \n                                                           \n* For the purpose of this paper, I have grouped together Evangelical Protestants and the Puritans that came \nto the New World to escape religious persecution. The Puritans and Evangelicals share some common \ntheological roots but they are distinct movements wi thin Protestant Christianity that approach evangelism \ndifferently (History.com Editors, 2025).  \n [ DOI: 10.61186/johepal.6.1.9 ]  [ Downloaded from johepal.com on 2025-08-25 ] \n                             7 / 26\nMyers Bartell, S.  \n \n \n E-ISSN: 2717 -1426  Volume: 6 Issue: 1 DOI:  10.61186 /johepal. 6.1.9 15 context, scientific developments, and changing views on religion's role in academia \n(Johnson, 1992). By the 20th century, American higher educational institutions had largely \ndivested their religious content and functions to embrace new forms and structures (Goldin \n& Katz, 1999). These developments included the rise of research universities, growth of \npublic  universities, and integration of professional schools (e.g., law, medicine, business, and \npublic administration) into broader university systems (Goldin & Katz, 1999).  \nNonetheless, the legacy of Puritanism has significantly influenced the evolution of the  \nUnited States' higher education system, from their commitment to literacy and learning to \nthe enduring need for knowledge in contemporary American society. The paradox is that \nPuritans also felt intellectual endeavors would result in moral decay. Excessiv e \nintellectualism was a distraction from spiritual obligations and practical responsibilities. \nPuritans believed pleasing God was through diligence, faith, and thrift, creating tension \nbetween worldly success and scholarly undertaking, placing material gai n over the intrinsic \nvalue of knowledge. While Puritans sought prosperity as a reflection of divine favor, they \nalso prized education and intellectual pursuits, mainly when aligned with their religious \nbeliefs.  \nGiven the competing values, early America str uggled to balance society's pragmatic \nneeds with intellectual enlightenment (Long et al., 1996). Practical knowledge (farming, \ncraftsmanship) was considered righteous, while intellectual pursuits (philosophy, literature) \nwere seen as ungodly for not venera ting religious absolutes. Puritans feared intellectual \nendeavors distracted from religious duties, leading to sin, while practical skills were viewed \nas more relevant to daily life and community. On balance, America was built by hard -working \nsettlers who v alued bible study, thrift, self -reliance, tireless effort, and followed the \nProtestant work ethic:  \n Be laborious and diligent in your callings \u2026 ; and if you cheerfully serve [God] in \nthe labor of your hands, with a heavenly and obedient mind, it will be a s \nacceptable to him as if you had spent all that time in more spiritual exercises \n(Richard Baxter, as cited in Ryken, n.d., para. 16).  \n \nAdapting to the new environment demanded a fresh set of skills focused on action \nrather than contemplation \u2014it was about  doing instead of thinking. The pioneers had to \ncultivate land and construct homes in a harsh and untamed territory, where literacy offered \nlittle advantage (Long et al., 1996 ). \nBy contrast, the founding fathers prioritized religious tolerance and envision ed a \"wall \nof separation between church and state\" to ensure religious freedom (Davis, 2003, p. 9). \nTheir revolutionary ideas about scientific progress, religious independence, and democratic \nself-government aligned with Puritan philosophy \u2014emphasizing indi vidual rights, integrity, \nand societal progress (Huang et al., 2021; De Tocqueville, 1998, as cited in Zang, 2009, p.  \n149). The founders' principles, influenced by Europe's Age of Enlightenment, led to modern \ndemocracy, the war for independence, and the cr eation of the United States. Despite \nEurope's ascent from the Dark Ages, American enlightenment fostered a populist mindset \nequating education with elitism (Jouet, 2017). It embraced pragmatism and the \"self -made \nman\" ideal (Huang et al., 2021, p. 5) to sh ape the nation and its people (Burns, 2013). The \nsanctity of common sense and folk wisdom (Jouet, 2017) made education seem unnecessary \nfor success. This became \"good old American know -how,\" favoring street smarts over \n [ DOI: 10.61186/johepal.6.1.9 ]  [ Downloaded from johepal.com on 2025-08-25 ] \n                             8 / 26\nPhDead?  \n  \n \n Journal of Higher Education Policy And Leadership Studies (JHEP ALS) 16 intelligence (Long et al., 1996 , p. 33). Educated intellectuals were seen as effeminate and \nineffectual compared to the rugged self -made man, who succeeded \"because he made \nhimself\" (Huang et al., 2021, p. 5).  \nThus, if history teaches us anything, it demonstrates the long -standing tradition i n \nAmerican society for mistrust and hostility toward intellect, intellectuals, and intellectual \npursuits, consigning intellectualism as \"un -American\" (Long et al., 1996, p. 33). While its \nform may change with time and place, anti -intellectualism is fundame ntally American, as \nseen in its historic roots. Education is needed for social progress and economic prosperity. \nIncongruously, anti -intellectualism is a persistent counterforce that pits populist attitudes \nagainst knowledge, widening the chasm between inf ormed discourse and the propagation \nof dis and misinformation (Huang et al., 2021).  \nThe Normalization of Ignorance and Anti -Intellectualism  \nAnti-intellectualism has been described as a \"virus\" (Peters, 2019), the \"kryptonite of a \ndemocracy\" (Childs, 2020),  and the leading threat to modern society (Berezow, 2016). These \njudgments are recognizable across the geo -political -social stratum, from the rhetoric of \npolitics, popular culture, religion, and business (Asimov, 1980; Hofstadter, 1963; Huang et \nal. 2021, Jacoby, 2009; Motta, 2018; Peters, 2019; Scott, 2014), to their intrusion within \nhigher education (Giroux, 2015; Pap, 2021; Sterling, 2024a). The consequences of this \nassault are far -reaching; undermining the nation's ability to deal effectively with compl ex \nissues (Sterling, 2024a, para. 2) and suffocating academic freedom, stifling intellectual \ndiversity, and suppressing the pursuit of knowledge (Norris, 2020a; West, 2022). As Childs \n(2020) eloquently explains,  \n[An] uneducated, ignorant citizenry can grea tly weaken or completely kill a \ndemocracy. Indeed a lack of respect for education can render a society \nunrecognizable as a democracy and actually usher in a totalitarian government. \nWhen we as a society begin to discredit knowledge and intelligence, and \nundermine the value of education we relegate ourselves to a great loss of \nfreedom. The mistakes made at that point would have great economic \nconsequences, which will ultimately cost lives (para. 2).  \n \nDemocracy and education share a critical bond (Hytten, 201 7). Democracy's essence \nis independence and liberty, with spiritual cornerstones of mind emancipation and \nunhampered freedom to think (Dewey, 1903), essential for dissent (West, 2022). Education \nstrengthens democracy's foundations and facilitates citizen p articipation by imparting \nknowledge and boosting critical thinking (Sterling, 2024b). A robust egalitarian society relies \non intellectual freedom and critical thought to secure the union between democracy and \neducation (Dewey, 1903, p. 204).  \nOn top of hist orical precedent, three inextricable trends have normalized the apparent \nubiquity of anti -intellectualism: the democratization of information (Hofstadter, 1963; \nPeters, 2019; Tewksbury & Rittenberg, 2012; Wallace & Van Fleet, 2005); the politicization \nof e verything (Baker, 2017; Douglass, 2023; Salzmann, 2018; Szalai, 2017); and public \ntolerance for hate speech, name calling, and condemnation of the messenger's character \nrather than the message (Brown, 2021; John et al., 2019; Niose, 2015; Paz et al., 2020) . In \n [ DOI: 10.61186/johepal.6.1.9 ]  [ Downloaded from johepal.com on 2025-08-25 ] \n                             9 / 26\nMyers Bartell, S.  \n \n \n E-ISSN: 2717 -1426  Volume: 6 Issue: 1 DOI:  10.61186 /johepal. 6.1.9 17 this intellectual milieu, ongoing tension between reason and belief systems pose ominous \nconsequences for universities, nonprofits, and think tanks (West, 2022).  \nDemocratization of Information  \nThe democratization of information is a direct result of the internet providing open access \nto information. An average person can easily access information digitally via Google and \nother search tools. From pooling global knowledge to the speed, access, and emergence of \nvarious communication modes, the internet l inks humankind such that \"We are all now \nconnected like neurons in a giant brain\" to paraphrase Stephen Hawking (Goodman, 2023). \nUnfortunately, the internet has also brought disadvantages such as information overload, \nlack of privacy, cybercrime, and infor mation piracy. It is also a means of spreading dis - and \nmisinformation, leading to a false sense of knowing. Conspiracy theories and distorted \nnarratives compete with expert knowledge, offering overly simplistic or flawed alternatives. \nThis promotes anti -intellectualism, breeds mistrust, and erodes confidence in objective \ntruth. Dr. Richard Baron (2019) makes this very point and others in his TED Talk, \u201cPlease \nDon\u2019t Confuse Your Google Search with My Medical Degree,\u201d where he discussed the \nessentiality for trust between doctors and patients when making personalized healthcare \ndecisions.  \nModreanu (2017) opines that we are living in a post -truth era, where \"objective facts \nare less influential in shaping public opinion than appeals to emotion and personal beli ef\" \n(p. 7). Empirical proof and rational discourse compete with postmodern pseudoscience, \nfortunetelling, astrology, paranorma l beliefs (Sokal, 2008, pp. 263 -370, as cited in Sidky, \n2018) and conspiracy theories to shape people's perception of reality and decision -making. \nConspiracy theories are exemplars of anti -intellectualism, rejecting established facts for self -\nreinfo rcing sources. Bowes Costello and  Tasimi (2023) state that conspiracy theories involve \n(a) conspirators, (b) secret plans, and (c) malici ous intent against others or society (p. 2). \nFrom Kennedy's assassination to contemporary intrigues about birtherism, election fraud, \nvaccines, and racial replacement theory, those endorsing conspiracy theories believe they \npossess insider knowledge, fulfi lling important identity needs (Jordan, & Whitmer, 2024). \nConspiracy theories reflect current social conditions, proliferating during crisis events (Basit, \n2021). Built on anti -intellectualism and often powered by political extremism and far -right \nradicali zation, they may lead to violence, as seen at the US Capitol on January 6, 2021. \nSterling (2024a, para. 6) notes, \"In a society where expertise is devalued and ignorance is \nglorified, demagogues and charlatans can easily manipulate public opinion, undermin ing the \nfoundations of a healthy democracy \". \nPoliticization of Everything  \nPoliticians, often unqualified, offer opinions contradicting historical and scientific evidence \non topics from vaccines to climate change (Merkley, 2020; Merkley & Loewen, 2021; Sidk y, \n2018). The pandemic's politicization highlights this issue (Druckman, 2022). Of the 1.1 \nmillion US COVID -19 deaths (Gamio et al., 2023), about one -third could have been \nprevented through vaccination and adherence to public health guidelines (Martinez & \nAubrey, 2022). President Trump and Republican leaders downplayed the virus risk and CDC \nadvisories, negatively influencing public behavior. Following health advice became a matter \nof political affiliation rather than science -based decision -making (Druckman , 2022; Lopez, \n [ DOI: 10.61186/johepal.6.1.9 ]  [ Downloaded from johepal.com on 2025-08-25 ] \n                            10 / 26\nPhDead?  \n  \n \n Journal of Higher Education Policy And Leadership Studies (JHEP ALS) 18 2021). Republican leadership's politicization of the pandemic and spread of misinformation \nled to more infections and deaths, as well as diminished faith in scientific protocols and \nexpert knowledge.  \nThe Backlash against Diversity, Equity, a nd Inclusion  \nTo address concerns about minority underrepresentation, universities have prioritized \ndiversity in recruiting and retaining faculty and students. Critics claim this emphasis on \nunderrepresented groups is reverse racism or just racism (Betts, 2 024), arguing individuals \nmay lose opportunities by not belonging to certain groups. They question the cost of \"DEI \nbureaucracies\" and view DEI as virtue signaling rather than meaningful affirmative action. \nDEI is a politically charged issue, attacked main ly by conservative operatives (Alfonseca, \n2024), emboldened by a Supreme Court ruling ending affirmative action in college \nadmissions (Olson et al., 2024). The backlash against DEI is part of a larger shift away from \npolitical correctness, civility, cultur al sensitivity, and \"wokeness\" (Florida Governor, 2021; \nMoss & O'Connor, 2020; Russell -Brown, 2023; Zavattaro & Bearfield, 2022) in contemporary \nsociety.  \nIf one is \"woke,\" it means they are aware of and concerned about significant societal \nissues related t o racial and social justice. While this seems a reasonable goal for liberal \neducation and promoting equity in a democratic society, an \"anti -woke crusade\" is \nunderway across the US, led by Republican -led states (Hanley, 2023). According to a recent \ntally, \"44 states have introduced bills or taken other steps that would restrict teaching critical \nrace theory or limit how teachers can discuss racism and sexism. Eighteen states have \nimposed these bans and restrictions either through legislation of other avenue s\" (Schwartz, \n2021, as cited in Hanley, 2023 , p. 1 ). One such state is Florida, where Governor Ron DeSantis \nsigned the Stop WOKE Act into law. WOKE in this case is an acronym for \"Stop the Wrongs \nto Our Kids and Employees.\" The law, which took effect on Ju ly 1, 2022, regulates the \ncontent of instruction and training in schools and workplaces (Florida Governor, 2021). It \nprohibits teaching critical race theory, white privilege, and material that could make \nindividuals feel responsible for historic injustices  due to race, gender, or national origin. The \nlaw carries penalties up to $10,000, and non -compliance could result in a university losing \nstate funding (Burt, 2022). President Fuchs of the University of Florida has described the \ncurrent political context a s \"encroaching authoritarianism\" (Burt, 2022), where the larger \nstory is a moral panic at odds with academic freedom despite claims to the contrary by \nconservatives (Hanley, 2023).  \nMetaphorically depicted as \"beleaguered citadels i n a vast ocean of irratio nality \", \ninstitutions of higher education are under siege globally (Sidky, 2018, para. 22); their \nacademic liberty, institutional autonomy, and core values are under attack, requiring them \nto balance academic integrity with external pressures (Hao, 2020).  \nThe Role of Media  \nThe signs of anti -intellectualism in contemporary society are numerous. In Western \ndemocracies, \u201ccognitive rigidity, dogmatism, intolerance, prejudice, and other forms of \nirrationalism\u201d threaten liberalism (Baron & Jost, 2019, p. 292), be nefiting authoritarianism \nand its disdain for heterogeneity and critical inquiry. Fueled by nativism, nationalism, and \nextremist movements, anti -intellectualism is advanced through social media propaganda, \n [ DOI: 10.61186/johepal.6.1.9 ]  [ Downloaded from johepal.com on 2025-08-25 ] \n                            11 / 26\nMyers Bartell, S.  \n \n \n E-ISSN: 2717 -1426  Volume: 6 Issue: 1 DOI:  10.61186 /johepal. 6.1.9 19 erosion of trust in traditional institutions, and false equivalencies by corporate news outlets \n(Childs, 2020; Ordway, 2017; Renze, 2021; Sterling, 2024b; Young, 2017; Zadronzy, 2024) \nclaiming to be \u201cfair and balanced \u201d. Ironically, the virtues of neutrality and objectivity in \njournalism sometimes get distorted, unintentionally by avoiding bias, and purposefully \nthrough lies, omissions, and propaganda, e.g., the $787M settlement between Dominion \nVoting Systems and Fox to avoid a trial that would have exposed network lies about the 2020 \npresidential election (Bauder et al., 2023). According to McKenzie Huitsing (202 4), a \nresearcher for the Media Bias/Fact Check website, an independent, reader -supported \nresource,   \nOverall, we rate Fox News right -biased based on editorial positions that align \nwith the right and questionable due to the promotion of propaganda, conspiracy \ntheories, pseudoscience, the use of poor sources, and numerous false claims \nand failed fact checks. Straigh t news reporting from beat reporters is generally \nfact-based and accurate, which earns them a mixed factual rating.  \n \nDespite the less than stellar rating on the Media Bias/Fact Check website, Fox News \nconsistently beats competitors in viewership across all  ratings categories (Seitz, 2023). \nAppealing to a particular echo chamber, even at the cost of truth, is apparently lucrative. \nViewer preferences and profitability may not align with objective truth but shape corporate \nnews media (Knobloch -Westerwick et al ., 2020; Renze, 2021). The press corps' inability to \ntolerate asymmetry is a job hazard of preserving impartial reporting. High ratings mean \nincreased advertising revenue as advertisers are drawn to networks with large audiences \n(Seitz, 2023). Still, shoul d facts (truth) and alternative facts (lies) receive equal time in the \nnews or academic discourse?  \nFalse Equivalences and Other Populist Strategies  \nAlterman (2013) maintains, \"Journalists create a sense of false equivalence between \npositions that rest on d ata and logic and those that don't\" (para. 3). False equivalence is an \ninsidious form of cognitive bias that leads people to believe two separate things are equally \nbad or equally good (Sarkis, 2019). Fairness does not require giving equal weight to opposi ng \nsides when a topic is a matter of fact that can be substantiated or refuted (Apperson, 2020). \nThat the earth is round, climate change is real, neither ivermectin nor hydroxychloroquine \ncure COVID -19, and the 2020 U.S. election was not stolen are demonst rable facts. As the \nlate Senator Daniel Patrick Moynihan stated, \"Everyone is entitled to his own opinion, but \nnot to his own facts\" (Apperson, 2020, para. 5).  \nAnti-intellectualism is not accidental or passive. Research shows a positive correlation \nbetween  anti-intellectualism and populism, which is rising globally (Merkley, 2020; Motta, \n2018; Norris, 2020b) and more vociferous than befo re (Kyle &  Meyer, 2020). The numbers \nare alarming. Evidence reveals populism at a 30 -year high, with almost \u201cfive times as  many \npopulist leaders and parties in power now than at the end of the Cold War, and three times \nmore since the turn of the century \u201d (Kyle & Meyer, 2020, p. 3). \"Populist Zeitgeist,\" coined \nby Mudde (2004, 2018), fittingly describes the world and era in wh ich universities function.  \nGrievance politics, book -bannings, fake news, and manipulative messaging have been \nemployed as tools to distract attention and delegitimize arguments through obfuscation \n(Huang et al., 2021). This tactic has successfully solidifi ed power and garnered support (Cole, \n [ DOI: 10.61186/johepal.6.1.9 ]  [ Downloaded from johepal.com on 2025-08-25 ] \n                            12 / 26\nPhDead?  \n  \n \n Journal of Higher Education Policy And Leadership Studies (JHEP ALS) 20 2023; Schneider, 2023; Scussel & Norris, 2023) by those seeking to protect their interests \nthrough ideological reasoning (Merkley, 2020). The GOP has embraced anti -intellectualism \nas a conservative form of populism (McM anus, 2022; Shogan, 2007) to appeal to John and \nJane Q Public. Political figures often emphasize anti -intellectualism in their public \nstatements (Scott, 2014). As Scott (2014) observes, \"politicians work hard to distance \nthemselves from intellectualism, or  to attach it to their opponents\" (p. 13). By mocking and \nrejecting intellectual elitism, the disparager establishes a shared enemy, gains support from \nordinary citizens, and enhances political currency.  \nPopulists employ various stratagems to subvert delib erative norms and practices \n(Cheshier, 2019). Logical fallacies are the most common tactics used alongside anti -\nintellectualism (Huang et al., 2021). Table 1 below, compiled mainly from Huang et al . (2021, \npp. 15 -18), highlights several common anti -intelle ctual strategies.  \n \nTable 1 . \nCommon Strategies of Anti -Intellectualism  (Source: Huang et al., 2021, pp. 15 -18) \nStrategy  Explanation  \nWhataboutism  \n Responding to an accusation by making a counteraccusation or raising a different issue \n(Huang et al ., 2021, p.  15). \nWillful \nIgnorance  \n Upholding a firm stance \u2014 often defended by values, intuition, emotions, or anecdotal \nevidence \u2014 and selectively disregarding contrary evidence. Willful ignorance is a \nconscious and calculated choice (Huang et al ., 2021, p. 16).  \nTareyton Effect  \n The Tareyton effect, coined by the author, occurs when willful ignorance becomes an \nexcuse to fight. Named for the famed Tareyton cigarettes ad campaign from 1963 to \n1981 (Vintage News Daily, 2021), it features the tagline \"Us Tareyton smo kers would \nrather fight than switch!\" The ads' protagonists sported a black eye, demonstrating \ndefiance, brand loyalty, and readiness to fight for their beliefs.  \nStrategic \nIgnorance  \n Any deliberate action(s) aimed at sowing doubt, misinformation, disinfor mation, and \nother forms of not knowing (Barbier et al., 2021; Jalonen, 202 4; Proctor & Schiebinger, \n2008; Scussel, 2024).  \nCircular \nArgument  A circular argument occurs when the premise assumes the conclusion rather than \nproviding supporting statements (Hua ng et al ., 2021, p. 16).  \nStrawman \nArguments  \n Rather than providing a whole picture, strawman arguments focus on portions of an \nargument that support their own assertions by reducing, generalizing, or \nmischaracterizing the opposing argument into something easily overturned to avoid \ndealing with the complexities of an opposing viewpoint (Huang et al ., 2021, p. 17).  \nFalse Causality  \n False causality occurs when someone erroneously believes a causative relationship \nexists between two objects or events (Huang et al ., 2021, p. 17).  \nFalse \nEquivalence  False equivalence occurs by making comparisons based on flawed reasoning, when no \nsuch similarity exists (Alterman, 2013; Apperson, 2020; Sarkis, 2019).  \nAssumed \nAuthority  \n This is the fallacy of assumed rational -legal authority where none exists. It occurs when \nsomeone cites the presumed expertise of an individual, irrespective of their actual \nknowledge, to prove a point (Huang et al ., 2021, pp. 17 -18). \nCherry Picking  \n This is the fallacy of incomplete evidence. Ch erry-picking, a ploy used by propagandists, \nentails selecting details from genuine research to skew data to one's own ends (Hardy, \n2023).  \nWeaponization of Language: What\u2019s in a Name?  \nAnti-intellectualism spreads false information, discourages dealing seri ously with complex \nissues, and fosters complacency and intellectual sloth (Sterling, 2024b). Public figures \n [ DOI: 10.61186/johepal.6.1.9 ]  [ Downloaded from johepal.com on 2025-08-25 ] \n                            13 / 26\nMyers Bartell, S.  \n \n \n E-ISSN: 2717 -1426  Volume: 6 Issue: 1 DOI:  10.61186 /johepal. 6.1.9 21 ridicule expertise, push opinion as fact, white wash history, and advocate violence (Giroux, \n2022; Pascale, 2019). Their rhetoric attacks opponents,  intimidates perceived enemies, and \ndiscredits interpretations of reality that don't support their agenda (Pascale, 2019; West, \n2022) since agreement and compliance matter more than objective reality and truth \u2013e.g., \nasserting that 2 + 2 = 5, as in Orwell' s 1984 (Cole, 2023).  \nThe public has frequently shown contempt and skepticism towards intellectuals, \nassociating them with communism, immorality, and other dubious qualities viewed as anti -\nAmerican (Hofstadter, 1963). During the McCarthy era of the 1950s, universities faced \nintense scrutiny over the perceived threat of communism on campuses, a consequence of \nthe Cold War between the Soviet Union and the United States. Faculty members were \naccused of being communists or having communist sympathies, leading to firings, blacklists,  \nand a climate of fear on campuses (Kirstein, 2004; Klein, 1997). This has left an unfavorable \nlegacy for American higher education where professors, researchers, and students were \noften targeted, creating a climate of fear and suspicion within academia, a nd one in which \neducation became the focal point  of anti -intellectual narratives  (Moore, 2017) .  \nMoore (2017) submits that epithets and disparaging names distance intellectuals from \nmainstream society, perpetuating the stereotype that these individuals, wh ile highly \nintelligent, lack social skills and are out -of-touch with accepted norms. Using pejoratives \nsuch as egghead was a deliberate form of ostracization that disassociated intellectual \nthought from that of ordinary Americans. Consequently, intellectua ls were linked in public \ndiscourse to communism, immorality, and other nefarious values considered anti -American \n(Hofstadter, 1963).  \nMerkley (2020) provides evidence of a strong association between anti -intellectualism \nand opposition to scientific position s on climate change, nuclear power, GMOs, and water \nfluoridation. This connection is especially pronounced for respondents with higher political \ninterest. Evidence shows anti -intellectualism is connected to populism, a worldview that \nsees political conflic t as primarily between ordinary citizens and a privileged, societal elite.  \nMerkley and Loewen (2021) examine whether anti -intellectualism influenced the \npublic's response to coronavirus disease 2019 (COVID -19). They show a consistent link \nbetween anti-intellectualism and the response to COVID -19, including risk perceptions, \nadherence to social distancing, mask usage, misperceptions and information acquisition. \nAnti-intellectualism posed a significant challenge in maintaining public compliance with \nexpert -recommended health directives during the pandemic.  \nBarker et al. (2022) highlight the partisan nature of anti -intellectualism, particularly \nepistemic hubris \u2014an inflated certainty about one's knowledge, linked to power, arrogance, \nand overconfidence.  Their findings reveal that epistemic hubris is partisan: intellectuals are \nmostly Democratic, while anti -intellectuals are mostly Republican. The intellectualism of \nBlue America and anti -intellectualism of Red America contribute to the intemperance and \nintransigence in current U.S. civil society.  \nAccording to Long (1996), negative portrayals of academics in popular culture stem \nfrom growing anti -intellectualism in American society. College faculty is often derided as \nthose whose work is primarily theoretic al, too esoteric for practical use. The professoriate is \nalso portrayed as foolish or eccentric. Popular culture and public opinion reflect general \ndissatisfaction.  \n [ DOI: 10.61186/johepal.6.1.9 ]  [ Downloaded from johepal.com on 2025-08-25 ] \n                            14 / 26\nPhDead?  \n  \n \n Journal of Higher Education Policy And Leadership Studies (JHEP ALS) 22 The rhetoric of anti -intellectualism has attained a \"new high water mark\" (Dewitt, \n2020, pa ra. 25) in recent years. Examples of ignorance, particularly attacks on higher \neducation, are ubiquitous and observed globally, echoed by political figures, religious \nleaders, comedians, and relatives who subscribe to conspiracy theories. Professors are \nroutinely condemned by right -wing organizations such as Campus Watch (Means et al., \n2024, p. 3) and groups who have embraced anti -intellectualism as a \"badge of positive \nAmericanism\" (Fedorova, 2012, p. 2).  \nFor instance, President Eisenhower first popularize d the use of anti -intellectual \noratory during his campaign, describing intellectuals as men who \u201ctake more words than \nnecessary to tell more than he knows\u201d (Hofstadter, 1963; Huang et al., 2021, p. 9; Moore, \n2017).  \nWhen George Wallace ran for president in 1972, he blamed \u201cpointy -headed \nintellectuals\u201d for all evils, from growing crime rates and changing sexual mores to busing and \nthe war in Vietnam (Morley, 1986, para. 1).  \n\"Universities are the Enemy\" was the title of a keynote speech given by then -Senator \nJ.D. Vance of Ohio at the 2021 National Conservatism Conference. The title echoed Richard \nNixon's statement to his national security advisor, Harvard professor Henry Kissinger, \n\"Professors are the enemy \u2026 write that on a blackboard 100 times and never forge t it\" (Hett, \n2021, para. 2 -3). Vance, like many conservatives, opposes academia as part of their culture \nwar against \"wokeism\" and believes universities indoctrinate learners in critical race theory, \nradical gender ideology, and DEI (diversity, equity and inclusion) rather than teaching \"an \nhonest, patriotic account of American history\" (Hett, 2021, para. 4).  \nIn Hungary, a bastion in Central Europe for pseudo -Christian styled nationalism and \nauthoritarian rule, Prime Minister Viktor Orb\u00e1n has declared war o n higher education, \nattacking professors and democratic values (Means et al., 2024) under the banner of his \n'illiberal democracy,' a term appropriated from political commentator Fareed Zakaria \n(Laruelle, 2022). Advancing his illiberal agenda, Orb\u00e1n has clo sed the Central European \nUniversity and Center for Social Sciences, dismantled research centers, censored scholarly \npublications, terminated scientists' employment, defunded and banned academic \nprograms, and stripped the Academy of Sciences of its autonomy  (Pap, 2021). Orb\u00e1n has \nadopted a campaign to eliminate the teaching of climate science and other erudite \ndisciplines that conflict with far -right ideology (Means et al., 2024).  \nA less consequential example but no less striking; at a recent fundraiser for Kari Lake\u2019s \nArizona Senate campaign, Roseanne Barr delivered an alarming admonition to college \nstudents via video rant ( TYT, 2024):  \n\u2026So I\u2019m just going to say to you, please drop out of college, because it\u2019s going \nto ruin your lives. Do me a favor, drop out , they don\u2019t teach you nothing good, \nuh, email me or Twitter me or whatever you call me, and I\u2019ll help you with your \nlife, but you gotta get out of college, because it isn\u2019t nothing but devil -\nworshipping, baby blood -drinking, Democrat donors.  \n \nIn just 24 -hours\u2019 time, the video went viral. Mocked by some and praised by others, \nRoseanne\u2019s histrionics on the evils of college proliferated at an exponential rate across the \n [ DOI: 10.61186/johepal.6.1.9 ]  [ Downloaded from johepal.com on 2025-08-25 ] \n                            15 / 26\nMyers Bartell, S.  \n \n \n E-ISSN: 2717 -1426  Volume: 6 Issue: 1 DOI:  10.61186 /johepal. 6.1.9 23 Internet and multiple social media platforms (e.g., Facebook, Instagram, TikTok, X, and \nYouTube), as well as on cable stations and late -night T.V.  \nRamifications for Academic Freedom  \nAnti-intellectualism and its correlates, ignorance and populism, pose significant challenges \nto the survival of academic freedom and core principles of higher educa tion.  Table 2 \nsummarizes the impacts and implications of anti -intellectualism for the future of academe.  \n \nTable 2  \nAnti-Intellectualism\u2019s Challenge to Academic Freedom  \nThreat  Consequences  \nThreat to Free \nInquiry  \n Anti-intellectual postures stifle research and critical inquiry. This mindset makes it \nharder for scholars to explore controversial or unconventional ideas without fear of \nreprisal or censure (Aliba\u0161i\u0107 et al., 2024; Burbules, 2022; Garry, 2023).  \nWeakens \nScholarly \nValues  Anti-intellectualism underm ines higher education's ideals of open dialogue, rigorous \nresearch, and intellectual curiosity. Academic independence suffers when these ideals \nare compromised (Ali ba\u0161i\u0107 et al., 2024; Sultana, 2018 ). \nOutside \nPressures  \n Anti-intellectual forces like author itarianism, state overreach, geopolitical conflict, right -\nwing populism, and religious nationalism globally may pressure universities to conform \nto specific ideologies or suppress dissenting views. This can limit academic freedom by \ndiscouraging scholars f rom expressing unpopular opinions or pursuing unconventional \nresearch topics (Berg et al., 2023; Douglass, 2023; Goodman, 2024; Klein & Norris, 2022; \nLerch et al., 2024; Pap 2021; Schofer et al., 2022; Unal, 2024).  \nMarket \nMechanisms  \n Academic freedom is in jeopardy due to market -oriented forces driving university \ncorporatization. When educational institutions prioritize consumer -oriented objectives \nover intellectual endeavors, education quality may suffer (Aliba\u0161i\u0107 et al., 2024; Benn, \n2015; Moody, 2023; S ultana, 20 18). \n \nTo combat anti -intellectualism and advance critical thinking and open inquiry, \nuniversities need to take several actions. Antidotes to anti -intellectualism that emerge from \nthis paper include promoting intellectual diversity; supporting ac ademic freedom for all \nfaculty, even those expressing unpopular opinions or engaging in controversial research; \nbuilding bridges by engaging with all stakeholders inside and outside academe to facilitate \ninformed citizen participation and public debate; an d calling out misinformation and \ndisinformation via media literacy.  \nConclusion  \nThis paper examined anti -intellectualism in its forms, considering the confluence of historic \nroots and current developments to foresee its impact on higher education and implications \nfor its future. Combating anti -intellectualism's reach is crucial to safeguard academic \nfreedom, shared governance, and higher education's integrity. Whether that future is bleak \nor bright, portending the academy's death or renewal, remains an  empirical question, \nintertwined with democracies' survival globally, both hanging in the balance. If taken for \ngranted, their demise is inevitable. A strong egalitarian society depends on intellectual \nfreedom, critical thought, and civil discourse to secu re the mutuality shared by democracy \nand higher education.  \n \n [ DOI: 10.61186/johepal.6.1.9 ]  [ Downloaded from johepal.com on 2025-08-25 ] \n                            16 / 26\nPhDead?  \n  \n \n Journal of Higher Education Policy And Leadership Studies (JHEP ALS) 24  \nDeclaration of Conflicting Interests  \nThere is no conflinct of interest to be cited here.  \nFunding  \nThere is no funding support to be cited here.  \nHuman Participants  \nThe paper does not involve any human participants; however, necessary ethical guidelines \nfor writing research papers are observed.  \nOriginality Note  \nI confirm that this manuscript represents original work and is entirely written by the author.  \nAll the key ideas used in the creation of this document have been appropriately cited and \nacknowledged according to standard academic practices. No part of this  manuscript has \nbeen plagiarized from any other source, and all research materials integral to this study are \ndisclosed and properly referenced. This manuscript has not been published elsewhere, nor \nis it under consideration by another publication.   \nUse o f Generative AI/ AI -assisted Technologies Statement  \nThe author(s)  claimed  that there  is \u201cNo Use of Generative  AI/ AI-assisted  Technologies\u201d  in \npreparing  this research.  \n \n \nReferences  \nAbbott, A. (2010). Varieties of ignorance. The American Sociologist, 41 (2), 174 -189. \nhttps://doi.org/10.1007/s12108 -010-9094 -x \nAlfonseca, K. (2024, July 23). DEI: What does it mean and what is its purpose? ABC. \nhttps://abc7chicago.com/post/what -is-dei-conservatives -claims -kamala -harris -is/15086265/  \nAliba\u0161i\u0107, H., Atkinson, C. L., & Pelcher, J. (2024). The liminal  state of academic freedom: Navigating \ncorporatization in higher education. Discover Education, 3 , 7. \nhttps://doi.org/10.1007/s44217 -024-00086 -x \nAlterman, E. (2013, October 24). 10 years of false equivalence and still going strong . Center for \nAmerican Progress . https://ww w.americanprogress.org/article/10 -years -of-false -\nequivalence -and-still-going -strong/  \nAmerican Heritage Education Foundation (AHEF) (2017, August 31). Why and how schools began in \nthe United States: The Puritans supported education for Bible literacy . \nhttps://americanheritage.org/schools -begin -united -states/  \nApperson, M. (2020, February 19). Fairness to 'both sides' should not lead to false equivalence . PBS \nStandards . https://www.pbs.org/standards/blogs/standards -articles/avoiding -false -\nequivalence/  \n [ DOI: 10.61186/johepal.6.1.9 ]  [ Downloaded from johepal.com on 2025-08-25 ] \n                            17 / 26\nMyers Bartell, S.  \n \n \n E-ISSN: 2717 -1426  Volume: 6 Issue: 1 DOI:  10.61186 /johepal. 6.1.9 25 Asimov, I. (1980, January 21). A cult of ignorance. Newsweek, 75 (4), 19. https://aphelis.net/wp -\ncontent/uploads/2012/04/ASIMOV_1980_Cult_of_Ignorance.pdf  \nBaker, K. (2017, January 31). The politicization of everything: Is no part of American life safe  from \npolitics in the age of Trump?  Politico Magazine . \nhttps://www.politico.com/magazine/story/2017/01/the -politicization -of-everything -214714/  \nBarbier, L., Boudia, S., Goumri, M., & Moizard -Lanvin, J. (2021). Ignorance. Widening the \nfocus.  Revue d\u2019Anthropologie des Connaissances , 15(15-4). \nhttps://doi.org/10.4000/rac.25543  \nBarker, D. C., Detamble,  R., & Marietta, M. (2022). Intellectualism, anti -intellectualism, and \nepistemic hubris in red and blue America. American Political Science Review, 116 (1), 38 -53. \nhttps://doi.org/10.1017/S0003055421 000988  \nBaron, J., & Jost, J. T. (2019). False equivalence: Are liberals and conservatives in the United States \nequally biased?  Perspectives on Psychological Science , 14(2), 292 -303. \nhttps://doi.org/1 0.1177/1745691618788876  \nBaron, R. (2019, May). Please don't confuse your Google search with my medical degree  [Video]. \nTED Conferences. \nhttps://www.ted.com/talks/richard_baron_please_don_t_confuse_your_google_search_wit\nh_my_medical_degree  \nBartell, S. M. (2007). Relearning the learning organization: A meta theoretical analysis . \n[Unpublished doctoral dissertation]. The Pennsylvania State Univ ersity. \nhttps://etda.libraries.psu.edu/files/final_submissions/5671  \nBasit, A. (2021). Conspiracy theories and violent extremism: Similarities, differences and the \nimplications. Counter Terrorist Trends and Analyses, 13 (3), 1 -9. \nhttps://www.jstor.org/stable/27040260  \nBauder, D., Chase, R., & Mulvihill, G. (2023, April 19). Fox, Dominion reach $787M settlement over \nelection claims . AP News . https://apnews.com/article/fox -news -dominion -lawsuit -trial-\ntrump -2020 -0ac71f75acfacc52ea80b3e747fb0afe  \nBenn, J. (2015). Anti-intellectualism in the age of contested knowledge production: Perpetual \ninaction, when ideas constrain discourse  (Publication No. 1600506). [Master's Thesis, \nUniversity of Colorado]. CU Scholar. \nhttps://scholar.colorado.edu/concern/graduate_thesis_or_dissertations/rn301200z  \nBerezow, A. (2016, June 26).  Anti-intellectualism is biggest threat to modern society . American \nCouncil on Science and Health (ACSH) . https://www.acsh.org/news/2016/06/26/anti -\nintellectualism -is-biggest -threat -to-modern -society  \nBerg, A. E., Jungblut, J., & Jupsk\u00e5s, A. R. (2023). We  don\u2019t need no education? Education policies of \nWestern European populist radical right parties. West European Politics, 46 (7), 1312 -1342. \nhttps://doi.org/10.1080/01402382.2023.2177010  \nBerg, T. C. (2019). Life patents, religion, and justice: A summary of themes. In T.C. Berg, R. Cholij, & \nS. Ravenscroft (Eds.), Patents on life: Religious, moral, and social justice aspects of \nbiotechnology and intellectual property  (pp.291 -306). Cambridge Universi ty Press. \nhttps://doi.org/10.1017/9781108659802.016  \nBetts, A. (2024, April 21). What to know about state laws that limit or ban D.E.I. efforts at colleges . \nThe New York Times . https://www.nytimes.com/2024/04/21/us/dei -education -state -\nlaws.html  \nBocian, K., Cichocka, A., & Wojciszke, B. (2021). Moral tribalism: Moral judgments of actions \nsupporting i ngroup interests depend on collective narcissism.  Journal of Experimental Social \nPsychology , 93, 104098. https://doi.org/10.1016/j.jesp.2020.104098  \n [ DOI: 10.61186/johepal.6.1.9 ]  [ Downloaded from johepal.com on 2025-08-25 ] \n                            18 / 26\nPhDead?  \n  \n \n Journal of Higher Education Policy And Leadership Studies (JHEP ALS) 26 Bowes, S. M., Costello, T. H., & Tasimi, A. (2023 ). The conspiratorial mind: A meta -analytic review of \nmotivational and personological correlates. Psychological Bulletin, 149 (5-6), 259 -293. \nhttps://doi.org/10.1037/bul0000392  \nBrown, S. (2021. August 20). The rise of the elite anti -intellectual . Dissent . \nhttps://www.dissentmagazine.org/online_articles/the -rise-of-the-elite -anti-intellectuals/  \nBurbules, N. C. (2022). Promoting critical thinking in anti -critical thinking times: Lessons from \nCOVID discourse. Philosophical Inquiry in Education, 29 (1), 5 -10. \nhttps://doi.org/10.7202/1088374ar  \nBurns, J. M. (2013 ). Fire and light: How the enlightenment transformed our world . Thomas Dunne \nBooks/St. Martin's Press.  \nBurt, C. (2022, May 06). Woke -up call: UF president sends video to faculty to deal with DeSantis -\nbacked bill . University Business . https://universitybusiness.com/woke -up-call-uf-president -\nsends -video -to-faculty -to-deal-with -desantis -backed -bill/ \nCassam, Q. (2018). Epistemic ins ouciance. Journal of Philosophical Research, 43 , 1-20. \nhttps://doi.org/10.5840/jpr2018828131  \nChakravartty, P., & Nesiah, V. (2024, April 05). Is this the end of academic freedom? The New York \nTimes . https://www.nytimes.com/2024/04/05/opinion/free -speech -academic -freedom.html  \nChambers College (n.d.). Christian liberal arts approach . http://chamberscollege.com/what -is-\nchambers -college/christian -liberal -arts-approach/  \nCheshier, D. M. (2019). Populists argue, but populism is not an argumentation (and why the \ndistincti on matters for argumentation theory). In C. Winkler (Ed.), Networking argument  (pp. \n83-88). Routledge.  \nChilds, D. (2020, May 11). The mis -education of the US populace: The danger of disinformation and \nanti-intellectualism in the age of the COVID -19 pandemi c. Democracy & Me . \nhttps://www.democracyandme.org/the -mis-education -of-the-us-populace -the-danger -of-\ndisinformation -and-anti-intellectualism -in-the-age-of-the-covid -19-pandemic/  \nCole, M. B. (2023). The desperate radicalism of Orwell\u2019s 1984: Power, socialism, and utopia in \ndystopian times. Political Research Quarterly, 76 (1), 267 -278. \nhttps://doi.org/10.1177/10659129221083286  \nDavis, D. H. (2003). Editorial: Thomas Jefferson and the \u201cWall of Separation\u201d metaphor. Journal of \nChurch and State, 45 (1), 5 -14. http://www.jstor.org/stable/23920156  \nDe Tocqueville, A. (1998). Democracy in America . Wordsworth Editions Limited.  \nDewey, J. (1903). Democracy in education. The Elementary School Teacher, 4 (4), 193 -204. \nhttp://www.jstor.org/stable/992653  \nDewitt, D. (2020, January 14). Ignorance is not bliss: The dangerous politics of anti -intellectualism . \nOhio Capital Journal . https://ohiocapitaljournal.com/2020/01/14/ignorance -is-not-bliss -the-\ndangerous -politics -of-anti-intellectualism/  \nDholakia, U. (2020, July 27). What is cancel culture?  Psychology Today . \nhttps://www.psychologytoday.com/us/blog/the -science -behind -behavior/202007/what -is-\ncancel -culture  \nD\u00edaz Villarreal, W. (2021). On a small glossar y of academic anti -intellectualism. CLCWeb: \nComparative Literature and Culture, 23 (2). https://doi.org/10.7771/1481 -4374.3777  \nDodig -Crnkovic, G., Kade, D., Wallmyr, M., Holstein, T., & Alm\u00e9r, A. (2017) . Transdisciplinarity seen \nthrough information, communication, computation, (inter -)action and cognition. In M. \nBurgin, & W. Hofkirchner (Eds.), Information studies and the quest for transdisciplinarity: \nUnity through diversity (pp. 217 -261). World Scienti fic. \nDouglass, J. A. (2023). US Universities face a red tide and a precipice: A neo -nationalism and \nuniversity brief. Center for Studies in Higher Education. \nhttps://escholarship.org/uc/item/6zb9602 z \n [ DOI: 10.61186/johepal.6.1.9 ]  [ Downloaded from johepal.com on 2025-08-25 ] \n                            19 / 26\nMyers Bartell, S.  \n \n \n E-ISSN: 2717 -1426  Volume: 6 Issue: 1 DOI:  10.61186 /johepal. 6.1.9 27 Druckman, J. N. (2022). Threats to science: Politicization, misinformation, and inequalities. The \nAnnals of the American Academy of Political and Social Science, 700 (1), 8 -24. \nhttps://doi.org/10.1 177/00027162221095431  \nFedorova, M. (2012). Eggheads arise: How the discourse of anti -intellectualism shaped modern \nAmerican politics  [Unpublished Master\u2019s thesis]. Washington State University. \nhttps://hdl. handle.net/2376/102625  \nFlorida Governor (2021, December 15). Governor DeSantis announces legislative proposal to stop \nW.O.K.E. activism and critical race theory in schools and corporations . \nhttps://www.flgov.com/eog/news/press/2021/governor -desantis -announces -legislative -\nproposal -stop -woke -activism -and-critical  \nFrankfurt, H. G. (2005). On bullshit . Princeton University P ress.  \nGalen, R., Schmidt, S., Stevens, S., & Wilson, R. (n.d.). An idea called America . The Lincoln Project . \nhttps://lincolnproject.us/an -idea -called -america -2/ \nGamio, L., Lutz, E., & Sun,  A. (2023, May 11). As emergency ends, a look at Covid\u2019s U.S. death toll . \nThe New York Times . https://www.nytimes.com/interactive/2023/05/11/us/covid -deaths -\nus.html  \nGarry, P. M. (2023). Threats to academic freedom in higher education. Society, 60 (2), 176 -180. \nhttps://doi.org/10.1007/s12115 -023-00821 -4 \nGiroux, H. A. (2015). Neoliberalism\u2019s war against higher ed ucation and the role of public \nintellectuals. L\u00edmite: Revista Interdisciplinaria de Filosof\u00eda y Psicolog\u00eda , 10(34), 5 -16. \nhttps://revistaschilenas.uchile.cl/handle/2250/219523  \nGiroux, H. A. (2022). Pedagogy of resistance: Against manufactured ignorance . Bloomsbury \nAcademic.  \nGoldin, C., & Katz, L. F. (1999). The shaping of higher education: The formative years in the United \nStates, 1890 to 1940. Journal of Economic Perspectives, 13(1), 37 -62. \nhttps://doi.org/10.1257/jep.13.1.37  \nGoodman, P. (2023, October 30). Advantages and disadvantages of the internet revolution . \nHubPages . https://discover.hubpages.com/technology/Advantages -and-disadvantages -of-\nthe-internet  \nGoodman, R. T. (2024). Higher education as the frontline of democracy: The case against Florida \nHouse Bill 233, the anti -shielding/intellectual viewpoint diversity/student recording \nlegislative act. Review of Education, Pedagogy, and Cultural Studies, 46 (1), 64 -84. \nhttps://doi.org/10.1080/10714413.2023.2245311  \nHanle y, R. (2023). Defense against the dark arts: Academic freedom meets the antiwoke crusade. \nAAUP Journal of Academic Freedom, 14 . https://www.aaup.org/JAF14/defense -against -dark -\narts \nHao, Z . (2020). Academic freedom under siege: What, why, and what is to be done. In Z. Hao, & P. \nZabielskis (Eds.), Academic freedom under siege: Higher education in East Asia, the U.S. and \nAustralia (pp. 1 -36). Springer. https://doi.org/10.1007/978 -3-030-49119 -2_1 \nHardy, T. (2023). Tropes of deception: Climate denial in the mainstream media is pervasive and \ndangerous \u2013 but how to spot it? RSA Journal, 169 (3), 40 -43. \nhttps://www.jstor.org/stable/48743451  \nHett, B. C. (2021, November 05). When politicians like JD Vance call professors like me the enemy, \nwhat's really going on?  History News Network . https://hnn.us/article/when -politicians -like-\njd-vance -call-professors -lik \nHistory.com Editors (2025, February 27). The Puritans . \nhttps://www.history.com/articles/ puritanism   \nHofstadter, R. (1963).  Anti-intellectualism in American life . Vintage Books.  \n [ DOI: 10.61186/johepal.6.1.9 ]  [ Downloaded from johepal.com on 2025-08-25 ] \n                            20 / 26\nPhDead?  \n  \n \n Journal of Higher Education Policy And Leadership Studies (JHEP ALS) 28 Hofstede, G. (1993). Cultural dimensions in people management: The socialization perspective. In \nV. Pucik , N. M. Tichy, & C. K. Barnett (Eds.), Globalizing management: Creating and leading \nthe competitive organization  (pp. 139 -158). John Wiley.  \nHotez, P. J. (2020). Anti -science extremism in America: Escalating and globalizing.  Microbes and \nInfection , 22(10), 505 -507. https://doi.org/10.1016/j.micinf.2020.09.005  \nHuang, E., Dorsey, J., Mosteller, C., & Chen, E. (2021). Understanding anti -intellectualism in the U.S. \nStudio ATAO. \nhttps://www.studioatao.org/_files/ugd/0107ab_925a8c3a89724cdea0fb96e8778aa309.pdf  \nHuitsing, M. (2024, December 2). Fox News (foxnews.com) \u2013 Bias and credibility . Media Bias Fact \nCheck LLC . https://mediabiasfactcheck.com/fox -news -bias/  \nHytten, K.  (2017). Democracy and education in the United States. Oxford Research Encyclopedia of \nEducation . Oxford University Press. https://doi.org/10.1093/acrefore/9780190264093.013.2  \nJacoby, S. (2009). The age of American unreason . Vintage Books.  \nJalonen, H. (2024). Ignorance in organisations \u2013 A systematic literature review. Management \nReview Quarterly, 74 (2), 909 -950. https://doi.org/10.1007/s11301 -023-00321 -z \nJohn, L. K., Blunden, H., & Liu, H. (2019). Shooting the messenger.  Journal of Experimental \nPsychology: General , 148(4), 644 -666. https://doi.org/10.1037/xge0000586  \nJohnson, H. C. (1992). \u201cDown from the mountain\u201d: Secularization and the higher learning in \nAmerica. The Review of Politics, 54 (4), 551 -588. http://www.jstor.org/stable/1407669  \nJordan, M. M., & Whitmer, J. M. (2024). Why believe conspiracy theories? Contexts, 23 (2), 24 -29. \nhttps://doi.org/10.1177/15365042241252124  \nJouet, M. (2017). Exceptio nal America: What divides Americans from the world and from each \nother . University of California Press.  \nKabasakal Badamchi, D. (2022). Academic freedom: How to conceptualize and justify it? Philosophy \n& Social Criticism, 48 (4), 619 -630. https://doi.org/10.1177/01914537211072888  \nKang, N. (2009). Puritanism and its impact upon American values. Review of European Studies, 1 (2), \n148-151. https://ccsenet.org/journal/index.php/res/article/download/4585/3924  \nKelly, M. (2021, December 09). Political polarization and its echo chambers: Surprising new, cross -\ndisciplinary perspectives from Princeton . Princeton University . \nhttps://www.princeton.edu/news/2021/12/09/political -polarization -and-its-echo -chambers -\nsurprising -new -cross -disciplinary  \nKirstein, P. N. (2004). Academic freedom and the new McCarthyism.  Situation Analysis , 3, 21-35. \nhttp://www.newlifetabernacleofchattanooga.org/attachments/File/Communism__Marxism_\n_and_Socialism/Academic_freedom_and_the_New_McCarthyism.pdf  \nKlein, E., & Norris, P. (Hosts). (2022, November 11). A powerful theory of why the far right is \nthrivi ng across the globe [Audio podcast]. In The Ezra Klein Show . The New York Times. \nhttps://www.nytimes.com/2022/11/01/opinion/ezra -klein -podcast -pippa -norris.html ? \nKlein, M. M. (1997). Academic freedom at the University of Tennessee: The McCarthy era. The \nJournal of East Tennessee History, 69 , 62-83. \nhttps://teachtnhistory.org/file/Academic%20Freedom%20at%20the%20University%20of%20\nTN-%20The%20McCarthy%20Era%20(Klein).pdf  \nKleinfeld, R. (2023, September 05). Polarization, democracy, and political violence in the United \nStates: What  the research says . Carnegie Endowment for International Peace . \nhttps://carnegieendowment.org/r esearch/2023/09/polarization -democracy -and-political -\nviolence -in-the-united -states -what -the-research -says?lang=en  \nKnobloch -Westerwick, S., Mothes, C., & Polavin, N. (2020). Confirmation bias, ingroup bias, and \nnegativity bias in selective exposure to polit ical information.  Communication Research , 47(1), \n104-124. https://doi.org/10.1177/0093650217719596  \n [ DOI: 10.61186/johepal.6.1.9 ]  [ Downloaded from johepal.com on 2025-08-25 ] \n                            21 / 26\nMyers Bartell, S.  \n \n \n E-ISSN: 2717 -1426  Volume: 6 Issue: 1 DOI:  10.61186 /johepal. 6.1.9 29 Kyle, J., & Meyer, B. (2020, February 07). High tide? Populism in power, 1990 -2020. Tony Blair \nInstitute for Global Change . https://www.institute.global/insights/politics -and-\ngovernance/high -tide-populism -power -1990 -2020  \nLaruelle, M. (2022). Illiberalism: A conceptual introduction. East European Politics, 38 (2), 303 -327. \nhttps://doi.org/10.1080/21599165.2022.2037079  \nLecklider, A. S. (2014, November 21). Are Amer icans really anti -intellectual?  Scholars Strategy \nNetwork (SSN) . https://scholars.org/brief/are -americans -really -anti-intellectual  \nLerch, J. C., Frank, D. J., & Schofer, E. ( 2024). The social foundations of academic freedom: \nHeterogeneous institutions in world society, 1960 to 2022. American Sociological Review, \n89(1), 88 -125. https://doi.org/10.1177/00031224231214000  \nLong, C. D., Gardner, B. B., & Long, C. D. (1996). It came from Hollywood: Popular culture casts \nprofessors in a negative light. Academe, 82 (4), 32 -36. http://www.jstor.org/stable/40250960  \nLopez, G. (2021 , July 06). How political polarization broke America\u2019s vaccine campaign.  Vox. \nhttps://www.vox.com/2021/7/6/22554198/political -polarization -vaccine -covid-19-\ncoronavirus  \nLunz Trujillo, K. (2022). Rural identity as a contributing factor to anti -intellectualism in the U.S. \nPolitical Behavior, 44 (3), 1509 -1532. https://doi.org/10.1007/s11109 -022-0977 0-w \nLytle, D. (2018, August 22). \u201cTo Know God Aright\u201d: Puritans and the gift of education II . \nhttps://ramblingeveron.com/2018/08/22/to -know -god-aright -puritans -and-the-gift-of-\neducation -ii/ \nMartinez, A., & Aubrey, A. (2022, May 16). How vaccine misinformation made the COVID -19 death \ntoll worse. NPR. https://www.npr.org/2022/05/16/1099070400/how -vaccine -\nmisinformation -made -the-covid -19-death -toll-worse  \nMcManus, M. (2022, November 19). Why conservative intellectuals are anti -intellectual . Current \nAffairs . https://www.currentaffairs.org/news/2022/11/why -conservative -intellectual s-are-\nanti-intellectual  \nMeans, A. J., Ida, Y., & Myers, M. (2024). Teaching beyond dread. Review of Education, Pedagogy, \nand Cultural Studies, 46 (1), 1 -7. https://doi.org/10.1080/10714413.2024.2 306079  \nMerkley, E. (2020). Anti -intellectualism, populism, and motivated resistance to expert consensus. \nPublic Opinion Quarterly, 84 (1), 24 -48. https://doi.org/10.1093/poq/nfz053  \nMerkley, E., & Loewen, P.  J. (2021). Anti -intellectualism and the mass public\u2019s response to the \nCOVID -19 pandemic.  Nature Human Behavior,  5, 706 -715. https://doi.org/10.1038/s41562 -\n021-01112 -w \nMerriam -Webster. (n.d. -a). An ti-intellectualism. In Merriam -Webster.com dictionary . \nhttps://www.merriam -webster.com/dictionary/anti -intellectualism  \nMerriam -Webster. (n.d. -b). Ignorance. In Merriam -Webster. com dictionary . https://www.merriam -\nwebster.com/dictionary/ignorance  \nModreanu, S. (2017). The post -truth era? Human and Social Studies, 6 (3), 7 -9. \nhttp://dx.doi.org/10.1515/hssr -2017 -0021  \nMoody, J. (2023, November 02). What do universities owe their donors?  Inside Higher Education . \nhttps://www.insidehighered.com/news/governance/executive -\nleadership/2023/11/02/what -do-universities -owe -their -donors  \nMoore, J. D. (2017). Anti-intellectualism and student perceptions of hi gher education  (Publication \nNo. 10263349) [Doctoral dissertation, Mercer University]. ProQuest Dissertations Publishing. \nhttps://www.proques t.com/openview/4f5ce331642c2e44a7300e60fe6bdcb2/1?cbl=18750\n&pq -origsite=gscholar   \nMorley, J. (1986, August 11). The Washington intellectu al. The New Republic . \nhttps://newrepublic.com/article/91589/the -washington -intellectual  \n [ DOI: 10.61186/johepal.6.1.9 ]  [ Downloaded from johepal.com on 2025-08-25 ] \n                            22 / 26\nPhDead?  \n  \n \n Journal of Higher Education Policy And Leadership Studies (JHEP ALS) 30 Moss, J. T., & O\u2019Connor, P. J. (2020). Political correctness and the alt -right: The development of \nextreme political attitudes. PLoS One, 15 (10), 1 -22, e0239259. \nhttps://doi.org/10.1371/journal.p one.0239259  \nMotta, M. (2018). The dynamics and political implications of anti -intellectualism in the United \nStates. American Politics Research, 46 (3), 465 -498. \nhttps://doi.org/10.1177/1532673X1771950 7 \nMudde, C. (2004). The populist zeitgeist.  Government and Opposition , 39(4), 541 -563. \nhttps://doi.org/10.1111/j.1477 -7053.2004.00135.x  \nMudde, C. (2018, October 02). Populism in the twenty -first century: An illiberal democratic \nresponse to undemocratic liberalism . Public Seminar (PS): A Global Intellectual Commons . \nhttps://publicseminar.org/essays/populism -in-the-twenty -first-century/  \nNiose, D. (2015, June 23). Anti-intellectualism is killing America . Psychology Today . \nhttps://www.psychologytoday.com/us/blog/our -humanity -naturally/201506/anti -\nintellectualism -is-killing -america  \nNorris, P. (2020a). Closed minds? Is a \u2018cancel culture\u2019 stifling academic freedom and intellectual \ndebate in political science?  (Harvard Kennedy S chool (HKS) Faculty Research Working Paper \nSeries RWP20 -025) . https://www.hks.harvard.edu/publications/closed -minds -cance l-culture -\nstifling -academic -freedom -and-intellectual -debate  \nNorris, P. (2020b). Measuring populism worldwide. Party Politics, 26 (6), 697 -717. \nhttps://doi.org/10.1177/1354068820927686  \nOlson, A., Hader o, H., & D\u2019Innocenzio, A. (2024, January 14). As diversity, equity and inclusion \ncomes under legal attack, companies quietly alter their programs . AP News . \nhttps://apnews.com/article/dei -diversity -corporations -affirmative -action -\n309864f08e6ec63a45d18ca5f25d7540  \nOnline Etymology Dictionary. (n.d.). Puritan. In Online Etymology Dictionary . \nhttps://www.etymonline.com/word/Puritan  \nOrdway, D -M. (2017, September 01). Fake news and the spread of misinformation: A research \nroundup . The Journalist\u2019s Resource . https://journalistsresource.org/politics -and-\ngovernment/fake -news -conspiracy -theories -journalism -research/  \nPap, A. L. (2021). Academic freedom: A test and a tool for illiberalism, neoliberalism, and liberal \ndemocracy.  The Brown Journal of World Affairs, 27 (2), 105 -126. https://bjwa.brown.edu/27 -\n2/academic -freedom -a-test-and-tool-for-illiber alism -neoliberalism -and-liberal -democracy/  \nPascale, C -M. (2019). The weaponization of language: Discourses of rising right -wing \nauthoritarianism. Current Sociology, 67 (6), 898 -917. \nhttps://doi.org/10 .1177/0011392119869963  \nPaz, M. A., Montero -D\u00edaz, J., & Moreno -Delgado, A. (2020). Hate speech: A systematized review. \nSage Open, 10 (4), 1 -12. https://doi.org/10.1177/2158244020973022  \nPeels, R. (2010) . What is ignorance? Philosophia, 38 (1), 57 -67. https://doi.org/10.1007/s11406 -\n009-9202 -8 \nPeters, M. A. (2019). Anti -intellectualism is a virus. Educational Philosophy and Theory, 51 (4), 357 -\n363. https://doi.org/10.1080/00131857.2018.1462946  \nPinto, M. F. (2019). Scientific ignorance: Probing the limits of scientific research and knowledge \nproduction. Theoria, 34 (2), 195 -211. https://doi.org/10.1387/theoria.19329  \nPritchard, D. (2021). Ignorance and normativity. Philosophical Topics, 49 (2), 225 -244. \nhttps://www.jstor.org/stable/48676549  \nProctor, R. N., & Schiebinger, L. (Eds.). (2008). Agnotology: The making and unmaking of ignorance . \nStanford University Press.  \nRenze, M. (2021, January 15). Escaping your information bubble . \nhttps://matthewrenze.com/articles/escaping -your -information -bubble/  \n [ DOI: 10.61186/johepal.6.1.9 ]  [ Downloaded from johepal.com on 2025-08-25 ] \n                            23 / 26\nMyers Bartell, S.  \n \n \n E-ISSN: 2717 -1426  Volume: 6 Issue: 1 DOI:  10.61186 /johepal. 6.1.9 31 Roy, D. (2024, March 03). How to tackle truth decay. The Atlantic . \nhttps://www.theatlantic.com/ideas/archive/2024/03/truth -decay -experts -hilary -\nputnam/677590/  \nRussell -Brown, K. (2023). \"The Stop WOKE Act\": HB 7, race, and Florida's 21st century anti -literacy \ncampaign. NYU Review of Law and Social Change, 47 (2), 338-386. \nhttps://scholarship.law.ufl.edu/facultypub/1200/  \nRyken, L. (n.d.). The original Puritan work ethic . Christian History Institute . \nhttps://christianhistoryinstitute.org/magazine/article/original -puritan -work -ethic  \nSalzmann, K. J. (2018, June 19). The politicization of everything . National Review . \nhttps://www.nationalreview.com/2018/06/politics -mainstream -culture -politicization -of-\neverything/  \nSarkis, S. (2019, May 19). This is not equal to that: How false equivalence clouds our judgm ent. \nForbes . https://www.forbes.com/sites/stephaniesarkis/2019/05/19/this -is-not-equal -to-\nthat-how -false -equivalence -clouds -our-judgment/  \nSchneider, B. (2023, March 19). Grievance politics, rather than problem solving, now at the heart of \nRepublican Party.  The Hill . https://thehill.com/opinion/campaign/3907317 -grievance -\npolitics -rather -than -problem -solving -now -at-the-heart -of-republican -party/  \nSchofer, E., Lerch, J. C., & Meyer, J. W. (2022). Illiberal reactions to higher education. Minerva, \n60(4), 509 -534. https://doi.org/10.1007/s11024 -022-09472 -x \nSchwartz, S. (2021, June 11). Map: Where critical race theory is under attack. Education Week . \nhttps://www.edweek.org/policy -politics/map -where -critical -race -theory -is-under -\nattack/2021/06  \nScott, J. W. (2017). On free speech and academic freedom. Bulletin of the American Academy of \nArts and Sciences, 70 (4), 14 -19. \nhttps://www.amacad.org/sites/default/files/bulletin/downloads/bulletin_Summer2017.pdf  \nScott, K. M. (2014). Toppling the ivory tower: Coded anti -intellectualism in American political \ndiscourse . [Unpublished master\u2019s thesis]. University of Washington. \nhttps://digital.lib.washington.edu/researchworks/bitstream/handle/1773/25383/Scott_wash\nington_0250O_12849.pdf  \nScussel, E. C. (2024). Man ufacturing ignorance: Agnotology, epistemology, and education policy.  \n[Unpublished doctoral dissertation]. Georgia State University. \nhttps://doi.org/10.57709/36394119  \nScussel, E. C., & Norris, J. E. (2023).  \u201cThat sounds scary, let's ban it:\u201d Analyzing manufactured \nignorance & the attack on critical race theory in K -12 Schools. Thresholds in Education, 46 (1), \n48-60. https://academyforeducationalstudies.org/wp -\ncontent/uploads/2023/03/scusselnorrisfinal.pdf  \nSeitz, L. (2023, June 27). Cable news ratings: How MSNBC, CNN and Fox News stacked up in the \n2nd Quarter ratings . The Wrap . https://www.thewrap.com/msnbc -cnn-fox-news -quarterly -\nratings -viewership/  \nShipton, C. K. (1958). The Puritan influence in education.  Pennsylvania History: A Journal of Mid -\nAtlantic Studies , 25(3), 223 -233. https://www.jstor.org/stable/27769818  \nShogan, C. J. (2007). Anti -intellectualism in the modern presidency: A republican populism. \nPerspectives on Politics, 5 (2), 295 -303. https://doi.org/10.1017/S153759270707079X  \nSidky, H. (2018). The war on science, anti -intellectualism, and \u2018alternative ways of knowing\u2019 in 21st -\ncentury America. Skeptical Inquirer, 42 (2). https://skepticalinquirer.org/2018/03/e -war-on-\nscience -anti-intellectualism -and-alternative -ways -of-knowing -in-21/ \nSmithson, M. (2015). Afterward: Ignor ance studies. In M. Gross, & L. McGoey (Eds.),  Routledge \nInternational Handbook of Ignorance Studies  (pp. 385 -397).  Routledge.  \nSokal, A. (2008). Beyond the hoax: Science, philosophy and culture . Oxford University Press.  \n [ DOI: 10.61186/johepal.6.1.9 ]  [ Downloaded from johepal.com on 2025-08-25 ] \n                            24 / 26\nPhDead?  \n  \n \n Journal of Higher Education Policy And Leadership Studies (JHEP ALS) 32 \u0160rol, J. & Galasov\u00e1, M. (2022). Inte llectualism and analytical thinking: Are they related? Personality \nand Individual Differences, 199 , 111842. https://doi.org/10.1016/j.paid.2022.111842  \nStel, N., (2019). Ignorance. In P. Atkinson, S . Delamont, A. Cernat, J.W. Sakshaug, & R.A. Williams \n(Eds.), SAGE Research Methods Foundations . SAGE Publications Ltd.  \nSterling, R. A. (2024a, March 23). The perilous path of anti -intellectualism in American society . \nMedium . https://rasterling.medium.com/the -perilous -path -of-anti-intellectualism -in-\namerican -society -37b263f58d8e  \nSterling, R. A. (2024b, April 20). The phenomenon of anti -intellectualism: A challenge in the \nmodern age . Medium . https://rasterling.medium.com/the -phenomenon -of-anti-\nintellectualism -a-challenge -in-the-modern -age-bde57a8d34ba  \nSullivan, S., & Tuana, N. (2007). Introduction. In S. Sullivan & N. Tuana (Eds.), Race and \nepistemologies of ignorance  (pp. 1 -10). State University of New York Press.  \nSultana, F. (2018). The false equivalence of academ ic freedom and free speech: Defending \nacademic integrity in the age of white supremacy, colonial nostalgia, and anti -\nintellectualism.  ACME: An International Journal for Critical Geographies , 17(2), 228 -257. \nhttps://doi.org/10.14288/acme.v17i2.1715  \nSzalai, J. (2017, October 17). Why is \u2018politicization\u2019 so partisan? The New York Times Magazine . \nhttps://www.nytimes.com/2017/10/17/magazine/why -is-politicization -so-partisan.html  \nTewksbury, D., & Rittenberg, J. (2012). Information democratization. In  News on the internet: \nInformation and citizenship in the 21st Century  (pp. 144 -159). Oxford Universit y Press. \nhttps://doi.org/10.1093/acprof:osobl/9780195391961.003.0008  \nThe Young Turks (TYT) (2024, April 06). Roseanne Barr has an unhinged message from Mar -A-Lago  \n[Video]. YouTube.  https://www.youtube.com/watch?v=l2L8GJ55CBE   \nUnal, D. (2024). Populists\u2019 struggle for epistemic hegemony and anti -gender attacks on higher \neducation in authoritarian contexts: The case of Turkey.  British Journal of Middle Eastern \nStudies,  1-20. https://doi.org/10.1080/13530194.2024.2331701  \nVintage News Daily (2021, February 24). Us Tareyton smokers would rather fight than switch!  \nhttps://vintagenewsdaily.com/us -tareyton -smokers -would -rather -fight -than -switch/  \nWallace, D. P., & Van Fleet, C. (2005). From the editors: The democratization of inf ormation? \nWikipedia as a reference resource. Reference & User Services Quarterly, 45 (2), 100 -103. \nhttp://www.jstor.org/stable/20864471  \nWest, D. M. (2022, September 08). Why academic freedom challenges ar e dangerous for \ndemocracy . Brookings . https://www.brookings.edu/articles/why -academic -freedom -\nchallenges -are-dangerous -for-democracy/  \nWorthen, M . (2014). Apostles of reason: The crisis of authority in American evangelicalism . Oxford \nUniversity Press.  \nYoung, J. G. (2017). Making America 1920 Again? Nativism and US immigration, past and present. \nJournal on Migration and Human Security, 5 (1), 217 -235. \nhttps://doi.org/10.1177/233150241700500111  \nZadronzy, B. (2024, January 18). Disinformation poses an unprecedented threat in 2024 \u2014 and the \nU.S. is less ready than ever . NBC News . \nhttps://www.nbcnews.com/tech/misinformation/disinformation -unprecedented -threat -\n2024 -election -rcna134290  \nZavattaro, S. M., & Bearfield, D. (2022). Weaponization of wokeness: The theater of management \nand implications for public administration. Public Administration Review, 82 (3), 585 -593. \nhttps://doi.org/10.1 111/puar.13484  \n  \n \n \n [ DOI: 10.61186/johepal.6.1.9 ]  [ Downloaded from johepal.com on 2025-08-25 ] \n                            25 / 26\nMyers Bartell, S.  \n \n \n E-ISSN: 2717 -1426  Volume: 6 Issue: 1 DOI:  10.61186 /johepal. 6.1.9 33  \n \nDr. Sherrie Myers Bartell is an instructor at University of the People, Department of Business Administration. \nWith a background in Public Administration, Bartell has dedicated 30 years to researching and teaching \ngraduate -level course s in both public and business administration. She holds a doctorate in Public \nAdministration with emphases in learning organizations and public management from The Pennsylvania \nState University.  Bartell's current work focuses on the detrimental effects of anti -intellectualism, \nilliberalism, and disinformation on democratic society. Her published works cover topics such as public \nbudgeting, learning organizations, and information system outsourcing . She has also delivered invited \ntestimony to the Insurance Committee of the Pennsylvania State House of Representatives. In addition to \nher academic pursuits, Bartell is Chief of Administration, Policy Analysis, and Research for the Bartell \nChiropractic C enter, which she co -owns with her husband, Dr. Michael J. Bartell. When not working, Bartell \nenjoys dog training and performing freestyle dance and \u201cnose work\u201d with her American Eskimo dog , Zurie . \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n This is an open access article distributed under the terms of the Creative Commons \nAttribution -NonCommercial 4.0 International  (CC BY -NC 4.0) which allows reusers to distribute, remix, adapt, \nand build upon the material in any medium or format for noncommercial purposes only, and only so long as \nattribution is given to the creator . \n [ DOI: 10.61186/johepal.6.1.9 ]  [ Downloaded from johepal.com on 2025-08-25 ] \nPowered by TCPDF (www.tcpdf.org)\n                            26 / 26", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Leadership Studies", "author": ["SM Bartell"], "venue": "NA", "pub_year": "NA", "abstract": "This article explores the gradual erosion of academic freedom in contemporary educational  institutions, attributing this decline to the pervasive influence of ignorance. Through"}, "filled": false, "gsrank": 852, "pub_url": "https://johepal.com/article-1-1109-fa.pdf", "author_id": [""], "url_scholarbib": "/scholar?hl=en&q=info:6BKc7NPX51AJ:scholar.google.com/&output=cite&scirp=851&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D850%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=6BKc7NPX51AJ&ei=obWsaKLFCqzWieoPic2ZoAU&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:6BKc7NPX51AJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://johepal.com/article-1-1109-fa.pdf"}}, {"title": "The Question of Genocide in Gaza: A Legal Analysis of the Events in the Gaza Strip Post-2023", "year": "2025", "pdf_data": " \n \n \n \n \n \n \n \n \n \n \nThe Question of Genocide in Gaza  \nA legal analysis of the events in the Gaza Strip post -2023  \n \n          Maya E. Gr\u00fcnenberg-Kebbell  \n  \n \n \n \n \n \n  \n \n \n \n \n \n  \n \n \n \n \n \nHuman Rights  \nBachelor Thesis  \n12 Credits  \nSpring 2025  \n28.05.2025  \nSupervisor: Mikael Sp\u00e5ng  \n13,953 words  \n \n \n 2018-01-04(Dnr)  1 (av 47) \n \n1 \n  \n \n \n  \n \n       \n \n \nThis thesis is dedicated to the Palestinians, a people whose continuous resilience in the face \nof oppression and injustice is a testament to their indomitable spirit.  \n \n\u0623\u064f\u06be\ufeaa\u064a \u06be\ufeac\u0647 \u0627\ufedf\ufeae\ufeb3\ufe8e\ufedf\ufe94 \u0625\ufedf\ufef0 \u0627\ufedf\ufeb8\ufecc\ufe90 \u0627\ufedf\ufed4\ufee0\ufeb4\ufec4\ufbff\ufee8\ufef2\u060c \u0630\ufedf\ufeda \u0627\ufedf\ufeb8\ufecc\ufe90 \u0627\ufedf\ufeac\u064a \ufe97\ufea0\ufeb4\ufeaa \ufebb\ufee4\ufeee\u062f\u0647 \u0627\ufedf\ufee4\ufeb4\ufe98\ufee4\ufeae \ufed3\ufef2 \u0648\ufe9f\ufbab \u0627\ufedf\ufec8\ufee0\ufee2 \u0648\u0627\ufedf\ufed8\ufbad\ufeae \ufeb7\ufbad\ufe8e\u062f\u0629 \ufecb\ufee0\ufef0 \n\u0631\u0648\ufea3\ufbab \u0627\ufedf\ufe98\ufef2 \ufefb \ufe97\u064f\ufed8\ufbad\u064e\ufeae  \n \n    \n \n      \n \n \n 2018-01-04(Dnr)  2 (av 47) \n \n2 \n  \n \nAbstract:  \n \nThe crime of genocide is  one of the worst  violations of international law and human rights, \nfundamentally challenging the core principles upon which human dignity is built. Despite the \nGenocide Convention\u2019s prevention mandate, the international community has largely \ndefaulted to denial over intervention. This thesis examines the applicability of the Genocide \nConvention and its dual -intent mandate in relation to Israel\u2019s actions in Gaza post- 2023, \nquestioning whether the events constitute genocide under international law. This thesis applies a legal dogmatics framework to conduct a  legal  analysis of South Africa\u2019s allegations \nof genocide in its proceedings against Israel, evidentiary standards to prove genocidal intent and the legal precedent s set by  Prosecutor v. Krsti\u0107 , Prosecutor v. Akayesu,  and Bosnia v. \nSerbi a. The findings indicate that Israel\u2019s actions in Gaza post -2023 exhibit a pattern \nconsistent with genocide rather than self -defence. The analysis of South Africa\u2019s allegations \nalongside relevant legal precedents reinforces this conclusion. While the Court  has yet to \nreach a verdict, concerns remain that by the time a decision is made, the destruction in Gaza \nmay be irreversible. It is therefore vital that states fulfil their legal obligations under the \nGenocide Convention to prevent further devastation and loss of life. The failure to uphold the \nConvention\u2019s prevention mandate emphasises the dangers of inaction and highlights the \nnecessity of global accountability.  \n \nKey Words:  \n Genocide Convention, International Law, South Africa v. Israel, Gaza   \n 2018-01-04(Dnr)  3 (av 47) \n \n3 \n  \nTable of Contents  \nGlossary  ................................................................................................................................................. 4 \n1. Introduction  .................................................................................................................................. 5 \n1.2 Chapter outline  ............................................................................................................................. 6 \n2. Methodology and Materials  ......................................................................................................... 6 \n2.1 Concepts  ....................................................................................................................................... 8 \n2.2 Important things to consider when applying international law.  .............................................. 9 \n2.2.1 Relevant conventions  ............................................................................................................. 9 \n2.2.2 Rati\ufb01cation status  ................................................................................................................ 10 \n2.2.3 Case precedents  ................................................................................................................... 10 \n2.2.4 Application of international conventions  ............................................................................ 12 \n2.2.5 Role of international courts  .................................................................................................  12 \n3. Specific intent  .................................................................................................................................. 13 \n3.1 Prosecutor v Krsti\u0107  ..................................................................................................................... 14 \n3.2 Three aspects of genocidal intent .......................................................................................... 15 \n4. SOUTH AFRICA V. ISRAEL  ........................................................................................................ 17 \n4.1 Overview:  ................................................................................................................................... 17 \n4.2 Facts:  ........................................................................................................................................... 19 \n5.1 Genocidal Acts Committed against the Palestinian People  ........................................................ 21 \n5.1.2  Killing Palestinians in Gaza:  ........................................................................................ 21 \n5.1.3  Causing serious bodily and mental harm : ................................................................... 22 \n5.1.4  Mass expulsion from homes and displacement of Palestinians in Gaza  ..................... 23 \n5.2 Expressions of Genocidal intent against the Palestinian people by Israeli State Officials and \nOthers  ............................................................................................................................................... 24 \n5.2.1 Types of o\ufb03cial  .................................................................................................................... 24 \n5.2.2 O\ufb03cial statements............................................................................................................... 25 \n6. Analysis  ............................................................................................................................................ 27 \n6.1 Specific intent  ............................................................................................................................. 27 \n6.2 Admissible evidence in the case of Gaza  .................................................................................... 31 \n6.2.1 Radio Recordings  ................................................................................................................. 31 \n6.2.2 Video footage  ...................................................................................................................... 32 \n6. Conclusion  ................................................................................................................................... 36 \nBibliography  ........................................................................................................................................ 38 \n 2018-01-04(Dnr)  4 (av 47) \n \n4 \n  \n \nGlossary  \n \nActus reus -  Criminal act.  \nArt \u2013 Article  \nBeyond a reasonable doubt  \u2013 legal burden of proof needed to validate the conviction of an \naccused.  \nDolus specialis  \u2013 the specific mental element to commit the crime of genocide. Also called \nGenocidal intent and specific intent. \nErga omnes \u2013 obligations relating to everyone.  \nErga omnes partes -  obligations owed by state parties to other state parties.  \nInter alia  \u2013 Among other things. \nJus cogens  \u2013 A peremptory norm and fundamental principle of international law. \nLegal norm  \u2013 a binding rule or principle.  \nMens rea  \u2013 Criminal intent. The mental element of a committed crime.  \nPer curiam \u2013 by the court. A decision attributable to a whole court rather than individual \njudges. Precedent \u2013 a judicial decision that is considered to be an authority for courts. Provisional measures  \u2013 interim orders to afford immediate protection for individuals whose \nrights are deemed to be at imminent risk.  \nStare Decisis \u2013 Stand by what has been decided. A legal principle which directs or requires courts to adhere to previous judgements on similar issues. \n \n \n \n \n \n 2018-01-04(Dnr)  5 (av 47) \n \n5 \n  \n\u201cFor me, planting is a form of resistance; they\u2019re taking away life, but I\u2019m bringing it to earth. No \nmatter what happens to me, the flowers I planted will still bloom.\u201d  \n- Mohammad \u2018Medo\u2019 Halimy,  \n2005-  29th of August 2024 (19 years old)  \nKilled by an Israeli Airstrike  \n1. Introduction  \n \nThe crime of genocide is regarded as the most egregious violation of international law, and \nthe Convention on the Prevention and Punishment of the Crime of Genocide 1948 (Genocide \nConvention) was drafted based on the belief that the commission of genocide affects the core \ndignity of human beings and is contrary to the spirit of humanity. The Convention was \nadopted by the United Nations in 1948 and signifies a promise to \u2018never again\u2019 commit or \nallow the commission of atrocities that happened during World War II. However, since its \nadoption, the world has witnessed three legally recognised genocides: the Cambodian \nGenocide 1975 -79, the Rwandan Genocide 1994, the Srebrenica Genocide 1995, and more \nrecently, the potential genocide in the Gaza Strip 2023- present. The topic of whether the \nsituation in Gaza can be described as a genocide, or whether it is simply Israel invoking its \nright to self -defence has created societal and political division, intense scholarly debates, and \nchallenges the legitimacy of the international human rights framework.  \nFollowing the 7th of October attacks in 2023, the State of Israel has used, what the UN \nconsiders as , disproportionate force (UN Human Rights Office, Media Statement, 4th of April \n2025) , and  has imposed military blockades against the civilian population in the Gaza Strip \ncausing the deaths of thousands of Palestinians.  On the 29th of December 2023, the Republic \nof South Africa officially initiated proceedings against  the State of  Israel in the International \nCourt of Justice, accusing Israel of having committed, and continuing to commit, genocide \nagainst the Palestinians in the Gaza Strip. In the filing, South Africa alleges that Israel\u2019s \nactions are genocidal in character , because they are intended to bring about the destruction of \na substantial part of the Palestinians in Gaza.  \n1.1 Research problem and research question : \nThis thesis engages with the question of the applicability of the legal concept of genocide to \nthe events in Gaza post -2023. Applicability is legally a question about groups, the  nature of \nevents, proof of evidence, but primarily about what is called specific intent. The nature of \nspecific intent will therefore be a significant focus in the thesis. It will elaborate on this based \n 2018-01-04(Dnr)  6 (av 47) \n \n6 \n on the Genocide Convention and relevant precedents, primarily Prosecutor v Krsti\u0107, Bosnia \nv. Serbia and Prosecutor v. Akayesu. Based on these considerations, I will then address the \nquestion about the applicability in the studied case. Thus, my research question is:  \n\u201cIn which way can the events in Gaza post 2023 be understood as a genocide based on previous precedents and the Genocide Convention?\u201d.  \nTo engage with the research question, this thesis will focus on the allegations of genocide set forth by South Africa in its  proceedings against Israel, the precedents set by the International \nCriminal Tribunal of Former Yugoslavia (ICTY) , and the International Criminal Tribunal of \nRwanda (ICTR), the Genocide Convention\u2019s dual -intent mandate, and admissible evidence in \ncases of genocide. Through the use of a legal dogmatics framework, international legislation, precedents and case studies, the thesis will conduct a legal analysis to examine the \napplicability of the Genocide Convention 1948 in relation to Israel\u2019s actions in the Gaza Strip \npost 2023. \nAs previously mentioned, the Genocide Convention is the most foundational and important \npiece of international human rights legislation adopted by the United Nations. The \ncommission of and failure to prevent or punish genocide challenge the foundation on which \nthe Human Rights framework is built, making it vital for human rights experts and scholars \nalike to engage with questions surrounding cases of genocide.  \n1.2 Chapter outline  \nAfter this introduction, follows chapter 2, which will discuss the methodology and material employed whilst researching the topic . Chapter 2 also outlines the conceptual framework \nused in the thesis and defines key legal terminology. The third  chapter discusses the element \nof specific intent, case precedents and what is considered admissible evidence to prove \ngenocidal intent. Following this, chapter four  introduces an overview of the allegations in \nSouth Africa\u2019s proceedings against Israel. This is followed by chapter five, which provides an \nin-depth explanation of the allegations against Israel. Chapter six  conducts a legal analysis of \nthe material. And finally, the last chapter presents a conclusion and response to the question of whether the events in Gaza can be defined as genocide.  \n2. Methodology and Materials  \nTo investigate the research question, I relied predominantly on South Africa\u2019s proceedings \nagainst Israel, the Genocide Convention, Bosnia v. Serbia (2007), Prosecutor v. Krsti\u0107 \n(2001), Prosecutor v. Akayesu (1998) and case precedents in addition to jurisprudential \nliterature. Moreover, I also used reports from news outlets such as Al Jazeera, The Times of \n 2018-01-04(Dnr)  7 (av 47) \n \n7 \n Israel, and Middle East Eye to find updated information on the evolving crisis in Gaza, such \nas the death toll. I additionally used information published by non- governmental \norganisations (NGO), such as Law for Palestine, which aims to create a network of  legal \nprofessionals who want to work with the Question of Palestine. Law for Palestine has \npublished a database of 500 statements made by Israeli officials, members of the Israeli \nDefence Force and Israeli public figures. The statements chosen  from Law for Palestine\u2019s \nwebsite were selected based  on established case precedents, thereby following what has been \nlegally codified , and because they bear similarities to those presented by South Africa. \nMoreover, some of the statements used were selected because they were made after South Africa initiated proceedings against Israel  and, therefore , are not included in the publicly \navailable court document.  \nIn the analysis, I relied on videos released by news outlets such as Middle East Eye , which \nhave been verified according to the news outlets themselves; however, the methods  used to \nverify the videos are  unclear. Nevertheless, i t would not be unreasonable to assume that the \nnews outlets employed a multi -faceted approach to verify video content, through combining \nreverse image search, cross -referencing, digital forensics and collecting video metadata \n(Ireton and Posetti, 2018, p.101).  Since many of the videos analysed in this thesis were \nuploaded by news outlets like Middle East Eye to their social media platforms, I cross -\nverified them across multiple sources, including other platforms and news organi sations such \nas Al Jazeera.  However, apart from Middle East Eye , very few news outlets posted the videos \nand instead posted descriptions of the footage. Therefore, when cross -referencing, I compared \nthe videos posted by Middle East Eye  to the descriptions given by other news outlets such as \nthe New York Times. If a video had multiple news outlets covering it, I chose to include it. Additionally, I scrutinised the bias of news outlets by using Media Bias Fact Check, a \nwebsite dedicated to outlining the bias of news outlets, whether that be a right -wing or left -\nwing bias. This website additionally details the reliability of news outlets overall. I used this site to attempt to avoid bias and exclusively relying on left -leaning media, to ensure the \nintegrity of my investigation. Although overall considered to be reliable, Media/Bias fact check has been criticised for the methodology it uses when determining credibility or \nfactualness, which I kept in mind during my research (Odhner, 2024). I chose to analyse \nvideo footage, as it is considered important evidence by the ICJ and direct documentary  \nevidence by the ICTR (Ferreira and Gromova, 2024, p.118; De Meester, 2020). Using the material mentioned in this chapter, I conducted a legal analysis rooted in a legal \ndogmatics framework to critically engage with the research question, as both of these \n 2018-01-04(Dnr)  8 (av 47) \n \n8 \n approaches engage with issues surrounding law. The term legal analysis describes the process \nof systematically examining legal issues, legal doctrines, statutes, and case law by identifying \nlegal issues and applying relevant laws (Romantz and Vinson, 2009, p. 3). A legal dogmatics \nframework consists of the interpretation, justification, structuring and explanation of \nfundamental legal norms and provisions (Peczenik, 1969, p.1). Legal dogmatics comprises \nmost discussions and commentaries about law, and is connected to jurisprudence, history of \nlaw, philosophy of law and sociology of law.  \n2.1 Concepts  \nThis section will attempt to explain the different legal concepts used throughout the thesis. Legal concepts are a foundational and central part of law and legal doctrine. Legal doctrine \ndescribes a framework, sets of rules, procedural steps or tests that are often set by case \nprecedents (Hage et al, 2009, p. xi). For something to be called a doctrine, it must be either \nvery important to the field of law or provide a comprehensive guide on how to solve certain legal issues. Despite their centrality, legal concepts are not very well understood, and there is \na lot of disagreement about when a legal concept is effective or ineffective (Stephanopoulos \nand Ginsburg, 2017, p. 1; Hage et al, 2009, p. xiii). \nThere are also different types of legal concepts. For this thesis, I have chosen to focus on \nofficial and dogmatic legal concepts.  \nOfficial legal concepts are those found in official texts such as statutes or judgements, such as \u201cmens rea\u201d \u201c, intent\u201d \u201c, obligations\u201d  and \u201c provisional measures\u201d. Whereas dogmatic legal \nconcepts are generally found in works of legal dogmatics (Hage et al, 2009, p.3). Legal dogmatics is a legal methodology that is described as an insider perspective as it takes the \nsame point of view as courts, institutions, lawyers, judges and certain applications of law. For \nexample, if a case study were to be conducted using legal dogmatics, there would be a \nrequirement to analyse from the position or perspective of a judge or lawyer in the \napplication of law. Examples of dogmatic legal concepts include  \u201ccausality\u201d  or \u201clegal \nnorm\u201d (Hage et al, 2009, pp 2- 3). In legal dogmatics, causality refers to the cause- and-effect \nrelationship between an action and the resulting harm or damage and establishes legal reliability by demonstrating that an action resulted in harm suffered (Law and Martin, 2003, \np.68) . \nLegal concepts have two functions: the law -stating function and the juridical -operative \nfunction. A law -stating function refers to when legal concepts describe or state material legal \ncontent, such as legal documents or important information that is significant in determining a \n 2018-01-04(Dnr)  9 (av 47) \n \n9 \n legal issue (Hage et al, 2009, p.2). A juridical -operative function describes concepts that \njuridically handle the legal content. The term juridical generally describes the administrative \nprocess of law or relates to jurisprudence, which often involves discussing legal concepts, \nsuch as the nature of intent or the foundation of morality and justice, by employing \nphilosophy (Hage et al, 2009, p. 2). \n \n2.2 Important things to consider when applying international law.  \n \nWhen interpreting and applying international law, several key factors must be considered. These include relevant conventions, their implementation and ratification status, established \ncase precedents, and the influence of international courts in shaping legal frameworks.  \n2.2.1 Relevant conventions  \n Firstly, it is essential to determine  which international Convention or t reaty is applicable, and \nwhether it is jus cogens  in nature. Jus cogens  refers to a category of peremptory norms which \nare norms found in customary law representing international obligation that arises from consistent international practices or shared international beliefs rather than written law \n(Lagerwall, 2015). Additionally, if a Convention is considered to be jus cogens in nature, the \nprovisions and rights within the Convention are considered to be non- derogable rights \n(European Commission Website, Fundamental Rights). These rights refer to a collection of human rights that cannot be suspended or infringed upon by the state, even in times of war or \nnational emergency, such as the right to life and freedom from torture and other cruel, \ninhuman or degrading treatment or punishment (Ibid). The prohibition of genocide is a norm \nof jus cogens under customary international law  and international law , giving rise to non-\nderogable obligations  erga omnes (General Assembly 74\nth session A/74/ p.190). Non-\nderogable obligations , refer to state obligations which cannot be avoided through derogation, \nmust be enforced and are therefore considered absolute. Moreover, Erga omnes  is a term that \nis used when referring to specifically determined legal obligations that are owed to the \ninternational community as a whole (Kammerhofer, 2024).  \nAs South Africa\u2019s proceedings against Israel are based on the Convention on the  Genocide \nConvention, which is a norm of jus cogens , the relevant Convention for this thesis would also \nbe the Genocide Convention. In Art II of the Convention, genocide is defined as the \ncommission of a set of specific acts with the intention to destroy in whole or in part, a \nreligious, ethnic, national, racial or religious group. The acts specified by the Convention \ninclude killing members of a group, creating conditions of lif e intended to bring about a \n 2018-01-04(Dnr)  10 (av 47) \n \n10 \n group\u2019s physical destruction, imposing measures intended to prevent births within the group, \nand forcibly transferring children of the group to another group. These acts must be \ncommitted with dolus specialis  (Specific intent or genocidal intent), which constitutes the \nmens rea  (mental element) of the crime of genocide (Robinson, 2002, p.1).  \nIn other words, the prohibition of genocide is an internationally accepted norm with absolute \nlegal obligations that are owed to everyone and cannot be avoided through derogation . \n2.2.2 Ratification status  \nSecondly, in the application of international law, it is necessary to consider the ratification status of state parties to Conventions, and whether there have been made any reservations, or \ndeclarations. In international law, ratification describes the action of signing an international \ntreaty or Convention and a state's consent to be legally bound by the provisions of the \nConvention or treaty. When a state ratifies a Convention, they are legally obligated to enforce \nthe provisions into their own domestic law and are bound by the legal obligations described \nin the Convention or treaty (Vienna Convention on the Law of Treaties, art.14). During the \nratification process, states are able to make declarations and reservations. The term \ndeclaration is often used by state parties to clarify their position, intention, and interpretation \nof a specific Convention or treaty and does not modify or exclude provisions (Klabbers, 2017, p.38). Contrastingly, reservations are used by state parties to exclude or amend the \nlegal effect of certain provisions in their application relating to the state. Reservations also \nallow states to ratify the treaty or Convention without being bound by provisions it does not \nwant to comply with (International Law Commission, 63\nrd session, 2011). For example, the \nstate of Israel has made reservations regarding art 30 paragraph 1 of the Convention against Torture and Other Cruel, Inhuman or Degrading Treatment or Punishment 1984 (CAT), \nstating that it does not consider itself bound by art 30 paragraph 1 which acknowledges the \njurisdiction of the International Court of Justice (ICJ) in solving disputes about the \ninterpretation of the Convention (CAT art. IX; United Nations Treaty Collection, CAT). \nIn this case, it would have to be considered whether South Africa and Israel have made any \nreservations or declarations to the Genocide Convention, as this could affect its applicability. \nSince neither state has made reservations or declarations, the Convention\u2019s applicability is \nmore straightforward.  \n2.2.3 Case precedents  \nOther laws relevant to the case of Palestine and Israel are the precedents  set by Bosnia v. \nSerbia (2007), Prosecutor v. Krsti\u0107 (2001) and Prosecutor v. Akayesu (1995). A case \nprecedent i s a decision made by a court that is considered to be an authority when deciding \n 2018-01-04(Dnr)  11 (av 47) \n \n11 \n later cases that have similar or identical facts or similar legal issues (Cornell Law School, \n2024).  These precedents are important as they are all cases of genocide that contributed to \nthe understanding of genocide, genocidal intent and who can be prosecuted for the crime of \ngenocide. Moreover, the tribunals that conducted the trials are referenced in South Africa v. \nIsrael, which further indicates their significance. All three of the above cases are cases of \ngenocide and have each set their own precedents, which I will briefly describe.  \nProsecutor v. Jean -Paul Akayesu (1995) is the first case in which an international tribunal \nconvicted an individual of committing genocide under the Genocide Convention. The International Criminal Tribunal for Rwanda (ICTR) found Akayesu guilty of genocide for his \nrole in the genocide against the Tutsi, which marked a significant moment in international \nlaw. This case also expanded the legal definition of genocide to include sexual violence, such \nas rape, as an act of genocide (Magnarella 1996, p.536). \nThe case of Prosecutor v. Krsti\u0107 (2001) set a significant precedent in international law, \nespecially regarding the legal interpretation of genocide and genocidal intent (Clark, 2015, \np.507). The International Tribunal of former Yugoslavia (ICTY) found Krsti\u0107 guilty of aiding \nand abetting genocide for his role in the Srebrenica massacre in 1995 and  ruled that the mass \nexecution of Bosniak men and boys constituted genocide. This ruling reinforced that the \ntargeting and killing of a specific group meets the legal requirement for genocide and \ngenocidal intent. Krsti\u0107\u2019s conviction established a precedent that individuals can be held \naccountable for genocide even if they did not personally carry out the acts. It also confirmed \nthat merely knowing about a plan to commit genocide is enough to demonstrate genocidal \nintent (Prosecutor v Krsti\u0107, para 379; Clark, 2015, p.507).  \nLastly, Bosnia v. Serbia (2007) set a precedent regarding the burden of proof for genocidal \nintent. The International Court of Justice  (ICJ)  held that where there is an absence of a \nconfession, reference to a pattern of conduct can be accepted as proof of genocidal intent, provided that nothing else can be inferred from the pattern of conduct other than the existence \nof such intent  (Bosnia v. Serbia, 2007, p. 196 para 373).   \nThese precedents have influenced the interpretation of the Genocide Convention, clarifying the burden of proof for genocidal intent, defining the legal scope, and determining its \napplicability. Since these case precedents are considered to be an authority on genocide, they \nare significant to the case of Palestine and South Africa\u2019s proceedings, as they will aid the \nICJ in reaching a verdict. When reasoning based on precedents, it is necessary to look at the \nfacts of the case, the final judgement made by the court, the comments made by the court \n 2018-01-04(Dnr)  12 (av 47) \n \n12 \n throughout the trial, and compare them to the facts of the case being analy sed (University of \nOxford, Law reports)  \n2.2.4 Application of international conventions  \nThe application of Conventions and treaties is codified in the Vienna Convention on the Law \nof Treaties (VCLT). The VCLT is technically only binding on its signatories. However, it is \nstill widely accepted as a codification of customary law. In articles 31 -33, the VCLT provides \nrules for the application and interpretation of treaties, however, it does not mention \u201cthe legal effects regarding space, time, persons and subject matter\u201d (Klabbers, 2017, p.58) . This gives \nthe states the ability to conclude treaties on most topics, provided these treaties do not conflict with jus cogens norms (Ibid., p.58). For example, regarding space, the general \nassumption of the VCLT is that treaties apply to the entire territory of a state, including \ncolonial states and their colonies, unless otherwise specified by the treaties (Ibid., p.58). As \nsuch, if Denmark concludes a treaty, the assumption is that the treaty will also apply to \nGreenland unless the contrary is specified . Klabbers (2017) notes that treaties often do clarify \ntheir applicability to colonies. As an example, he references the EU T reaties and the decision \nmade in the 1980s that they would no longer apply to Greenland, despite Greenland being \npart of Denmark  (Ibid., p.59).  \nThe working of treaties over time is complicated. Generally, it is assumed that treaties do not have a retroactive effect unless otherwise specified. However, it gets complicated when  a \nconcluded treaty affect s the operation of another treaty. Klabbers (2017) provides extradition \ntreaties as an example of this, stating that an extradition treaty can conflict with a human \nrights C onvention (Ibid., p. 59). If all state parties to the overlapping treaties are identical, the \nprinciple of lex posterior  will take effect, which means that the newer Convention is \nprioritised (Ibid., p.59).  \n2.2.5 Role of international courts  \nLastly, one must also consider the role of international courts, in this case, the International Court of Justice (ICJ). The ICJ is the United Nations\u2019 most important judicial body. Its role is \nto give advisory opinions on legal matters submitted to it and to settle legal disputes \nsubmitted to it by one or more states. Although the ICJ cannot prosecute individuals for \ncrimes, including genocide, its opinions and decisions still carry significant weight (ICJ \nwebsite, FQA; Klabbers, 2017, p. 178). Additionall y, the task of the ICJ is to preserve \nnational courts, ad hoc tribunals established by the United Nations (UN) and the International Criminal Court. Art IX of the Genocide Convention refers to the jurisdiction of the ICJ in \nsolving matters concerning interpretation, application and fulfilment of the Convention. In \n 2018-01-04(Dnr)  13 (av 47) \n \n13 \n the cases of Bosnia and Rwanda, the United Nations\u2019 Security Council established two ad \nhoc criminal tribunals, the ICTY  and the ICTR. The role of these tribunals was to prosecute \nthe individuals responsible for the perpetration of genocide, war crimes, and other serious humanitarian violations (UN international law documentation courts and tribunals; Shelton \n2009, p.542). The ICJ also imposes provisional measures  on states, which are a type of \nbinding interim order used to protect the rights of a protected group if there is a risk that these rights will be compromised or violated whilst they are waiting for the ICJ\u2019s verdict (Shelton, \n2009, p.549). Since the ICJ has imposed provisional measures on Israel relating to its conduct \nin the Gaza Strip, these provisional measures are also important to consider when applying \ninternational law. In this chapter, I have clarified which materials and methodology have \nbeen used as well as which legal elements have to be assessed when conducting a legal \nanalysis. The following chapter will discuss the importance of intent in the context of the \ncrime of genocide.  \n3. Specific intent  \nThe most crucial element in defining the crime of genocide is genocidal intent. In this \nchapter, I will explain the Genocide Convention\u2019s dual intent mandate, case precedents \nregarding the interpretation of specific intent, and what is considered admissible evidence \nwhen attempting to prove specific intent.  \n Genocidal intent ( specific intent or dolus specialis ) has been described, inter alia , as the \nextended mental element ( mens rea ) of the crime of genocide. Extended because it is widely \naccepted that genocide has two elements of mens rea. Firstly, it is required that the \nperpetrators intentionally committed the actions or conduct (actus reus) of the crime of genocide. Secondly, the perpetrators must have dolus specialis  to destroy in whole or in part \na national, ethnic, racial or religious group (Clark, 2015, p.500; Genocide Convention, 1948, Art. II). The element of dolus specialis  is not dependent on actus reus , i.e., what is crucial is \nthe perpetrator\u2019s intentions to destroy a group, not that they succeeded in doing so (Clark, 2015, p.525).    \nGenocide, as defined in Article II of the Genocide Convention, is comprised of acts and \nelements of intent. The Convention prohibits the killing of groups of people based on their \nnationality, race, ethnicity and religion, as well as intentionally causing serious mental and \nbodily harm, forcibly transferring children of the group to another group, preventing births and creating life conditions intended to destroy the group in part or in whole. Therefore, the \n 2018-01-04(Dnr)  14 (av 47) \n \n14 \n intention just to kill people in large numbers is not inherently sufficient to prove specific \nintent; the killing must be performed with dolus specialis  to destroy the group in part or in \nwhole (Klabbers, 2017, p.244).  \n3.1 Prosecutor v Krsti\u0107  \nThe precedent elaborating on the doctrine of specific intent is the case Prosecutor v. Radislav \nKrsti\u0107 (2001). The proceedings against Krsti\u0107 commenced on 2nd of August 2001, on the \nbasis of his involvement in Srebrenica in 1995. At the time, Krsti\u0107 was first the Chief of Staff \nand thereafter promoted to the Commander of the Drina Corps, part of the Bosnian Serb \nArmy (VRS). Following the seizure of Srebrenica, all the crimes committed were committed \nwithin the Area of Responsibility (AOR) assigned to the Drina Corps (Prosecutor v. Krsti\u0107, p. \n2, Para. 3). The indictment alleged, that Krsti\u0107 played a significant role in an operation that \ninvolved an attack on Srebrenica, part of which involved the calculated shelling of the \nenclave. This attack was intended to terrify the Bosnian Muslims (Bosniaks) into seeking \nrefuge in the town of Poto\u010dari, where there was a United Nations (UN) presence but  a \nscarcity of food, water, sanitation and shelter. This total lack of basic necessities increased \nfear and panic among the Bosniaks, ultimately fuelling their unwillingness to leave the \nenclave (Prosecutor v Krsti\u0107, Para 37, 122 & 617).  \nThe International Criminal Tribunal of former Yugoslavia (ICTY) found that there was \nsufficient evidence that Radislav Krsti\u0107 participated in two plans to (1) ethnically cleanse \nSrebrenica of Bosniaks , and (2) kill all military -aged men in the enclave. The ICTY found \nKrsti\u0107 guilty of committing murder under Art III, Persecutions under Art V, and genocide under Art IV of the Genocide Convention (para 719). Radislav Krsti\u0107 was the first high-\nranking official to have been convicted of  the crime of genocide, and as such, the case set a \nprecedent for individual responsibility and specific intent. \nThe most prevalent challenge for ICTY was clarifying the level of intent required for \ngenocide. The issue related to whether a criminal act, e.g., killing members of a group, had to \naim to destroy the group or whether it was enough that the perpetrator had the full knowledge \nthat this crime would  inevitably cause the destruction of the group, or whether the knowledge \nthat this crime would probably  lead to the destruction of the group was enough (Touranye, \n2003, p.450). According to Touranye, the chambers of  ICTY unanimously agreed that \ngenocide and genocidal intent are both characterised by the aim  to destroy a protected group, \nand that committing acts with the knowledge that they would inevitably or probably lead to the destruction of a group would be considered recklessness rather than genocide. The court \nheld that genocide cannot be committed through recklessness as aim is an essential  element \n 2018-01-04(Dnr)  15 (av 47) \n \n15 \n (Jelisic Appeal Judgement, para 46; Touranye, 2003, p.450). In Krsti\u0107\u2019s trial judgement, the \ncourt held that a perpetrator\u2019s knowledge of the victims\u2019 membership to a certain ethnic, \nreligious, national or racial group would not be sufficient to establish genocidal intent \n(Prosecutor v Krsti\u0107, para 561; Touranye, 2003, p. 450) . \nThe testimonies and judgements made by the ICTY in Prosecutor v. Krsti\u0107 were later used in the case Bosnia v. Serbia (2007) by the prosecution as evidence of Serbia committing \ngenocide in Bosnia.\n \n3.2 Three aspects of genocidal intent \n \nThe ICTY and International Criminal Tribunal\u2019s jurisprudence relating to four important issues of specific intent have been important in uncovering the ambiguities of genocidal \nintent. Namely, \u201cDoes knowledge  suffice for genocidal intent? What is the definition of a \n\u2018group\u2019? And \u2018what is sufficient evidence for genocidal intent?\n\u2019. \n \n3.2.1 Does knowledge suffice?  \nIn Prosecutor v Krsti\u0107, the ICTY noted that Krsti\u0107, inter alia, was in frequent contact with General Ratko Mladic, who was the head of the VRS, including during the time period of the \nSrebrenica genocide. They further noted that Krsti\u0107 became the de facto  commander of the \nDrina Corps, from which point he fully and willingly participated in the plans to kill all Bosniak men (Prosecutor v Krsti\u0107, para 379). The court found, beyond a reasonable doubt, \nthat Krsti\u0107 had knowledge of the criminal plans to kill all the Bosniak men and of the \ngenocide in Srebrenica. The tribunal held that from the point that he learned about the \nsystematic killings, and from the point of his involvement, he shared the intent to commit \ngenocide against the Bosniak male population (Clark, 2015, p.507). Krsti\u0107\u2019s convictions of \naiding and abetting the genocide in Srebrenica demonstrate that the knowledge and position \nof a perpetrator are significant factors in establishing genocidal intent.  \n3.2.2 What is a group ? \n The third aspect of genocidal intent is the aim to destroy a specific protected group.  A point \nof ambiguity for the ICTY was defining the terms \u2018racial, ethnic, religious and national\u2019 and \ndetermining  what kind of groups they referred to in the Bosnian context. In ICTY cases, the \nquestion was whether \u2018group\u2019 referred to all existing Muslims, Bosniaks or Bosniaks that lived within a specific municipality like Prijedor or Srebrenica (Touranye, 2003, p.457). This \nquestion was largely avoided by the ICTY, and it was therefore largely up to the Trial \n 2018-01-04(Dnr)  16 (av 47) \n \n16 \n Chambers to make this distinction (Ibid., p.457). Some judgements from the International \nCriminal Tribunal for Rwanda (ICTR) attempted to define every single group mentioned in \nthe Genocide Convention (racial, ethnic, national and religious). According to the ICTR in \nProsecutor v. Akayesu, a national group is defined as the following: \u201ca collection of people \nwho are perceived to share a legal bond based on common citizenship, coupled with \nreciprocity of rights and duties\u201d  (Prosecutor v. Akayesu, para 512). In the same case the \nICTR defined an ethnic group as a \u201cgroup whose members share a common language or culture\u201d ( para 513), a racial group as a \u201c group based on the hereditary physical traits often \nidentified with a geographical region, irrespective of linguistic, cultural, national or religious factors\u201d (para 514) and religious group as a \u201c group where its members share the same \ndenomination, mode of worship or religion\u201d  (para, 515). \n3.2.3 What is admissible evidence?  \nSpecific intent is the most important and difficult element to prove in cases of genocide. A perpetrator can establish a system that leads to the destruction of a group without  explicitly or \nimplicitly  stating  their intent to destroy the group, and it is unlikely that the y will provide a \nconfession. Additionally, it is unclear what constitutes admissible evidence, as there is no \nexplicit guideline. This section aims to detail which evidence was considered admissible by \nthe ICJ, ICTY and ICTR.   \nThe evidence provided in Prosecutor v. Krsti\u0107 (2001) was considered sufficient to prove that \nthe crimes were committed with genocidal intent. The evidence submitted by the prosecution \nincluded forensic evidence such as soil analysis, mass grave exhumation reports, shell casing, \nand retained ballistics. Identity documents and personal items were found in the exhumed \nmass graves , and indicated that the victims were connected to Srebrenica, e.g., license cards \nwith reference to Srebrenica. In some cases, personal items found on the bodies were enough to identify victims as residents of Srebrenica, such as photographs, artificial limbs, jewellery, \nand Quran verses (Prosecutor v Krsti\u0107, p. 23, Para 74). The result of the forensic \ninvestigations suggested that a majority of the bodies found were not killed in combat but \nkilled in mass executions, and determined that a majority of the bodies exhumed, including \nbodies of severely disabled victims, had been killed by gunshot wounds (Prosecutor v Krsti\u0107, \np. 23, para 75).  \nOther evidence considered admissible by ICTY included witness testimonies, intercepted \ncommunications, the frequency of communications between Krsti\u0107 and individuals involved \nin Srebrenica, and the deliberate destruction of mosques and Bosnian homes. The ICTY held \n 2018-01-04(Dnr)  17 (av 47) \n \n17 \n that physical and biological destruction is often accompanied by attacks on cultural and \nreligious property and symbols of the protected group, which may be considered as legitimate \nevidence of specific intent (Bosnia v. Serbia, Trial judgement, p. 203 para 580). \nIn the case of Rwanda, the evidence submitted by the prosecution during the proceedings in \nthe ICTR (2015) to prove the genocide against the Tutsi , and the intent of the accused, such \nas Akayesu, was  also extensive. The evidence submitted includes witness statements, seizures \nfrom accused persons, diaries and notebooks of the accused persons and other people, and \nrecords/documents from, what is described as, various offices in Rwanda, public reports from \ninternational organisations, Radio Rwanda broadcasts and video clips (Baghel, International \nCriminal Tribunal for Rwanda, N.D, pp 4 -6). This material underwent an exhaustive mapping \nwith the help of experts, who assisted the Office of the Prosecutor (OTP) in the trial, to conceptualise the conflict and translate the actions into pertinent criminal liabilities.  \nIn its judgement in Bosnia v. Serbia (2007), ICJ held that in the absence of direct and conclusive evidence such as a confession of intent, specific intent \u201c has to be convincingly \nshown by reference to particular circumstances, unless a general plan to that end can be convincingly stated to exist; and for a pattern of conduct to be accepted as evidence of its \nexistence, it would have to be such that  it could only point to the existence of such \nintent\u2019.  (Bosnia v. Serbia, 2007, p. 196 para 373). In other words, in the absence of \nconclusive evidence, the circumstances or pattern of conduct must be so overwhelming that \nnothing other than genocidal intent can be inferred; this requirement is similar to the \u201cbeyond \na reasonable doubt\u201d criteria in criminal law (Santen, 2025, p.174). \nThe precedent and evidence from Prosecutor v Krsti\u0107, the ICTY and ICTR were taken into \nconsideration by South Africa in their proceedings against Israel, which I will unfold in the \nfollowing section. \n4. SOUTH AFRICA V. ISRAEL  \n \n4.1 Overview:  \nOn the 29th of December 2023, the Republic of South Africa submitted a request for the \nindication of provisional measures and the application of  the Genocide Convention 1948 in \nthe Gaza Strip to the International Court of Justice (ICJ). In preparation for its application, South Africa paid close attention to the interpretation of the Genocide Convention and the \njurisprudence of the ICTY and the ICTR (South Africa v. Israel, p. 1 para 2). \n 2018-01-04(Dnr)  18 (av 47) \n \n18 \n South Africa\u2019s application to the ICJ alleges that the S tate of Israel is in violation of its legal \nobligation to prevent genocide , in addition to engaging in acts of genocide against the \nPalestinians in Gaza (South Africa v. Israel, p.2 para 4) . \nSouth Africa further alleges that Israel\u2019s actions, including large -scale bombings, attacks on \ncivilian infrastructure, blockades and mass displacements, reflect genocidal intent ( dolus \nspecialis ) and fulfil the criteria for genocide, as described in the Genocide Convention 1948 \n(South Africa v. Israel, p.2 para 2). In its application, South Africa argues that the genocidal \nacts must be considered within the broader context of Israel\u2019s conduct towards the \nPalestinians during its 75 -year-long apartheid, the 56- year-long illegal occupation of the \nPalestinian territory and its siege of the Gaza Strip  (Ibid., p.2 Para 2) . Whilst the Republic of \nSouth Africa acknowledged that these crimes could also amount to other breaches of \ninternational humanitarian law, they assert ed that the acts and omissions by Israel are \ngenocidal in character, because they are committed with a specific intent to destroy  a \nsubstantial part of the  population in G aza, who belong to the  distinct national, racial and \nethnic group known as Palestinians  (Ibid ., p.2 Para 2) . \nIn its application, South Africa asserts that it is mindful of the jus coge ns nature and character \nof the prohibition of genocide. However, it is also acutely aware of the erga omnes  and erga \nomnes partes  character of its legal obligations under international law, as a state party to the \nGenocide Convention ( South Africa v. Israel, p.4 para 5) . \nConcerning the Palestinians in Gaza, the conduct of Israel through its state agents, persons \nand entities that are acting on the state\u2019s instructions, or under its directions, control or \ninfluence, is a violation of its legal obligations under the Genocide Convention. The alleged \nbreached art icles include Arts I, III, IV, V and VI, which are read with the consideration of \nArt II. South Africa claims that these violations include:  \n \n\u201c(a) Failing to prevent genocide in violation of Art. I  \n(b) Committing genocide in violation of Art III (a)  \n(c) Conspiring to commit genocide in violation of Art III (b)  \n(d) Direct and public incitement to commit genocide in violation of Art II  \n(e) Attempting to commit genocide in violation of Art III (d)  \n(f) Complicity in genocide in violation of Art III (e)  \n(g) Failing to punish genocide, conspiracy to commit genocide, direct and public incitement \nto genocide, attempted genocide and complicity in genocide, in violation of Arts I, III, IV, and \nVI. \n 2018-01-04(Dnr)  19 (av 47) \n \n19 \n (h) Failing to enact the necessary legislation to give effect to the provisions of the Genocide \nConvention and to provide effective penalties for persons guilty of genocide and complicity in \ngenocide in violation of Art V  \n(i)    Failing to allow and/or directly or indirectly impeding the investigation by competent international bodies or fact -finding missions of genocidal acts committed against \nPalestinians in Gaza, including those Palestinians removed by Israeli state agents or forces to Israel, as a necessary and corollary obligation pursuant to Arts I, III, IV, V and VI\u201d  (p. \n166 para 110).  \nIsrael has denied South Africa\u2019s allegations of genocide, claiming that it is  acting in self -\ndefence, is  exclusively targeting Hamas militants , and is  acting within the scope of \ninternational law. Israel further responded to the allegations of genocide by calling them \n\u201cmorally repugnant\u201d and \u201cantisemitic\u201d (p. 22, para 14). \n \n4.2 Facts:  \nAt the time of the proceedings, South Africa alleged that in addition to ethnic cleansing, \napartheid, expulsion, annexation, occupation, and the continuous denial of the right of the \nPalestinians to self -determination \u2013 Israel has also, since the 7th of October, failed to uphold \nits legal obligation to prevent and prosecute direct and public incitements to genocide (South Africa v. Israel, p.10 para 4). South Africa alleged that Israel is committing acts of genocide, \nciting actions such as the deliberate killing of Palestinians, causing them severe physical and \npsychological harm, and imposing living conditions designed to lead to their destruction. \nSouth Africa\u2019s case against the state of Israel concludes by requesting that the ICJ indicate \nprovisional measures relating to the Palestinians in Gaza as part of a protected group. As \npreviously mentioned, provisional measures are interim orders imposed by the ICJ to protect \nthe rights of a protected group, if there is a risk of irreparable acts prejudicial to the rights of \nthe protected group, might be taken before a final verdict is reached (ICJ statute, art 41.3).  \nWhile the ICJ has yet to reach a verdict on whether the events in Gaza constitute  genocide, in a per curiam  ruling on the 26\nth of January 2024, the ICJ determined that there is a plausible \ncase for genocide in Gaza, emphasising that Israel must take immediate measures to prevent further harm and ensure compliance with the Genocide Convention, especially the following \nprovisions in art II (Galand and Muller, 2024) : \n\u201c(a) killing members of the group. \n(b) causing serious bodily or mental harm to members of the group. \n(c) deliberately inflicting on the group conditions of life calculated to bring about its  \n 2018-01-04(Dnr)  20 (av 47) \n \n20 \n physical destruction in whole or in part;  \n(d) imposing measures intended to prevent births within the group.\u201d  \nAdditional provisional measures imposed by the ICJ include that Israel must take all \nmeasures to prevent and punish the direct and public incitement of genocide , and ensure that \nthe Israeli Defence Force does not carry out any acts described in Art II of the Convention. Additionally, Israel must take immediate and effective measures to provide humanitarian aid \nto mitigate and address the deterioration of living conditions experienced by the Palestinians \nin the Gaza Strip. Furthermore, the ICJ stated that Israel must take effective measures to \npreserve evidence related to the alleged acts committed in violation of Arts II and III of the \nGenocide Convention. Lastly, Israel must submit a report to the ICJ detailing all measures \ntaken to uphold this order within one month, which has not been fulfilled by Israel.  \nOn the 26\nth of February 2024, Amnesty International published a report stating that Israel was \nviolating ICJ orders to prevent genocide by failing to allow adequate humanitarian aid into \nGaza (Amnesty International, 26th of February 2024). Additionally, on the 14th of November \n2024, the United Nations\u2019 Special Committee found that Israel\u2019s actions in Gaza are consistent with the characteristics of genocide (UN special committee report, 14\nth of \nNovember 2024) . \n5. Genocidal acts and expressions of specific intent  \nIn this chapter, I will analyse the genocidal acts and expressions of specific intent alleged by \nSouth Africa in its proceedings against Israel. \nAs mentioned, specific intent is the hardest and most crucial element to prove in cases \nalleging genocide for a number of reasons, such as the standard of proof and the ambiguities \nof genocidal intent.  \nIn 2023, South Africa submitted 16 pages detailing statements made by Israeli officials, as 45 pages detailing genocidal actions and 3 pages where genocidal intent was recognised by \ninternational organisations as evidence of Israel\u2019s genocidal intent against the Palestinians. In \nthe following, I will systematically examine each of South Africa\u2019s allegations.  \nIt is important to note that South Africa has, as of the 28th of October 2024, submitted further \nevidence, which is detailed in 750 pages and allegedly supported by 4,000 additional pages of \nexhibits and annexes. This evidence, however, is confidential ; therefore, the evidence \ndetailed in this chapter is by no means exhaustive.  \n 2018-01-04(Dnr)  21 (av 47) \n \n21 \n 5.1 Genocidal Acts Committed against the Palestinian People \nThis subsection will provide an overview of the genocidal acts alleged by South Africa, but \nwith updated and additional information found through news outlets, the United Nations and \nNon-Governmental Organisations like Human Rights Watch . \n \n5.1.2 Killing Palestinians in Gaza:  \nAccording to the United Nations Office for Coordination of Humanitarian Affairs (OCHA), \n52,928 Palestinians have been killed since Israel started its military assault on Gaza, 70% of \nwhom are believed to be women and children (OCHA impact snapshot,14th of May 2025;  UN \nOHCHR press release, 18th of May 2025). As of April  2025, 15,613 of the fatalities have \nbeen identified as children, which is a 200% increase in the number of Palestinian children \nkilled in the last 1 8 months (OCHA impact snapshot,15th of April 2025). However, according \nto Al Jazeera, the Palestinian Red Crescent estimates that the real number of civilian deaths in Gaza is over 61,709, 17,422 of whom are children, with 14,222 still missing and presumed to be buried under the rubble (Al Jazeera, Israel -Gaza War live tracker, 17th of April 2025). \nPalestinians in Gaza have been killed in hospitals, UNRWA schools, churches, mosques, their homes, places they sought shelter, as they tried to find food and water for their families \nand as they attempted to evacuate to Israeli -declared\u201d safe zones\u201d such as Rafah (South \nAfrica v. Israel, para 46).  According to South Africa, IDF soldiers have performed summary executions, including executions of multiple members of the same family where boys and \nmen were separated from the rest of their family members and shot in front of them; after \nwhich the women and girls were attacked (South Africa v. Israel para 46; Jamous, 2023, p.1). \nFurthermore, South Africa refers to reports of unarmed people who presented no threat -  \nbeing shot dead on sight, including Israeli hostages and including whilst waving white flags \n(South Africa v. Israel, p. 78, para 46; Rose, 2023). Israel\u2019s full blockade of Gaza and its \ndestruction of civilian infrastructure have rendered any rescue attempts virtually impossible \n(South Africa v. Israel, para 45).  \nIsrael has used Artificial Intelligence systems to generate 100 bombing targets daily and so-\ncalled dumb bombs (unguided bombs) and bombs weighing 900kg on Gaza, which have a \ndamage radius of up to 360 meters. Most of the targets have been Palestinian residential \nblocks or homes, which have resulted in the deaths of entire multigenerational families \n(South Africa v. Israel, p. 28, para 19; South Africa v. Israel, p. 78, para 47). According to \nSouth Africa, the level of mortality among Palestinian family members is so exorbitant that \ndoctors and medics have had to create the acronym \u201cWCNSF\u201d, which means \u201cWounded \n 2018-01-04(Dnr)  22 (av 47) \n \n22 \n Child, No Surviving Family\u201d (South Africa v. Israel, p. 80, para 47). According to UNICEF, \nthe rate of child fatalities is 40%, which is two times higher than any conflict in the last 15 -20 \nyears, leading them to label Israel\u2019s military assault on Gaza as a war on children. As of May 2025, UNICEF released a statement that more than 50,000 children have been killed or \ninjured in Gaza since October 2023 (27\nth of May 2025). \nAdditionally, doctors, journalists, academics, teachers and other professionals have been killed at unprecedented rates (South Africa v. Israel, p. 82, para 49). According to the United \nNations, 1,000 doctors, 209 Journalists, 408 aid staff, more than 280 of whom were UNRWA \nemployees, and at least 260 teachers have been killed (UN Secretary -General, Highlight, 3rd \nof January 2025). The rate at which journalists are being killed in Gaza is significantly higher than that of WWII (South Africa v. Israel, p. 72, para 44).  \nHundreds of Palestinian civilians have sustained life -threatening injuries with no possibility \nof receiving medical care due to Israel\u2019s siege and bombings of hospitals in Gaza.  \nIsrael\u2019s complete blockade of Gaza has prevented necessary humanitarian aid to the Palestinians in Gaza, including water, food, shelter, medical aid and medicine. \nInfectious diseases were rapidly spreading, with vulnerable Palestinians like expectant \nmothers, children, the sick, infirm and elderly being particularly at risk, due to the lack of \naccess to medical care and sanitation.  \nFollowing this, South Africa presented evidence detailing how Israel is causing serious \nbodily and mental harm.  \n5.1.3 Causing serious bodily and mental harm : \nSince 2023, 121,034 Palestinians have been seriously injured in Israel\u2019s military attacks on Gaza, the majority being women and children (Al Jazeera, 18\nth of May 2025; OCHA, 14th of \nMay 2025; South Africa v. Israel, para 51). According to the UN, there are no fully functioning hospitals left in Gaza, leaving severely injured Palestinians without access to life -\nsaving medical treatment, reducing them to die slow and painful deaths (South Africa v. \nIsrael, p. 44, para 51; UN press release, 17th of April 2025). Additionally, there are reports of \nthe IDF using white phosphorus in heavily populated areas of Gaza, which cause \u201c deep and \nsevere burns, penetrating through bone and can reignite after initial treatment\u201d (South Africa v. Israel, p. 44, para 52; Human Rights Watch, 12th of October 2023) , and due to the \nscale of Israel\u2019s military assault on Gaza, there are no remaining safe areas.   \nAccording to South Africa, the impact of repeated exposure to violence and conflicts, and \nhousing demolitions has caused severe emotional and mental harm. In 2007 after Hamas took \n 2018-01-04(Dnr)  23 (av 47) \n \n23 \n over Gaza, Israel imposed a land, air and sea blockade on the Gaza strip, restricting access to \nfood, water electricity, construction material, humanitarian assistance and limiting fishing \nareas for fisherman to 20 nautical miles (37km) (UN report, The Gaza Strip, July 2015). This \nblockade has been consistently enforced since 2007 and has been intensified as of January \n2024, with Israel fully blocking any aid into Gaza as of March 2025. Israel\u2019s 2007 blockade \nof Gaza has caused severe levels of psychological distress among the Palestinians (South \nAfrica v. Israel, p.86 para 53). As of the 19th of May 2025, no food, water or medical aid has \nentered Gaza since the 2nd of March, and it is estimated that 57 children have already died of \nmalnutrition and starvation (UNRWA situation report #171). \n Moreover, the disruption of education and day- to-day life severely impacts the children of \nGaza\u2019s physical and mental health, which the UN Security Council expressed deep concerns about in their Resolution 2712 (South Africa v. Israel, p. 86, para 53). Additionally, South \nAfrica claims that Israel has engaged in the dehumanisation and cruel, inhumane and \ndegrading treatment of Palestinians in Gaza and conducted large -scale arrests of Palestinian \ncivilians, including children and the elderly, who have been blindfolded and taken to unknown locations which has caused severe mental harm and distress (South Africa v. Israel, \np. 44, para 54). The destruction of homes and the military assault on the Gaza Strip have also \nled to the forced displacement of Palestinians in Gaza.\n \n \n5.1.4 Mass expulsion from homes and displacement of Palestinians in Gaza  \nAccording to the United Nations Relief and Works Agency (UNRWA), 90% of Palestinians in Gaza have been forced from their homes since the 7th of October 2023 (UNRWA, \nsituation report #165). There is nowhere in Gaza that is safe enough to seek refuge, and those \nwho have refused to leave their homes or cannot leave have either been killed or are at great \nrisk of being killed (South Africa v. Israel, p. 44, para 55). When Israel began its military \nassault in 2023, Palestinians in northern Gaza had a 24- hour window to evacuate to the \nsouthern part of Gaza along specific designated routes, during certain hours of the day. Despite the evacuation orders, there are many reported instances of Israeli shelling and \nattacks on Palestinian civilians who were evacuating along the designated routes (South \nAfrica v. Israel, p. 90, para 57). During this time, the IDF continued to bomb the southern \nGaza, killing many of the civilians who evacuated, prompting many famili  es to re- evacuate \nto the north so they could, at least, ri sk being bombed in familiar surroundings (Ibid., p.90, \nPara 57) , and It is estimated by OCHA that 90% of homes in the Gaza Strip are either \n 2018-01-04(Dnr)  24 (av 47) \n \n24 \n completely destroyed or damaged (situation update #277). As referenced by South Africa, per \nthe judgement in Croatia v Serbia, the forced displacement of the Palestinians can be \nconsidered genocidal in nature as it is taking place during circumstances that are designed to \nbring about the physical destruction of the Palestinians (Croatia v Serbia, 2015, pp. 71- 72, \npara 163; South Africa v. Israel, p.94, para 60).  \n \n5.2 Expressions of Genocidal intent against the Palestinian people by \nIsraeli State Officials and Others  \n \nAccording to South Africa, evidence of Israel\u2019s state officials\u2019 genocidal intent has been \nsignificant, overt, and consistent since 2023 (South Africa v. Israel, p. 140, para 101). \nFurthermore, according to South Africa, these expressions of intent, coupled with the scale of \nkillings, displacement, destruction and maiming and combined with the siege of Gaza, \nevidence an ongoing genocide (Ibid., p.140, Para 101). According to the European Centre for \nConstitutional and Human Rights (ECCHR), official statements or documents made by the \nstate constitute direct evidence of specific intent and are considered the most conclusive form \nof evidence in relation to Art II of the Genocide Convention (2024, p.3).  \n5.2.1 Types of official  \nThere are different types of official statements. There are statements made by an individual who holds an office within government and acts in state capacity, such as Ministers, and there \nare those made by others who make official statements but are located much lower in the \nhierarchy of state employees, such as army reservists. There are also different levels of \nofficials within the government. In Israel, the Prime Minister is appointed through a majority \nvote in the Knesset and is the most powerful political figure and the head of government in \nIsrael (Prime Minister\u2019s Office, 5\nth of November 2023, gov.il). The Knesset is Israel\u2019s \nparliament, the supreme authority of the state and has all of the legislative power and the power to enact or repeal laws. The Knesset has de jure parliamentary supremacy, meaning that it can pass laws through majority votes and has the ability to remove the president or \nPrime Minister from their position and revoke the immunity of its members (Israel\u2019s Ministry \nof Foreign Affairs, political structures and elections, 8\nth of February 2022). The cabinet of \nMinisters is the executive authority of the state of Israel and is made up of the Prime Minister and other Ministers who serve as heads of their respective offices (Ibid).   \nIt is generally accepted that Ministers and other government officials are immune to prosecution whilst in office (Klabbers, 2017, p.113). This was confirmed by the 2002 arrest \n 2018-01-04(Dnr)  25 (av 47) \n \n25 \n warrant case, where state leaders and foreign Ministers were determined to be immune from \nprosecution whilst in office; an immunity which extended to the acts they performed whilst in \noffice (Ibid., p.113). However, during trials in the ICTY and ICTR, the ad hoc tribunals lifted \nthe immunity from state officials and political leaders to prosecute them for their role in the \ncommission of genocide (Ibid., p.113). Additionally, according to Art. III Genocide \nConvention, no one is immune from the charge of genocide, whether they are constitutional \nrulers, public officials or individuals.  \nLastly, the Israeli military is also tied to the government. All IDF branches answer to the General of Staff, which is a forum of senior commanders. Heading the General staff is the \nLieutenant General, who is in charge of all subordinates in addition to reporting directly to \nthe Minister of Defence and indirectly to the Prime Minister (Britannica, 2025, Israeli \nDefence Force). \n \n5.2.2 Official statements  \nThe NGO Law for Palestine (LFP) released a database of over 500 statements made by Israeli \nofficials from 2023 to 2024. According to the NGO and the South African prosecutor, some \nof the statements were made by current officials, including the following:  \nCurrent Government officials  \n \n\u201cWe are facing monsters, monsters who murdered children in front of their parents . . . This is a battle not only of Israel against these barbarians, it\u2019s a battle of civilisation against barbarism\u201d -  Benjamin Netanyahu, Prime Minister (South Africa v. Israel, para 101) . \n \u201cHate the enemy. Hate the monsters. Any vestige of internal bickering is a \nmaddeningly stupid waste of energy. Invest this energy in one thing: Erasing all of Gaza from  \nthe face of the earth. That the Gazan monsters will fly to the southern fence and try to enter  \nEgyptian territory. Or they will die, and their death will be evil. Gaza should be erased.\u201d  \n- Galit Distel Atbaryan, Member of the Knesset (LFP, p.5, nr 39) . \n \n\u201cWe must not show mercy to cruel people, there is no place for any humanitarian gestures \u2013 \nWe must erase the memory of Amalek (biblical tribe hostile to the Israelites) \".  \n- Boaz Bismuth, Member of the Knesset (LFP, p.4, nr.19) . \n \n 2018-01-04(Dnr)  26 (av 47) \n \n26 \n Former officials  \n \n\u201cI have ordered a complete siege on the Gaza Strip. There will be no electricity, no food, no \nfuel, everything is closed. We are fighting human animals, and we are acting accordingly\u201d.     \n- Yoav Gallant, former Minister of Defence (South Africa v. Israel, para 101, s.3) . \n \n\u201dDo not leave stone upon stone in Gaza. Gaza needs to turn into Dresden, yes. Complete \nincineration. No more hope\u2026 Annihilate Gaza Now!\u201d \u2013 Moshe Feigl in, Former Minister \n(LFP, s20, p23) . \n \nThe state of Israel has stated on multiple occasions that it is acting in self -defence and that its \ngoal is to destroy Hamas, whilst minimising damage to civilians. However, the above statements made by Israeli officials could indicate an intent to destroy the Palestinians in \nGaza. Furthermore, they are dehumanising in nature and do not seem to make a distinction \nbetween Hamas and civilians. Statements such as \u201cwe must not show mercy to cruel people\u201d, \n\u201cwe are facing monsters\u201d, and \u201cerase all Gaza from the earth\u201d indicate an intention to destroy \nall of Gaza and not just Hamas, as they claim. This is further illustrated by a statement made \nby Avigdor Lieberman, a member of the Israeli Knesset who stated, \u201c there are no innocent \npeople in Gaza\u201d  (South Africa v. Israel, para 105; LFP, p.6, nr.70) and IDF soldier Yehuda \nLopez, who in 2024 stated \u201c\"There are no innocents there. We have to get that into our \nheads. No innocents, yes. Future solution? that no one remains.\" (LFP, p.27, nr.51).  This \nsentiment has been repeated by Israeli officials, researchers, and entertainers.  \n \nAccording to South Africa, these statements also exemplify public incitement to commit \ngenocide, which has been left unpunished (South Africa v. Israel, p.152, para 103). These \nstatement, coupled with the acts of the IDF in Gaza, including the number of citizens killed, \ninjured or maimed and the scope of the displacements, makes it challenging to infer anything \nother than genocidal intent. \nMany of the statements presented by South Africa and LFP were posted on social media by \nthe Israeli officials or posted in the local Israeli news outlets, like The Israel Times (LFP, \npp.1- 27). As previously mentioned, statements made by officials are considered to be the \nmost conclusive form of evidence for genocidal intent. In the ICTR, notebooks and diaries \nconstituted admissible evidence for proving specific intent; in recent years, forums such as \nTwitter have become a platform for people to broadcast information, thoughts, and feelings \n 2018-01-04(Dnr)  27 (av 47) \n \n27 \n that they likely would not have shared without such platforms (Zhao and Rosson, 2009, p.1). \nIt could be argued that this kind of \u2018micro- blogging\u2019 is contemporary society\u2019s equivalent of \ndiaries.  \nIf diaries and notebooks were considered admissible evidence by ICTR, it could be argued \nthat social media posts, posted by Israeli officials, could potentially qualify as admissible \nevidence of genocidal intent. Some might argue that platforms like Twitter and Facebook \nlack conclusive reliability, as profile owners may not personally write or manage their \naccounts. However, cyber forensics and profile verification make it possible to trace public \nposts with relative accuracy. I will further analyse official statements by Israeli government \nofficials and related genocidal acts in the following  chapter.  \n6. Analysis  \nIn this chapter, I will be analysing the facts and definitions presented by the ICTY and ICTR. Thereafter, I will analyse these facts and definitions in relation to the allegations submitted by South Africa in its proceedings against Israel. As there is currently no verdict in the case, I \nwill be mobilising arguments based on the material that is accessible at this moment.  \n \n6.1 Specific intent  \nAs previously mentioned, statements made by state officials and confessions are the most conclusive form of evidence of dolus specialis. First, I will exemplify statements used as \nevidence in Prosecutor v. Krsti\u0107 and Bosnia v. Serbia, then I will analyse statements by \nIsraeli officials, building on Krsti\u0107 and Bosnia v. Serbia as precedents.  \nIn Prosecutor v Krsti\u0107, the defence argued that that \u201cinflammatory public statements made by one group against another \u2013 short of calling for killings -  are common practice in any war \nand cannot be taken as evidence of genocidal intent\u201d  in this case, the key words are \u201cshort of \ncalling for killings\u201d  (Prosecutor v Krsti\u0107, p.210, para 593). Examples mentioned included, \namong others, the following:  \n\u201cThe Drina Corps has been conducting this operation successfully. We have not suspended \nthis operation. We are going all the way to liberate the municipality of Srebrenica. We \nguarantee safety to civilians. They will be taken safely to a destination of their choice.\u201d  \n(Prosecutor v Krsti\u0107, p. 130, para 346) . \nThis kind of statement was considered conclusive enough to constitute admissible evidence to \nprove that Krsti\u0107 aimed and intended to destroy a protected group in part or in whole. \nParticularly relevant was his knowledge of the Drina Corps\u2019 plans in Srebrenica and the fact \n 2018-01-04(Dnr)  28 (av 47) \n \n28 \n that he, having this knowledge, did not take steps to prevent the carrying out of it entailed \nthat he had dolus specialis .  \nAs noted, Bosnia v. Serbia is also of importance in this context. Relevant here is the following statement by the president of Serbia, Slobodan Milo\u0161evi\u0107:  \n\u201cWe certainly know that we must give up something \u2014  that is beyond doubt in so far as we \nwant to achieve our first strategic goal: to drive our enemies by the force of war from their homes, that is the Croats and Muslims, so that we will no longer be together [with them] in a \nState.\u201d  (Bosnia v. Serbia, p.196, para. 37) . \nThe ICJ argued that this was not sufficient to prove Serbia\u2019s genocidal intent, as it did not clearly demonstrate the intent to destroy the Bosniaks, in part or in whole. The statements \npresented in Prosecutor v. Krsti\u0107 and Bosnia v. Serbia emphasise the desire to either  expel or \nethnically cleanse the Bosniaks from Srebrenica. The difference being that Krsti\u0107 was aware \nof the Drina Corps \u2019 plan, whilst there was no proof that Milo\u0161evi\u0107 had any knowledge of the \nplans and events in Srebrenica.  \nThese statements are in stark contrast to the statements made by Israeli officials, both in \nscope and in nature.  \n6.1.2 Israeli official statements  \nAs previously demonstrated, statements made by Israeli officials often call for the complete destruction of the Gaza Strip  and make no distinction between Hamas and civilians. As \nmentioned, government officials, such as the former Deputy Prime Minister Avigdor Lieberman, have publicly stated, \u201cThere are no innocent people in the Gaza Strip\u201d.  \nThe current president , Herzog , stated:  \n\u201cIt\u2019s an entire nation out there that is responsible. This rhetoric about civilians not aware, \nnot involved, it\u2019s absolutely not true. They could\u2019ve risen up, they could have fought against \nthat evil regime.\u201d -  President of Israel, Isaac Herzog (LFP, s.13, p.1).  \nThe Minister of National Security has stated:  \nI want the possibility to behead head after head, head after head of the Nakhba\u201d \u2013 Itamar \nBen Gvir, Minister for National Security (LFP, s63, p.6). \n \nOther statements from current government officials are, for example, Knesset Member Tally \nGotlib, who in response to Knesset member Aida Touma saying, \u201cThe lives of children in \nGaza and the gazan envelope both matter\u201d, publicly stated \u201cNo, they don\u2019t, there is no \nsymmetry, the children of Gaza brought this upon themselves\u201d (LFP, s25, p.4).  \n 2018-01-04(Dnr)  29 (av 47) \n \n29 \n Additional statements are, for instance:  \nFormer Minister Moshe Feiglin , who stated , \u201cIt is not Hamas that should be eliminated. \nGaza should be razed, and Israel\u2019s rule should be restored to the place. This is our country.\" \nLFP, s11, p.23).  \nFormer head of the Mossad Hostages and MIA unit, Rami Igra , stated:  \n\u201cIn Gaza, everyone is involved, everyone chose Hamas, everyone over the age of 4 is a \nHamas supporter\u201d . (LFP, s.33, p.26). \nAnd lastly, IDF army reservist Ezra Yachin, who in a speech made to boost the morale of IDF soldiers , stated:  \n\u201cDo not leave anyone behind. Erase the memory of them. Erase them, their families, mothers, \nand children. These animals can no longer live. Every Jew with a weapon should go out and \nkill them. If you have an Arab neighbour, don\u2019t wait to go to his home and shoot him. We \nwant to invade not like before, we want to enter to destroy what\u2019s in front of us, and destroy \nhouses, then destroy the one after it. With all of our forces, complete destruction, enter and \ndestroy. As you can see, we will witness things we\u2019ve never dreamed of. Let them drop bombs \non them and erase them\u201d (South Africa v. Israel, p.150). \nWhen analysing the statements made by Serbian officials and Israeli officials, there is a clear difference in the description and aim of the statements. As previously mentioned, the \nstatements made by Serbian officials distinguish between Bosnian civilians and Serbia\u2019s \n\u2018enemies\u2019 and aim to expel Bosnians out of Srebrenica rather than calling for their \ndestruction. Contrastingly, the Israeli officials clearly and intentionally equate civilians to \nHamas, call for the killing of Palestinians in Gaza, and for the complete destruction of the \nGaza Strip. The statements made by Israeli officials seemingly aim at not only expelling the \nPalestinians in the Gaza Strip, but also at \u2018erasing\u2019 the Palestinians in their entirety. \nAdditionally, while the Serbian officials made no statements regarding children, Israeli \nofficials have labelled children Hamas supporters, as shown in the above statement made by \nRami Igra.  \nIn Prosecutor v Krsti\u0107, the defence argued that inflammatory statements were to be expected in war , but made a point in excluding statements that called for killings. If this argument  were \napplied  to the statements made by Israeli officials above, they  would not be considered \u2018just \ninflammatory. Additionally, in Bosnia v. Serbia, the IC J held that the evidence must be so \nconclusive that nothing else can be inferred. T could be argued that due to the severity and explicit nature of the statements above, it w ould be very difficult to infer anything other than \n 2018-01-04(Dnr)  30 (av 47) \n \n30 \n genocidal intent, especially if one also considers the scale of destruction caused by the IDF \nand the number of civilian deaths.   \nBased on the decisions made by the ICTY  and ICJ  regarding dolus specialis , it seems \nprobable that  the statements made by Israeli officials fulfil the criteria and description \nprovided by the tribunal. Furthermore, it could be argue d that even without the precedent set \nby the ICTY, the statements made by Israeli officials are in fact expressions of dolus \nspecialis . This argument is rooted in the nature  of the statement s, the equation of civilians to \nmilitary targets, and the explicit call for the killing of Palestinians.  \n Additionally, South Africa also claims that the statements made by Israeli officials, including \nPrime Minister Benjamin Netanyahu, provide significant evidence of genocidal intent.    \nFurthermore, in their proceedings against Israel, South Africa further asserted that statements \nsuch as the above provide a clear indication of intent and aim to destroy Palestinians in Gaza \nas a group and that statements made by non- officials constitute clear examples of direct and \npublic incitement to genocide (South Africa v. Israel, p. 156, para 107).  \n \nThe most common arguments in discussions relating to statements made by Israeli officials \ninclude that these statements are merely rhetoric shaped by the intensity of the conflict and \nthat the identification of Hamas with Palestinians could just be strategic discourse rather than expressed intent to target them as a collective.  \nIt could be argued  that these arguments are insufficient , as they ignore the nature of the \ncomments and do not consider them in conjunction with the damage caused to the Gaza Strip \nand the number of civilian casualties. Additionally, s tatements such as \u201cThey are animals, \nthey have no right to exist [\u2026] they should be exterminated\u201d (LFP, p.3, s5) do not  seem to  \nreflect  the characteristics of rhetoric merely shaped by the intensity of a situation. If these \nstatements had been made on one singular occasion, were not repeated and did not reflect the situation in Gaza, perhaps the arguments referring to intensity and strategic discourse would \nbe more convincing.  \nSince the 7\nth of October 2023, Prime Minister Benjamin Netanyahu and the IDF have \npublicly justified the military operations in the Gaza Strip on the basis of their stated \nobjective, which is the eradication of Hamas (The Times of Israel, 7th of October 2023). \nHowever, statements made by Israeli officials equating Palestinian civilians with Hamas raise critical legal and ethical concerns. If civilians are rhetorically framed as being an extension or \npart of Hamas, and Hamas is Israel\u2019s declared military tar get, then the underlying implication \nextends beyond the combatants to the Palestinian population in Gaza as a whole. It could be \n 2018-01-04(Dnr)  31 (av 47) \n \n31 \n further argued that when analysed in conjunction with the statements in Prosecutor v Krsti\u0107, \nthe statements by Israeli officials explicitly demonstrate a plan to destroy in whole or in part a \nprotected group and are more brutal and severe in nature than those considered admissible \nevidence of dolus specialis  by the ICTY.   \nSimilarly to Prosecutor v Krsti\u0107, it seems like there is a plan to destroy the Palestinians in Gaza, based on the historical treatment of the Palestinians by Israel, the pattern of conduct \nafter the 7\nth of October, and the statements made equating the Palestinians to Hamas, whom \nthe Israeli government  have labelled their military target.  \n \n6.2 Admissible evidence in the case of Gaza  \nIn this section, I will discuss video footage and radio clips from Gaza as evidence of a pattern \nof conduct targeting civilians, in conjunction with video footage from Rwanda, which was \nconsidered admissible evidence.  \nIn the case of Rwanda, the prosecution submitted videotapes and radio recordings as evidence of genocidal intent, which was considered admissible evidence to prove genocidal intent and \nactions by the ICTR. I will start by analysing radio recordings.  \n \n6.2.1 Radio Recordings \nIn this section, I will analyse two radio recordings. The first recording was released by RTLM radio and was submitted to the ICTR by the prosecution, which will be analysed in \nconjunction with a radio interview with an IDF commander conducted by the Israeli radio \nstation 103fm . \nAccording to Nzitatira et.al (2024), the radio station RTLM forcefully and consistently underlined that the Hutu needed to defend themselves against possible Tutsi attacks. One \nradio journalist, during a radio broadcast, stated, \u201cRwanda is a Hutu land. We are the \nmajority. They [Tutsi] are a minority of traitors and invaders. We will squash their \ninfestation .\u201d (2024, p.1). RTLM radio further stated that the Rwandan Patriotic Army (RPA) \nwere advancing with the help of the Tutsi, who they claimed intended to subjugate the Hutu. The radio station further remarked that the only way to avoid this was to find the enemy \namong them and to work with the authorities to help destroy the RPA and all of their \nsupporters (Nzitatira et.al 2024, pp. 878- 879). The implication of a generalised statement \nsuch as the \u2018 Tutsi are aiding the RPA \u2019 is that there are no innocents among the Tutsi, framing \nthem all as a threat. These statements have similar characteristics to those shared by not only \nIsraeli officials but also members of the Israeli army.  \n 2018-01-04(Dnr)  32 (av 47) \n \n32 \n In an interview with the Israeli radio station 103fm, Oren Schindler, the commander of the \n74th battalion of the 188th brigade, said, \u201cWe need to make sure that whenever the IDF meets \nGaza, there is devastation. Nothing more, nothing less [\u2026] In every place we were, there was only sand left and houses on the ground [\u2026] In Gaza, there is no innocence\u201d  (Middle East \nEye 2024, A) . \nIn the interview, the commander clearly states that the IDF must ensure the complete \ndevastation and destruction of Gaza. He further describes how his battalion has largely \nsucceeded in destroying civilian infrastructure and houses to the point of only sand \nremaining. He concludes by saying that there is no innocence in Gaza, thus implying that \nevery Palestinian in Gaza is involved. \nThis interview shares characteristics with the RTLM radio recording. Both clips detail the \ndestruction of , or the alleged claim to , a piece of land. Moreover, both recordings imply that \nthere are no innocent civilians among the protected groups in a way that could be indicative of a desire to destroy in whole or in part the group they are referring to. Although the \ncommander does not explicitly call for the killing of the Palestinians, his interview seems to \nbe indicative of the existence of such intent. This differs from the RTLM recording, as the \nradio station called for the killing of the Tutsi in a more explicit manner by stating, \u201cwe will \nsquash their infestation\u201d.  \n6.2.2 Video footage  \nAs previously mentioned, video footage was considered admissible evidence by the ICTR. Therefore, this subsection will detail and analyse video footage from the Rwandan genocide \nand the Gaza Strip. It is , however , important to clarify that the video footage is slightly \ndifferent in nature. Firstly, although I was unable to find any information about the videos submitted to the ICTR, I found details about videos that were circulating in the press or taken \nduring the Rwandan genocide. Secondly, due to the prevalence of social media in current \nsociety, some of the video footage from Gaza has been uploaded to TikTok and Instagram by \nIDF soldiers to their personal accounts. This footage has subsequently been downloaded and \nthen reuploaded by news outlets. \nAccording to Thompson, one video from Rwanda, shot in 1994, shows two human figures \nkneeling on the dirt with their arms stretched out towards members of a death squad. The \nfootage later shows the death squad members brutally beating them to death with clubs \n(Thompson, 2009, p.245). The same recording shows footage of a Tutsi man and a woman \nwho appear to be praying while kneeling on a red clay road, as a group of people walk around \nnearby with machetes, crowbars and sticks protruding from their bodies (Ibi d., p.245). The \n 2018-01-04(Dnr)  33 (av 47) \n \n33 \n footage captures two men walking towards the praying man and woman, one of the men \nstrikes the man in the head with a stick (Ibid., p.245). The victim coils up on the ground in \npain before suffering more fatal blows. Shortly after, the second assailant fatally strikes the \nwoman with such force that she is almost decapitated. The two assailants then leave, leaving \nthe bodies of the man and woman in the street (Ibid., p.245). \nFor the purpose of this thesis, I will assume that video footage of a similar nature was \nsubmitted to the ICTR.  \nSince 1994, technology has rapidly developed, and with the prevalence of social media, it has become easy to record, upload and access video footage. The amount of video footage \nrecorded in Gaza and uploaded to social media by not only Palestinians but also IDF soldiers \nhas led the Palestinian UN Ambassador Riyad Mansour to label Gaza as \u201cthe most \ndocumented genocide in history\u201d (Al Jazeera, 17\nth of July 2024). \nIn January 2024, a video recorded in Gaza by an ITV news cameraman was reported by news outlets like ITV News. The footage shows a group of five unarmed Palestinians carrying a \nwhite flag in Khan Younis, an area the IDF had previously declared a safe zone, coming \nunder fire. One of the men is then fatally shot by the IDF. Similarly, in March 2024, Al \nJazeera reported video footage that shows two Palestinian men walking separately on the \nbeach, towards their homes in Northern Gaza, both waving white flags. One of the men walks \ntowards the IDF soldiers, still holding the white flag, and they let him approach; he \ndisappears from view behind a building. The second man turns around and starts walking \nback the way he came, still waving a white flag. The footage shows the IDF soldiers chasing \ndown the second man in an armoured vehicle; he turns and waves the white flag at them. The \nIDF soldiers open fire on the unarmed man, fatally shooting him. A bulldozer arrives on the \nscene, where the footage shows the body of the first man. Thereafter, the bulldozer picks up \nthe two victims and buries them in the sand (Al Jazeera, 28\nth of March 2024). \nOther video footage recorded in Gaza shows Israeli soldiers targeting Palestinians who were \nactively fleeing, gathering food or waiting for aid convoys ( Middle East Eye , 2024, B; C; D; \nE; F).  \nThe video footage from Rwanda and Palestine bears similarities in that both show unarmed, \nvulnerable civilians who display surrender being killed by soldiers. The differences are the \nmethods in which they are killed and their display of surrender. Where the Rwandans were \npraying, leaving them clearly vulnerable, the Palestinians were brandishing white flags, an \ninternational symbol of surrender. Based on the admissibility of the Rwandan footage, it \n 2018-01-04(Dnr)  34 (av 47) \n \n34 \n could be argued that the footage coming out of Gaza should also be considered admissible \nevidence for genocidal intent and acts.  \n In the case of the IDF\u2019s conduct in the Gaza Strip, due to the accessibility of cameras and social media, there is more recorded footage of soldiers\u2019 statements and conduct than radio \nrecordings. The types of footage filmed by IDF soldiers include incriminating statements and \nwhat appears to be the intentional destruction of civilian houses and infrastructure.  \nIn 2023, the independent news site Doha News (Amnesty International, 2016) released footage of an alleged IDF soldier on a recorded video call stating: \u201cWe are looking for \nbabies, but there are no babies left [\u2026] maybe I killed a girl, she was 12 but I\u2019m looking for \na baby.\u201d (Doha News, 2023). This is not the only instance of an IDF soldier being caught on \ncamera expressing intent to harm civilians. Other footage recorded by IDF soldiers includes \nexpressions of intent to massacre the population, such as \u201cHere is Captain Loupy. He will \ntake you into Gaza. This is going to be great. It will be great. We are going to Massacre \nthem\u201d ( Middle East Eye , 2024, G) And \u201cthank God, we destroyed a vast land for them, we \nkilled them, tens of thousands of Amalekites\u201d ( Middle East Eye , 2024, H).  \nAdditional footage shows IDF soldier Ben Sabag, filming a dog searching for food in Gaza, \ndescribing the dog as \u201cthe only uninvolved civilian in Gaza\u201d, echoing the rhetoric of the \nright -wing Israeli politician Avigdor Lieberman ( Middle East Eye , 2025) . \nIt could be argued that, although most of the statements made by IDF soldiers were captured \non video and not radio recordings, these videos , alongside  the recording of the IDF \ncommander , bear similarities to the recordings of RTLM radio \u2019s statements during the \nRwandan genocide. T he RTLM recordings , IDF soldier videos , and the interview with the \nIDF commander share a similar rhetoric that den ies the existence of  innocent or uninvolved \ncivilians. The key  difference between the presented material  is that w hile RTLM radio \nrecordings were deemed admissible, videos of IDF soldiers , which were filmed and published \non social media , either by the soldiers themselves or by eyewitnesses , have not yet been \nformally recognised as admissible evidence . Because this type of  video footage  was not \naddressed during the ICTR trials , likely due to the technological landscape at the time, it is  \nunclear whether such video footage would qualify as admissible evidence.  \nUnder the principle of stare decisis , since the ICTR has previously accepted video footage as \nadmissible evidence, the ICJ  should likewise consider footage of the IDF as admissible. \nThese videos do not exhibit soldiers targeting Hamas combatants or Militants; rather, they expose the systematic targeting of civilian infrastructure and expressions of intent to destroy \nthe Palestinian population in Gaza. Moreover, after the video footage posted by the IDF led a \n 2018-01-04(Dnr)  35 (av 47) \n \n35 \n Brazilian court to investigate an IDF soldier visiting Brazil, Israel\u2019s M inistry  of Foreign \nAffairs  made a statement, warning soldiers to stop posting their actions  in Gaza on social \nmedia (Shotter and Saleh, 2025). However, the Ministry did not order  the soldiers to stop \ntheir actions in Gaza; this not only potentially reveals the extent of the Israeli government\u2019s \nknowledge of the IDF\u2019s actions, but also potentially exposes the complicity of the Israeli \ngovernment itself. Since the release of the Ministry\u2019s warning, videos of Israeli soldiers have \nstarted disappearing from the internet, according to Al Jazeera (Marich and Bhagat,11th of \nApril 2025). This indicates that Israel may actively be attempting to cover up potential crimes, which, if true, means  Israel \u2019s government is complicit. As seen in Prosecutor v \nKrsti\u0107, the knowledge of , and active participation in , plans relating to the destruction of a \nprotected group is considered sufficient evidence of genocidal intent. I t could be  argue d that \nIsrael\u2019s bid for the  removal of incriminating videos, whilst being informed of the actions of \nthe IDF, could constitute active participation and knowledge as decided in Prosecutor v \nKrsti\u0107.  \nIt could be argued that, considering video footage, knowledge of the IDF\u2019s actions, and \nstatements from both IDF soldiers and government officials, the sheer scale of destruction in \nGaza, the deliberate targeting of civilian infrastructure, the high number of civilian casualties , \nespecially among women and children, and the complete siege of the Gaza Strip,  collectively  \nindicate the presence of dolus specialis . It could be  further argue d that the above also reveals \nthe aim to destroy in whole or in part the Palestinians in Gaza as an ethnic, racial, religious or national group and not only Hamas as publicly stated.  \nDue to the advancements of technology, some may argue that videos of IDF soldiers and radio recordings can be manipulated, edited or created using AI. This raises a question of the \nintegrity of video evidence and whether it would be considered admissible by the ICJ. \nAdditionally, today, AI can clone voices of real people almost flawlessly, which also calls \ninto question the admissibility of voice recordings as evidence (Josan, 2024, p.1). \nNonetheless, The Washington Post and the Middle East Eye  claim to have identified and \nverified over 120 videos posted by IDF soldiers, which may  lend credibility to the footage \n(The Washington Post, 3\nrd of December 2024). Furthermore, many of these soldiers have \nsubsequently been identified as their identification numbers are clearly visible in the videos, and as the videos were posted to their personal social media accounts (Middle East Eye, 3\nrd of \nOctober 2024; Al Jazeera, 3rd of October 2024).  \n 2018-01-04(Dnr)  36 (av 47) \n \n36 \n Additionally, if video footage is no longer considered reliable evidence due to potential \nmanipulation  and editing, other evidence such as paper documents, signatures and voice \nrecordings could also be considered unreliable , as they too can be subject to manipulation and \nforgery. Although the ICJ and ICC do not indicate how they verify or authenticate submitted \nevidence,  it must  be assume d that they have access to cyber forensics or other means of \nverification, like analysing geolocation, tags and cross -referencing publishing dates across \nsocial media platforms. Nevertheless, like any evidence, the video footage should undergo \nrigorous scrutiny and be considered in conjunction with other evidence.  \nIn this chapter , I have systematically analysed various forms of evidence based on what has \nbeen considered admissible during the ICTR\u2019s proceedings relating to the Rwandan genocide. \nIn the following, I will return to my research question and conclude the thesis. \n7. Conclusion  \nThe crime of genocide is considered a fundamental violation of international law and human \nrights. International human r ights  law was developed to promote and protect human rights , \nbased on the belief that these rights are basic, fundamental , and inherent to all human beings. \nHuman r ights scholars who actively engage in conversation surrounding the topic of genocide \nhelp initiate a deeper understanding of human rights, personal responsibilities and the consequences and  dangers of remaining silent, indifferent or apathetic when confronted with \na real situation of genocide and the suffering of others. Additionally, these conversations highlight  the dangers of racism, xenophobia, hatred, dehumanisation and discrimination and \nhow they can be preconditions for genocide. However, since the adoption of the Genocide Convention, it has become clear that the international community has failed to uphold the \nprevention mandate , and that the Convention, in addition to its state parties, have only been \nsuccessful in punishing perpetrators of genocide. Moreover , it has become increasingly \nevident that the international community\u2019s first response to allegations of genocide is denial \nrather than action or investigation, leading to the failure to uphold the prevention mandate. In \nthis context , further research should be conducted to explore what causes states to default to \ngenocide denial , and therefore fail to fulfil their obligations of prevention, rather than \nformally investigating allegations of genocide . This research could lead to a better \nunderstanding of the Genocide Convention, its enforceability , and applicability.  \n Israel\u2019s actions in Gaza post -2023 have raised questions about whether the events can be \nunderstood as genocide , or whether Israel is acting in self -defence.  \n 2018-01-04(Dnr)  37 (av 47) \n \n37 \n This thesis analysed the applicability of the Genocide Convention and its dual intent mandate \nto the events in Gaza post -2023. It examined cases that set precedents on the scope, \ninterpretation , and application of the Genocide Convention, and the evidence that has \npreviously been considered admissible to prove genocidal intent. It analysed the allegations \nof genocide submitted to the ICJ by South Africa in its proceedings against Israel  and \ncompared the allegations and evidence to the cases of Prosecutor v. Akayesu, Prosecutor v. Krsti\u0107 and Bosnia v. Serbia. The findings of the analysis  revealed that Israel\u2019s actions in Gaza \nexhibit a pattern of conduct that does not seem to be consistent with the characteristics of self-defence as described in international human rights law. \nThe findings from the legal analysis further indicate that the acts perpetrated by Israel in Gaza post -2023 are genocidal in character  and exhibit  a pattern of conduct that convincingly \nindicates the presence of genocidal intent. Additionally, the statements made by government officials and IDF soldiers used for the analysis further indicate the presence of such intent.  \nAs such, this thesis concludes that the events in Gaza post -2023 seem to be consistent with \nthe characteristics of genocide.  \nThe International Court of Justice has yet to reach a verdict regarding whether the events in \nGaza post -2023 amount to genocide. However, based on the above, it would not be \nunreasonable to assume that the International Court of Justice may return with a guilty verdict in the case of Israel and Palestine. Due to the recent escalation, however, there is a growing \nconcern that by the time the ICJ reaches its verdict, the Gaza Strip may have been completely \ndevastated and ethnically cleansed.  It is therefore vital that states fulfil their legal obligation \nand take the appropriate measures to prevent further devastation and loss of life. \n \n \n \n \n \n   \n \n \n \n \n \n 2018-01-04(Dnr)  38 (av 47) \n \n38 \n Bibliography \n \nConventions and Reservations  \nThe Convention on the Prevention and Punishment of the Crime of Genocide (1948)  \nThe Convention against Torture and Other Cruel, Inhuman or Degrading Treatment or \nPunishment  (1984).  \nThe Vienna Convention on the Law of Treaties (1969)  \nThe Statute of the Court of Justice (1945) https://www.icj -cij.org/statute  \nUnited Nations Treaty Collection, Convention Against Torture and Other Cruel, Inhuman or \nDegrading Treatment or Punishment  (1984), reservations, declarations and objections \nhttps://treaties.un.org/pages/showDetails.aspx?objid=080000028003d679&clang=_en  \nCases  \nApplication of the Convention on the Prevention and Punishment of the Crime of Genocide in \nthe Gaza Strip (South Africa v. Israel 2023) , International Court of Justice. Retrieved 5 April \n2025, from https://www.icj- cij.org/case/192. \nApplication of the Convention on the Prevention and Punishment of the Crime of Genocide \n(Bosnia and Herzegovin a v Serbia and Montenegro, 2007).  International Court of Justice. \nRetrieved 5 April 2025, from https://www.icj- cij.org/case/91  \nBosnia v. Serbia (2007) Trial judgement  \nApplication of the Convention on the Prevention and Punishment of the Crime of Genocide  \n(Croatia v. Serbia)  Judgement (2015) International Court of Justice https://icj-\ncij.org/sites/default/files/case -related/118/118- 20150203- JUD- 01-00-EN.pdf   \n Prosecutor v. Radislav Krsti\u0107 (Trial Judgement) . (2001). Refworld. Retrieved 7 May 2025, \nfrom https://www.refworld.org/jurisprudence/caselaw/icty/2001/en/40159 \nProsecutor v Goran Jeslic (Appeal judgement)  (2001) Refworld. Retrieved 7 May \nhttps://www.refworld.org/jurisprudence/caselaw/icty/2001/en/17659  \nThe Prosecutor v. Jean- Paul Akayesu (Trial Judgement) . (1995). Refworld. Retrieved 7 May \n2025, from https://www.refworld.org/jurisprudence/caselaw/ictr/1998/en/19275 \nDocument detailing background information from the International Criminal Tribunal for \nRwanda\u2019s official website \nhttps://unictr.irmct.org/sites/unictr.org/files/publications/compendium- documents/i -\nstreamlining -cases -through- evidence -icty-perspecitve -baghel.pdf   \n 2018-01-04(Dnr)  39 (av 47) \n \n39 \n  \nUnited Nations  \nEnd unfolding genocide or watch it end life in Gaza: UN experts say States face defining \nchoice. (n.d.). OHCHR. Retrieved 21 May 2025, from https://www.ohchr.org/en/press -\nreleases/2025/05/end- unfolding- genocide -or-watch -it-end-life-gaza- un-experts -say-states -\nface \nEuropean Convention on Human Rights . (n.d.).  \nHighlight 17 April 2025 | United Nations Secretary -General . (n.d.). Retrieved 19 May 2025, \nfrom https://www.un.org/sg/en/content/highlight/2025 -04-17.html  \nFundamental rights \u2014European Commission. (n.d.). Retrieved 22 May 2025, from \nhttps://home -affairs.ec.europa.eu/networks/european- migration- network -emn/emn -asylum -\nand-migration- glossary/glossary/fundamental -rights_en \nHumanitarian Situation Update #277 | Gaza Strip | OCHA . (2025, April 4). \nhttps://www.unocha.org/publications/report/occupied- palestinian -territory/humanitarian -\nsituation -update -277-gaza -strip \nInternational Law Commission. (n.d.). Retrieved 19 May 2025, from \nhttps://legal.un.org/ilc/sessions/63/  \nINTERNATIONAL COURT OF JUSTICE, FQA. (n.d.). Retrieved 19 May 2025, from \nhttps://www.icj -cij.org/frequently -asked -questions  \n \nPress release: UN expert condemns attack on Al -Ahli hospital in Gaza. Question of Palestine . \n(17th of April 2025) Retrieved 18 April 2025, from \nhttps://www.un.org/unispal/document/press -release- un-expert -condemns -attack -on-al-ahli-\nhospital -in-gaza/  \nReport of the International Law Commission : Seventy- first session (29 April \u20137 June and 8 \nJuly\u20139 August 2019) .  \nReported impact snapshot | Gaza Strip (14 May 2025) . (2025, May 14). United Nations \nOffice for the Coordination of Humanitarian Affairs -  Occupied Palestinian Territory. \nhttps://www.ochaopt.org/content/reported -impact -snapshot -gaza-strip-14-may-2025  \nReported impact snapshot | Gaza Strip (15 April 2025) . (2025, April 15). United Nations \nOffice for the Coordination of Humanitarian Affairs -  Occupied Palestinian Territory. \nhttps://www.ochaopt.org/content/reported -impact -snapshot -gaza-strip-15-april-2025 \n 2018-01-04(Dnr)  40 (av 47) \n \n40 \n Research Guides: UN International Law Documentation: Courts & Tribunals  [Research \nguide]. United Nations. Dag Hammarskj\u00f6ld Library. Retrieved 26 May 2025, from \nhttps://research.un.org/en/docs/law/courts  \nUN Human Rights Office: Alarm over killings and unlawful use of force by local police in \nGaza amidst deteriorating public order. Question of Palestine  (4th of April, 2025) . Retrieved \n23 May 2025, from https://www.un.org/unispal/document/un -human -rights -o\ufb03ce -alarm -\nover -killings -and-unlawful -use-of-force -by-local- police -in-gaza -amidst -deteriorating -public -\norder/  \nUNRWA Situation Report #171 on the Humanitarian Crisis in the Gaza Strip and the West \nBank, including East Jerusalem . (16th of May 2025). UNRWA. Retrieved 19 May 2025, from \nhttps://www.unrwa.org/resources/reports/unrwa -situation -report -171-situation -gaza-strip-\nand-west-bank -including -east-jerusalem  \nUNRWA Situation Report #165 on the Humanitarian Crisis in the Gaza Strip and the West Bank, including East Jerusalem . (28\nth of March.). UNRWA. Retrieved 19 May 2025, from \nhttps://www.unrwa.org/resources/reports/unrwa -situation -report -165-situation -gaza -strip -\nand-west -bank -including -east-jerusalem  \n(General Assembly 74th session A/74/ p.190 UN Special Committee finds Israel\u2019s warfare methods in Gaza consistent with genocide, \nincluding the use of starvation as a weapon of war . (14\nth of November 2024). OHCHR. \nRetrieved 21 February 2025, from https://www.ohchr.org/en/press -releases/2024/11/un-\nspecial -committee -finds -israels -warfare -methods -gaza- consistent -genocide  \nUNICEF  \u2018Unimaginable horrors\u2019: More than 50,000 children reportedly killed or injured in \nthe Gaza Strip. ( 27th of May 2025). Retrieved 28 May 2025, from \nhttps://www.unicef.org/press -releases/unimaginable- horrors -more -50000 -children-\nreportedly- killed -or-injured- gaza- strip \n  \nMaterial from other International Organisations  \nAmnesty International concludes Israel is committing genocide against Palestinians in Gaza. (2024, December 5). Amnesty International. \nhttps://www.amnesty.org/en/latest/news/2024/12/amnesty -international -concludes -israel -is-\ncommitting -genocide -against -palestinians -in-gaza/  \nLaw for Palestine Releases Database with 500+ Instances of Israeli Incitement to Genocide \u2013 \nContinuously Updated (2024, January 4. Law for Palestine . https://law4palestine.org/law -for-\n 2018-01-04(Dnr)  41 (av 47) \n \n41 \n palestine -releases -database- with-500-instances -of-israeli -incitement- to-genocide-\ncontinuously- updated/  \n Israel: White Phosphorus Used in Gaza, Lebanon | Human Rights Watch. (2023, October \n12). https://www.hrw.org/news/2023/10/12/israel -white -phosphorus -used-gaza- lebanon  \nQatar: Blocking of Doha News website \u2018an outright attack\u2019 on media freedom. (2016, \nDecember 1). Amnesty International . https://www.amnesty.org/en/latest/press -\nrelease/2016/12/qatar -blocking- of-doha -news -website -is-an-outright -attack -on-media -\nfreedom/  \n \nLiterature  \nClark, J. N. (2015). Elucidating the Dolus Specialis: An Analysis of ICTY Jurisprudence on \nGenocidal Intent. Criminal Law Forum , 26(3), 497\u2013531. https://doi.org/10.1007/s10609- 015-\n9260- 5 \nFerreira, D and Gromova E. A (2024) Digital evidence in disputes involving states, \nSymposium on digital evidence, Cambridge University Press , doi:10.1017/aju.2024.4  \nHage, J. C., & Pfordten, D. von der. (2009). Concepts in Law . Springer Science & Business \nMedia. Volume 88 https://doi.org/10.1007/978- 90-481-2982- 9    \nEds. Ireton and Prosetti (2018) Journalism, Fake news and Disinformation, United Nations Educational, Scientific and Cultural Organisation (UNESCO)  \nJosan, H. S. (2024). AI and Deepfake Voice Cloning: Innovation, Copyright and Artists\u2019 Rights, Centre for International Governance Innovation \nKlabbers, J. (2017). International Law  (2nd edition). Cambridge University Press. \nLaw, J., & Martin, E. A. (2003). A Dictionary of Law. In A Dictionary of Law . Oxford \nUniversity Press. Retrieved 22 May 2025, from \nhttps://www.oxfordreference.com/display/10.1093/acref/9780199551248.001.0001/acref -\n9780199551248 \nMagnarella, P. J. (1997). Some Milestones and Achievements at the International Criminal \nTribunal for Rwanda: The 1998 Kambanda and Akayesu Cases . \nNzitatira, H. N., Billing, T., & Edgerton, J. F. (2024). How Radio Affects Violent Conflict: \nNew Evidence from Rwanda. American Sociological Review . \nhttps://doi.org/10.1177/00031224241278905 \nPeczenik, A. (1969). Empirical Foundations of Legal Dogmatics. Logique et Analyse , 12(45), \n32\u201364. \n 2018-01-04(Dnr)  42 (av 47) \n \n42 \n Santen, B. V. (2025). SEARCHING FOR A PLAN: DEMONSTRATING GENOCIDAL \nINTENT BEFORE THE ICJ . International law and politics Vol. 57:155  \n Shelton, D. (2009). Form, Function, and the Powers of International Courts. Chicago Journal of International Law . \nStephanopoulos, N., & Ginsburg, T. (2017). The Concepts of Law . University of Chicago \nLaw Review: Vol. 84: Iss. 1, Article 8.  \nThompson, A. (2009). The genocide video. Media, War & Conflict , 2(3), 245- 262. \nhttps://doi.org/10.1177/1750635209345184  \nTournaye, C. (2003). Genocidal Intent before the ICTY . The International and Comparative \nLaw Quarterly, 52(2), 447\u2013462. http://www.jstor.org/stable/3663116  \nZhao, D., & Rosson, M. B. (2009). How and why people Twitter: The role that micro-\nblogging plays in informal communication at work. Proceedings of the 2009 ACM \nInternational Conference on Supporting Group Work , 243\u2013252. \nhttps://doi.org/10.1145/1531674.1531710 \n \nWebsites \nAdvanced Guide on Verifying Video Content . (n.d.). Retrieved 14 May 2025, from \nhttps://gijn.org/resource/advanced- guide -on-verifying- video- content/  \nAbout Prime Minister\u2019 s Office Prime Minister\u2019 s Office . (n.d.). Retrieved 19 May 2025, from \nhttps://www.gov.il/en/pages/about_pm_o\ufb03ce  \n Cornell Law school  Precedent . (2024). LII / Legal Information Institute. Retrieved 14 May \n2025, from https://www.law.cornell.edu/wex/precedent  \nDe Meester, K (2020) Audio and Video Recording . Oxford Public International Law. \nhttps://opil.ouplaw.com/display/10.1093/law -mpeipro/e2602.013.2602/law -mpeipro- e2602  \nPolitical Structure and Elections, Ministry of Foreign Affairs . (n.d.). Retrieved 6 May 2025, \nfrom https://www.gov.il/en/pages/political- structure -and-elections  \nGaland and Muller (2024) The ICJ\u2019s Findings on Plausible Genocide in Gaza and its \nImplications for the International Criminal Court. Opinio Juris . \nhttps://opiniojuris.org/2024/04/05/the -icjs-\ufb01ndings -on-plausible -genocide -in-gaza -and-its-\nimplications -for-the-international- criminal- court/  \nOdhner, K (2024) MediaBiasFactCheck.com as a Tool for Lateral Reading \u2014News Literacy \nInitiative . Penn State University https://newsliteracy.psu.edu/news/mediabiasfactcheck -com-\nas-a-tool-for-lateral -reading  \n 2018-01-04(Dnr)  43 (av 47) \n \n43 \n Robinson, P. (2002). Mens Rea. Encyclopedia of Crime & Justice . \nhttps://scholarship.law.upenn.edu/faculty_scholarship/34  \nKammerhofer, J (2024) Obligations erga omnes . Oxford Public International Law. Retrieved \n19 May 2025, from https://opil.ouplaw.com/display/10.1093/law:epil/9780199231690/law -\n9780199231690- e1400  \nIsrael Defence Forces (IDF) | History, Units, Conscription, & Women | Britannica. (n.d.). \nRetrieved 19 May 2025, from https://www.britannica.com/topic/Israel- Defense -Forces  \n \nLagerwall, A (2015)  Jus Cogens . Oxford Public International Law.  Retrieved 19 May 2025, \nfrom https://www.oxfordbibliographies.com/display/document/obo -9780199796953/obo -\n9780199796953- 0124.xml  \n \nLaw Reports | Faculty of Law . (n.d.). Retrieved 19 May 2025, from \nhttps://www.law.ox.ac.uk/legal -research -and-mooting -skills -programme/law -reports  \n \nNews outlets  \nDeaths from Israel\u2019s attacks on Gaza close to 62,000 as missing added. (n.d.). Al Jazeera. \nRetrieved 19 May 2025, from https://www.aljazeera.com/news/2025/2/3/gaza -death -toll-\nrises-close- to-62000- as-missing -added  \nGaza is \u2018most documented genocide in history,\u2019 says Palestinian UN rep. (n.d.). Al Jazeera. \nRetrieved 19 May 2025, from https://www.aljazeera.com/program/newsfeed/2024/7/17/gaza -\nis-most -documented- genocide -in-history- says-palestinian -un-rep \nIbrahim, N., & Li, A. (2024, November 14). Video: Video Captures Israeli Strike on \nHumanitarian Zone in Gaza. The New York Times . \nhttps://www.nytimes.com/video/world/middleeast/100000009825987/israel -strike -gaza-\nmawasi.html \nITV News (Director). (2024, January 24). M oment  innocent civilian brandishing white flag in \nGaza \u2018safe zone\u2019 is shot dead | ITV News  [Video recording]. \nhttps://www.youtube.com/watch?v=PGdyXRHS2Ig  \nIsrael begins Gaza ground operation, kills 144 in relentless bombardment . (n.d.). Al Jazeera. \nRetrieved 21 May 2025, from https://www.aljazeera.com/news/2025/5/18/children- among-\nover-100-palestinians -killed -in-israeli -barrage- across -gaza \n 2018-01-04(Dnr)  44 (av 47) \n \n44 \n Israeli soldiers are filming themselves mocking Palestinians . (n.d.). Al Jazeera. Retrieved 7 \nMay 2025, from https://www.aljazeera.com/program/newsfeed/2024/1/18/israeli- soldiers -are-\nfilming -themselves -mocking- palestinians  \nIsraeli soldiers \u2018TikToking\u2019 potential war crimes in Gaza, new documentary reveals . (n.d.). \nMiddle East Eye. Retrieved 27 May 2025, from https://www.middleeasteye.net/news/israel-\nsoldiers -document -war-crimes -social -media -gaza- new-documentary  \nIsrael -Gaza war in maps and charts: Live tracker . Al Jazeera. Retrieved 19 May 2025, from \nhttps://www.aljazeera.com/news/longform/2023/10/9/israel- hamas -war-in-maps -and-charts -\nlive-tracker  \nNazzaro, M. (2023, October 12). Egypt warned Israel of Hamas strike days before attack: \nGOP chair [Text]. The Hill. https://thehill.com/policy/international/4252561- egypt -warned -\nisrael -of-hamas -strike -days-before -attack -gop-chair/  \nNetanyahu: We will target Hamas everywhere it operates; Gazans should \u2018get out now\u2019 . (7th \nof October 2023) The Times of Israel. Retrieved 19 May 2025, from \nhttps://www.timeso\ufb01srael.com/liveblog_entry/netanyahu -we-will- target -hamas -\neverywhere- it-operates -gazans -should -get-out-now/  \nNew York Times investigation reports Israel knew about Hamas\u2019 October 7 attack plan. \n(2023, December 1). https://www.lemonde.fr/en/israel- palestine/article/2023/12/01/new -\nyork- times -investigation -reports -israel -knew -about -hamas -october -7-attack -\nplan_6305821_139.html  \n Revenge, fire and destruction: A year of Israeli soldiers\u2019 videos from Gaza. (3\nrd of December \n2024). Washington Post. Retrieved 19 May 2025, from \nhttps://www.washingtonpost.com/investigations/interactive/2024/israel -videos -war-idf-gaza/  \nRose, E. (2023, December 28). Israeli troops killed hostages, mistaking their cries for help as \nambush by - military. Reuters . https://www.reuters.com/world/middle -east/israeli -troops -\nkilled -hostages -mistaking -their-cries -help-ambush- military -2023- 12-28/ \nShe was fleeing with her grandson, who was holding a white flag. Then she was shot | CNN . \n(26th of January 2024). Retrieved 7 May 2025, from \nhttps://edition.cnn.com/2024/01/26/middleeast/hala -khreis -white -flag-shooting- gaza-cmd-\nintl/index.html  \n 2018-01-04(Dnr)  45 (av 47) \n \n45 \n Shotter, J., & Saleh, H. (2025, January 5). Israel warns troops off social media after Brazil \nseeks soldier over Gaza. Financial Times . https://www.ft.com/content/b2eaef83- 86ff- 49ea-\nb852- db1626357c01  \nStaff, A. J. (n.d.). Israeli soldiers shoot and kill two unarmed Palestinians in Gaza: Video. Al \nJazeera. Retrieved 19 May 2025, from https://www.aljazeera.com/news/2024/3/28/israeli-\nsoldiers -shoot -dead -two-unarmed -palestinian -men-in-gaza- video  \n The Times of Israel (7th of October 2023) Netanyahu: We will target Hamas everywhere it \noperates; Gazans should \u2018get out now\u2019  \nhttps://www.timeso\ufb01srael.com/liveblog_entry/netanyahu -we-will- target -hamas -\neverywhere- it-operates -gazans -should -get-out-now/   \nThe Take: Why is evidence of Israel\u2019s war crimes in Gaza disappearing? (n.d.). Al Jazeera. \nRetrieved 19 May 2025, from https://www.aljazeera.com/podcasts/2025/4/11/the -take- why-\nis-evidence -of-israels -war-crimes -in-gaza- disappearing \nUnit, A. J. I. (n.d.). What did Al Jazeera\u2019s investigation into Israeli war crimes in Gaza \nreveal?  Al Jazeera. Retrieved 27 May 2025, from \nhttps://www.aljazeera.com/news/2024/10/3/what -did-al-jazeeras -investigation- into-israeli -\nwar-crimes -in-gaza-reveal  \n \nVerified videos released by news outlets  \nDoha News [@dohanews] (28th of October 2023) Watch as an Israeli soldier brazenly admits \nto killing a 12- year-old Palestinian girl [video]. Instagram \nhttps://www.instagram.com/reel/C1Z9SZqs3ZX/?utm_source=ig_web_copy_link&igsh=MzRl\nODBiNWFlZA==   \n 2024 (A):  Middle East Eye  [@middleeasterneye] (18\nth of January 2024) \u201cIn every place we \nwere, there was only sand left and houses on the ground.\u201d  TikTok [video] \nhttps://www.tiktok.com/@middleeasteye/video/7325561011799477536  \n2024 (B): Middle East Eye  [@middleeasterneye] (8th of January 2024) part 34. Exclusive \nfootage shows a Palestinian woman being shot by Israeli forces as she and others attempted \nto evacuate Gaza City, whilst holding white flags. TikTok [Video] \nhttps://vm.tiktok.com/ZMB72QBtY/   \n 2018-01-04(Dnr)  46 (av 47) \n \n46 \n 2024 (C): Middle East Eye  [@Middleeasterneye] (26th of January 2024) part 136, \nPalestinians who attempted to flee Khan Younis were under heavy gunfire. TikTok [video] \nhttps://vm.tiktok.com/ZMB72Bxvr/   \n2024 (D): Middle East Eye  [@Middleeasterneye] (25th of January 2024) part 116. Footage \ncaptured by ITV News  shows the Israeli army shooting a man carrying a white flag. TikTok \n[video] https://vm.tiktok.com/ZMB72HW1q/   \n 2024 (E): Middle East Eye  [@Middleeasterneye] (10th of January 2024) part 321, Israel \nopens fire at Palestinians who were waiting for the arrival of humanitarian aid in Gaza. \nTikTok [video] https://vm.tiktok.com/ZMB72G7GB/   \n2024 (F): Middle East Eye  [@middleeasterneye] (20th January 2024) A French- Israeli  soldier \nrecords himself making statements about leading an operation to Gaza, expressing intent to \n\u201cmassacre\u201d the population [Video]. TikTok \nhttps://www.tiktok.com/@middleeasteye/video/7326291328445271329?_t=ZM -\n8vuPqcRbxaP&_r=1   \n2024 (G): Middle East Eye  [@middleeasterneye] (1st of February 2024) An Israeli soldier \nshared a video on social media on Tuesday where he proclaimed that they have \u201ckilled tens of \nthousands of Amalekites\u201d  [video] TikTok \nhttps://www.tiktok.com/@middleeasteye/video/7330656784803188000?_r=1&_t=ZM -\n8wVtJcvNkPQ   \nMiddle East Eye  [@middleeasterneye] (2nd of May 2025) \u201cThe only uninvolved civilians in \nGaza.\u201d  [video] \nTikTokhttps://www.tiktok.com/@middleeasteye/video/7332173966938852640?_r=1&_t=Z\nM-8vuKHkUsDXZ   \n \n \n \n \n \n \n \n \n ", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "The Question of Genocide in Gaza: A Legal Analysis of the Events in the Gaza Strip Post-2023", "author": ["M Gr\u00fcnenberg-Kebbell"], "pub_year": "2025", "venue": "NA", "abstract": "The crime of genocide is one of the worst violations of international law and human rights,  fundamentally challenging the core principles upon which human dignity is built. Despite the"}, "filled": false, "gsrank": 854, "pub_url": "https://www.diva-portal.org/smash/record.jsf?pid=diva2:1973933", "author_id": [""], "url_scholarbib": "/scholar?hl=en&q=info:1C7QZ5NQcDoJ:scholar.google.com/&output=cite&scirp=853&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D850%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=1C7QZ5NQcDoJ&ei=obWsaKLFCqzWieoPic2ZoAU&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:1C7QZ5NQcDoJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://www.diva-portal.org/smash/get/diva2:1973933/FULLTEXT01.pdf"}}, {"title": "Framing Democracy", "year": "2024", "pdf_data": "F raming Democracy:\nDeciphering China\u2019s Anti-Democratic Propaganda using W ord Embeddings\nPatrick J. Chester\u2217\nAugust 23, 2024\nAbstract\nAutocrats have long used propaganda to maintain their grip on power, but what\nhappens when they are forced to confront the appeal of alternative regimes? I employ\nword embeddings to measure whether there is a significant difference in how Chinese\nstate media portrays democratic and non-democratic countries using three-way fixed\neffects regression analysis. My results show that the more democratic a country is, the\nmore China\u2019s state media portrays its politics as chaotic and corrupt relative to two\nbaseline news publications. This study offers novel insights into the behavior of Chi-\nnese state media, with significant implications for to our understanding of autocratic\nstability and the spread of democracy .\n\u2217Postdoctoral Researcher at the China Data Lab with the University of California, San Diego. Contact:\npatrickjchester@gmail.com W ebsite: patrickjchester.com\n1\nIntroduction\nIt is well documented that authoritarian regimes use their control over state media to\ninfluence public opinion. But what rhetorical strategies do they employ to shape it and\nat what scale? In this paper, I provide the first quantitative evidence of China\u2019s largest\npurveyor of international news framing the politics of foreign liberal democracies as chaotic\nand corrupt. T o measure propaganda I use word embeddings, numeric representations of\nwords used in similar contexts.\nThe existing theoretical and quantitative literature on propaganda has primarily focused\non two propaganda strategies: pro-regime propaganda, which aims to persuade citizens of\nthe regime\u2019s value and encourage continued support (Petrova 2011 ; Gelman et al. 2014 ;\nGehlbach and Sonin 2014 ; Adena et al. 2015 ), and strength signaling, where the regime\npresents itself as resilient to discourage challenges (Edmond 2013 ; Huang 2015b ).\nHowever, an alternative propaganda strategy known as negative legitimation has been\nobserved, where an authoritarian regime portrays alternative regime types as undesirable\n(Zhong 1996 ; Edel and Josua 2018 ). Survey data suggest this strategy may effectively\nincrease support for authoritarian rulers (Huang 2015a ), and experimental data indicates\nsusceptibility to propaganda about foreign regimes (Mattingly et al. 2023 ). While some\nevidence from interviews indicate China has employed this strategy since the 1980s (Zhong\n1996 ), quantitative evidence is lacking, and the scale of its implementation remains unknown.\nMost existing measures of bias and propaganda rely on expert coders or third-party\nsources, limiting their flexibility and scalability for large media datasets. T o address this, I\nuse word embeddings to measure propaganda, producing a continuous metric to compare the\nstrength of biases across text corpora in a language-neutral and coder-independent manner.\nT o assess China\u2019s state media\u2019s negative legitimation, I analyze over one million news\narticles from Xinhua News, comparing them with T aiwan\u2019s Central News Agency (CNA) and\nAgence F rance Press (AFP). Using three-way fixed-effects regression analysis, I investigate\nhow China\u2019s state media portrays democratic countries\u2019 politics as more chaotic and corrupt\nPage 2\nthan autocracies, controlling for potential confounding variables and examining the impact\non political news. The results indicate a significant association between media framing and\na country\u2019s democratic status, consistent with theories of propaganda (Huang 2015a ).\nThis paper contributes significantly to the literature by providing quantitative evidence\nof Chinese media\u2019s negative legitimation strategy targeting liberal democracies. Moreover,\nit highlights the strategy\u2019s long-term usage by China\u2019s largest international news outlet,\nwhich has implications for Chinese people\u2019s perception of and demand for democracy and\nthe stability of autocratic regimes. Additionally , the study showcases the application of\nword embeddings to quantify framing and propaganda, introducing new Chinese-language\nsentiment and topical dictionaries generated by the conclust algorithm.\nThe rest of the paper is organized as follows: I present the theoretical framework linking\npropaganda definitions to measurement targets and explaining why negative legitimation\nbenefits authoritarian regimes. Next, I outline the reasons supporting the idea that Chinese\nmedia portrays the politics of democratic countries as chaotic and corrupt. Then, I detail the\nmeasurement methods and empirical strategy . The subsequent section reviews the results\nand assesses their robustness using different methods and model specifications. Finally , I\ndiscuss these findings in the context of the broader literature on the topic.\nTheory\nT o what benefit is it for an authoritarian regime to change its citizens\u2019 beliefs? Also,\nwhich beliefs would a regime wish to manipulate with propaganda? A self-interested au-\nthoritarian ruler has a strong incentive to promote beliefs among their citizens that enhance\nregime stability . One of the chief threats to regime stability is the emergence of a popular\nrevolution seeking to install an alternative regime type \u2013 typically liberal democracy (Ace-\nmoglu and Robinson 2006 ; F reeman and Quinn 2012 ). The regime can prevent revolution\nby manipulating their citizens\u2019 beliefs using propaganda and censorship.\nPage 3\nF rom the citizen\u2019s perspective, there are at least three relevant beliefs that inform their\ndecision to either remove the status quo regime or allow it to continue:11) the degree to\nwhich they will derive future benefits from the current regime; 2) the benefits they expect\nto receive in future periods should their country change regime types; 3) how costly they\nbelieve it would be to transition to the alternative regime type.\nThese beliefs inform citizens\u2019 willingness to either support the regime and help it main-\ntain the status quo or to demand political reform. Given that the regime wishes to maintain\npower, it would prefer as many citizens as possible to believe that maintaining the status quo\nregime is preferable to transitioning to some alternative regime type. T o achieve this with\npropaganda, the regime must either make itself appear desirable or make the alternative less\nso.\nMuch of the extant literature on propaganda has focused on pro-regime propaganda,\nwhich increases the perceived payoffs of the current regime (White, Oates, and Mcallister\n2005 ; Adena et al. 2015 ; Carter and Carter 2016 ; Rozenas and Stukal 2019 ). Likewise, sev-\neral studies have discussed how regimes use propaganda to make themselves appear costly\nto overthrow (Huang 2015b ; Little 2017 ). However, the use of propaganda to make alter-\nnative regime types appear less desirable is poorly understood.2This is a significant gap in\nthe literature because pro-regime propaganda may exhibit diminishing returns to effort as\ncitizens learn to mistrust state media\u2019s coverage of the government (Chen and Shi 2001 ).\nA negative legitimation strategy has a significant advantage compared to pro-regime\npropaganda. Namely , citizens of autocracies cannot directly experience life under foreign\ngovernments, so they may be more easily persuaded by negative coverage of liberal democ-\nracy . This advantage has been described by Gentzkow and Shapiro ( 2006 ) who found that\nmedia have more room for bias when media consumers do not receive information from the\n1This model is a variant of the classic Downsian voter model (Downs 1957 ) with the addition of a\ncost parameter, which represents any significant cost associated with transitioning from an autocratic to a\ndemocratic regime, including the costs of repression, social stability , etc.\n2There has been significant literature on the portrayal of political out-groups (see Adena et al. ( 2015 )).\nIn contrast, my research question explicitly deals with the framing of alternative regime types, which has\nbeen less closely examined in the literature.\nPage 4\nworld that can contradict their messages. This theoretical finding is supported by Mat-\ntingly et al. ( 2023 ) who find evidence suggesting that subjects may be highly susceptible to\npropaganda about the quality of regime types they do not live under.\nChina\u2019s government is well-positioned to use a negative legitimation propaganda strat-\negy . In China, state-owned media outlets, such as Xinhua News, The People\u2019s Daily , or\nThe Global Times, produce much of the news coverage of foreign affairs consumed in China.\nWhile commercialized Chinese media sources also exist in China, their coverage of foreign\naffairs broadly follows the narrative pattern of state media (Stockmann 2013 ). Moreover,\nChinese citizens have limited access to foreign media sources, as their web addresses are\nblocked by China\u2019s national internet censorship apparatus, commonly called the \u201cGreat\nFirewall\u201d (Stockmann 2013 ; King, Pan, and M. Roberts 2013 ). This control over their citi-\nzens\u2019 information environment allows the regime to influence their citizen\u2019s beliefs towards\nthe e\ufb00icacy of democratic institutions by portraying democratic countries in a negative light.\nHypotheses\nThe literature on persuasion tells us that not all framing strategies are equally effective\nat changing beliefs (Nelson and Oxley 1999 ). One rhetorical strategy that may be particularly\npotent for Chinese media consumers is portraying foreign democracies\u2019 politics as \u201cchaotic\u201d .\nThere are three reasons to think that such a strategy may be used to shape public opinion\nin China. First, there is a well-documented antipathy among people in mainland China\nagainst social and political instability . Second, this fear of instability appears to translate\ninto support for the regime. Third, qualitative evidence suggests that Chinese elites have\nused such a strategy to maintain stability in the post-1989 era.\nThe limited polling and survey data of Chinese public opinion indicates that the Chinese\npublic, by and large, has a strong preference for social stability and a fear of political disorder.\nIn a poll of Beijing residents, Chen, Zhong, and Hillard ( 1997 ) found that when presented\nwith a choice between living in an orderly society or a freer society that was more prone\nPage 5\nto disorder, 93% of respondents chose the former. These findings are supported by further\npolling performed by Chen ( 2004 ) and interviews performed by Zhong ( 1996 ). Several of\nthe above authors speculated that this interest in political stability could be the byproduct\nof both regime propaganda and Chinese historical experience with multiple periods of social\nand political instability in the 20th century .3\nAnother reason why portraying democracy as chaotic may be a successful propaganda\nstrategy for the Chinese government is that concerns about political stability are associated\nwith support for the Chinese government. In their respective surveys of Chinese citizens,\nChen, Zhong, and Hillard ( 1997 ) and Chen ( 2004 ) found that the greater the degree to\nwhich a respondent expressed support for political stability , the greater their support for\nthe regime. F urthermore, consuming information about foreign political instability increases\nsupport for China\u2019s government. Huang ( 2015a ) found that Chinese respondents who are\nmore knowledgeable about political instability in foreign countries were more optimistic\nabout China\u2019s future prospects, and to express trust in the Chinese government and political\nsystem. This evidence indicates that portraying foreign democracies as unstable may deliver\npolitical dividends for China\u2019s regime.\nMoreover, evidence from interviews with journalists and government o\ufb00icials suggest\nthat this rhetorical strategy has been used in China. In interviews with Chinese o\ufb00icials\nand residents, Zhong ( 1996 ) found that CCP media o\ufb00icials made an effort to portraying\ndemocracy and liberalism as a cause of political disorder while citing instability in the post-\nSoviet states as examples.\nGiven this evidence, I expect the following pattern in media produced by Chinese state-\nrun media:\nH1:China\u2019s state media will portray democratic countries as being more chaotic than\nthose of non-democracies relative to other media outlets without the same political objectives\nThis media strategy would induce a belief among the Chinese public that democrati-\n3Examples of social and political instability that many living Chinese people have survived include the\nCultural Revolution and the 1989 Tiananmen Square Massacre.\nPage 6\nzation would lead to political chaos, thereby decreasing their willingness to overthrow the\nregime.\nHowever, other rhetorical approaches could be used to dissuade citizens in authoritarian\nregimes from holding positive views of democracy . F or instance, autocracies could frame the\npolitics of democratic countries as being wasteful and corrupt. There are many examples of\nChinese media actors employing this rhetoric against democratic countries like the United\nStates. One case of this occurred as a response to the Democracy Summit called by Pres-\nident Biden. The Global Times printed an extended editorial calling the United States a\n\u201ccorruption hub\u201d in which the \u201cUS election has become a \u201cmoney-burning game\u201d of \u201cone\ndollar, one vote\u201d\u201d ( Global Times 2021 ). This sentiment was echoed by an editorial in Xinhua\nNews, which speculated whether the United States was consumed by a \u201ccorruption illness\u201d\n(Xinhua News 2021 ). These cases lead me to make the following prediction:\nH2:China\u2019s state media will describe democratic countries as being more corrupt than\nthose of non-democracies relative to other media outlets\nFinally , if China\u2019s government wishes to instill the belief that liberal democracy , as\na system of government, is less desirable than their own, they should target their negative\nrhetoric towards political events and actors within those countries. This ensures that Chinese\nconsumers of this news are familiar with examples of negative political events that occurred\nin democratic countries; these examples could then be contrasted with positive political pro-\npaganda targeting their system of government. Accordingly , I expect the following patterns\nto hold for both the chaos and corruption propaganda strategies:\nH3:China\u2019s state media frame the politics of democratic countries as being chaotic\nrelative to other outlets\nH4:They will likewise frame the politics of democratic countries as being relatively\ncorrupt.\nIn sum, I expect that a passive news consumer in China would perceive democracies\nas being more chaotic and corrupt than autocratic regimes writ large. I argue that this\nPage 7\ndifferential is attributable to an effort by the Chinese government to persuade citizens that\nthe status quo is preferable to any political alternatives. By understanding the rhetoric\nstate media target to their citizens, we may better understand the factors that have shaped\nChinese public opinion and their demand (or lack thereof) for political reform.\nMethods\nMeasuring propaganda, information targeted at a consumer with the intent of chang-\ning their beliefs, has been a significant challenge for communications and social science\nscholars. Three primary methodologies have been used to measure propaganda in media:\nnominal measures in which all content produced by a publication is assumed to be propa-\nganda (Adena et al. 2015 ); measures that utilize references to external ideologically charged\ncontent, such as think tanks (Groseclose and Milyo 2005 ; Chiang and Knight 2011 ); human-\ncoder-produced content analysis in which humans assign propaganda labels to text data\n(Matthes and Kohring 2008 ; Rozenas and Stukal 2019 ).\nWhile each of these methodologies have strengths, they also have limitations. Nomi-\nnal classifications of media sources as being propaganda can depend on di\ufb00icult to validate\nassumptions. F or example, this approach depends on all content produced by that media\nsource should be considered propaganda. This assumption can fail when media outlets have\nmultiple competing objectives, such as maximizing advertising revenue while also promoting\nthe status quo regime. Additionally , while content analysis produced by expert or crowd\nevaluators are considered a gold standard by researchers, they do have limitations. Namely ,\ncontent analysis is prohibitively costly in both time and financial resources to implement on\nlarge-scale corpora. Finally , approaches that utilize external sources tend to be only appli-\ncable to cases where ideologically charged external references are included and, therefore,\nare not applicable beyond a small set of use cases.\nIn this study , I use word embeddings to measure propaganda. W ord embeddings are\nPage 8\na class of unsupervised machine learning models that take as inputs ordered sequences of\nwords as they appear in natural text and output numeric vectors representing contexts in\nwhich words appear. Higher similarities between these vectors indicate that words frequently\nco-occur in a given text.\nThe approach to measuring propaganda I describe in this section draws upon lines of\nliterature on word embeddings in the political, data, and cognitive science literature. Recent\narticles in political science have applied word embeddings towards measuring how politically\nrelevant concepts are associated in text (Rodman 2020 ; Y ang and Roberts 2021 ). Addition-\nally , researchers have used word embeddings to identify racial and gender biases in large\ntext corpora (Garg et al. 2018 ; Zhang et al. 2020 ). This study builds on the methods used\nby these scholars, using word embeddings to compare pairs of concepts across subcorpora to\nidentify between-corpus biases in media content.\nMeasuring Propaganda\nIdeally , a measure of propaganda should match existing conceptualizations in the com-\nmunications and political science literature. In this section, I examine and synthesize lit-\nerature on propaganda and apply it to construct a shared conceptualization of propaganda\nthat is theoretically grounded and measurable.\nOne common thread in the propaganda literature is that propaganda is information\npresented with the intention of manipulating the beliefs of its consumer (Kenez 1985 ; W alton\n1997 ; Jowett and O\u2019Donnell 2018 ). This definition is in line with the political economy\nliterature on persuasion. These models have modeled propaganda as a messaging strategy\nin which state media attempts to persuade the populace to support the regime (Gehlbach\nand Sonin 2014 ).\nOne of the greatest measurement challenges with propaganda produced by media is that\nit involves information asymmetry . The propagandist is aware of some set of facts about\nthe world. Y et, it has an incentive to selectively present information in a way that leads\nPage 9\npropaganda consumers to behave in a way that is beneficial to the propagandist. In an\nauthoritarian context, this can involve supporting the government, abstaining from protests\nagainst the government, or complying with mobilization campaigns (Gehlbach and Sonin\n2014 ).\nAs it pertains to propaganda in the media, this implies the potential existence of two\nmessages from a propagandist: S\u2032\noaandS\u2217\noa, where the former is the manipulated association\nbetween a particular target object, o, and attribute, a, that is intended to bring about the de-\nsired belief, and the latter is the counter-factual association that would have been generated\nabsent a desire to persuade. W ere we to imagine that the associations between attributes\nand objects were represented numerically , the difference in the association between S\u2032\noa and\nS\u2217\noa would represent the change in the message that is brought about by the propagandist\u2019s\nwillful action. I call this difference the propaganda effect :\nPropaganda Effectoa=S\u2032\noa\u2212S\u2217\noa (1)\nIn other words, for a given message, the propaganda effect is the deviation in the\nassociation between a particular target object and attribute from the one that would exist\nabsent any political motivation to persuade the message consumer.4The propaganized\nrelationship between attributes and objects is easily observable given media produced by a\npropagandist; however, the latter must be inferred from external sources of information.\nAssociations between objects and attributes in text can be produced through a combi-\nnation of framing, i.e. associating concepts in the text itself, and censorship. An example\nof the former was found by Rozenas and Stukal ( 2019 ): Russian state media was found to\nassociate economic failures with external factors and attribute economic successes to the\n4There is a conceptual difference between what I describe as a propaganda effect and the common use\nof the word \u201cpropaganda. \u201d The former is commonly used to describe messages intended to persuade. F or\ninstance, one might refer to a news article produced by Xinhua or China\u2019s Global Times as an example of\npropaganda. In contrast, the propaganda effect is the difference in framing observed between a propagandized\nmessage and one produced without the intent to persuade. This term is not used to describe the message\nitself, but instead the persuasive component of the message.\nPage 10\nregime\u2019s policies. Censorship can also reduce associations in text that may be perceived\nas harmful to the government, such as criticism targeted towards the government on social\nmedia King, Pan, and M. Roberts ( 2013 ).\nWhat external sources of information could be used to infer the counterfactual message?\nModels of media behavior suggest that private media tend to produce content that maximizes\nmedia consumption. This will lead to news content that is largely consistent with the ground\ntruth as they perceive it, as factual information is valuable to consumers (Gehlbach and Sonin\n2014 ). Of course, models of media behavior are imperfect; for instance, they do not take\ninto account the well-documented phenomenon that market segmentation can lead to biased\ncoverage, even in the absence of government intervention. I address this concern by selecting\ncomparison media outlets that satisfy three criteria: 1) a reputation for unbiasedness; 2)\neither private ownership or public funding that is not conditional on content; 3) it produces\ncontent in an uncensored, i.e. global, media environment.\nFigure 1: Concept Similarity Generation Procedure\n(1) (2) (3)\nap\n1\nap\n2ap\n1,g1\nap\n2,g1\nap\nnap\nn,gkWp Sp\noa\nDoa......\nT o measure the propaganda effect and test hypotheses 1-4, I first need measures for S\u2032\noa\nandS\u2217\noa, or the similarity between relevant objects and attributes for propagandized and un-\npropagandized news corpora. However, dyadic comparisons between objects and attributes\nare insu\ufb00icient to test my hypotheses, as each hypothesis implies the presence of a condition-\ning or grouping variable; for hypotheses 1 and 2, I am interested in the association between\ncountries and attributes over time ( S(Country, Attribute | Time) ), while for hypotheses\n3 and 4, I am concerned with the association of an attribute with the politics of a given\nPage 11\ncountry ( S(Country, Attribute | Country) ). Because each of these strategies imply not\njust an object and attribute, but also a conditioning variable (S(O,A|G)), a simple compar-\nison of similarities between an object, attribute pair is insu\ufb00icient to test my hypotheses.\nInstead, I incorporate conditins into my analysis through restructuring the data. Figure 1\ndescribes this measurement strategy .\nIn Part 1 (see Figure 1), articles are assigned grouping labels ( gk): the quarter (i.e.,\nperiods of three months) for testing hypotheses 1 and 2, and country for testing hypotheses 3\nand 4. F or instance, to test hypothesis 1, I group examine the similarity between each pairing\nof a country and chaos within each publication-quarter subcorpus (ex. S(Argentina, Chaos\n| 2005-Q1) ). In contrast, to test hypotheses 3 and 4, the target object is politics and the\ngrouping variable is the country; for example, S(Politics, Chaos | Afghanistan) .\nT o assign country labels to articles, I used a dictionary of Chinese-language country\nnames and a majority rule: an article is labeled according to which country was mentioned\nmore times than any other. F or instance, if the United States was mentioned three times\nin a given article while China was mentioned twice, the article would be assigned a \u201cUSA\u201d\nlabel.567\nF or Part 2 of my measurement strategy (see Figure 1Part 2), skip-gram word embedding\nmodels are fit upon each publication-group subcorpus of articles. The output is a set of fitted\nword embedding models, Wp, in which each element, wp\ngi\u2208Wp, is an embedding model that was\n5I use a dictionary of 259 terms that represent 201 unique country labels with both T aiwanese and\nmainland name variants compiled from various sources to assign country labels to articles.\n6In Online Appendix C, I analyze the accuracy of this classification methodology by comparing country\nlabels assigned by the dictionary plurality rule and two other assignment rules with country labels assigned\nto 2000 articles by a research assistant. I find that compared to alternative dictionary-based rules, the\nplurality rule had comparable accuracy with no loss in the number of articles classified. Accordingly , it is\nthe rule used to assign country labels in the analysis for hypotheses 3 and 4.\n7In this analysis, I am mindful of a core tradeoff implicit in the word embedding analysis method:\nthe need for embeddings reflecting localized meanings of words and fitting good quality embeddings. The\nliterature indicates that embedding models fit on fewer than 200 to 500 articles tend to reflect poorly the\nunderlying semantic relationships in text (Roberts 2016 ; Rodman 2020 ; Zhou, Ethayarajh, and Jurafsky\n2021 ). T o prevent this structural relationship from biasing my findings, I directly control for the number of\ntokens associated with objects and attributes and exclude groups from my analysis for which any publication\nhad produced fewer than 400 articles.\nPage 12\nfit on a subcorpus of articles, a1,gi, a2,gi, . . . a n,gi , corresponding to the members of each group\nfor a given publication. Each model is estimated with context windows of size 10 and 300\nword embedding dimensions on the top ten thousand most frequent features of the corpus.\nThese parameter choices were made to maximize model accuracy while minimizing training\ntime based on the analysis performed by Spirling and Rodriguez ( 2021 ). The skip-gram word\nembedding model version used in this study is from the word2vec package implemented in\nPython 3.8\nNext, we use the embedding models and a set of keywords to compute how similar\nconcepts of interest are to one another within each subcorpus. More precisely , the word\nembedding models and a set of target and attribute word pairs, Doa, are used to generate a\ncosine similarity matrix in which every element is the cosine similarity score between a word\npair from the attribute and target object within a publication-group subcorpus.9\nIn the final stage (see Figure 1Part 3), I aggregate the elements of each similarity matrix\nto identify a single measure of the degree of similarity between a particular target object\n- attribute pair within each publication-group, or sp\noa,gi\u2208 Sp\noa. I do so using the average\nacross all term pairs grouped by concept pair and weighted by term frequency . Compared to\nthe simple mean, the weighted average has the advantage of implicitly controlling for term\nfrequency , i.e. giving weight to frequently occurring term pairs and less weight to those that\nrarely occur.10 11\n8The Chinese characters are all converted to simplified to ensure that the feature sets from the T aiwanese\ncorpus are comparable with those of the Xinhua corpus.\n9T o address concerns raised by Rodman ( 2020 ) about the sensitivity of embedding models to the inclusion\nof individual documents, the ordering of articles in the training data, and to the random seed used by the\nword embedding algorithm, I employ the bootstrapping approach used by Rodman ( 2020 ) for all cosine\nsimilarity estimates.\n10The unweighted average is used as a robustness check to ensure that the results are not contingent on\nthis particular aggregation method.\n11A detailed definition of the weighted average measure of concept similarity and a discussion of its\nadvantages over the simple mean is available in Online Appendix E.\nPage 13\nDictionary Generation\nA requirement for estimating a measure of propaganda is a set of dictionaries represent-\ning target objects and attributes of interest:\n\u2022Objects: country names (H1,2); politics (H3,4); sports (placebo for H3,4)\n\u2022Attributes: chaos (H1,3), corruption (H2,4)\nNo freely available Chinese-language dictionaries of these concepts exist, so I use seed\nwords and the conclust R package to generate them.12The rationale of having robust\ndictionaries to represent concepts is that they will represent the concept of interest with\nless error; i.e., while individual words may deviate from the intended meaning in a given\nsubcorpus, a dictionary of conceptually related words should see less random measurement\nerror. The sports target object was chosen to be a placebo because there is no clear strategic\nrationale for China\u2019s state media or the benchmark media outlets to portray other countries\u2019\nsports as being more corrupt or chaotic.\nData\nT wo types of data are needed to measure the propaganda effect : messages produced\nby a propagandized media outlet and by at least one baseline media agency , the former\nrepresented by China\u2019s Xinhua News and the latter by T aiwan\u2019s Central News Agency and\nAgence F rance Press. The news content for these publications was gathered from the fifth\nedition of the Chinese Gigaword from Parker et al. ( 2011 ). The archive included 772,000,\n690,000, and 135,000 news articles covering international affairs from CNA, Xinhua, and\nAFP . Both CNA and Xinhua have news articles covering 1992 to 2010, while AFP only\n12A more detailed description of the algorithm and the keywords used to generate the dictionaries as well\nas an analysis of the dictionaries themselves is available in Online Appendix A. The dictionaries are available\nin Online Appendix B. A more detailed description of the algorithm can be found in Chester ( 2024 ).\nPage 14\nincludes coverage from 2001 to 2010. Given those differences, I focus my tests of hypotheses 1\nand 2 on the period of 2001 to 2010, where all three publications have overlapping coverage.13\nXinhua News is China\u2019s largest state-owned media outlet, with over 170 foreign bu-\nreaus and 1900 journalists. It is responsible for producing or reprinting much of the foreign\nnews consumed in China, generating around 700 foreign news items daily (Battistella and\nReporters Without Borders 2005 ). The magnitude of the content it generates, combined\nwith limits on competition from foreign sources imposed by China\u2019s great firewall, ensures\nthat Chinese citizens, directly and indirectly , consume Xinhua\u2019s publications. These facts\nmake Xinhua an attractive media agency to examine as a tool of negative legitimation, as\nno other source in China has the same capacity to influence Chinese public perceptions of\nforeign countries.\nLike Xinhua, T aiwan\u2019s CNA generates much of the Chinese-language foreign news cov-\nerage consumed by its domestic audience. While not directly managed by the T aiwanese\ngovernment,14CNA also receives large subsidies and is legally considered T aiwan\u2019s national\nnews agency . In addition to producing its own content, CNA partners with many other lead-\ning international news sources, such as Reuters, AP , and Agence F rance-Presse.15Finally ,\nCNA\u2019s content has been rated as being highly factual with a slight center-left bias by the\nnon-profit organization Media Bias F act Check.16\nF ounded in 1835 in Paris, Agence F rance-Presse is one of the oldest news organizations\nin the world. Like Xinhua and CNA, Agence F rance-Presse produces Chinese-language\ncontent and is largely focused on international coverage with its content. Unlike the two\nother news agencies, AFP is not state-owned, though it receives income indirectly from the\nF rench government via government subscriptions to its news services (Assemblee Nationale\n13As a robustness check, I examine whether Xinhua and CNA differ in their framing of countries over the\nfull period of 1992-2010.\n14In 1996, T aiwan\u2019s government passed a law making CNA a non-profit corporation, placing it outside\nthe T aiwanese government\u2019s direct control.\n15https://focustaiwan.tw/aboutus\n16The same NGO rated Xinhua as having a mixed record of factual reporting due to a lack of linked\nsourcing and prevalent pro-government propaganda.\nPage 15\n2012 ). Overall, the news reporting of AFP has been rated by multiple independent media\nrating agencies to be low in ideological bias and high in factual accuracy (AllSides 2020 ; Ad\nF ontes Media 2021 ; Media Bias/F act Check 2023 ).\nEmpirical Strategy\nWith this measure of propaganda, I compare how Xinhua frames democracies relative\nto CNA and AFP . But identifying a difference in framing between these publications must\nbe done cautiously . A simple difference in means hypothesis test may fail to control for\nmany potentially confounding variables at the country level. F or instance, when countries\nexperience increases in inflation, coverage of them may include more mentions of economic\n\u201cchaos. \u201d Should Xinhua give preferential coverage to inflation, and if inflation is associated\nwith regime type, this could bias a naive difference in means or OLS regression that failed\nto account for them. Therefore, to test hypotheses 1 and 2, I employ three-way fixed effects\nregression with controls for potentially confounding variables:\nYpct=\u03b1+\u03b21GctPp+\u03b22Gct+\u03b23Pp+\u03b2PpXpct+\u03b2X pct+\u03b3c+\u03c9t+\u03bbct+\u03b4pt+\u03f5pct (2)\nThe unit of analysis in Equation 2is the publication ( p) country ( c) quarter ( t). The\nparameter Ypct represents the mean cosine similarity between concept pairs. This variable\u2019s\ntheoretical range is [\u2212100,100] , though we do not observe any negative cosine similarity\nscores in practice.17The parameter Ppis a binary indicator variable for Xinhua News; Gct\nis the average Polity IV score of country cfor a given quarter in the 2001 and 2010 period\n(Marshall, Jaggers, and Gurr 2017 ).\nThe term Xkpct refers to a battery of control variables (see Online Appendix F: T able 16\n17Negative cosine similarity values would imply that concepts are negatively correlated, i.e., that increased\nfrequency of words associated with a target object results in decreased frequency of an attribute, or vice\nversa. While negative associations are theoretically possible, we do not observe this for any concept pair, as\nthe smallest observed similarity score between a pair of concepts for a given country is 9%.\nPage 16\nfor summary statistics) including model-level controls, such as the logged number of articles\nand counts of country and chaos terms, as well as country-level variables, such population and\nGDP per capita obtained from the International Monetary F und\u2019s W orld Economic Outlook\nIndicators ( International Monetary F und 2019 ). I also interact the controls with Ppto\ncontrol for heterogeneous effects within publications. Additional controls include inflation,\ngovernment revenue, government expenditures, debt, GDP growth, country-level data on\nimports from China and T aiwan from the Correlates of W ar project (Barbieri and Keshk\n2016 ), an indicator for diplomatic relations with T aiwan (Rich 2009 ), as well as a count\nof the number of conflict events that occurred in each country as measured by ACLED\n(Raleigh et al. 2010 ), the Corruption Perceptions Index for corruption (Apaza 2009 ), and\nthe presence of a bilateral alliance (Gibler 2009 ).18Country-level and time-level fixed effects\nare represented by \u03b3cand\u03c9t. I also include the interactions between country fixed effects\nand time fixed effects, \u03bbct, as well as the interaction between publication and time, \u03b4pt.19\nThe parameter of interest in Equation 2is\u03b21, as it represents the percent change in\ncosine similarity between an object \u2013 a country , in this case \u2013 and an attribute \u2013 either\nchaos or corruption \u2013 one observes for every one unit change in a country\u2019s polity score for\nXinhua\u2019s news coverage relative to CNA and AFP . The similarity can be interpreted as the\ndegree to which an attribute is ascribed to the target object. Accordingly , \u03b21is a measure of\nthe propaganda effect or the difference observed between a politicized association between\nconcepts and a non-politicized association. If China engages in a negative legitimation\nstrategy , I expect the estimator \u02c6\u03b21to be statistically significant and positive. This would\nindicate that, relative to the baselines, Xinhua describes countries as being more chaotic or\ncorrupt the more democratic they are.\n18All control variables, except corruption, are measured at the quarter level. Unfortunately , there do not\nappear to be any quarterly measures of corruption.\n19Time and country fixed effects are included to account for potential ommitted variable bias associated\nwith individual countries and time periods. The interactions between these variables control for country-\nspecific shocks that may be correlated with both regime type the outcome. Finally , publication-time fixed\neffects are included to control for publication-specific behaviors that both vary over time and are potentially\ncorrelated with the outcome varaible. Overall, I find that fixed effects do not meaningfully affect the results.\nPage 17\nThe parameter \u03b22represents how the association between the target object and attribute\nvaries according to regime type within AFP and CNA\u2019s news coverage. Given the findings of\nGoldstone et al. ( 2010 ) that full autocracies and full democracies tend to be the most stable\nregime types, while partial autocracies and democracies tend to see more instability , one\nwould expect that there would be either a modestly negative or even non-linear relationship\nbetween a country\u2019s polity score and the baselines\u2019 association of chaotic sentiment with\nthem. Similarly , the theoretical and quantitative literature on political corruption suggests\nthat polities with larger winning coalitions, i.e., democracies, experience less corruption than\ndo autocracies (Bueno de Mesquita et al. 2001 ; Montinola and Jackman 2002 ; Sung 2004 ;\nDrury, Krieckhaus, and Lusztig 2006 ). Given these empirical regularities and assuming that\nthe baseline publications produce news in ways that are consistent with them, I expect \u03b22\nto have a negative coe\ufb00icient for both attributes.\nThus far, we have described how we expect the framing of countries to differ across media\nsources. However, to test hypotheses 3 and 4, it is necessary to introduce an alternative\nobject of interest: \u201cpolitics. \u201d This poses a challenge: how do we measure how the politics of\na particular country are associated with an attribute of interest. T o address this issue, I use\nan alternative dictionary of political terms as the object and divide the data into subsets\naccording to the country mentioned most frequently in each given article. This approach\nallows us to examine to what extent the politics of a given country are framed as chaotic\nor corrupt. Additionally , it allows us to introduce a placebo object, sports, to examine the\nrobustness of any findings and measurement strategy . Equation 3describes the new model\ndesigned to test hypotheses 3 and 4.\nYpc=\u03b1+\u03b21GcPp+\u03b22Gc+\u03b23Pp+\u03b2PpXpc+\u03b2X pc+\u03b3c+\u03f5pc (3)\nRelative to Equation 2, the parameters are the same with a few significant changes.\nFirst, the unit of analysis for this model is the country ( c) publication ( p). Second, the\ndependent variable is interpreted as the cosine similarity between the object \u2013 politics or the\nPage 18\nplacebo sports \u2013 and the attributes of chaos and corruption. Third, all variables, including\nPolity IV and the control variables, are aggregated at the country level instead of across the\nfull 1992-2010 period. Finally , publications included in this analysis are limited to Xinhua\nand CNA, as AFP has approximately 20% of the corpus size, and therefore many fewer\ncountries are covered to a large enough degree to fit meaningful embedding models on their\nsubcorpora. As before, the main parameter of interest remains \u03b21, which I expect to be\nstatistically significant and positive.\nResults\nIn this section, I first perform several tests of my hypotheses 1 and 2 while varying the\npresence of control variables and fixed effects. Next, I test hypotheses 3 and 4 using the\nsame approach. Finally , I discuss analysis of the placebo, alternative model configurations,\nand measurement strategies designed to determine whether my findings are robust.\nIn T able 1, I regress my measure of similarity between country and attribute dictio-\nnaries on the interaction between regime type and state media. The variable Polity (IV)\nrepresents the baseline relationship between regime type and the Country-Attribute associa-\ntion for CNA and AFP . In contrast, Xinhua x Polity (IV) represents the change in cosine\nsimilarity in Xinhua\u2019s news relative to the baselines for every one unit change in the polity\nindex. I include eight model variations with and without control variables and country-time\nfixed effects and across both chaos and corruption attributes.20\nAcross all eight models, I find consistent evidence that as a country\u2019s polity score in-\ncreases, Xinhua associates more chaos and corruption sentiment with them relative to CNA\nand AFP . In Model 1, we see that for every one unit increase in Polity IV, there is a corre-\nsponding 0.26% increase in the similarity between Politics and Chaos for Xinhua relative to\n20In Models (1) through (4), the dependent variable is the cosine similarity between a given country and\nthe chaos attribute, while in Models (5) through (8), the dependent variable is the similarity between each\ncountry and corruption.\nPage 19\nT able 1: Impact of Regime Type on Association between Country labels and Negative At-\ntributes\nChaos Corruption\nModel (1) Model (2) Model (3) Model (4) Model (5) Model (6) Model (7) Model (8)\nIndependent V ariables\nXinhua \u221210.22*** \u221238.73*** \u221213.25*** \u221224.57***\n(0.40) (3.61) (0.40) (2.89)\nCNA \u22123.89*** \u22125.42***\n(0.61) (0.55)\nPolity (IV) \u22120.52*** \u22120.21*** \u22120.45*** \u22120.19***\n(0.07) (0.05) (0.06) (0.04)\nXinhua x Polity (IV) 0.26*** 0.15*** 0.28*** 0.13*** 0.26*** 0.17*** 0.28*** 0.16***\n(0.05) (0.04) (0.05)(0.04) (0.05) (0.03) (0.05)(0.04)\nStatistics\nObservations 15 828 13 483 15 828 13 483 15 828 13 483 15 828 13 483\nConditions\nControls No Yes No Yes No Yes No Yes\nFE No No Yes Yes No No Yes Yes\n* p<0.1, ** p <0.05, *** p <0.01\nNote:\nDependent variable is defined as the average cosine similarity between dictionaries representing countries and the respective attribute.\nFixed-effects include country, year, publication-year, and country-year effects. Robust standard-errors are clustered at the country level\nand reported in parentheses: * p <0.10, **p <0.05, *** p <0.01\nFull table with control variables can be found in Appendix F.\nCNA. This effect is significant at the 0.01 level. The inclusion of controls in Model 2 results\nin a decrease of the coe\ufb00icient size to 16%; however, standard errors likewise decrease so the\ncoe\ufb00icient does not decrease in significance.\nWhen we look at Models 3 and 4, we see that the inclusion of country and time fixed\neffects do little to change this observed relationship. In Model 4, we can see that a one\npoint increase in Polity is associated with a 0.2% increase in the similarity between chaos\nand countries covered by Xinhua relative to CNA and AFP .21This is remarkably similar to\nthe effect observed in Model 2, indicating that fixed effects are not confounding the observed\nrelationship between concept similarity and Polity . Overall, this evidence is consistent with\nmy first hypothesis, that Xinhua preferentially associates the politics of democracies with\nchaotic language.\nWhen we look at the relationship between countries and the corruption attribute, we see\nsimilar results. Across Models 5 through 8, we see a consistent pattern whereby if a country\nis more democratic, Xinhua associates it with higher levels of corruption relative to CNA and\n21I use the Model 4 specification as the baseline model in subsequent regressions, as it is the most robust\nto omitted variable bias.\nPage 20\nAFP . This finding is not dependent on the inclusion or exclusion of fixed effects or control\nvariables, as pis less than 0.01 in all four cases. In sum, we see consistent evidence that\nsupports both hypotheses 1 and 2, i.e. as Xinhua shows a willingness to portray democracies\nas both chaotic and corrupt relative to alternative media outlets.\nT o illustrate how media framing by each publication changes over various levels of Polity ,\nI present the marginal effects of Polity on cosine similarity disaggregated by publication in\nFigure 2(see T able 18 in Appendix Ffor full disaggregated regression results). On the y-axis\nwe see the predicted cosine similarities between countries and attributes; on the x-axis we\nsee each level of Polity IV represented in our data. As before, standard errors are clustered\nat the country level.\nFigure 2: Marginal Effects of Regime Type on Country F raming\n2224262830\n\u221210 \u22125 0 5 10\nPolity IVA. Chaos\n22.525.027.530.0\n\u221210 \u22125 0 5 10\nPolity IVB. Corruption\nPublication AFP CNA XinhuaPredicted Similarity (%)\n22\nAs with T able 1, we see differences between the slopes of each media publication, with\nCNA and AFP showing strongly negative slopes as Polity increases.23With China\u2019s state\nmedia, we see a different pattern of behavior: on an absolute scale, Xinhua covers author-\n23This pattern is particularly pronounced for AFP , as the differential between a highly authoritarian\ncountry and a highly democratic country \u2013 with polity scores of -10 and 10, respectively \u2013 is approximately\n6%. This behavior is not unexpected. As discussed before, the literature indicates that underlying corruption\nlevels and political instability are negatively associated with levels of democracy .\nPage 21\nitarian countries with roughly equal levels of chaotic sentiment to democratic countries.\nHowever, compared to the baseline publications, we see relatively more chaos sentiment\nassociated with democracies. In contrast, when looking at the similarity of corruption sen-\ntiment across countries, we see differential coverage of autocracies, with Xinhua showing\nmuch lower levels of similarity .\nOne challenge with interpreting these findings is that it is not clear what aspects of\ncountries are being described as \u201cchaotic\u201d or \u201ccorrupt. \u201d If Xinhua is engaged in a negative\nlegitimation strategy , it will stand to reason that these attributes are targeted at the politics\nof democratic countries (hypotheses 3 and 4). W e examine whether that is the case in the\nregression models presented in T able 2. F or each of these models, the dependent variable\nis the average cosine similarity between a dictionary of terms representing \u201cpolitics\u201d and\n\u201cchaos\u201d or \u201ccorruption\u201d attributes for a given publication-country subcorpus. T o determine\nto what degree the results are influenced by control variables and fixed effects, they are\nsequentially included and excluded within each object-attribute pairing.\nT able 2: Impact of Regime Type on Association between Politics Object and Negative\nAttributes\nChaos Corruption\nModel (1) Model (2) Model (3) Model (4) Model (5) Model (6) Model (7) Model (8)\nIndependent V ariables\nXinhua \u221211.55*** \u221239.16*** \u221211.55*** \u221216.41 \u221210.58*** \u221216.37 \u221210.44*** 1.50\n(1.82)(10.74)(1.81) (9.96) (1.77)(12.93)(1.84)(10.59)\nXinhua x Polity (IV) 0.58** 0.77*** 0.58** 0.77*** 0.78*** 0.43* 0.76*** 0.50**\n(0.24) (0.20) (0.24) (0.15) (0.23) (0.25) (0.24) (0.23)\nStatistics\nObservations 180 126 180 126 179 126 179 126\nEffects\nCountry No No Yes Yes No No Yes Yes\n* p<0.1, ** p <0.05, *** p <0.01\nNote:\nDependent variable is defined as the average cosine similarity between dictionaries representing the object \u2013 politics \u2013 and the respective\nnegative attributes. Robust standard-errors are clustered at the country level and reported in parentheses. Full table with control\nvariables can be found in Appendix F.\nCollectively , these findings indicate that Xinhua frames the politics of democracies as\nbeing more chaotic and corrupt relative to CNA. In the case of the Politics-Chaos pairing,\nthis effect is quite significant, with a p-value of less than 0.01 and a coe\ufb00icient indicating that\nfor every one point increase in Polity , we see a 0.77 percent increase in similarity between\nPage 22\npolitics and similarity terms. Across the full range of Polity , this indicates a 16% increase\nin similarity . Looking at the Politics-Corruption attribute-object pair, we see a smaller but\nstill significant ( p < 0.05) increase in similarity as Polity increases. Overall, these patterns\nare consistent with the hypothesis that China\u2019s state media is using a negative legitimation\nstrategy: a news consumer who exclusively reads Xinhua News would come away with an\nimpression that the politics of democratic countries are far more chaotic than would a reader\nof CNA or AFP .\nRobustness\nThe results described above involve using a novel word embeddings-based measure of\npropaganda for which I had to make several potentially significant assumptions. T o what\nextent is the measure for propaganda valid? Do these results hold when my assumptions are\nrelaxed or when alternative measures are used? This section examines two validation checks\nand whether my findings are robust to alternative measurement configurations.\nV alidation\nOne potential criticism for the validity of my test of hypotheses three and four is that\nChina\u2019s state media may cover all affairs in democratic countries in a negative light, not\njust their politics. T o address this concern, I use a placebo object, \u201csports,\u201d as an alterna-\ntive to \u201cpolitics. \u201d Given the negative legitimation hypothesis, we have no reason to expect\ndifferential use of chaos and corruption sentiment towards sports news across publications\nand regime types. Accordingly , in T able 17 in Appendix F, I estimated four separate OLS\nmodels in which the dependent variables were the similarity of four attribute-object pairs:\nPolitics-Chaos, Politics-Corruption, Sports-Chaos, Sports-Corruption. As expected, I see no\nstatistically significant difference in how Xinhua and CNA frame sports across regime types.\nNext, I validate my findings for hypotheses 1 and 2 through the use of an alternative\nmeasurement strategy: using a measure of net sentiment as a proxy for media framing.\nPage 23\nThis approach is less precise than word embeddings because it is not useful for identifying\nspecific framing strategies. However, I expect it to be directionally consistent with the word\nembeddings approach. In sum, we see results consistent with expectations: when covering\ncountries that are more democratic, Xinhua uses more negative and less positive sentiment\nthan CNA and AFP . This analysis approach and the results are discussed in greater detail\nin Appendix D.\nAlternative Specifications\nOne potential concern with the results presented in T able 1is that this effect is driven\nentirely by one of the baselines, AFP or CNA. T o address this concern, I disaggregated this\nmodel, running separate analyses using CNA and AFP as separate baselines for Xinhua (see\nT able 18 in Appendix Fand Figure 2). I find that Polity x Xinhua remains statistically\nsignificant, whichever publication is held as a baseline. Moreover, when using CNA as a\nbaseline, Polity x Xinhua remains significant no matter whether the base period of 2001\nor 1992 is used (see T able 26).\nAdditionally , one might be concerned that these findings are a byproduct of the partic-\nular dictionary terms selected to represent the objects and attributes of interest. My main\nresults were generated using dictionaries produced by the conclust algorithm, which took as\ninputs a small selection of seed words and a word embeddings model fitted on the full Xinhua\nand CNA news corpus. T o determine whether my findings are dependent on this particular\ndictionary , I examine how they vary when I use an alternative set of dictionaries obtained by\napplying conclust to F acebook\u2019s fastText word embeddings model24. I find that the results\nobtained using the fastText dictionary are consistent with those of the baseline model (see\nT ables 19 and 20 in Appendix F). While we see that the fastText shows a significant decrease\nin the coe\ufb00icient estimates for the Politics-Chaos concept pair, the overall effect of Polity\n(Xinhua) is still positive and significantly different from zero at a 95% confidence level.\n24This model was fit on the Chinese-language text from the Common Crawl corpus and Wikipedia (Bo-\njanowski et al. 2017 )\nPage 24\nThe next set of checks involve reevaluating the skip-gram embedding models using\nwindow sizes of 5, 10, and 15 words. This entails varying the number of words considered\nthe \u201ccontext\u201d for any word and is used to fit the word embedding model. Larger windows give\nweight to more distant words from the target word, while smaller windows only give weight\nto words that appear within a narrow distance. If we found that the association between\nour objects and attributes was only present for larger windows, one could argue that the\nassociation between these terms is incidental. However, in T ables 21 and 22 in Appendix F,\nwe see significance at all levels of window size the coe\ufb00icients relevant to hypotheses 1, 2,\n3, and 4. This tells us that the observed associations between the objects and attributes in\neach instance are unlikely to be due to random word cooccurrence.\nF or hypotheses three and four, word embedding models were fit on country-publication\nsubcorpora; because word embedding model quality scales with the size of the corpus it\nwas fit upon, I excluded country-publication subcorpora from my analysis that had fewer\nthan 400 articles, as this is in the minimum range recommended by Rodman ( 2020 ).25As\nthe specific threshold I used in my analysis is somewhat arbitrary , I also examine how\nvarying this threshold from 300 to 600 articles influences my results. The results of this\nanalysis can be found in T able 23 in Appendix F. I find that increasing the minimum article\nnumber threshold does not meaningfully change the Xinhua x Polity coe\ufb00icient estimates\nfor the Politics-Chaos concept pair. However, there is a reduction in the magnitude of\nthe Polity coe\ufb00icient to insignificance for the Politics-Corruption concept pair when the\nminimum article threshold is set to 500; though increasing the threshold to 600 results in\nmarginal significance at a p < 0.1level. One possible explanation is that for many democratic\ncountries covered infrequently by Xinhua, the little coverage they receive tends to involve\npolitical corruption. In any case, these results support hypothesis 3, though it is equivocal\nto hypothesis 4.\nFinally , I performed additional checks to determine whether my results were due to\n25As a robustness check, I vary this threshold to see to what extent it influences my findings.\nPage 25\nthe particular measurement decisions made for my dependent variable. I used the weighted\naverage of term similarity for my dependent variable to compute the average similarity scores\nbetween concepts. This measurement strategy has advantages, such as assigning a higher\nweight to more frequent words. However, one could argue that the simple mean is more\nparsimonious. Accordingly , I check to see whether my findings still hold when using the\nsimple mean. In Appendix F, T able 24 shows the results for hypotheses 1 and 2, while\nT able 25 shows the results for hypotheses 3 and 4. W e see little difference compared to the\nbaseline model for hypotheses 1, 2, and 3, with a slightly larger coe\ufb00icient estimate in the\nlatter case. However, we see a smaller coe\ufb00icient estimate for Xinhua x Polity (IV) for\nthe Politics-Corruption concept pair to the extent that it is not statistically significant at the\n0.1 level. This result suggests that the weighted mean measure of similarity is working as\nintended: coe\ufb00icients in the unweighted results are smaller due to greater measurement error\ncaused by rarely occurring word pairs. Regardless, these results provide further evidence for\nhypotheses 1, 2, and 3, and against hypothesis 4.26\nOverall, changing model parameters, dictionaries, and other facets of my analysis gener-\nally paint a consistent picture with those presented in my baseline model. There appears to\nbe consistently robust evidence that the authoritarian media outlet, Xinhua News, portrays\ndemocratic politics as more chaotic than CNA and AFP , as was anticipated. Additionally ,\nthere was robust evidence that corruption sentiment is generally more strongly associated\nwith democratic countries than authoritarian countries in Xinhua\u2019s media coverage compared\nto baseline outlets. However, while there was some evidence indicating that this corruption\ncoverage was targeted toward the politics of democracies, this result appears to be sensi-\ntive to some model specifications, such as the inclusion of countries that are rarely covered\nand alternative measurement strategies for the dependent variable. Overall, these results\npresent strong evidence consistent with hypotheses 1, 2, and 3 but only equivocal evidence\n26As an additional check to ensure that these results were not driven by a single influential country , I\ndropped the United States from the pool of countries covered by Chinese and non-Chinese media. I find that\ndropping the United States does not meaningfully impact my findings. This suggests that Chinese media\ncovers democratic countries writ large with chaotic and corrupt sentiment.\nPage 26\nfor hypothesis 4.\nConclusion\nIn sum, I find strong evidence consistent with the argument that China\u2019s state media\ntends to portray liberal democracies as chaotic and corrupt. Moreover, I have provided\nevidence that they target the politics of democracies with chaotic and corruption senti-\nment, though the association between politics and corruption appears to be dependent on a\nnarrower range of model specifications. Overall, these findings are consistent with the predic-\ntions of the negative legitimation hypothesis: that authoritarian regimes seek to portray the\npolitics of alternative regime types in a negative light to maintain the tacit support of their\ncitizens. These conclusions have significant substantive and methodological implications.\nFirst, this study has significant implications for understanding how propaganda func-\ntions in authoritarian countries. This new evidence for negative legitimation is consistent\nwith the propaganda strategy described by Zhong ( 1996 ) and with the role that bench-\nmarking plays in belief formation as described by Huang ( 2015b ). However, it is notable\nthat a similar negative portrayal of foreign countries does not appear to be employed by\nChina\u2019s online army of social media influencers (King, Pan, and M. E. Roberts 2017 ). F ur-\nther study is needed to determine under what conditions this strategy is employed. Moreover,\nit remains to be seen whether the use of a negative legitimation strategy is limited to China\nor is broadly practiced by other authoritarian countries.\nSecond, the results of this paper suggest that while Chinese state media show a consis-\ntent pattern of framing democracies as relatively more chaotic and corrupt than baselines,\nthey appear to apply these attributes in different ways. F or instance, while Xinhua tends\nto cover chaotic events in autocracies similar to CNA and AFP , it frames democracies as\nrelatively more chaotic than the baselines. In contrast, authoritarian regimes are portrayed\nas being much less corrupt by Xinhua compared to the baselines. However, there is little\nPage 27\ndifference in their portrayal of countries with high levels of democracy . This suggests that\nXinhua may use negative rhetoric differently: to downplay autocratic corruption and high-\nlight democratic chaos. This finding may have important implications for how democracy\nand autocracy are perceived in countries like China. It also exemplifies the advantages of\nword embedding-based methods as a tool to perform analysis of propaganda.\nF urthermore, the procedure used by this paper to measure propaganda may have a wide\nvariety of applications beyond the limited study of propaganda in Chinese media. Using the\napproach pioneered by researchers like Rodman ( 2020 ) and expanded upon in this paper, it is\npossible to examine to what degree political actors are using specific propaganda strategies.\nAll that is required are dictionaries for the target object and attributes, politicized text, and\na control corpus.\nThese findings also have implications for the resilience of authoritarian regimes writ\nlarge. In this paper, I provide evidence that Chinese state media produces media content\nthat is consistent with a negative legitimation strategy supply of this propaganda, yet it\nremains to be seen whether this propaganda fulfills its purpose. Potentially , by framing\nalternative regime types as undesirable, autocracies have the power to shape the appeal\nof democracy to their citizens and thus their willingness of their citizens to challenge the\nregime, even when it performs poorly . Should such a link exist, it may help explain how\npoorly-performing autocracies, such as North Korea and Cuba, are able to prevent popular\nmovements demanding democratic reforms from emerging. I hope that future experimen-\ntal research will examine whether there exists a causal link between negative legitimation\nmessages and skepticism towards democratic reforms among citizens of autocracies.\nPage 28\nReferences\nAcemoglu, Daron, and James A. Robinson. 2006. Economic origins of dictatorship and\ndemocracy. Cambridge University Press.\nAd F ontes Media. 2021. \u201cAgence F rance-Presse Bias and Reliability.\u201d Ad F ontes Media.\nhttps://adfontesmedia.com/agence-france-presse-bias-reliability/ .\nAdena, Maja, Ruben Enikolopov, Maria Petrova, V eronica Santarosa, and Ekaterina Zhu-\nravskaya. 2015. \u201cRadio and the Rise of the Nazis in Prewar Germany.\u201d The Quarterly\nJournal of Economics, 1885\u20131939.\nAllSides. 2020. \u201cAFP F act Check Media Bias Rating.\u201d AllSides. https://www.allsides.com/\nnews-source/afp-fact-check-media-bias .\nApaza, Carmen R. 2009. \u201cMeasuring Governance and Corruption through the W orldwide\nGovernance Indicators: Critiques, Responses, and Ongoing Scholarly Discussion.\u201d ISBN:\n1049096509, PS: Political Science & Politics 42 (01): 139.\nAssemblee Nationale. 2012. \u201cAu Nom de La Commission Des Affaires Culturelles et de L n\neducation Sur Le Projet de Loi de Finances Pour 2012.\u201d https : / / www . assemblee -\nnationale.fr/13/budget/plf2012/a3806-tvii.asp#P115_11426 .\nBarbieri, Katherine, and Omar M. G. Keshk. 2016. \u201cCorrelates of war project trade data set\ncodebook, version 4.0.\u201d\nBattistella, Gautier, and Reporters Without Borders. 2005. The World\u2019s Biggest Propaganda\nAgency. T echnical report October.\nBojanowski, Piotr, Edouard Grave, Armand Joulin, and T omas Mikolov. 2017. \u201cEnriching\nW ord V ectors with Subword Information.\u201d Transactions of the Association for Compu-\ntational Linguistics 5:135\u2013146.\nPage 29\nBueno de Mesquita, Bruce, James D. Morrow, Randolph Siverson, and Alastair Smith. 2001.\n\u201cPolitical competition and economic growth.\u201d Journal of Democracy 12:58.\nCarter, Brett L, and Erin Baggott Carter. 2016. \u201cPropaganda and Protest : Evidence from\nPost-Cold W ar Africa,\u201d 1\u201330.\nChen, J. 2004. Popular political support in urban China. 1st. W ashington D.C.: W oodrow\nWilson Center Press.\nChen, Jie, Y ang Zhong, and Jan William Hillard. 1997. \u201cThe Level and Sources of Popu-\nlar Support for China\u2019s Current Political Regime.\u201d Communist and Post-Communist\nStudies 30 (1): 45\u201364.\nChen, Xueyi, and Tianjian Shi. 2001. \u201cMedia effects on political confidence and trust in the\npeople\u2019s republic of China in the post - Tiananmen period.\u201d East Asia 19 (3): 84\u2013118.\nChester, Patrick. 2024. \u201cEmbedded Lexica: Extracting Keywords from Unlabeled Corpora\nusing W ord Embeddings.\u201d\nChiang, Chun F ang, and Brian Knight. 2011. \u201cMedia bias and influence: Evidence from\nnewspaper endorsements.\u201d Review of Economic Studies 78 (3): 795\u2013820.\nDong, Zhendong, Qiang Dong, and Changling Hao. 2010. \u201cHowNet and its computation of\nmeaning.\u201d In Coling2010-23rdInternationalConferenceonComputationalLinguistics,\nProceedings of the Conference.\nDowns, Anthony. 1957. An Economic Theory of Democracy. 1st. 1\u2013310. New Y ork: Harper /\nRow.\nDrury, A. Cooper, Jonathan Krieckhaus, and Michael Lusztig. 2006. \u201cCorruption, Democ-\nracy, and Economic Growth.\u201d International Political Science Review 27 (2): 121\u2013136.\nPage 30\nEdel, Mirjam, and Maria Josua. 2018. \u201cHow authoritarian rulers seek to legitimize repression:\nframing mass killings in Egypt and Uzbekistan.\u201d Democratization 25 (5): 882\u2013900.\nEdmond, Chris. 2013. \u201cInformation manipulation, coordination, and regime change.\u201d Review\nof Economic Studies 80 (4): 1422\u20131458.\nF reeman, John R., and Dennis P . Quinn. 2012. \u201cThe economic origins of democracy recon-\nsidered.\u201d American Political Science Review 106 (1): 58\u201380.\nGarg, Nikhil, Londa Schiebinger, Dan Jurafsky, and James Zou. 2018. \u201cW ord Embeddings\nQuantify 100 Y ears of Gender and Ethnic Stereotypes.\u201d PNAS 115 (16): 635\u2013644.\nGehlbach, Scott, and Konstantin Sonin. 2014. \u201cGovernment control of the media.\u201d Journal\nof Public Economics 118 (October): 163\u2013171.\nGelman, Andrew, John B Carlin, Hal S Stern, David B Dunson, Aki V ehtari, and Donald B\nRubin. 2014. Bayesian data analysis. 661.\nGentzkow, Matthew, and Jesse M. Shapiro. 2006. \u201cMedia Bias and Reputation.\u201d Journal of\nPolitical Economy 114 (2): 280\u2013316.\nGibler, Douglas M. 2009. International Military Alliances, 1648-2008. Congressional Quar-\nterly Press.\nGlobal Times. 2021. America: Anti-Corruption Leader or Corruption Hub?\nGoldstone, Jack A, Robert Bates, David Lester Epstein, T ed Robert Gurr, Michael B Lustik,\nMonty G Marshall, Jay Ulfelder, and Mark W oodward. 2010. \u201cA Global Model for\nF orecasting Political Instability.\u201d American Journal of Political Science 54 (1): 190\u2013\n208.\nGroseclose, Tim, and Jeffrey Milyo. 2005. \u201cA Measure of Media Bias.\u201d The Quarterly Journal\nof Economics 120 (4): 1191\u20131237.\nPage 31\nHamilton, William L., Kevin Clark, Jure Leskovec, and Dan Jurafsky. 2016. \u201cInducing\ndomain-specific sentiment lexicons from unlabeled corpora.\u201d EMNLP 2016 - Confer-\nence on Empirical Methods in Natural Language Processing, Proceedings, 595\u2013605.\nHuang, Haifeng. 2015a. \u201cInternational Knowledge and Domestic Evaluations in a Changing\nSociety: The Case of China.\u201d American Political Science Review 109 (3): 613\u2013634.\n. 2015b. \u201cPropaganda as Signaling.\u201d Comparative Politics 47 (4): 419\u2013437.\nInternational Monetary F und. 2019. World Economic Outlook Indicators. W ashington D.C.\nJowett, Garth S., and Victoria O\u2019Donnell. 2018. Propaganda and Persuasion. Sixth. 462.\nLos Angeles: Sage.\nKenez, Peter. 1985. The Birth of the Propaganda State: Soviet Methods of Mass Mobilization.\n1\u2013324.\nKing, Gary, Jennifer Pan, and Margaret Roberts. 2013. \u201cHow Censorship in China Allows\nGovernment Criticism but Silences Collective Expression.\u201d American Political Science\nReview 107 (917): 326\u2013343.\nKing, Gary, Jennifer Pan, and Margaret E. Roberts. 2017. \u201cHow the Chinese government\nfabricates social media posts for strategic distraction, not engaged argument.\u201d American\nPolitical Science Review 111 (3): 484\u2013501.\nLee, Sungjick, and Han Joon Kim. 2008. \u201cNews keyword extraction for topic tracking.\u201d\nProceedings - 4th International Conference on Networked Computing and Advanced\nInformation Management, NCM 2008 2:554\u2013559.\nPage 32\nLi, Xiaotao, Shujuan Y ou, Y awen Niu, and W ai Chen. 2021. \u201cLearning Embeddings for\nRare W ords Leveraging Internet Search Engine and Spatial Location Relationships.\u201d In\nProceedings of *SEM 2021: The Tenth Joint Conference on Lexical and Computational\nSemantics, 278\u2013287. Proceedings of SEM 2021: The T enth Joint Conference on Lexical\nand Computational Semantics. Online: Association for Computational Linguistics.\nLittle, Andrew T. 2017. \u201cPropaganda and credulity.\u201d GamesandEconomicBehavior 102:224\u2013\n232.\nMarshall, Monty G., Keith Jaggers, and T ed Robert Gurr. 2017. \u201cPolity IV Project. Political\nRegime Characteristics and T ransitions, 1800-2016.\u201d Polity IV Project.\nMatthes, J\u00f6rg, and Matthias Kohring. 2008. \u201cThe content analysis of media frames: T oward\nimproving reliability and validity.\u201d Journal of Communication 58 (2): 258\u2013279.\nMattingly, Daniel, T revor Incerti, Changwook Ju, Colin Moreshead, Seiki T anaka, and\nHikaru Y amagishi. 2023. \u201cChinese State Media Persuades a Global Audience That the\n\u201cChina Model\u201d Is Superior: Evidence F rom A 19-Country Experiment.\u201d\nMedia Bias/F act Check. 2023. \u201cAFP (Agence F rance Presse) - Bias and Credibility.\u201d Media\nBias/F act Check. https://mediabiasfactcheck.com/afp-agence-france-presse/ .\nMontinola, GR, and R W Jackman. 2002. \u201cSources of corruption: A cross-country study.\u201d\nBritish Journal of Political Science 32:147\u2013170.\nNelson, Thomas E, and Zoe M. Oxley. 1999. \u201cIssue F raming Effects on Belief Importance\nand Opinion.\u201d The Journal of Politics 61 (4): 1040\u20131067.\nParker, R, D Graff, K Chen, J Kong, and K Maeda. 2011. \u201cChinese Gigaword Fifth Edition.\nLinguistic Data Consortium. Philadelphia.\u201d\nPetrova, Maria. 2011. \u201cNewspapers and parties: How advertising revenues created an inde-\npendent press.\u201d American Political Science Review 105 (4): 790\u2013808.\nPage 33\nQuinn, Kevin M., Burt L. Monroe, Michael Colaresi, Michael H. Crespin, and Dragomir R.\nRadev. 2010. \u201cHow to analyze political attention with minimal assumptions and costs.\u201d\nAmerican Journal of Political Science 54 (1): 209\u2013228.\nRaleigh, Clionadh, rew Linke, H\u00e5vard Hegre, and Joakim Karlsen. 2010. \u201cIntroducing ACLED:\nAn armed conflict location and event dataset.\u201d Publisher: Sage Publications Sage UK:\nLondon, England, Journal of peace research 47 (5): 651\u2013660.\nRehurek, Radim, and Petr Sojka. 2010. \u201cSoftware F ramework for T opic Modelling with\nLarge Corpora.\u201d Proceedings of the LREC 2010 Workshop on New Challenges for NLP\nFrameworks, 45\u201350.\nRich, Timothy S. 2009. \u201cStatus for sale: T aiwan and the competition for diplomatic recog-\nnition.\u201dIssues and Studies 45 (4): 159\u2013188.\nRoberts, Kirk. 2016. \u201cAssessing the corpus size vs. similarity trade-off for word embeddings\nin clinical NLP.\u201d In Proceedings of the Clinical Natural Language Processing Workshop\n(ClinicalNLP), 54\u201363.\nRodman, Emma. 2020. \u201cA Timely Intervention: T racking the Changing Meanings of Political\nConcepts with W ord V ectors.\u201d Political Analysis 28:87\u2013111.\nRothe, Sascha, Sebastian Ebert, and Hinrich Sch\u00fctze. 2016. \u201cUltradense word embeddings\nby orthogonal transformation.\u201d 2016 Conference of the North American Chapter of\nthe Association for Computational Linguistics: Human Language Technologies, NAACL\nHLT 2016 - Proceedings of the Conference, 767\u2013777.\nRozenas, Arturas, and Denis Stukal. 2019. \u201cHow autocrats manipulate economic news: Evi-\ndence from Russia\u2019s state-controlled television.\u201d Journal of Politics 81 (3): 982\u2013996.\nPage 34\nSpirling, Arthur, and Pedro L Rodriguez. 2021. \u201cW ord Embeddings What works, what\ndoesn\u2019t, and how to tell the difference for applied research.\u201d Journal of Politics, 1\u2013\n56.\nStockmann, Daniela. 2013. Media Commercialization and Authoritarian Rule in China. 1st.\n335. New Y ork: Cambridge University Press.\nSung, Hung-En. 2004. \u201cDemocracy and political corruption: A cross-national comparison.\u201d\nCrime, Law and Social Change 41 (2): 179\u2013193.\nW alton, Douglas. 1997. \u201cWhat Is Propaganda, and What Exactly Is W rong with It.\u201d Public\nAffairs Quarterly 11 (4): 383\u2013413.\nWhite, Stephen, Sarah Oates, and Ian Mcallister. 2005. \u201cMedia effects and Russian elections,\n1999-2000.\u201d British Journal of Political Science 35 (2): 191\u2013208.\nXinhua News. 2021. A Perspective on One of America\u2019s Illnesses: Legalized Corruption.\nY ang, Eddie, and Margaret E Roberts. 2021. \u201cCensorship of Online Encyclopedias : Impli-\ncations for NLP Models.\u201d\nY ang, Yi, Shimei Pan, Y angqiu Song, Jie Lu, and Mercan T opkara. 2016. \u201cImproving topic\nmodel stability for effective document exploration.\u201d In IJCAI International Joint Con-\nference on Artificial Intelligence, vol. 2016-Janua, 4223\u20134227. 2.\nZhang, Haoran, Amy X. Lu, Mohamed Abdalla, Matthew McDermott, and Marzyeh Ghas-\nsemi. 2020. \u201cHurtful words: Quantifying biases in clinical contextual word embeddings.\u201d\narXiv, 110\u2013120.\nZhong, Y ang. 1996. \u201cLegitimacy crisis and legitimation in China.\u201d Journal of Contemporary\nAsia 26 (2): 201\u2013220.\nPage 35\nZhou, Kaitlyn, Kawin Ethayarajh, and Dan Jurafsky. 2021. \u201cF requency-based Distortions in\nContextualized W ord Embeddings.\u201d\nPage 36\nF raming Democracy\nOnline Appendix\nAppendices\nA conclust\nBefore identifying the existence of an association between a particular attribute and\ntarget object in text, it is first necessary to identify a measure of both concepts. One intuitive\napproach would be to use a dictionary of interrelated words that collectively represent the\nmeaning associated with the target object. Accordingly , Chinese-language dictionaries for\nthe core concepts relevant to our hypotheses, such as politics and corruption, are needed.\nWhile there are no such dictionaries freely available, multiple methods exist for identifying\nkeywords in the extant literature. However, some of these approaches - such as topic models\n- give limited control to the researcher over what \u201ctopics\u201d or keyword clusters are produced\n(Y ang et al. 2016 ). Others based on deterministic algorithms, such as those that use tf-idf\nweights, fail to consider the context in which words are used (Lee and Kim 2008 ). I propose\na new algorithm, conclust , to address this gap.\nTheconclust algorithm bears similarities to methods employed by Rothe, Ebert, and\nSch\u00fctze ( 2016 ) and Hamilton et al. ( 2016 ) that are designed to extract semantically similar\nsentiment dictionaries from word embedding models. What differentiates conclust from\nRothe and Hamilton\u2019s models is that instead of being designed to extract dictionary pairs\nthat represent a latent polarity in text, it identifies the maximally self-similar word set to\nthe seed words provided by the user. Unlike Rothe and Hamilton\u2019s models, the keywords\nare not required to be adjectives or have any latent polarity dimension, allowing for the\nextraction of non-sentiment dictionaries, such as terms associated with the word \u201cpolitics\u201d .\nIn this application, conclust takes sets of four seed words, and a skip-gram word embeddings\nmodel fit upon the full Gigaword Xinhua and Central News Agency news corpora.27It then\noutputs four dictionaries that vary in length from 25 to 63 tokens.\n27The seed terms used to identify dictionaries using conclust and the fitted embedding model can be seen\nin Online Appendix A T able 3.\nPage A-1\nThe conclust function takes a fitted word embeddings model28and a set of seed words\nas inputs and estimates a similarity matrix between each pair of words in the corpus. Next,\nthe model identifies the word most similar to the existing seed words. In each subsequent\nstep, the next most similar word to the current set of words is added to the group. The\nalgorithm ends once either a maximum dictionary size has been reached or no word exists in\nthe corpus that has an average cosine similarity score to the current group members greater\nthan a user-chosen similarity threshold. The intuition behind this function is that at each\nstage, it adds new members to the dictionary that are most similar to the current set of\nmembers until a user-determined co-similarity or dictionary-size threshold is satisfied.\nAlgorithm 1: conclust\nInput: Seed words: S; Distance matrix: M ; Size threshold: n;\nSimilarity threshold: t\nResult: Keyword set: K\nK=S;\nwhile |K| \u2265ndo\n\u00afm=\u2200m\u2208M max(sim( K, m ));\nif mean(sim(K, \u00afm))\u2265tthen\nK=K\u222a\u00afm;\nelse\nbreak;\nend\nend\nF our concepts of interest were targeted using the conclust function: politics, sports,\nchaos, and corruption. The former two are considered to be target objects, as they represent\nconcepts that can and do frequently appear in the news. The latter two are attributes that\ntarget objects may possess to some degree. Politics, chaos, and corruption were selected to\nevaluate hypotheses 1 and 2. In contrast, sports was selected as a placebo.29\nThe seed words that were used to identify each concept are listed below (see T able 3).\n28The specific model used in this project is the skip-gram word embeddings model as implemented in\nPython\u2019s Gensim package (Rehurek and Sojka 2010 ). In a skip-gram model, a feed-forward neural network\nmaximizes the probability of other words for each given word in the corpus.\n29Sports was chosen as a placebo, because it is not clear how citizens would associate sports performance\nwith the quality of a country\u2019s political system; therefore, an authoritarian regime would benefit little for\nportraying the sports of democracies as being excessively corrupt or chaotic.\nPage A-2\nThe main criteria used to select terms was that each seed word should be an example of\nthe key concept as it would be used in human language. F or instance, articles that have\npolitical topics frequently describe actors such as presidents ( \u1239\u0e64 ) and prime ministers ( \u1239\n\u09d8). Likewise, examples of sports - such as soccer, basketball, and baseball - were used\nto identify other words used in similar contexts. T o identify chaos and corruption, I used\nadjectives with similar definitions to one another.\nT able 3: Seed words\nSeed word English definition Concept\n1\u0af6\u11f6 Democracy Politics\n2\u0fca\u0908 Election Politics\n3\u0f49\u0645 Constitution Politics\n4\u1239\u0e64 President Politics\n5\u1239\u09d8 Prime Minister Politics\n6\u0801\u0a79 Chaos Chaos\n7\u0a79\u0f60 Chaotic situation Chaos\n8\u0482\u03bd Unsettled Chaos\n9\u119a\u0a82 Argue Chaos\n10\u06aa\u03e7 Corruption Corruption\n11\u0e03\u06aa Corruption Corruption\n12\u0d73\u07f4 Accept bribe Corruption\n13\u0f9b\u07f4 T o bribe Corruption\n14\u1240\u0c6f Soccer Sports\n15\u09a5\u0c6f Basketball Sports\n16\u03ff\u0c6f Baseball Sports\n17\u10b3\u10a3 Swimming Sports\nThe skip-gram model used as an input for the conclust function was fit upon the\n10 thousand most frequently occurring terms in the Xinhua News, T aiwan Central News\nAgency , and Agence F rance Press news corpora from the Fifth edition gigaword corpus. The\nmodel estimated the probability of observing each term within a 10-word window of each\ntarget term. This model generated a 300\u00d710000 word embedding matrix with 300 word\nembedding dimensions and 10,000 columns representing each unique term used to fit the\nmodel.\nF rom the word embedding matrix and seed terms, the conclust algorithm identified 61\nPage A-3\npolitical terms, 63 sports terms, 25 corruption terms, and 38 chaos terms (see T ables 4-12\nin Online Appendix B). The minimum similarity threshold used to identify these terms was\nfixed at 35%, meaning the model added new members to the keyword set until no more words\nhad at least an average of 35% similarity to the current set of members. This threshold was\nchosen so that the dictionaries would be conceptually homogeneous, as too low a threshold\nmight include words that are beyond the scope of the target object.\nI perform a basic qualitative examination of the dictionaries produced by conclust by\nexamining their definitions and comparing them with those of the seed words and the target\nconcept. Overall, these dictionaries appear to be consistent with the target concepts. The\npolitical dictionary included terms, like election ( \u0fca\u0908 ), ruling party ( \u11b3\u119f\u0594,) and the names\nof several political parties. The sports dictionary included volleyball ( \u0b86\u0c6f ), gymnastics ( \u0e38\n\u04a0), and many other examples of sports, while the output for chaos and corruption were\nvirtually all either synonymous or directly related to the original seed words. In fact, there\nappear to be few if any words identified by the algorithm that were not in some way related\nto the target object.\nI also perform principal component analysis to identify whether concepts that we would\nexpect to cluster together, in fact do so. In particular, given that the terms are plotted\naccording to the first and second principal components, one would expect two patterns to\nemerge. First, words from the same concept should roughly cluster together. Second, because\ncorruption and chaos terms are more generally more likely to describe political events than\nsports events, one would expect that they would be more closely aligned with the cluster\nof political terms than sports terms. I perform this principal component analysis using the\n300\u00d710,000 dimension word embedding matrix derived used to identify the dictionary terms.\nPage A-4\nFigure 3: Concepts over First and Second Principal Components\nFigure 3displays the four dictionaries plotted against their first and second principal\ncomponents. The first and second principal components represent approximately 3.3% and\n2.9% of variation observed in the term-word embeddings matrix. The clustering of these\nwords conforms to expectations. First, terms in each dictionary cluster with other terms\nwithin the same dictionary . Second, the chaos and corruption terms cluster closely with the\nterms from the politics dictionary . These patterns also hold when the terms are evaluated\nover the third principal component. Generally , this suggests that descriptive words that\nare often to be used to describe politics tend to cluster with politics but not an unrelated\nconcept.\nIn sum, I used the conclust function to identify four sets of keywords that are intended\nto represent the target objects of politics and sports and the attributes of chaos and corrup-\ntion. This evidence is consistent with these keywords being reasonable approximations of\nthe target objects and attributes.\nPage A-5\nB Chinese Dictionaries\nT able 4: Keywords generated by conclust for Politics (1-25)\nT erm Definition Similarity (%)\n1\u11b3\u119f\u0594 ruling party , the party in power 54.37\n2\u119f\u0594 political party 51.05\n3\u111d\u1037\u0594 opposition party 49.62\n4\u0594\u0613\u0651 opposition (political) party 49.24\n5\u0594\u06be the party 48.78\n6\u0a06\u0594 two party 48.34\n7\u111d\u1037 to be out of (political) o\ufb00ice, to be out of power 46.85\n8\u0af6\u11f6\u0594 Democratic Party 46.47\n9\u09f3\u0786\u119f\u06a9 coalition government 46.18\n10\u06f2\u119f\u0594 each ruling party 46.03\n11\u0594\u06f2 each party 45.95\n12\u0d20\u0594\u07f6 socialist party 45.66\n13\u0cd8\u0594 three parties 45.47\n14\u0594\u0b3d within the party (esp. Chinese communist party) 45.12\n15\u0ca6\u0af6\u0594 People\u2019s party (of various countries) 44.80\n16\u0d20\u0af6\u0594 Social Democratic party 44.75\n17\u0576\u0fca general election 44.20\n18\u0fca\u0908 to elect, election 43.86\n19\u0594\u0b8a political party , faction 43.74\n20\u1194\u108f group of people, camp, faction, sides in a dispute 43.54\n21\u0af6\u0594\u08c9 Democratic Progressive Party (T aiwan) 43.28\n22\u0753\u0af6\u0594 Guomindang or Kuomintang (KMT) Nationalist Party\n(T aiwan)43.00\n23\u1231\u10ae\u0594 Liberal Party 42.83\n24\u11b3\u119f to hold power, in o\ufb00ice 42.30\n25\u1231\u0af6\u0594 Liberal Democratic Party (Japanese political party) 42.15\nPage A-6\nT able 5: Keywords generated by conclust for Politics (26-50)\nT erm Definition Similarity (%)\n26\u0f8d\u0594 New Party (Republic of China) 41.69\n27\u0d20\u07f6\u0af6\u11f6\u0594 Social Democratic Party 41.68\n28\u0594\u06f2\u0b8a each party , faction 41.62\n29\u0657\u09a1 pan-blue 41.55\n30\u07f6\u0753 Parliament (UK) Congress (US) Diet (Japan) 41.13\n31\u0753\u0576\u0594 Indian Congress party 41.06\n32\u09f3\u0ad0\u0594 Lega Nord (Italian political party) 40.81\n33\u1246\u06ee to form a cabinet 40.81\n34\u1231\u10ae\u0af6\u11f6\u0594 Liberal Democratic Party 40.28\n35\u10b7\u0b8a (political) right, right-wing, rightist 40.14\n36\u040c\u0d6f\u0594 conservative political parties 40.07\n37\u0b8a\u0f22 sect faction 40.06\n38\u0f8d\u119f\u06a9 new government 39.75\n39\u0594\u06fd worker\u2019s party , labor party 39.58\n40\u0753\u0c54 coalition between the T aiwanese Guomindang and Peo-\nple\u2019s First Party39.40\n41\u0fca\u07aa post-election 39.37\n42\u0613\u0651\u0b8a opposition faction 39.07\n43\u1239\u0e64\u0576\u0fca presidential election 38.90\n44\u0fca\u0c2d pre-election 38.50\n45\u0d3b\u0fca to win an election 37.66\n46\u04d4\u1037 all levels of society , the imperial court and the ordinary\npeople37.63\n47\u1070\u07f6\u0fca\u0908 parliamentary or legislative election 37.61\n48\u0fca\u0af6 voter, constituency , electorate 37.48\n49\u0fa9\u0f49 to amend the constitution 37.03\n50\u0b3d\u06ee( government) cabinet 36.82\nPage A-7\nT able 6: Keywords generated by conclust for Politics (51-61)\nT erm Definition Similarity (%)\n51\u0594\u0784\u070b Republican Party 36.80\n52\u0657\u0a73 pan-green 36.76\n53\u0c54\u0af6\u0594 People First Party (T aiwan) 36.65\n54\u0753\u0664\u0576 African National Congress (South Africa) 36.51\n55\u07a9\u0fca\u0ca6 candidate 36.34\n56\u1250\u0b8a (political) left, left-wing, leftist 36.32\n57\u0594\u098a faction leader, head of political party 36.29\n58\u0f49\u0645 constitution (of a country) 32.97\n59\u0af6\u11f6 democracy 32.01\n60\u1239\u0e64 president (of a country) 31.80\n61\u1239\u09d8 premier, prime minister 28.28\nNotes: Similarity (%) is the average cosine similarity of a term to other terms in the same dictionary . English\ndefinitions were obtained from the MDBG Chinese to English dictionary .\nPage A-8\nT able 7: Keywords generated by conclust for Sports (1-25)\nT erm Definition Similarity (%)\n1\u0b86\u0c6f volleyball 47.68\n2\u0d1d\u0870 archery , to shoot an arrow 46.32\n3\u09a5\u0c6f basketball 46.02\n4\u1d28\u0c88\u05a1 taekwondo (Korean martial art) 45.97\n5\u0e38\u04a0 gymnastic, gymnastics 45.37\n6\u10d5\u0ab0\u0c6f shuttlecock, badminton 45.12\n7\u0d6d\u0c6f team handball 44.89\n8\u0c77\u0750\u0c6f field hockey 44.34\n9\u121d\u0c6f table tennis, table tennis ball (T w), billiards, pool,\nsnooker (HK, Singapore, Malaysia)44.32\n10\u09c8\u0c6f softball 44.32\n11\u03ff\u0c6f baseball 44.14\n12\u0bd8\u0b93\u0c6f table tennis, ping-pong table, tennis ball 43.83\n13\u0908\u11d7 to lift weights, weight-lifting (sports) 43.54\n14\u0874\u080c fencing (sport) 43.50\n15\u1240\u0c6f soccer ball, a football, soccer, football 42.94\n16\u10d5\u0c6f badminton 42.86\n17\u0cbc\u05a1 judo 42.84\n18\u040c\u0a2d\u0c6f ten-pin bowling (loanword), bowling ball 42.81\n19\u0fca\u0d6d athlete, contestant 42.72\n20\u0e42\u08e5 track and field (athletics) 42.67\n21\u0c88\u080c boxing 42.06\n22\u18c3\u18a1\u0c6f football played with oval-shaped ball (rugby , American\nfootball, Australian rules etc)41.80\n23\u082f\u08e9 competition of skill (e.g. sports), athletics, tournament 41.79\n24\u0ea9\u0c6f tennis, tennis ball 41.71\n25\u120f\u0c6f billiards, billiards ball, pool (game) 41.34\nPage A-9\nT able 8: Keywords generated by conclust for Sports (26-50)\nT erm Definition Similarity (%)\n26\u0cd7\u0e58 boat race, racing ship or boat, rowing (sport) 41.07\n27\u0753\u0d6d (sports) member of the national team, national repre-\nsentative (medicine, chess etc)40.82\n28\u0b6f\u1240 women\u2019s soccer 40.72\n29\u11cf\u0612\u07bf Chinese team 40.66\n30\u0431\u0cd7 competition (sports etc), match, to compete 40.66\n31\u11cf\u0612\u0753 China\u2019s team 40.64\n32\u110e\u05ee\u10f4 athlete 40.38\n33\u0b6f\u0612 women\u2019s team 40.21\n34\u0b33\u0612 men\u2019s team 40.07\n35\u0b6f\u0b86 women\u2019s volleyball abbr. for \u0b6f\u1230\u0b86\u0c6f 39.96\n36\u0612\u0845\u0753 the national team 39.73\n37\u0c6f\u0612 sports team (basketball, soccer, football etc) 39.60\n38\u10b3\u10a3 swimming, to swim 39.57\n39\u0462\u0c6f ice hockey , puck 39.43\n40\u0e38\u10e2 sports, physical education 39.40\n41\u089d\u0a00 instructor, sports coach, trainer 39.29\n42\u057d\u0456\u0612 delegation 39.28\n43\u0e38\u10e2\u110e\u05ee sports, physical culture 39.22\n44\u0b6f\u09a5 women\u2019s basketball 39.20\n45\u0d99\u1d2f to trip and fall, to wrestle wrestling (sports) 38.29\n46\u0b6f\u0fca\u0d6d female player 37.57\n47\u0cd7\u0d59 competition (e.g. sporting) 37.49\n48\u0bc3\u07c3\u0e58 canoe, kayak 37.49\n49\u0c42\u0b87 contract bridge (card game) 37.44\n50\u0c6f\u10f4 sports club member: footballer, golfer etc 36.88\nPage A-10\nT able 9: Keywords generated by conclust for Sports (51-63)\nT erm Definition Similarity (%)\n51\u0eb6\u0c04 the game of Go 36.84\n52\u083d\u0753\u0f60\u0c04 chess 36.73\n53\u0b33\u09a5 men\u2019s basketball, men\u2019s basketball team 36.67\n54\u0495\u0cd7 to compete, to take part in a competition 36.66\n55\u0ef3\u0d8c military skill or technique (in former times), all kinds\nof martial art sports (some claiming spiritual develop-\nment)36.52\n56\u0e76\u0e38\u0cd7 team competition 36.35\n57\u0495\u0cd7\u0fca\u0d6d contestant 36.09\n58\u0f60\u0c04 Chinese chess 35.93\n59\u0e38\u0e06 sporting circles the world of sport 35.83\n60\u0e4b\u0da3 to dive (into water) (sports), diving, to commit suicide\nby jumping into water (fig.), (of stock prices etc) to fall\ndramatically35.64\n61\u07bd\u1022\u07c1\u0462 figure skating 35.52\n62\u1240\u0c6f\u110e\u05ee soccer 35.27\n63\u0dce\u07c1 speed skating 34.84\nNotes: Similarity (%) is the average cosine similarity of a term to other terms in the same dictionary . English\ndefinitions were obtained from the MDBG Chinese to English dictionary .\nPage A-11\nT able 10: Keywords generated by conclust for Corruption (1-25)\nT erm Definition Similarity (%)\n1\u0d73\u07f4 to accept a bribe 51.24\n2\u0e03\u16e0 (of an o\ufb00icial) corrupt and negligent of his duty 50.18\n3\u0f9b\u07f4 to bribe, to give bribes 49.25\n4\u0e03\u0eea to be corrupt, corruption, to embezzle 48.23\n5\u0eb4\u0645 illegal, to break the law 47.43\n6\u07f4\u0a5f to bribe, a bribe 45.93\n7\u0482\u0645 lawless, illegal, unlawful 45.14\n8\u0b73\u10a8 to shift (funds) to (legitimately), to embezzle, to mis-\nappropriate45.13\n9\u0d6c\u0d73 to receive, to accept 42.86\n10\u0e6d\u09e6 to seek one\u2019s benefit 42.27\n11\u0704\u097b public money 41.48\n12\u0d1f\u03c3 (of a perpetrator, victim, weapon, sum of money etc)\nto be involved in the case40.75\n13\u0eb4\u0840 lack of discipline, to break a rule, to violate discipline,\nto breach a principle40.14\n14\u0ef7\u0440 to engage in fraud 40.14\n15\u0d3e\u11af to lose one\u2019s job, unemployment, dereliction of duty 40.10\n16\u0eb4\u0645\u0f9b\u0eb9 illegal behavior 39.85\n17\u06aa\u03e7 corruption, to corrupt, to rot, rotten 39.66\n18\u0d1f\u0f40 to be a suspect (in a crime), to be suspected of 39.30\n19\u114a\u0bfa fraud, deception 39.17\n20\u08b2\u070d to collude with, to collaborate with, to gang up with 39.16\n21\u04b0\u03f7 to investigate and handle (a criminal case) 38.94\n22\u0eb4\u073f to violate (rules), irregular, illegal, corrupt 38.67\n23\u0440\u03c3 scandal 37.71\n24\u0c53\u115d to invade and occupy (territory) 37.44\n25\u0e03\u06aa corruption 36.73\nNotes: Similarity (%) is the average cosine similarity of a term to other terms in the same dictionary . English\ndefinitions were obtained from the MDBG Chinese to English dictionary .Page A-12\nT able 11: Keywords generated by conclust for Chaos (1-25)\nT erm Definition Similarity (%)\n1\u1e88\u0e6c conflict 55.28\n2\u0674\u119a to dispute 54.82\n3\u050a\u0e6c conflict, to conflict, clash of opposing forces, collision\n(of interests), contention54.76\n4\u05ee\u0a79 turmoil, upheaval, unrest 53.74\n5\u0a40\u0fd3\u050a\u0e6c bloody conflict 53.50\n6\u119f\u11cd\u0eb2\u080f political crisis 49.54\n7\u0ef3\u120d\u050a\u0e6c armed conflict 49.24\n8\u119a\u11b3 to dispute, to disagree, to argue opinionatedly , to wran-\ngle48.86\n9\u0412\u0a79 riot, rebellion, revolt 48.49\n10\u0eb2\u080f crisis 46.96\n11\u0b3d\u115e civil war 45.58\n12\u08c5\u1166\u0905\u0d5d tense situation 45.32\n13\u119a\u060a dispute, controversy , conflict 45.25\n14\u115e\u0d59 war, hostilities, fighting 44.52\n15\u0595\u05ee unrest (social or political), turmoil, upheaval, commo-\ntion43.57\n16\u0ce0\u0a79 disturbance, riot, to create a disturbance 43.46\n17\u0613\u09eb to oppose, to set sth against, to be antagonistic 43.15\n18\u0412\u05ee insurrection, rebellion 42.96\n19\u0412\u09ef\u0d59\u0871 violent event 42.73\n20\u119a\u1070 controversy , dispute, to dispute 42.20\n21\u0b09\u0488 friction, rubbing, chafing, fig. disharmony , conflict 41.05\n22\u0613\u11c4 to stand, opposite to, confront, confrontation 40.89\n23\u0673\u0c06 divergent, difference (of opinion, position) disagreement 39.88\n24\u119a\u0a82 to argue, to debate, to contend, argument, contention,\ncontroversy , debate39.73\n25\u115e\u119a war, conflict 39.53Page A-13\nT able 12: Keywords generated by conclust for Chaos (26-38)\nT erm Definition Similarity (%)\n26\u0ab1\u061b contradiction, conflicting views, contradictory 39.00\n27\u115e\u0a79 chaos of war 38.89\n28\u0674\u08ef dispute 38.85\n29\u0836\u08dc\u0eb2\u080f economic crisis 38.19\n30\u0684\u046f disturbance, crisis, disputes, restlessness 38.04\n31\u087a\u0905 impasse deadlock 38.01\n32\u0c06\u086e disagreement, differing interpretations 37.57\n33\u0613\u05b1 hostile, enemy (factions), combative 37.28\n34\u08c5\u1166 nervous, keyed-up, intense, tense, strained, in short sup-\nply , scarce37.00\n35\u0801\u0a79 confusion, chaos, disorder 36.49\n36\u115e\u0805 conflagration, the fire of war 36.23\n37\u0482\u03bd unpeaceful, unstable, uneasy , disturbed, restless, wor-\nried34.50\n38\u0a79\u0f60 chaos, madness 34.04\nNotes: Similarity (%) is the average cosine similarity of a term to other terms in the same dictionary . English\ndefinitions were obtained from the MDBG Chinese to English dictionary .\nPage A-14\nC Country Label Assignment\nAssigning high-dimensional labels to text data has been a consistent challenge in data\nscience. Supervised machine learning models tend to struggle with this challenge, as it is\nvery costly for human coders to label a su\ufb00icient amount of data for rarely occurring label\nvalues to be predicted with accuracy .\nAssigning country labels to international news articles is a perfect example of this\ndilemma. There are 193 countries that the United Nations recognize, which are not dis-\ncussed in the media in a symmetric way (see Figure 4). Without an impractically large\ntraining data set, a supervised machine learning model would struggle to accurately assign\ncountry labels to articles, particularly for rarely occurring labels.\nFigure 4: International T ext V olume Published by Publication\nAfghanistan\nAlbaniaAlgeriaAngolaArgentina Australia\nAustria\nAzerbaijanBangladesh\nBelarusBelgium\nBoliviaBrazil\nBulgaria CambodiaCanada\nChileChina\nColombiaCuba\nDenmark\nEast TimorEgypt\nEl Salvador\nFijiFinland\nGeorgiaGermany\nGreece\nGuatemalaGuineaHaitiHong Kong\nHungary\nIcelandIndia\nIndonesiaIranIraq\nIrelandIsrael\nItalyJapan\nJordanKazakhstanKenya\nKuwait\nKyrgyzstan\nLaosLebanon\nLibya\nLithuania\nLuxembourgMacao\nMalaysia\nMaliMexicoMongolia\nMyanmarNepalNetherlands\nNew Zealand\nNicaragua\nNigerNigeriaNorth Korea\nNorwayPakistanPalestinian National Authority\nPanama\nParaguayPeruPhilippinesPoland\nPortugal\nQatarRepublic of MacedoniaRomaniaRussia\nSaudi Arabia\nSenegalSerbiaSingapore\nSlovakiaSomaliaSouth AfricaSouth Korea\nSpain\nSri LankaSudanSweden\nSwitzerland\nSyriaTaiwan\nThailand\nTurkey UkraineUnited KingdomUnited States\nUruguayVenezuelaVietnam\nYemen\n681012\n6 8 10 12\nlog(Tokens) CNAlog(Tokens) Xinhua\n\u221210\u221250510Polity\nGiven this problem, a dictionary-based approach offers some advantages. It is compu-\ntationally fast and can be a powerful tool to classify documents given a set of assumptions\n(Quinn et al. 2010 ):\n1. Categories are known\n2. Category nesting, if any , is known\nPage A-15\n3. Relevant text features are known\n4. Mapping is known\n5. Coding can be automated\nIn this particular use case, each of these conditions is satisfied. First, there are a finite\nnumber of countries in the world; likewise, a limited number of terms are commonly used to\ndescribe them in each language. Second, countries are, for the most part, separate entities,\nwhere each word used to describe a country refers to that country alone, so there is little\nnesting of concern. Third, names of countries are public knowledge, accessible in practically\nevery relevant language in publicly available databases provided by the United Nations and\nother international organizations.\nIn this section, I briefly validate several dictionary methods designed to assign country\nlabels to news articles using a set of 2000 human-labeled news articles randomly drawn from\nthe Chinese Gigaword 5 news corpus. I instructed the research assistant to assign labels that\nbest describe 1) the location of the event described in the article and 2) the actors described\nin the news article.30\nWith these human-coded articles, I compare the performance of three different dictio-\nnary algorithms for assigning country labels to text.\n1. plurality rule: an article is determined to be about a given country if it is mentioned\nmore times than any other.\n2. majority rule: an article is determined to be about a given country if at least 50% of\nthe mentions of a country in an article are of that country; articles in which no country\nis mentioned a majority of the time are excluded from the analysis.\n30I removed any mention of the publication name in each article and converted the text to simplified\nChinese to decrease the potential for bias.\nPage A-16\n3. consensus rule: an article is determined to be about a given country if it is the only\ncountry mentioned in the article; articles in which more than one country is mentioned\nare excluded from the analysis.\nThere are two trade-offs associated with these three rules. First, stricter rules are more\nlikely to assign country labels to articles accurately . However, the more stringent rules will\nalso exclude articles that may have been correctly labeled and relevant to the analysis. The\nfirst trade-off is measured using classification accuracy \u2013 correctly classified articles over the\ntotal number, while the second is operationalized using the percentage of unlabeled articles\nusing each algorithm. The following analysis aims to characterize the degree to which these\ntrade-offs are present across each classification rule to inform which rule should be applied\nin my primary analysis.\nIn Figure 5, we can see the performance of dictionary classification across each assign-\nment rule. The plurality rule shows a 66.35% classification accuracy rate across the 2000\nlabeled articles. With this rule, all documents are assigned a label. In contrast, the majority\nrule sees a 70.68% accuracy rate, while 15.75% of articles are unlabeled and excluded from\nthat statistic. Finally , the consensus rule sees the highest overall accuracy , with 78.45% of\narticles being labeled correctly; however, 55.45% of articles received no label, making this\nrule the most costly of the three to implement.\nPage A-17\nFigure 5: Country Assignment Algorithm Performance\nAccuracy Lost Articles\nPlurality Majority Concensus020406080\n020406080\nRule TypePercent\nThese results suggest that there indeed is a significant trade-off across the accuracy and\narticle loss rates of these three dictionary assignment rules. The changes in accuracy across\nrules are non-trivial, as the most inaccurate rule (plurality) has a 12% lower classification\nrate than the most accurate rule (consensus); however, the differences in article loss are\nmuch more significant. The consensus rule, in particular, appears to fare a steep trade-off\nin unlabeled articles relative to gains in accuracy . Compared to the majority rule, it is only\n7.8% more accurate but fails to label 39.7% more articles. Given these results, I use the\nplurality rule for my main analysis, as it offers reasonably high classification accuracy for no\nloss of articles.\nPage A-18\nD Sentiment Benchmark\nOne challenge of using word embeddings as a measurement tool is that it is quite new\nrelative to existing methodologies. Accordingly , it is valuable to examine whether similar\nresults can be replicated using better understood text as data methodologies. T o this end,\nI examine the frequency of net sentiment generally , and of the attributes used in my word\nembedding analysis.\nF or my sentiment analysis I use the HowNet Chinese sentiment dictionary to quantify\nthe average net sentiment at the subcorpus level, i.e. at the level of publication-country-\nquarter (Dong, Dong, and Hao 2010 ). I measure sentiment by taking the average net positive\ntokens ( Pi) and negative tokens ( Ni) at the level of the article, i, and take the mean of these\naverage sentiments across all articles in a given subcorpus, N:\nTone i=\u2211N\niPi\u2212Ni\u2211N\niTokens i(4)\nIn addition to measuring average net sentiment, I examine to what extent the use of\npositive and negative sentiment varies across publications. Accordingly , I decompose 4into\npositive and negative sentiment over the total word count:\nRate i=\u2211N\niAi\u2211N\niTokens i(5)\nGiven hypotheses one and two, I expect that Xinhua will produce relatively negative\nnet sentiment the more democratic a country is relative to the baseline news publications,\nCNA and AFP . Likewise, I expect that Xinhua\u2019s news coverage of democracies will use\nhigher proportions of negative sentiment and lower levels of positive sentiment compared to\nnon-democracies and the baselines.\nYpct=\u03b1+\u03b21GctPp+\u03b22Gct+\u03b23Pp+\u03b2PpXpct+\u03b2X pct+\u03b3c+\u03c9t+\u03f5pct (6)\nPage A-19\nT o test these hypotheses, I again estimate a three-way fixed-effects regression in which\nthe units of analysis are the publication-country-quarter and the independent variable is the\ninteraction between Xinhua ( Pp) and Polity IV ( Gct). When using Tone pct as the dependent\nvariable, I expect the coe\ufb00icient of interest, \u03b21to be negative and statistically significant.\nThis would indicate that Xinhua covers democratic countries with a more negative tone as the\ncountry covered becomes more democratic. Conversely , when using Rate pct as the dependent\nvariable, I expect \u03b21to be negative for positive sentiment frequency and negative for negative\nsentiment. This would suggest that Xinhua uses relatively more negative sentiment and less\npositive sentiment when covering democracies. T o limit risk of omitted variable bias, control\nvariables as well as publication, country , and time fixed-effects are included in each model.\nPage A-20\nT able 13: Impact of Regime Type on Sentiment Metrics By Publication\nTone Rate (Positive) Rate (Negative)\nIndependent V ariables\nXinhua 0.75(1.63) 1.38(0.61)** \u22121.68(0.41)***\nCNA 3.71(1.49)** 0.83(0.38)** \u22120.60(0.24)**\nPolity (IV) 0.03(0.02)** 0.02(0.01) \u22120.02(0.01)***\nXinhua x Polity (IV) \u22120.06(0.02)*** \u22120.03(0.01)* 0.03(0.01)***\nControl V ariables\nCountry Terms (Freq) 0.09(0.05)** 0.13(0.04)*** 0.05(0.03)**\nAttribute Term (Freq) \u22120.17(0.17)\nImports (USD) 0.00(0.05) 0.01(0.04) 0.01(0.03)\nTrade Balance (USD) 0.00(0.00) 0.00(0.00) 0.00(0.00)\nGDP (log) 0.33(0.40) 0.05(0.32) \u22120.27(0.27)\nGDPPC (log) \u22120.11(0.37) 0.09(0.28) 0.19(0.27)\nInflation (%) 0.00(0.01) 0.01(0.01) 0.01(0.01)\nBilateral Treaty (Count) 0.05(0.19) 0.01(0.14) \u22120.02(0.12)\nConflict (Freq) 0.00(0.04) \u22120.01(0.03) \u22120.02(0.03)\nCorruption Index \u22120.13(0.07)* \u22120.02(0.06) 0.11(0.03)***\nCNA x Country Terms (Freq) \u22120.01(0.04) \u22120.12(0.04)*** \u22120.06(0.03)**\nXinhua x Country Terms (Freq) \u22120.12(0.06)* \u22120.07(0.05) 0.04(0.04)\nCNA x Attribute Term (Freq) \u22120.28(0.18)\nXinhua x Attribute Term (Freq) 0.30(0.20)\nCNA x Imports (USD) 0.09(0.07) 0.06(0.06) \u22120.06(0.04)\nXinhua x Imports (USD) 0.11(0.08) 0.10(0.07) \u22120.03(0.05)\nCNA x Trade Balance (USD) 0.00(0.00) 0.00(0.00) 0.00(0.00)\nXinhua x Trade Balance (USD) 0.00(0.00) 0.00(0.00) 0.00(0.00)\nCNA x GDP (log) \u22120.09(0.07) 0.03(0.07) 0.09(0.04)**\nXinhua x GDP (log) \u22120.07(0.10) \u22120.15(0.08)* \u22120.06(0.06)\nCNA x GDPPC (log) \u22120.11(0.08) \u22120.06(0.06) 0.09(0.04)**\nXinhua x GDPPC (log) \u22120.18(0.14) 0.02(0.10) 0.19(0.07)***\nCNA x Inflation (%) 0.00(0.01) \u22120.01(0.01) \u22120.01(0.00)**\nXinhua x Inflation (%) 0.01(0.01) 0.00(0.01) \u22120.01(0.00)**\nXinhua x Bilateral Treaty (Count) \u22120.02(0.38) 0.26(0.26) 0.31(0.20)\nCNA x Conflict (Freq) \u22120.03(0.03) 0.00(0.03) 0.05(0.02)**\nXinhua x Conflict (Freq) 0.00(0.06) \u22120.02(0.04) \u22120.03(0.04)\nCNA x Corruption Index 0.10(0.04)*** 0.03(0.03) \u22120.07(0.02)***\nXinhua x Corruption Index 0.18(0.06)*** 0.06(0.04) \u22120.12(0.04)***\nStatistics\nObservations 12 013 12 013 12 013\nFixed effects\nCountry Yes Yes Yes\nYear Yes Yes Yes\nNote:\nIn each model a separate dependent variable is used. For Tone, the outcome is the average net\nsentiment (P - N / Total), where P is the positive token count, N is the negative token count, and\nTotal is the total word count associated with a given publication-country-quarter subcorpus. For Rate\n(Positive) and Rate (Negative) the outcome is (A / Total) where A is the total number of tokens\npositive or negative tokens associated with a given subcorpus. Robust standard-errors are clustered at\nthe country level and reported in parentheses: * p < 0.10, **p < 0.05, ***p < 0.01\nPage A-21\nT able 13 shows the results of the models described in Equation 6. In Model 1, the\ndependent variable is T one, i.e. the difference in positive and negative sentiment for a given\nsubcorpus. As expected, the coe\ufb00icient associated with Xinhua \u00d7Polity is both negative\nand statistically significant at the 0.05 level. This suggests that Xinhua targets countries\nthat are more democratic with more negative news coverage than they do non-democracies.\nWhen we decompose T one into positive and negative sentiment, we see that this effect\nis largely symmetric: Xinhua uses relatively more negative and less positive sentiment with\ndemocracies. The coe\ufb00icients estimated in Models 1, 2, and 3 are each statistically significant\nat the 0.01 level.\nOverall, results from this sentiment analysis are in line with my main findings: Xin-\nhua targets democracies with negative sentiment and less positive sentiment compared to\nalternative news publications.\nPage A-22\nE Concept Similarity Metrics\nWhen applying word embedding methods to data with the goal of measuring the degree\nto which dictionaries are similar to one another, researchers oftentimes need to compute the\naverage similarity of word pairs across groupings of keywords or dictionaries. F or instance,\nif a researcher wishes to know the average similarity between politics and chaos , they\nmust aggregate across each pairing of words representing each concept. Here, let\u2019s say that\npolitics is represented by [\u2019government\u2019, \u2019president\u2019] and chaos by [\u2019unstable\u2019, \u2019chaotic\u2019]. Each\nof those term pairs have respective similarities as they appear in text and word frequencies,\nindicating how often each term appeared in the text:\nT able 14: Sample W ord Pair Similarity T able\nPolitics Chaos Politics (F req) Chaos (F req) Similarity (%)\ngovernment unstable 15 8 40\ngovernment chaotic 15 3 80\npresident unstable 5 8 60\npresident chaotic 5 3 75\nGiven that the researcher wishes to know how similar these concepts are to one another,\nthe most obvious means of doing so is to compute the average cosine similarity across each\nword pair:\nE[C] =\u2211N\nici\nN(7)\nWhile this approach is intuitive, it has two flaws. First, not all terms are equally\nrepresented in the text. In the example above, the term \u2018government\u2018 occurs at three times\nthe rate of president in the text; yet, similarities computed using the former are given equal\nweight to the latter using the simple mean. As a consequence, this measure may be biased by\nthe inclusion of rarely occurring words in concept dictionaries. The second problem is that\nword vectors for rarely occurring words may be poorly fitted, which may result in higher rates\nPage A-23\nof both random and systemic measurement error.(Li et al. 2021 ) T o address these concerns,\npropose the use of a mean weighted by term frequency .\nI define Cijas the harmonic mean of two weighted average cosine similarity scores: \u00afci\nand \u00afcj. The first term, \u00afciis weighted by the frequency of terms of the attribute, and the\nsecond is weighted by the frequency of terms of the target object.\nCij=\u221a\n\u00afci\u00d7\u00afcj (8)\nwhere\n\u00afci=\u2211n\nk=1wikck\u2211n\nk=1wik(9)\nThe output of Equation 8,Cpcij , represents the aggregate cosine similarity between\nattribute iand target object jfor the coverage of publication pof country c. This represents\nhow strong an association exists for this pair of concepts in the text written about a country\nby a given publication.\nThe advantage this measure offers over the unweighted mean across all elements m\u2208M\nis that the final result is weighted by the frequency of terms of both the target object and\nthe attribute; thus, the final value will be weighted to reflect the similarity between term\npairs that occur more frequently . Consequently , the weighted average similarity score would\nbetter reflect the degree to which these concepts are related from the perspective of a human\nreader of the text.\nPage A-24\nF Supplemental Analysis\nF.1 F ull Models\nPage A-25\nT able 15: Impact of Regime Type on Association between Country labels and Negative Attributes\nChaos Corruption\nModel (1) Model (2) Model (3) Model (4) Model (5) Model (6) Model (7) Model (8)\nIndependent V ariables\nXinhua \u221210.22(0.40)*** \u221238.73(3.61)*** \u221213.25(0.40)*** \u221224.57(2.89)***\nCNA \u22123.89(0.61)*** \u22125.42(0.55)***\nPolity (IV) \u22120.52(0.07)*** \u22120.21(0.05)*** \u22120.45(0.06)*** \u22120.19(0.04)***\nXinhua x Polity (IV) 0.26(0.05)*** 0.15(0.04)*** 0.28(0.05)*** 0.13(0.04)*** 0.26(0.05)*** 0.17(0.03)*** 0.28(0.05)*** 0.16(0.04)***\nControl V ariables\nCountry Terms (log) \u22122.00(0.27)*** \u22122.74(0.31)*** \u22122.87(0.15)*** \u22123.22(0.26)***\nAttribute Terms (Freq) \u22127.75(0.34)*** \u22127.05(0.18)***\nImports (USD) \u22120.64(0.19)*** \u22120.40(0.24)* \u22120.15(0.17) 0.10(0.22)\nTrade Balance (USD) 0.00(0.00) 0.00(0.00) 0.00(0.00) 0.00(0.00)\nGDP (log) \u22120.39(0.38) \u22120.41(0.31)\nGDPPC (log) 0.54(0.35) 0.25(0.34)\nInflation (%) 0.00(0.02) \u22120.05(0.02)**\nBilateral Treaty (Count) \u22121.73(1.28) \u22123.21(1.36)** \u22122.99(0.96)*** \u22123.83(1.15)***\nConflict (Freq) 0.49(0.23)** 0.42(0.18)**\nCorruption Index \u22120.95(0.21)*** \u22120.59(0.18)***\nXinhua x Country Terms (log) 0.24(0.19) 0.42(0.41) 0.58(0.22)*** 0.94(0.29)***\nXinhua x Attribute Terms (Freq) 4.18(0.42)*** 2.00(0.39)***\nXinhua x Imports (USD) \u22120.61(0.27)** \u22120.69(0.38)* \u22120.23(0.25) \u22120.64(0.35)*\nXinhua x Trade Balance (USD) 0.00(0.00) 0.00(0.00) 0.00(0.00) 0.00(0.00)\nXinhua x GDP (log) 0.90(0.34)*** 0.70(0.47) 0.53(0.34) 0.72(0.46)\nXinhua x GDPPC (log) \u22120.48(0.27)* 0.26(0.37) \u22120.36(0.27) 0.34(0.34)\nXinhua x Inflation (%) 0.02(0.02) 0.02(0.03) 0.05(0.02)** 0.02(0.02)\nXinhua x Bilateral Treaty (Count) 1.53(1.76) 2.84(1.51)* 3.70(1.32)*** 4.93(1.26)***\nXinhua x Conflict (Freq) \u22120.35(0.17)** \u22120.02(0.20) \u22120.44(0.14)*** \u22120.15(0.15)\nXinhua x Corruption Index 0.50(0.17)*** 0.16(0.21) 0.16(0.16) \u22120.15(0.20)\nStatistics\nObservations 15 828 13 483 15 828 13 483 15 828 13 483 15 828 13 483\nFixed effects\nFE No No Yes Yes No No Yes Yes\nNote:\nDependent variable is defined as the average cosine similarity between dictionaries representing countries and the respective attribute. Fixed-effects include country, year, publication-year, and\ncountry-year effects. Robust standard-errors are clustered at the country level and reported in parentheses: * p < 0.10, **p < 0.05, *** p < 0.01\nPage A-26\nF.2 Controls\nT able 16: Covariate Summary Statistics and Sources\nN Mean SD Min Max Source\nPolity IV 180 3.94 6.36 \u221210.00 10.00 Marshall et al. (2014)\nCosine similarity (%) 180 46.56 15 .43 18 .89 84.73 Author (2023)\nTokens - Object (log) 180 7.95 1.38 4.57 13.69 Author (2023)\nTokens - Attribute (log) 180 6.89 1.45 3.47 11.63 Author (2023)\nImports (log) 174 4.29 2.52 0.00 10.22 Izmirlioglu (2017)\nGDP (log) 176 3.59 2.07 \u22120.86 8.79 IMF (2019)\nGDPPC (log) 174 7.73 1.70 4.28 10.59 IMF (2019)\nInflation (%) 174 150.43 567 .24 \u22125.91 4734 .91 IMF (2019)\nCurrent Account Balance 176 \u22121.11 15 .94 \u221251.61 112 .39 IMF (2019)\nAlly 180 0.04 0.19 0.00 1.00 Gilber (2009)\nConflict Events (log) 180 1.45 2.96 0.00 9.48 Raleigh et al. (2010)\nCorruption Index 128 4.83 2.60 0.40 10.00Transparancy International (2018)\nF.3 Placebo\nPage A-27\nT able 17: Impact of Regime Type on Association between Politics Object, Sports Placebo, and Negative Attributes\nPolitics Sports\nChaos (1) Corruption (2) Chaos (3) Corruption (4)\nIndependent V ariables\nXinhua \u221216.41(9.96) 1.50(10.59) \u221237.64(10.53)*** \u221220.68(10.74)*\nXinhua x Polity (IV) 0.77(0.15)*** 0.50(0.23)** 0.50(0.33) \u22120.07(0.31)\nControl V ariables\nCountry Terms (Freq) \u22126.42(1.80)*** \u22127.97(2.12)*** \u22125.89(1.77)*** \u22126.20(1.20)***\nAttribute Term (Freq) \u22127.69(1.36)*** \u22126.96(1.63)*** \u22129.00(1.61)*** \u22128.57(1.02)***\nBilateral Treaty (Count) 7.92(4.95) 7.43(4.68) 1.90(5.85) \u22122.66(5.07)\nImports (USD) \u22120.22(0.34) \u22120.22(0.41) \u22120.12(0.41) 0.17(0.50)\nXinhua x Country Terms (Freq) 0.12(1.48) \u22123.02(1.28)** 2.73(1.23)** \u22120.42(1.84)\nXinhua x Attribute Term (Freq) \u22120.17(1.37) 1.98(1.14)* 0.16(1.15) 2.49(1.41)*\nXinhua x GDP (log) \u22120.03(0.65) 0.57(0.95) \u22122.38(0.91)** \u22121.69(1.16)\nXinhua x GDPPC (log) 0.96(1.19) \u22120.20(1.37) 3.12(1.38)** 3.09(2.19)\nXinhua x Inflation (%) 0.00(0.00) 0.00(0.00) 0.00(0.00) 0.00(0.00)\nXinhua x Trade Balance (USD) \u22120.02(0.02) 0.02(0.04) \u22120.06(0.03)** \u22120.08(0.05)*\nXinhua x Conflict (Freq) 0.32(0.26) \u22120.05(0.30) 0.49(0.34) \u22120.69(0.30)**\nXinhua x Corruption Index \u22120.68(0.53) \u22120.25(0.70) \u22121.03(0.68) \u22121.56(1.09)\nStatistics\nObservations 126 126 126 126\nFixed effects\nCountry Yes Yes Yes Yes\nNote:\nDependent variable is defined as the average cosine similarity between dictionaries representing the objects \u2013 politics and\nsports \u2013 and the respective attributes \u2013 chaos and corruption. Robust standard-errors are clustered at the country level\nand reported in parentheses: * p < 0.10, **p < 0.05, ***p < 0.01\nPage A-28\nF.4 Alternative Baseline\nPage A-29\nT able 18: Impact of Regime Type on Association between Country labels and Negative Attributes with V arying Baseline\nChaos Corruption\nAFP (1) CNA (2) Both (3) AFP (4) CNA (5) Both (6)\nIndependent V ariables\nXinhua x Polity (IV) 0.20(0.07)*** 0.10(0.05)** 0.13(0.04)*** 0.23(0.07)*** 0.14(0.04)*** 0.16(0.04)***\nControl V ariables\nCountry Terms (log) \u22123.13(0.43)*** \u22122.41(0.34)*** \u22122.74(0.31)*** \u22124.27(0.35)*** \u22122.72(0.29)*** \u22123.22(0.26)***\nImports (USD) \u22121.26(0.41)*** \u22120.51(0.34) \u22120.40(0.24)* \u22120.80(0.35)** \u22120.28(0.31) 0.10(0.22)\nTrade Balance (USD) 0.00(0.00) 0.00(0.00) 0.00(0.00) 0.00(0.00) 0.00(0.00) 0.00(0.00)\nBilateral Treaty (Count) 1.79(1.08) \u22120.75(1.01) \u22123.21(1.36)** 0.57(0.90) 1.28(1.10) \u22123.83(1.15)***\nXinhua x Country Terms (log) 0.84(0.46)* \u22120.06(0.46) 0.42(0.41) 1.92(0.48)*** 0.14(0.31) 0.94(0.29)***\nXinhua x Imports (USD) \u22120.57(0.62) \u22120.13(0.36) \u22120.69(0.38)* \u22120.36(0.62) \u22120.14(0.34) \u22120.64(0.35)*\nXinhua x Trade Balance (USD) 0.00(0.00) 0.00(0.00) 0.00(0.00) 0.00(0.00) 0.00(0.00) 0.00(0.00)\nXinhua x GDP (log) 1.30(0.74)* \u22120.11(0.46) 0.70(0.47) 0.90(0.75) \u22120.05(0.44) 0.72(0.46)\nXinhua x GDPPC (log) 0.31(0.62) 0.23(0.35) 0.26(0.37) 0.42(0.53) 0.32(0.36) 0.34(0.34)\nXinhua x Inflation (%) 0.02(0.04) 0.03(0.03) 0.02(0.03) 0.04(0.05) 0.01(0.02) 0.02(0.02)\nXinhua x Bilateral Treaty (Count) \u22120.20(1.49) 2.84(1.51)* 2.00(1.66) 4.93(1.26)***\nXinhua x Conflict (Freq) \u22120.11(0.34) \u22120.09(0.22) \u22120.02(0.20) \u22120.15(0.30) \u22120.29(0.20) \u22120.15(0.15)\nXinhua x Corruption Index 0.42(0.35) \u22120.08(0.20) 0.16(0.21) \u22120.10(0.31) \u22120.23(0.20) \u22120.15(0.20)\nStatistics\nObservations 9255 9348 13 483 9255 9348 13 483\nFixed effects\nFE Yes Yes Yes Yes Yes Yes\nNote:\nDependent variable is defined as the average cosine similarity between dictionaries representing countries and the respective attribute. Fixed-effects include country,\nyear, publication-year, and country-year effects. Robust standard-errors are clustered at the country level and reported in parentheses: * p < 0.10, **p < 0.05,\n***p < 0.01\nPage A-30\nF.5 Dictionary\nPage A-31\nT able 19: Impact of Regime Type on Association between Country labels and Negative Attributes Conditioning on Concept\nDictionaries\nChaos Corruption\nWord2Vec (1) Fasttext (2) Word2Vec (3) Fasttext (4)\nIndependent V ariables\nXinhua x Polity (IV) 0.13(0.04)*** 0.09(0.04)** 0.16(0.04)*** 0.16(0.04)***\nControl V ariables\nCountry Terms (log) \u22122.74(0.31)*** \u22123.35(0.28)*** \u22123.22(0.26)*** \u22122.81(0.22)***\nImports (USD) \u22120.40(0.24)* 0.27(0.22) 0.10(0.22) \u22120.57(0.18)***\nTrade Balance (USD) 0.00(0.00) 0.00(0.00) 0.00(0.00) 0.00(0.00)\nBilateral Treaty (Count) \u22123.21(1.36)** \u22123.75(1.26)*** \u22123.83(1.15)*** \u22122.53(1.02)**\nXinhua x Country Terms (log) 0.42(0.41) 1.28(0.27)*** 0.94(0.29)*** 0.01(0.29)\nXinhua x Imports (USD) \u22120.69(0.38)* \u22120.74(0.35)** \u22120.64(0.35)* \u22120.50(0.30)*\nXinhua x Trade Balance (USD) 0.00(0.00) 0.00(0.00) 0.00(0.00) 0.00(0.00)\nXinhua x GDP (log) 0.70(0.47) 0.74(0.41)* 0.72(0.46) 0.73(0.38)*\nXinhua x GDPPC (log) 0.26(0.37) 0.94(0.33)*** 0.34(0.34) 0.11(0.32)\nXinhua x Inflation (%) 0.02(0.03) 0.02(0.03) 0.02(0.02) 0.02(0.02)\nXinhua x Bilateral Treaty (Count) 2.84(1.51)* 3.73(1.53)** 4.93(1.26)*** 2.93(1.29)**\nXinhua x Conflict (Freq) \u22120.02(0.20) 0.08(0.16) \u22120.15(0.15) 0.02(0.17)\nXinhua x Corruption Index 0.16(0.21) \u22120.11(0.20) \u22120.15(0.20) 0.06(0.17)\nStatistics\nObservations 13 483 13 396 13 483 13 494\nFixed effects\nFE Yes Yes Yes Yes\nNote:\nDependent variable is defined as the average cosine similarity between dictionaries representing countries and the respective\nattribute. Fixed-effects include country, year, publication-year, and country-year effects. Robust standard-errors are\nclustered at the country level and reported in parentheses: * p < 0.10, **p < 0.05, ***p < 0.01\nPage A-32\nT able 20: Impact of Regime Type on Association between Politics Object and Negative Attributes by Dictionary Source\nChaos Corruption\nBaseline (1) Fasttext (2) Baseline (3) Fasttext (4)\nIndependent V ariables\nXinhua \u221216.41(9.93) \u221215.09(10.98) 1.50(10.55) 4.12(12.32)\nXinhua x Polity (IV) 0.77(0.15)*** 0.54(0.18)*** 0.50(0.23)** 0.67(0.20)***\nControl V ariables\nBilateral Treaty (Count) 7.92(4.93) 1.83(4.48) 7.43(4.66) 7.75(6.21)\nImports (USD) \u22120.22(0.34) 0.35(0.35) \u22120.22(0.41) \u22120.04(0.52)\nCountry Terms (Freq) \u22126.42(1.79)*** \u22127.48(2.44)*** \u22127.97(2.11)*** \u22128.78(3.02)***\nAttribute Term (Freq) \u22127.69(1.36)*** \u22128.52(2.04)*** \u22126.96(1.63)*** \u22127.19(3.13)**\nXinhua x GDP (log) \u22120.03(0.65) \u22120.16(0.70) 0.57(0.95) \u22120.13(1.02)\nXinhua x GDPPC (log) 0.96(1.18) 0.17(1.15) \u22120.20(1.36) \u22120.15(1.50)\nXinhua x Inflation (%) 0.00(0.00) 0.00(0.00) 0.00(0.00) 0.00(0.00)\nXinhua x Trade Balance (USD) \u22120.02(0.02) 0.00(0.02) 0.02(0.04) \u22120.01(0.02)\nXinhua x Conflict (Freq) 0.32(0.26) 0.11(0.27) \u22120.05(0.30) \u22120.16(0.34)\nXinhua x Corruption Index \u22120.68(0.53) \u22120.50(0.45) \u22120.25(0.70) \u22120.89(0.59)\nXinhua x Country Terms (Freq) 0.12(1.47) \u22121.01(1.42) \u22123.02(1.27)** \u22121.95(2.00)\nXinhua x Attribute Term (Freq) \u22120.17(1.36) 1.79(1.30) 1.98(1.14)* 0.66(2.10)\nStatistics\nObservations 132 132 132 132\nFixed effects\nCountry Yes Yes Yes Yes\nNote:\nDependent variable is defined as the average cosine similarity between dictionaries representing the object \u2013 politics\n\u2013 and the respective attributes \u2013 chaos and corruption. Robust standard-errors are clustered at the country level and\nreported in parentheses: * p < 0.10, **p < 0.05, ***p < 0.01\nPage A-33\nF.6 Window size\nPage A-34\nT able 21: Impact of Regime Type on Association between Country labels and Negative Attributes Conditioning on Window\nSize\nChaos Corruption\nWindow 5 (1) Window 10 (2) Window 15 (3) Window 5 (4) Window 10 (5) Window 15 (6)\nIndependent V ariables\nXinhua x Polity (IV) 0.14(0.05)*** 0.15(0.04)*** 0.13(0.04)*** 0.12(0.05)** 0.18(0.04)*** 0.14(0.04)***\nControl V ariables\nCountry Terms (log) \u22124.23(0.38)*** \u22123.27(0.29)*** \u22122.80(0.31)*** \u22124.72(0.30)*** \u22124.32(0.27)*** \u22122.92(0.22)***\nImports (USD) \u22120.35(0.27) \u22121.24(0.31)*** \u22120.34(0.23) 0.47(0.28) \u22120.85(0.27)*** 0.10(0.20)\nTrade Balance (USD) 0.00(0.00) 0.00(0.00) 0.00(0.00) 0.00(0.00) 0.00(0.00) 0.00(0.00)\nBilateral Treaty (Count) \u22124.09(1.66)** 1.40(0.87) \u22122.87(1.28)** \u22124.61(1.56)*** 0.51(0.73) \u22123.54(1.08)***\nXinhua x Country Terms (log) 1.11(0.43)** 0.38(0.41) 1.66(0.34)*** 0.84(0.29)***\nXinhua x Imports (USD) \u22120.81(0.47)* \u22120.69(0.38)* \u22120.58(0.39) \u22120.58(0.32)*\nXinhua x Trade Balance (USD) 0.00(0.00) 0.00(0.00) 0.00(0.00) 0.00(0.00)\nXinhua x GDP (log) 0.45(0.58) 0.84(0.46)* 0.41(0.52) 0.63(0.42)\nXinhua x GDPPC (log) 0.57(0.45) 0.13(0.36) 0.34(0.37) 0.25(0.31)\nXinhua x Inflation (%) 0.02(0.03) 0.01(0.02) 0.00(0.02) 0.01(0.02)\nXinhua x Bilateral Treaty (Count) 4.61(1.89)** 3.48(1.54)** 7.56(1.61)*** 5.95(1.28)***\nXinhua x Conflict (Freq) \u22120.04(0.22) \u22120.03(0.20) \u22120.16(0.16) \u22120.13(0.13)\nXinhua x Corruption Index 0.02(0.27) 0.10(0.21) \u22120.08(0.22) \u22120.17(0.18)\nStatistics\nObservations 13 384 13 483 13 398 13 478 13 483 13 487\nFixed effects\nFE Yes Yes Yes Yes Yes Yes\nNote:\nDependent variable is defined as the average cosine similarity between dictionaries representing countries and the respective attribute. Fixed-effects include country,\nyear, publication-year, and country-year effects. Robust standard-errors are clustered at the country level and reported in parentheses: * p < 0.10, **p < 0.05,\n***p < 0.01\nPage A-35\nT able 22: Impact of Regime Type on Association between Politics Object and Negative Attributes\nChaos Corruption\nWin 5 (1) Win 10 (2) Win 15 (3) Win 5 (4) Win 10 (5) Win 15 (6)\nIndependent V ariables\nXinhua \u221221.99(10.44)** \u221216.41(9.93) \u221212.67(8.91) \u22129.81(11.49) 1.50(10.55) 5.39(11.28)\nXinhua x Polity (IV) 0.81(0.14)*** 0.77(0.15)*** 0.74(0.17)*** 0.45(0.18)** 0.50(0.23)** 0.57(0.27)**\nControl V ariables\nBilateral Treaty (Count) 5.04(4.87) 7.92(4.93) 9.01(5.04)* 7.01(3.45)** 7.43(4.66) 8.34(5.76)\nImports (USD) 0.07(0.32) \u22120.22(0.34) \u22120.35(0.33) \u22120.01(0.33) \u22120.22(0.41) \u22120.34(0.46)\nCountry Terms (Freq) \u22128.40(1.55)*** \u22126.42(1.79)*** \u22125.91(1.82)*** \u22129.98(2.08)*** \u22127.97(2.11)*** \u22127.12(2.21)***\nAttribute Term (Freq) \u22127.95(1.15)*** \u22127.69(1.36)*** \u22127.08(1.41)*** \u22127.24(1.55)*** \u22126.96(1.63)*** \u22126.03(1.81)***\nXinhua x GDP (log) \u22120.14(0.69) \u22120.03(0.65) \u22120.03(0.60) \u22120.12(0.85) 0.57(0.95) 0.56(1.08)\nXinhua x GDPPC (log) 0.37(1.15) 0.96(1.18) 1.07(1.10) 0.27(1.33) \u22120.20(1.36) \u22120.24(1.56)\nXinhua x Inflation (%) 0.00(0.00) 0.00(0.00) 0.00(0.00) 0.00(0.00) 0.00(0.00) 0.00(0.00)\nXinhua x Trade Balance (USD) \u22120.01(0.02) \u22120.02(0.02) \u22120.02(0.02) 0.02(0.04) 0.02(0.04) 0.02(0.04)\nXinhua x Conflict (Freq) 0.47(0.24)* 0.32(0.26) 0.14(0.27) \u22120.03(0.26) \u22120.05(0.30) \u22120.12(0.39)\nXinhua x Corruption Index \u22120.50(0.48) \u22120.68(0.53) \u22120.72(0.51) \u22120.41(0.60) \u22120.25(0.70) \u22120.08(0.78)\nXinhua x Country Terms (Freq) 0.15(1.43) 0.12(1.47) \u22120.16(1.28) \u22122.13(1.28) \u22123.02(1.27)** \u22123.48(1.53)**\nXinhua x Attribute Term (Freq) 0.74(1.27) \u22120.17(1.36) \u22120.25(1.30) 2.39(1.22)* 1.98(1.14)* 2.15(1.50)\nStatistics\nObservations 132 132 132 132 132 132\nFixed effects\nCountry Yes Yes Yes Yes Yes Yes\nNote:\nDependent variable is defined as the average cosine similarity between dictionaries representing the object \u2013 politics \u2013 and the respective attributes \u2013 chaos and\ncorruption. Robust standard-errors are clustered at the country level and reported in parentheses: * p < 0.10, **p < 0.05, ***p < 0.01\nPage A-36\nF.7 Minimum Threshold\nPage A-37\nT able 23: Impact of Regime Type on Association between Politics Object and Negative Attributes across Minimum Article\nThresholds\nChaos Corruption\nMinimum 300 (1) Minimum 400 (2) Minimum 500 (3) Minimum 600 (4) Minimum 300 (5) Minimum 400 (6) Minimum 500 (7) Minimum 600 (8)\nIndependent V ariables\nXinhua \u221211.88(10.38) \u221216.41(9.93) \u221217.13(8.39)** \u221215.33(8.94)* 0.14(11.51) 1.50(10.55) \u22120.51(9.85) 1.16(8.89)\nXinhua x Polity (IV) 0.61(0.19)*** 0.77(0.15)*** 0.68(0.14)*** 0.70(0.14)*** 0.53(0.21)** 0.50(0.23)** 0.34(0.24) 0.42(0.22)*\nControl V ariables\nBilateral Treaty (Count) 7.67(4.94) 7.92(4.93) 11.27(2.57)*** 11.57(2.57)*** 6.10(4.63) 7.43(4.66) 9.94(3.19)*** 9.55(2.99)***\nImports (USD) \u22120.11(0.37) \u22120.22(0.34) \u22120.19(0.33) \u22120.21(0.31) 0.02(0.42) \u22120.22(0.41) \u22120.28(0.39) \u22120.29(0.38)\nCountry Terms (Freq) \u22127.83(2.08)*** \u22126.42(1.79)*** \u22125.03(1.65)*** \u22125.77(2.08)*** \u22129.31(1.93)*** \u22127.97(2.11)*** \u22126.38(2.01)*** \u22126.85(2.06)***\nAttribute Term (Freq) \u22127.00(1.60)*** \u22127.69(1.36)*** \u22127.70(1.31)*** \u22127.31(1.67)*** \u22125.89(1.43)*** \u22126.96(1.63)*** \u22127.03(1.50)*** \u22127.13(1.48)***\nXinhua x GDP (log) 0.31(0.68) \u22120.03(0.65) \u22120.11(0.47) \u22120.21(0.49) 0.66(0.97) 0.57(0.95) 0.62(0.85) 0.13(0.73)\nXinhua x GDPPC (log) 0.18(1.20) 0.96(1.18) 0.63(0.87) 0.44(0.91) \u22120.40(1.41) \u22120.20(1.36) \u22120.34(1.19) \u22120.65(1.07)\nXinhua x Inflation (%) 0.00(0.00) 0.00(0.00) 0.00(0.00) 0.00(0.00) 0.00(0.00) 0.00(0.00) 0.00(0.00) 0.00(0.00)*\nXinhua x Trade Balance (USD) \u22120.02(0.02) \u22120.02(0.02) \u22120.02(0.02) \u22120.02(0.02) 0.02(0.04) 0.02(0.04) 0.02(0.03) 0.02(0.03)\nXinhua x Conflict (Freq) 0.10(0.27) 0.32(0.26) 0.12(0.26) 0.14(0.26) 0.13(0.27) \u22120.05(0.30) \u22120.21(0.33) \u22120.23(0.32)\nXinhua x Corruption Index \u22120.41(0.52) \u22120.68(0.53) \u22120.30(0.43) \u22120.26(0.43) \u22120.13(0.68) \u22120.25(0.70) 0.17(0.60) 0.29(0.60)\nXinhua x Country Terms (Freq) \u22120.51(1.48) 0.12(1.47) \u22120.65(1.47) \u22120.74(1.47) \u22121.89(1.40) \u22123.02(1.27)** \u22123.03(1.18)** \u22122.56(1.21)**\nXinhua x Attribute Term (Freq) 0.46(1.31) \u22120.17(1.36) 1.12(1.20) 1.16(1.24) 0.60(1.19) 1.98(1.14)* 2.45(0.95)** 2.11(1.16)*\nStatistics\nObservations 140 132 128 125 140 132 128 125\nFixed effects\nCountry Yes Yes Yes Yes Yes Yes Yes Yes\nNote:\nDependent variable is defined as the average cosine similarity between dictionaries representing the object \u2013 politics \u2013 and the respective attributes \u2013 chaos and corruption. Robust standard-errors are clustered\nat the country level and reported in parentheses: * p < 0.10, **p < 0.05, ***p < 0.01\nPage A-38\nF.8 Alternative Dependent V ariable\nPage A-39\nT able 24: Impact of Regime Type on the Unweighted A verage Similarity between Country labels and Negative Attributes\nChaos Corruption\nModel (1) Model (2) Model (3) Model (4) Model (5) Model (6) Model (7) Model (8)\nIndependent V ariables\nXinhua \u221212.00(0.42)*** \u221245.30(3.66)*** \u221214.00(0.41)*** \u221225.14(2.97)***\nCNA \u22123.76(0.63)*** \u22126.98(0.55)***\nPolity (IV) \u22120.55(0.07)*** \u22120.22(0.05)*** \u22120.45(0.07)*** \u22120.18(0.04)***\nXinhua x Polity (IV) 0.28(0.05)*** 0.16(0.04)*** 0.30(0.06)*** 0.14(0.04)*** 0.22(0.05)*** 0.16(0.04)*** 0.24(0.06)*** 0.14(0.04)***\nControl V ariables\nCountry Terms (log) \u22122.44(0.27)*** \u22123.09(0.34)*** \u22123.14(0.16)*** \u22123.43(0.27)***\nAttribute Terms (Freq) \u22128.62(0.34)*** \u22127.15(0.18)***\nImports (USD) \u22120.64(0.20)*** \u22120.42(0.24)* \u22120.11(0.17) 0.20(0.23)\nTrade Balance (USD) 0.00(0.00) 0.00(0.00) 0.00(0.00) 0.00(0.00)\nGDP (log) \u22120.29(0.38) \u22120.39(0.31)\nGDPPC (log) 0.46(0.36) 0.33(0.34)\nInflation (%) 0.00(0.02) \u22120.04(0.02)**\nBilateral Treaty (Count) \u22122.15(1.33) \u22123.25(1.40)** \u22123.30(1.02)*** \u22123.97(1.23)***\nConflict (Freq) 0.48(0.23)** 0.41(0.18)**\nCorruption Index \u22120.94(0.23)*** \u22120.58(0.19)***\nXinhua x Country Terms (log) 0.29(0.21) 0.49(0.45) 0.68(0.23)*** 1.06(0.30)***\nXinhua x Attribute Terms (Freq) 4.83(0.43)*** 1.83(0.41)***\nXinhua x Imports (USD) \u22120.57(0.27)** \u22120.73(0.42)* \u22120.14(0.27) \u22120.57(0.35)\nXinhua x Trade Balance (USD) 0.00(0.00) 0.00(0.00) 0.00(0.00) 0.00(0.00)\nXinhua x GDP (log) 0.84(0.36)** 0.73(0.51) 0.36(0.36) 0.57(0.47)\nXinhua x GDPPC (log) \u22120.44(0.29) 0.27(0.40) \u22120.34(0.27) 0.29(0.35)\nXinhua x Inflation (%) 0.02(0.02) 0.02(0.03) 0.04(0.02)** 0.01(0.02)\nXinhua x Bilateral Treaty (Count) 2.95(1.75)* 4.01(1.62)** 5.47(1.20)*** 6.44(1.38)***\nXinhua x Conflict (Freq) \u22120.40(0.18)** \u22120.07(0.22) \u22120.43(0.14)*** \u22120.18(0.14)\nXinhua x Corruption Index 0.43(0.18)** 0.09(0.23) 0.13(0.16) \u22120.15(0.21)\nStatistics\nObservations 15 828 13 483 15 828 13 483 15 828 13 483 15 828 13 483\nFixed effects\nFE No No Yes Yes No No Yes Yes\nNote:\nDependent variable is defined as the unweighted average cosine similarity between dictionaries representing countries and the respective attribute. Robust standard-errors are clustered at the country level\nand reported in parentheses: * p < 0.10, **p < 0.05, ***p < 0.01\nPage A-40\nT able 25: Impact of Regime Type on Unweighted Similarity between Politics Object and Negative Attributes\nChaos Corruption\nModel (1) Model (2) Model (3) Model (4) Model (5) Model (6) Model (7) Model (8)\nIndependent V ariables\nXinhua \u221212.18(1.79)*** \u221236.84(9.31)*** \u221212.18(1.78)*** \u221227.34(9.15)*** \u221211.40(1.73)*** \u221219.41(10.82)* \u221211.29(1.80)*** \u22129.34(9.46)\nXinhua x Polity (IV) 0.62(0.24)** 0.75(0.18)*** 0.62(0.23)** 0.73(0.14)*** 0.80(0.23)*** 0.28(0.21) 0.79(0.24)*** 0.34(0.21)\nControl V ariables\nCountry Terms (Freq) \u22123.08(1.24)** \u22125.99(1.54)*** \u22124.86(1.84)** \u22128.10(1.98)***\nAttribute Term (Freq) \u22128.14(1.05)*** \u22127.11(1.21)*** \u22125.33(1.59)*** \u22126.15(1.50)***\nBilateral Treaty (Count) 3.55(2.73) 6.74(3.79)* 2.48(3.13) 5.36(4.23)\nImports (USD) 0.10(0.30) \u22120.04(0.31) \u22120.63(0.45) \u22120.11(0.41)\nXinhua x Country Terms (Freq) 1.03(1.64) 1.91(1.47) \u22121.75(1.70) \u22121.69(1.19)\nXinhua x Attribute Term (Freq) 1.22(1.59) \u22120.59(1.33) 2.94(1.56)* 1.99(1.15)*\nXinhua x GDP (log) \u22120.70(0.66) \u22120.19(0.60) \u22120.01(1.00) 0.22(0.83)\nXinhua x GDPPC (log) 1.73(1.47) 0.83(1.15) 1.43(1.71) 0.19(1.21)\nXinhua x Inflation (%) 0.00(0.00) 0.00(0.00) 0.00(0.00)** 0.00(0.00)***\nXinhua x Trade Balance (USD) \u22120.03(0.02) \u22120.02(0.02) 0.00(0.03) 0.01(0.04)\nXinhua x Conflict (Freq) 0.34(0.26) 0.38(0.24) \u22120.29(0.37) \u22120.15(0.32)\nXinhua x Corruption Index \u22120.50(0.73) \u22120.41(0.54) \u22120.61(0.99) \u22120.33(0.66)\nStatistics\nObservations 180 126 180 126 179 126 179 126\nFixed effects\nCountry No No Yes Yes No No Yes Yes\nNote:\nDependent variable is defined as the unweighted average cosine similarity between dictionaries representing the object \u2013 politics \u2013 and the respective attributes \u2013 chaos and corruption. Robust standard-errors\nare clustered at the country level and reported in parentheses: * p < 0.10, **p < 0.05, ***p < 0.01\nPage A-41\nT able 26: Impact of Regime Type on the A verage Similarity between Country labels and Negative Attributes Over 1992-2010\nChaos Corruption\nModel (1) Model (2) Model (3) Model (4) Model (5) Model (6) Model (7) Model (8)\nIndependent V ariables\nXinhua 2.00(0.41)*** \u221220.65(4.13)*** 2.98(0.36)*** \u221221.85(2.66)***\nPolity (IV) \u22120.38(0.06)*** \u22120.18(0.04)*** \u22120.28(0.05)*** \u22120.16(0.03)***\nXinhua x Polity (IV) 0.01(0.05) 0.12(0.03)*** 0.10(0.06)* 0.10(0.05)** 0.01(0.04) 0.16(0.03)*** 0.11(0.05)** 0.13(0.04)***\nControl V ariables\nCountry Terms (log) \u22121.89(0.24)*** \u22122.33(0.32)*** \u22122.13(0.14)*** \u22122.55(0.28)***\nAttribute Terms (Freq) \u22127.21(0.34)*** \u22127.19(0.19)***\nImports (USD) \u22120.63(0.20)*** \u22120.45(0.28) \u22120.11(0.16) \u22120.36(0.27)\nTrade Balance (USD) 0.00(0.00) 0.00(0.00) 0.00(0.00) 0.00(0.00)\nGDP (log) 0.28(0.34) \u22120.05(0.26)\nGDPPC (log) 0.34(0.27) 0.22(0.28)\nInflation (%) \u22120.01(0.01) \u22120.02(0.01)**\nBilateral Treaty (Count) \u22120.35(1.21) \u22121.03(1.03) 0.67(1.02) 1.13(1.25)\nConflict (Freq) 0.40(0.16)** 0.54(0.15)***\nCorruption Index \u22120.67(0.15)*** \u22120.53(0.14)***\nXinhua x Country Terms (log) 0.07(0.25) \u22120.11(0.47) \u22120.22(0.25) \u22120.05(0.38)\nXinhua x Attribute Terms (Freq) 3.14(0.45)*** 3.11(0.33)***\nXinhua x Imports (USD) \u22120.81(0.23)*** \u22120.37(0.34) \u22120.22(0.22) \u22120.37(0.31)\nXinhua x Trade Balance (USD) 0.00(0.00) 0.00(0.00) 0.00(0.00) 0.00(0.00)\nXinhua x GDP (log) 0.35(0.31) \u22120.09(0.45) 0.03(0.29) 0.02(0.42)\nXinhua x GDPPC (log) \u22120.42(0.24)* 0.28(0.33) \u22120.26(0.25) 0.27(0.34)\nXinhua x Inflation (%) 0.02(0.01)* 0.01(0.02) 0.02(0.01)** 0.01(0.01)\nXinhua x Conflict (Freq) \u22120.21(0.15) 0.01(0.20) \u22120.53(0.13)*** \u22120.30(0.20)\nXinhua x Corruption Index 0.33(0.14)** \u22120.06(0.18) 0.13(0.14) \u22120.10(0.19)\nStatistics\nObservations 19 919 12 223 19 919 12 223 19 919 12 223 19 919 12 223\nFixed effects\nFE No No Yes Yes No No Yes Yes\nNote:\nDependent variable is defined as the weighted average cosine similarity between dictionaries representing countries and the respective attribute. Robust standard-errors are clustered at the country\nlevel and reported in parentheses: * p < 0.10, **p < 0.05, ***p < 0.01\nPage A-42", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Framing Democracy", "author": ["PJ Chester"], "pub_year": "2024", "venue": "NA", "abstract": "Autocrats have long used propaganda to maintain their grip on power, but what happens when  they are forced to confront the appeal of alternative regimes? I employ word embeddings"}, "filled": false, "gsrank": 855, "pub_url": "https://patrickjchester.com/publication/chprop1/chprop1.pdf", "author_id": ["L15fgGQAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:Grp2KlcRDYMJ:scholar.google.com/&output=cite&scirp=854&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D850%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=Grp2KlcRDYMJ&ei=obWsaKLFCqzWieoPic2ZoAU&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:Grp2KlcRDYMJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://patrickjchester.com/publication/chprop1/chprop1.pdf"}}, {"title": "Transnational nationalism? Comparing right-wing digital news infrastructures in Western Democracies", "year": "2018", "pdf_data": "Transnational nationalism?  \nComparing right -wing digital news infrastructures in Western Democracies  \n \n \nWorking p aper prepared for presentation at the IPP 2018 conference,  \nUniversity of Oxford/Oxford Internet Institute, 20 -21 September 2018.  \nPlease do not c ite without permission of the authors.  \n \n \n \nAnnett Heft1 (corresponding author)  \nannett.heft@fu -berlin.de   \nEva Mayerh\u00f6ffer2 \nevamay@ruc.dk  \nSusanne Reinhardt1  \ns.reinhardt@fu -berlin.de  \nCurd Kn\u00fcpfer1  \ncurd.knuepfer@fu -berlin.de  \n1Freie Universit\u00e4t Berlin, Weizenbaum Institute for the networked society, Germany  \n2Roskilde University, Denmark  \n \nKeywords: digital news infrastructures, online right -wing media, social media, (trans -)national \nnetworking, (trans -)national public sphere   \n1 Transnational nationalism?  \nComparing right -wing digital news infrastructures in Western Democ racies  \n \n \nIntroduction  \nThe rise of right -wing populist parties and movements across European countries, increasing tensions \nbetween EU member states in light of issues such as the handling of debt crises, the challenges of \nmigration or the \u2018Brexit\u2019 all signal growing polarization within  and across European societies \n(Armingeon, Guthmann and We isstanner, 2015) . In the United States, the unexpected outcome of the \n2016 election and the Trump presidency have widened partisan divides (Pew Research Center, 2017)  \nand challenged core beliefs about the institutional media environment. While traditional mass media \nas one of the cornerstones o f democratic societies are under pressure, confronted with decreasing \ntrust and accused of being aligned with a political mainstream and a \u2018lying press\u2019 (Chandler, 2015) ; \nonline news media such as Breitbart.com , the German Compact magazine or Swedish Nyheter Idag \nrely on digital platforms to establish a new media landscape on the political right. These online partisan \nnews media promise to provide an alternative to legacy or mainstream media sources in times of high -\nchoice media environments (Van Aelst et al. , 2017) . This emerging digital news infrastructure on the \npolitical right, which might foster further polarization and radicalization of political views within and \nacross national and transnational public spheres -  especi ally since their users are unlikely to be exposed \nto the so -called mainstream media (Benkler et al. , 2017; Newman et al. , 2017)  -, lies at the center of \nour attention.  \nOur study focuses on far -right and right -wing populist online news media which are part of the political \ninformation environment in digital times. We examine alternative online news media (and \naccompanying soc ial media accounts on Twitter and Facebook) used by far- right actors as their main \nmode of news distribution and political mobilization. Such sites are marked by populist communication \nstyles (Jagers and Walgrave, 2007; Wolf, 2017)  as they refer to \u2018the people\u2019 combined with an anti -\nestablishment, anti -elite tone and take up right -wing, anti -hegemonic positions on many issues. With \ntheir claim to challenge power structures and their stance of being an alternative  to the media \nmainstream they inhibit some features of \u2018alternative media\u2019 (Atkinson and Berg, 2012)  while lacking \nmedia practices that strengthen democratic culture (Atton, 2006, 2007) . While their digital reach \nincreases, as of yet there exist no comp rehensive, comparative accounts of their infrastructures and \ntheir national and transnational interconnectedness. We assume that the embeddedness in particular \nmedia and political contexts is decisive for the shape those infrastructures and interconnections  take.  \n \n \n2 Against this backdrop , our analysis is driven by two overarching research questions: First, we assess \nwhat commonalities and differences we can find in the architectures of right -wing digital news \ninfrast ructures in different countries and how they correspond to variations in the media and political \ncontexts. Second, we analyze to what extent this digital information environment on the far- right is \ninterconnected both within and across countries capitalizi ng on the unique opportunities of digital \ntechnologies and media to build transnational networks and alliances of mutual recognition and \nsupport.  \nOur paper proceeds as follows: First, we provide a short overview on research on digital news \ninfrastructures  and focus on research on far- right and right -wing populist online news media. We then \npresent the design of our study including 70  alternative online news media on the far-  and populist \nright from six countries (Austria, Denmark, Germany, Sweden, United Kingdom and United States) . \nThose countries have been chosen due to differences in the general political information environment \nin which the partisan news providers emerge. We explain the methods we applied to gather insi ghts \ninto the supply and demand structures of those media  and their national or cross -country \ninterconnections. In the results section, we begin presenting our findings on overall structural \ncharacteristics of the online news media analyzed , includin g their topical scope and transnational \nfeatures . In the final part of our analysis,  we present results on the extent to which these  online news \nmedia are interconnect ed within and across countries.  \n \nDigital news infrastructures and context dependency  \nOur study draws on research characterizing the media environment and especially the political \ninformation environment within a specific society (Br\u00fcggemann et al. , 2014; Mosca and Quaranta, \n2016; Humprecht and Esser, 2017; Van Aelst et al. , 2017) . Van Aelst et al. define the political \ninformation environment as \u201cthe supply and demand of political news and political information\u201d (2017, \np. 4) . This literature offers several indicators to describe and explain the eme rgence of distinct news \ninfrastructures. While such  research attempts to describe and explain the supply and demand side of \npolitical information in general, our study focuses on the partisan news niche of far- right and right -\nwing populist online news  media. However, as a background for explaining different patterns of digital \nnews infrastructures on the political right and their transnational interconnectedness, the following \ncontext conditions could be decisive:  \nFirst, how online news media in general are facilitated and controlled in a given context influences the \nconditions  under which our partisan news sites can be established. Whether public press support,  e.g. \nthrough  state subsidies or VAT exemption, is ( also) made available  for online news media might \ninfluence their foundation  and maintenance . The same applies to the steps necessary to register as an \nonline medium (accreditation requirements) and the regulation of right -wing extremist content .  \n3 Second, the  levels of  overall online news media polarization  as well as  the polarization within the \ntraditional mass media and their tendency towards populist communication styles constitute the \ncontext in which far- right and right -wing p opulist news can either fill a market niche or are less \nnoteworthy. In a similar vein, trust in \u2018mainstream\u2019 news on - and offline might influence the demand \nand thus prospects of alternative online news providers on the political right. For e xample, research \nshows consistently for various countries  that the audiences who identify as right -leaning  are deeply \ndistrustful of the news in general and use alternative media because of their distrust in mainstream \nmedia (H\u00f6lig and Hasebrink, 2018; Newman et al. , 2018) .  \nFinally, the existence of online niche news providers  on the political right and especially their degree \nof (transnational) interconnectedness might be linked up to patterns of overall online and social media \nusage among a given population. I f online media  and social media do not play a sufficiently large role \nas a source of news in a given market it doesn \u2019t seem sustainable and lucrative to establish oneself as \na new brand and to address users and supporters in this way.  \nRegarding the political context, the electoral success of right -wing parties and the participation in (or \nsupport of) governments can be  seen as indicators of public tolerance towards right -wing and populist \npositions , i.e. to what extent right- wing positions and populist views have institutionalized access to \nmass media and public debates. In contexts where right -wing positions are pushed aside in the \nestablished mass media, n iche media on the far-  and populist right might be more likely  to flourish , as \nwell as have an incentive to establish  transnational connections among like -minde d outsiders. The \ninteresting question to ask here  is to what extent niche media in this specific segment behave like \nmedia actors that pay attention , for example, to their professionalism and uniqueness treating other \nmedia as competitors or whether they a re closer to the behavior  of political and movement actors . For \nparties and movements on the far right , research has shown that linking to one another is used to \ncoordinate action, to amplify their positions, to foster a sense of community and to build an  \noverarching group  identity (Burris, Smith and Strahm, 2000; Ackland and Gibson, 2013; Caiani and \nParenti, 2013; Pavan and Caiani, 2017) . For exam ple, Burris et al. (2000)  showed that white \nsupremacist movements often linked to sites in other countries . The authors interpreted this as a \nresponse to restrictions  the movements face in the national context.  Journalistic media traditionally \ncater to geographically located audiences and act as competitors, but journalism research in general \nobserves changes towards more collaboration (Lewis, 2016) . Such collaboration could be especially \nattractive for niche media with a political mission  and for a field in which we can expect that the \nboundaries between medium and political (movement) actor are especially blurred .  \n \n \n \n4 Far-right and right -wing populist online news media   \nResearch on far- right and right -wing populist online news media focusing on a) their digital news offers \n(supply and demand) and b) their transnational interconnectedness across news media is quite sparse. \nResearch is more likely to address questions of extreme right groups use of the Internet (Caiani and \nKr\u00f6ll, 2015; Simpson and Druxes, 2015)  or media populism in general (Kr\u00e4 mer, 2017a, 2017b)  than to \nlook  at right -wing media in particular.  \nResearch on German -language media from the far right (classification, description of content and \ndistribution, social media demand) mainly stems from civil society organiz ations adopting a watchdog \nfunction towards the extreme and populist right (Baldauf et al. , 2016, 2017; Beyersd\u00f6rfer et al. , 2017; \nJugendschutz.net, 2017) . In Denmark, research on right -wing online news media is virtually non -\nexistent, despite the fact that the few existing outlets, in particular Den ko rte avis , are a regular issue \nof public debate. One exception is J\u00f8nsson (2017) , who has analyzed right -wing online news content \nto explore the level of \u201cfake news\u201d in Danish media.  For the case of Sweden, Holt (2016a, 2016b, 2017a, \n2017b)  has conducted research on so -called \u201cimmigrant -critical alternative media\u201d (ICAM). His \nresearch focuses on aspects of media criticism and media distrust as a fundament of Swedish IC AM, as \nwell as on comparing them in content and style to mainstream media. He does however not focus \nspecifically on online media, nor assess transnational linkages of these media outlets . For the US case, \nwhich offers a wide variety of different forms o f right -wing and far right political news content, several \nclassifications exist which characterize such forms of media, but it is difficult to maintain a stable list, \nas ideologies shift. A variety of watchdog organizations (rightwingwatch.org; mediamatte rs.org) and \nweb -based collaborative efforts provide online material that links to and classifies such sites \n(wikipedia.org; mediabiasfactcheck.com). Furthermore, previous research based on partisan digital \ninformation flows has revealed degrees of intercon nectedness between various sites during the 2016 \npresidential campaign (Benkler et al. , 2017) . But as of yet, we are not aware of any study focused on \nthe international or transnational connections these sites have to foreign and likeminded news \nproviders.  \n \nContexts of far-right and right -wing populist online news media  in six countries   \nWe are interested  in far-right partisan online news media in six countries : Austria, Denmark, Germany, \nSweden, U nited Kingdom and United States . The countries represent northern, central and western \ntypes of media systems (Br\u00fcggemann et al. , 2014)  and they differ in their political polarization \nregarding the acceptance of far- right positions within politics and society.  \n \n \n \n5 Political context  \nWe take electoral success of far- right and right -wing populist parties/politicians and their participation \nin [or support of] governments as an indicator of the overall resonance of right -wing positions within \nsociety. Sweden, Germany and the UK represent countrie s in which right -wing extremist or right -wing \npopulist positions are currently comparatively marginalized. In Germany, the r adical right had been \ncomparatively weak for decades (Arzheimer, 2009) . Since 2013, the newly founded right -wing party \nAlternative for Germany (AfD) is on the rise (Arzheimer, 2015; Berbuir, Lewandowsky and Siri, 2015) , \nit successfully entered r egional parliaments and reached a vote share of almost 13 per cent in the 2017 \ngeneral election1. Britain \u2019s UK Independence Party (UKIP), which in the 2015 general election had still \nattained 12.6 per cent (Hawkins, Keen and Nakatudde, 2015) , fell into insignificance afterwards (2017: \n1.8 per cent2) and active support for organized far right groups and parties in Britain is considered \nbeing at its lowest for 25 years (HOPE not hate, 2018). However, the ruling conservative party tends \nrelatively strongly towards the right  (Polk et al. , 2017) .  In Sweden , after decades in which radical right -\nwing parties had been comparatively  unsuc cessful , the right -wing populist Sweden Democrats have \nbeen continuously  rising in political importance since entering national parliament in 2010 (Str\u00f6mb\u00e4ck \net al. 201 7). They are currently shunned by the other political parties  represented in parliament . \nIn contrast, the acceptance of right -wing and right -wing populist views is much more pronounced in \nDenmark and Austria. In Denmark, the liberal- conservative government depends on the support of the \nDansk Folkeparti (DF, Danish Peoples Party), whic h had become the second strongest party in the 2015 \nelection with around 21 per cent vote share.3 In Austria, the FP\u00d6, a party with strong right -wing \npositions and the third strongest force in the last general election4, is currently coalition partner of t he \nfederal government. Meanwhile, the United States  presents somewhat of a challenge in terms of \nsingling ou t and quantifying far-right or populist preferences among the voting public. This is partly \ndue to the de facto  two-party system , in which Republi cans and Democrats become catch -all parties \nfor the potentially more radical political currents . One indicator for such tendencies can be observed \nin the results of in ter-party primary elections, in which establishment Republicans have increasingly \nfaced s trong challenges from the right -wing fringes over the last election cycles on both state and local \nlevels. Furthermore, the success of sub -caucuses  and coalitions within the existing party structure, \nmarked, for example, by the rise of the so -called Tea Party  can be seen as a gradual shift towards more \nextreme forms of right- wing politics in the US. As Mann and Ornstein (2012)  have  pointed out, the  \nstark polarization of American politics has  therefore been marked by lopsidedness  as asymmetries \n                                                           \n1 https://www.bundeswahlleiter.de/info/presse/mitteilungen/bundestagswahl -\n2017/34_17_endgueltiges_ergebnis.html  (24.08.2018)  \n2 http://researchbriefings.parliament.uk/ResearchBriefing/Summary/CBP -7979#fullrepor t. (24.08. 2018)   \n3 http://www.electionguide.org/elections/id/2832/.  (24.08.2018)  \n4 https://wahl17.bmi.gv.at/  (24.08.2018).  \n6 emerged whic h pushed Republicans farther to the right than Democrats have shifted to the left. Based \non indicators for political ideology, they note that, \u201c nearly 80 percent of the freshmen Republicans in  \nthe 112th Congress would have been in the right wing of the  party in the 111th Congress \u201d (Mann and \nOrnstein, 2012, p. 57) . Arguably, the results of the 2 016 election, in which Donald Trump ran on an \nanti-establishment platform  might be seen as a further indicator for right -wing preferences among the \nAmerican public . While Trump won 46,09% of the popular vote,5 a perhaps more precise indicat or for \npublic support of this  type of political agenda and style might be derived from his approval ratings, \nwhich have polled fairly consistently at around  35-40% . \n \nMedia polarization and populism  \nDenmark has a long tradition for an open culture of public debate  that allows voicing politically  \nincorrect issues and opinions . This has resulted in a harsh tone of debate  in the media , in particular \nwith regard to immigration that speaks to the profile of the Danish People\u2019s Party (DF)  (Hellstr\u00f6m and \nHervik, 2014) . Denmark \u2019s legacy media indirectly supports DF b y emphasizing/conflict -framing \nimmigration in their reporting, for which DF has issue ownership  (Esser, Stepi\u0144ska and Hopmann, 2016; \nB\u00e4chler and Hopmann, 2017) . Based on information about the political leaning of news audiences of \nthe top online news brands of the country , Denmark displays a medium degree of online news media \npolarization  - compared to the ot her countries in our sample ( score of 2.82 according to the Reuters \nInstitute Digital News Report, Newman et al. , 2017, p. 40) .6 But trust in news overall is comparatively \nhigh ( 56%, 6th out of 3 7 countries) and quality news brands both from public service and private media \nhave similarly high trust scores  (Newman et al. , 2018, p. 75) . \nThe Swedish culture of public debate  is markedly different from neighboring Denmark, which leaves \nits marks on the level of polarization in traditional mass media as well  (e.g. Hellstr \u00f6m and Hervik, \n2014) . Public debate often centers around the presumed existence of a so -called \u201dopinion corridor\u201d \n(\u00e5siktskorridor ) limiting the range of issues and opinions that are being expressed in the public, \nincluding mass media content (e.g. Oscarsson, 2013) .The Sweden Democrats (SD) have long been \nostracized by Swedish mainstream media, but the \u201ccordon sanitaire\u201d erected by the media around SD \nseems to have been wearing o ff in the past years  (Hellstr\u00f6m and Hervik, 2014; Esser, Stepi\u0144ska and \nHopmann, 2016, p. 372; Str\u00f6mb\u00e4ck, Jungar and Dahlberg, 2017) .  Sweden Democrats and other right -\nwing groups have a hard time reaching out to a wider audience through mainstream media an d have \ntherefore resorted to building and maintaining an alternative digital infrastructure  (Str\u00f6mb\u00e4ck, Jungar \nand Dahlberg, 2017, p. 76) .  Online news media polarization is relatively low  in Sweden  (score of 2 .34, \n                                                           \n5 https://transition.fec.gov/pubrec/fe2016/federalelections2016.pdf  (24.08.2018).  \n6 The o nline news media polarisation score for eac h country is the mean of the polarisation score for each of \nthe top 15 online brands of a country (level of dispersion) multiplied by their weekly reach.  See Newman et al. \n2017, p. 40.  \n7 Newman et al. , 2017, p. 40) . The audiences of alternative and partisan online news brands are however \nsubstantially further to the right of the audience of the top 15 news brands  (Newman et al. , 2018, p. \n46). Trust in news in general, however, is lower than in the neighboring northern country ( 41%, 23rd \nout of 37 countries,  Newman et al. , 2018, p. 105) . \nGermany\u2019s traditional media are said to report critically on right -wing populist parties and reluctantly \non sm all parties  (Esser, Stepi\u0144ska and Hopmann, 2016; Fawzi, Obermaier and Reinemann, 2016) . The \nfew available empirical analyses on public medias reporting on populist actors corroborate such a \ncritical tenor (Reinemann, 2017) , which can be traced back to the country\u2019s history. Populist parties \nand actors react with their o wn assessment of how they feel treated by the media: The slogan \u2018Lying \npress\u2019, chosen German nonword of the year 20147, had been revived by German Pegida demonstrators \nin order to deny traditional media\u2019s credibility (Geiges, Marg and Walter, 2 015) . Thus, Germany\u2019s \ntraditional media landscape does not seem to leave much room for actors and positions from the far \nand populist right, at least in the past.  Online news media polarization is lowest in Germany (score of \n1.64 , Newman et al. , 2017, p. 40) , and trust in news is comparatively high. 50 per cent of respondents \nin the latest Reuters digital news survey (11th out of 37 countries) think they can trust most of the news \nmost of the time (Newm an et al. , 2018, p. 81) .  \nAlthough right -wing populist actors play a considerable role in Austrian politics, research on news \nmedia\u2019s dealing with populism has been relatively neglected in the past (Schmuck, Matthes and \nBoomgaarden, 2016 ). Research ascribes various Austrian mass media a market -focused and populist \nnewsroom logic which opens opportunity windows for right -wing and populist actors such as the F P\u00d6 \nto get attention (Schmuck, Matthes and Boomgaarden, 2016, p. 91 ; Plasser an d Ulram, 2003; Seethaler \nand Melischek, 2013) . Online news media polarization in Austria is with a score of 2.62 considerably \nlower than in the US (5.92) and UK (3.18), but higher than in Ge rmany (1.64) (Newman et al. , 2017, p. \n40). However, w hile less polarized, many of the top 15 online news sources in Austria such as Krone \nonline  cater to more right -leaning audiences. The far- right alternative news medium Unzensuriert  is \nthe furthest to the right in this audie nce measure (Newman et al., 2018, pp. 44\u2013 45). Regarding trust in \nnews in general, only 41 per cent of respondents in the latest Reuters digital news survey think they \ncan trust most of the news most of the time ( 23rd out of 37 countries, Newman et al. , 2018, p. 65) .   \nRegarding British mass media, research highlights a generally critical tone towards politicians and an \nemphasis on personalities, conflict, strategy and tactics while substantive issues attain less attention \n(Esser, Stepi\u0144ska and Hopmann, 2016) . As for UK television news, Wayne and Murray ascribe them a \n\u201cpopulist antagonism towards politics that is personalized and an ti-systemic in its focus \u201d (2009, p. 416) . \n                                                           \n7 Katzenberger, P aul (2015):  Kampfbegriff gegen die Demokratie. \"L\u00fcgenpresse\" als Unwort des Jahres.  \nSueddeutsche Zeitung . 13.01.2015.  http://www.sueddeutsche.de/kultur/luegenpresse -ist-unwort -des-jahres -\nkampfbegriff -gegen -die-demokratie -1.2301815 (24.08.2018).  \n \n8 Popular newspapers, in Britain especially the most -read The Sun, are expected to provide a favorable \nplatform for populist politics. However, empirical evidence on this is uncertain (Akkerman, 2011; \nStanyer, Archetti and Sorensen, 2016) . It seems at least that the British classical media environment \noffers opportunity structures  for actors and positions from the far right.  In the UK, the top online news \nbrands attract mostly left -leaning audiences (for example, Guardian Online, Huffington Post ), with Sky \nNews , Times  and MailOnline catering to (a lower number of) right -leaning aud iences. Compared to the \nhighest polarized country, the US (polarization score 5.93), the UK audience pattern is slightly less \npolarized (score 3.18) , but polarization is higher than in the other countries of our sample  (Newman et \nal., 2017, p. 40) . Regarding far- right alternative news media, Westmonster  and Breitb art UK  cater to \naudiences which self -identified strongest o n the right (Newman et al. , 2018, pp. 44\u2013 45).  42 per cent \nof respondents in the latest Reuters digital news survey think they can trust most of the news most of \nthe time ( 20th out of 3 7 countries, Newman et al. , 2018, p. 63) .   \nThe current US media  environment is marked by high degrees of fragmentation and polarization \nprocesses  (Mancini, 2013; Hopkins et al. , 2014) . These  have given rise to a host of niche -oriented news \nsources, many of which are geared towards partisan or sensationalized news reporting. This has been \nespecially true for emergent news environments like cable television, the early blogosphere or digitally \nnative news outlets. In 2014, even before the starkl y polarizing presidential election of 2016, the Pew \nResearch Center reported stark partisan divides within the American public and linked these to news \nconsumption habits  (Mitchell et al. , 2014, p. 1) . The report showed that while members of the public \nwho identified as liberal consumed a fairly diverse spec trum of news sources, 47 % of conservatives \nreported that they received the majority of their news only from Fox News, while being deeply \ndistrustful of other sources. O nline news media polarization is highest in the US (score 5.92, Newman \net al. , 2017, p. 40)  and the audiences of the furthest left and furthest right media are f urthe st apart. \nAlternative online news media such as Breitbart , The Daily Caller  and InfoWars  are \u2013 together with Fox \nNews - the ones with an audience much further on the right than other websites (Newman et al. , 2018, \npp. 45 \u201346). Trust in news media has declined considerably in the US. The polling company Gallup \nreports a 20 point drop in the percentages of Americans who say they trust the mass media between \n1997 (53 %) and 2016 (32 %)8. According to the Reuters Digital News Report 2018 only 34 % of the \ngeneral population now say that they trust the news  generally (putting the US at 30th out of 37  analyzed \ncountries ; Newm an et al. , 2018, p. 113) . Furthermore, the report s hows stark discrepancies between \nnews consumers who identify as left and those that identify as right. While 49 % on the left say they \n\u201ctrust most news most of the time,\u201d only 17 % of those on the right s ay the same (Newman et al. , 2018, \np. 18) .  \n \n                                                           \n8 https://news.gallup.com/poll/195542/americans -trust -mass -med ia-sinks -new -low.aspx. (24.08.2018)  \n9 TABLE  1: Overview P olitical and M edia Context Factors  \nPolitical and \nmedia context  SWE  DEN  GER AUT  UK USA  \nElectoral \nsuccess right -\nwing/ populist \nparties/ \npolitici ans Relatively \nlow \nSD 12,86% \n(2014)  \n Relatively \nstrong  \nDF 21,1% \n(2015)  Relatively \nlow \nAfD 12,6% \n(2017)  Relatively \nstrong  \nFP\u00d6 26% \n(2017)  Relatively \nlow \nUKIP 1,8%  \n(2017)  \n Relatively \nstrong  \nTrump \n46,09% \n(2016)  \nPolitical role  Opposition  Government \nsupport par ty   Opposition  Government  None  Government  \nMedia system  Northern \nType Northern   \nType  Central Type  Central Type  Western \nType  Western \nType  \nMass media & \npopulism  Dismissal/ \ndemarcation  (Unintended) \ncomplicity  Dismissal/ \ndemarcation  (Unintended) \ncomplic ity (Unintended) \ncomplicity / \nideological \npartnership  (Unintended) \ncomplicity / \nideological \npartnership  \nOnline news \nmedia \npolarization  2,34 2,83 1,64 2,62 3,18 5,93 \nTrust in news  41%  56%  50%  41%  42%  34%  \nOnline use for \nnews (at least \nonce a week)  87%  82%  65%  76%  74%  73%  \nSocial Media \nUsage (Almost \nevery day)  60%  59%  32%  42%  53%  (no compara -\nble data )9  \nSocial Media as \nsource of news \n(at least once a \nweek)  53%  46%  31%  49%  39%  45%  \n \n \nRole of internet and social media  \nLooking at internet penet ration in our countries, we do not find stark differences (all data according to \nthe Reuters Institute Digital News Report 2018).  Denmark has the highest rate with an i nternet \npenetration  of 97% (Newman et al. , 2018, p. 74)  and Austria the lowest one ( 85 per cen t, Newman et \nal., 2018, p. 64) , all other countries are in between. Online news (incl. social media) is either the most \nimportant (Sweden, 87%; Denmark, 82%; UK, 74%; Austria, 76%; US, 73% ) or second most importan t \nnews source ( Germany, 65%).10 In the Nordic countries, social media play a bigger role. In Sweden and \nDenmark, 60% and 59% use online social networks every day or almost every day, with Sweden having \nthe highest number among all EU member states (European Commission, 2017) . 53%  of Swedish users \nuse social media as a source of news at least once a week  (Newman et al. , 2018, p. 105) . In Denmark, \nthis applies to 46% of users, though numbers have declined significantly since  2016 (56%; Newman et \nal., 2018, p. 75) . In Germany, o nly 32 per cent of the general population use social media almost every \n                                                           \n9 Data for US: 69% use at least one social media site site  in general , http://www.pewinternet.org/fact -\nsheet/social -media/  (27.08.2018) . \n10 Percentage respondents have used it as source of news in the past week. All data Reuters Digital News \nReport 2018.  \n10 day (European Commission, 2017) . Fewer users than  in other countries, only 31 per cent, use social \nmedia for news  (Newman et al. , 2018, p. 81) . In Austria, social media use for news grew to 49 per cent \nin 2018 (Newman et al. , 2018, p. 65) , with 42 per cent of the general population using social media \nalmost every da y (European Commission, 2017) . In the UK, 53 per cent of the general population use \nsocial media almost every day (European Commission, 2017)  but only 39 per cent use social media for \nnews (Newman et al. , 2018, p. 63) . 69 % of the American population use at least one social media site \nin general11, and social media use for news is at 45  per cent in 2018 (Newman et al. , 2018, p. 113) . \n \nMethods  \nSelection of alternative online news media of the far - and populist right  \nWe examine online news media and their social media accounts on Twitter and Facebook  (FB) used by \nfar-right and right -wing populist actors as important channels of news distribution and political \nmobilization. By online news media we refer to digital news providers belonging to \u201cinstitutionalized \njournalism\u201d  (Wolf, 2014, p. 72)  in the sense that they are characterized by some form of \ninstitutionalization as media (1) ( for example, self -description as media offer, legal notice, given \ninformation on editorial responsib ility) and provide current, non- fictional and text -based content with \na given periodicity  (2). We focus on alternative media  (3) understood as offers that a) deal with the \nopinions of small minorities, b) express attitudes which are anti- mainstream and against widely -held \nbeliefs and c) maintain views or address subjects not regularly dealt with in general media coverage \n(definition as proposed by the Royal Commission on the Press, 1977,  cited in Atton, 2002, p. 1) . We \nare interested in alternative media espousing far-right and right -wing populist views  (4). While the \ndefinition of far- right attitudes is contested, they are thought to contain multiple attitudes, including \nauthoritarianism (a willingness to subordination to a [not legitimized] leader), nat ionalism (the \npreservation and empowerment of a nation as guiding principle), xenophobia (tendency to \ndiscriminate against other people), anti- semitism and pro -nazism (St\u00f6ss, 2000, p. 22) . Right -wing \npopulism, on the other hand, can be defined i n three steps (Wolf, 2017) : (1) Populism as a rhetorical \nstyle, where there is no coherent political program, but emphasis on a \u2018will\u2019 of the people, criticism of \nthe government/elites, using dichotomous friend -or-foe-schemes, common sense arguments and \nfactoids. (2) Populism as a thin ideology where elites are blamed to betray the people, governments \nor democracy in general are seen as bad and not responsible to the people\u2019s needs and  a strong \nemphasis that the people \u2019s will needs to be heard. \u2018The people\u2019 are seen as a homogenous, monolithic \ngroup without internal differences, having  a common will (Jagers and Walgrave, 2007) , being hard -\nworking and honest. (3) Right -wing populism as thick ideology, according to which the people are not \n                                                           \n11 Data not directly comparable. Source http://www.pewinternet.org/fact -sheet/social -media/ (24.08.2018).  \n \n11 citizens  of the state but defined by common ancestry/lineage. Anti -hegemonic, anti -establishment as \nwell as protectionist positions on many issues are characteristic as well as claims to challenge power \nstructures and to be an alternative outside of the media and party mainstream. According to this thick \nideology, vertical and horizontal demarcation is necessary since outgroups (both elites and \u2018others\u2019 \nsuch as migrants or other minorities) harm the people (Jagers and Walgrave, 2007)  which need to be \nprotected from \u2018others\u2019 influence. In tendency, right- wing populism is xenophobic or even racist, anti-\nSemitic, authoritarian.  \nTo select alternative online news media of the far - and populist right in our six countries we conducted \nan extensive literature and online search starting from well- established alternative online media of the \nextreme right, from monitoring organizations in our countries and other \u2018watchdog\u2019 lists as well as \nresearch in the field . We compiled a list of around 150 news sites and classified them according to our \nselection criteria  as described above. In order to be considered, the sites also had to belong to one of \nour countries, i.e. usually have their headquarters in one of our countries. Genuinely transnational \nmedia with headquarters outside one of our countries were explicitly excluded. As a result of this \nprocedure, 70 online media were included in this study. We additionally contacted country experts in \norder to validate our selection. However, we follow a case study approach and although we have tried \nto cover the field as comprehensively as possible, we do not claim to survey this fie ld of alternative \nonline media in its entirety.  \n \nIndicators and measu rement supply and demand  \nApplying the concept of political information environment to the partisan news niche of far- right and \nright -wing populist online news media, we analyzed supply - and demand- side indicators  with respect \nto our news sites . Our a nalysis includes a) the webpages of the 70  alternative online news media, b) \ntheir Twitter accounts , c) their FB accounts (b and c if applicable)  and d) audience metrics data available \nthrough Alexa.com .  \nWith respect to the webpages , we conducted a manual content analysis based on a standardized \ncodebook.12  \nWe measured the following static indicators  as basis for our analysis of the supply side  of homepage \nstructures. Regarding the diversity of infrastructures, we recorded the ways and platforms via which \ncontent is distributed (print, Twitter , FB, YouTube etc.). To describe the organizational transparency \nand capacity of each news site, we recorded the number of staff, the form of organization as well as \n                                                           \n12 All webpages have been stored offline between  June 21st and July 5th 2018 and processed using MaxQDA. \nThe codebook includes all static indicators measured on webpage basis. It is available upon request from the \nauthors. Coding was done by a team of four trained coders. Intercoder reliability tests re sulted in reliability \ncoefficients of  1.0 for print , 0.95 for platform usage, 0.90 for platform information, 0.94 for funding, 0.90 for \ntopic categories, 0.93 for integrated multimedia features, 0.91 for interactive elements, 1.00 for languages and \n0.84 for linking patterns to other homepages (4 coders, n = 10 webpages, Holsti reliability coefficient).   \n12 the location of the editorial offices, and ways of financing. With respect to platform architecture, we \ncoded the amount and type of news categories of the websites, multimedia features and interactive \nelements. It is difficult to estimate the activity of these online media. W e operationalize activity as the \nnumber of articles in a period of four weeks  using the Media Cloud database .13 \n \nRegarding demand side  information on homepage audiences, we relied on data collected by Alexa, a \ncompany providing web audiences and t raffic data14, in order to capture the attention a site is able to \nattract  (Webster, 2014; Mukerjee, Majo -Vazquez and Gonzalez- Bailon, 2018)  . Since we deal with niche \nmedia , we were not abl e to retrieve a number of estimated unique visitors per site. For a rough \napproximation on attention attracted, we rely on the rank a website has in a given country.15 \nWith respect to the Twitter  and FB accounts of our news sites , we operatio nalize user attention \n(demand) by the number of followers on Twitter and the number of FB subscriptions. As for Twitter, \nwe assess the activity of a medium (supply) by the number of tweets in a period of four weeks (June 1 \n- July 1 2018). The Twitter data were automatically retrieved via DMI\u2019s Twitter Collection and Analysis \nToolkit (TCAT) hosted at Roskilde University  (Borra and Rieder, 2014) . \nFB subscriber data have been collected manually from the FB  accounts on August 2 2018.  \n \nIndicators and measurement  of transnationality  \nWe understand transnational communication as communication that crosses and transcends borders \nof nation  states and national cultures in the sense that those borders lose their relevance for \ncommunication processes (Wessler and Br\u00fcggemann, 2012, p. 3) . To capture the transnationality  of \nour digital news media , we apply static and dynamic indicators. From a static perspective , we consider \norganization -related and content- related indicators of our online media. We record  whether the \nmedium maintains an editorial office outside of the country of origin and whether the medium offers \ncontent in languages other than the official language in the respective country. Regarding the news \n                                                           \n13 From the project\u2019s website, available under https://mediacloud.org : \u201cMedia Cloud is  an open source \nplatform for studying media ecosystems. \u201d The platfor m is a joint project by the MIT Center for Civic Media and \nthe Berkman Klein Center for Internet & Society at Harvard University . Media Cloud collects online news stories \nthrough the RSS feeds of online media sources. We thank Annissa Pierre and Anushka Shah for support with \nsetting up the country- based collections  containing the websites we analzed.  For the analysis in this paper, we \ntake the time span from June 22 to July 22 2018 into account.  \n14 Alexa is a company providing web metrix da ta. According to Alexa, its traffic estimates are based on data \nfrom a global traffic panel, which is a sample of millions of Internet users using one of many different browser \nextensions. In addition, Alexa gathers traffic data from direct sources in the form of sites that have chosen to \ninstall the Alexa script on their site and certify their metrics. However, site owners can always choose to keep \ntheir certified metrics private. Alexa data do not rely on a representative sample. For details, see \nhttps://www.alexa.com/siteinfo .  \n15 The Alexa country- specific ranking is a measurement of how a website ranks in a particular country relative \nto other sites over the past month. The rank is calculated using a combina tion of average daily visitors and \npageviews over the past month. For details, see https://www.alexa.com/siteinfo . \n13 categories on the websites, we measure whether they explicitly address a domestic, national (other \ncountries), European or international scope.16  \nWith respect to dynamic indicators  of transnationality on the websites, we recorded whether the news \nsites provided hyperlinks to partners or othe r \u2018friends\u2019 media in specific sections of their news sites, \nfor example sections like  \u201cFree Media\u201d, \u201cAlternative Media\u201d  or \u201cPartners \u201d. If so, we coded those actors \u2019 \nname,  URL and  country a s well as  the type of actor  and connection \n(national/transnational/international)  by a manual content analysis.17   \n \nRegarding the T witter  and FB accounts, we use the following measures to operationalize horizontal \nlinkages between the different nation states and media (Koopmans and Erbe, 2004, p. 101; Be nkler, \n2006, p. 212) : \nOn Twitter , our analysis of horizontal, cross -country interconnections between our different news \nproviders relies on two approaches. First, a connection to other T witter users can be established by \nmentioning another user wit hin a tweet, by retweeting the post of another user or by a reply to a \nmessage of another user (Jungherr, 2015; Vergeer, 2015) . In our study, we conceptualize users (media) \nsending a tweet as source s and users  they interact with via mentions or retw eets  as targets of a \ncommunicative connection. Second, a connection to other Twitter users can be built by hyperlinking \nto these users\u2019 w ebsites  within a tweet. Here, the user sending a tweet is considered as source and the \nuser connected to via a hyperlink  to their homepage  is considered as target of this connection.  \nFor both approaches, a tweet can include diverse targets. The number of tweets therefore does not \nequal the number of connections (edges). Our analysis includes the T witter profiles of 66  media from \nour sample ( 4 media do not  run a T witter account  and 13 media  did not interact with others  at least \nonce during our time span of analysis ). During that time span, altogether 41.281 tweets have been \nsent by our online media ; among them  18.129 tweets containing mentions or retweets to other actors \nand 2.678  tweets that contain references to  our 70 right -wing news providers via mentions or \nretweets . Within the tweets, among 52.901 hyperlinks we find 28.920 tweets that contain hyperlinks  \nto our 70 online media . These references are often  self-references. Repeated references are added up \nand represented as  edge weight in the networks . \nFB offers the possibility to \u201clike\u201d other pages. Pages\u2019 administrators can thus publicly nominate other  \npages as their liked pages, which in turn are shown to users on the respective page\u2019s main site. In this \nregard, we conceptualize our online media (and account holder) as source and the actors signaled as \nfriend as target of the digital connection. We collected data on these page- likes and additional \n                                                           \n16 See description on codebook and coding procedure as above.  \n17 Coding of homepage partner link s was done by one coder. Intercoder reliability had been tested beforehand \nby two coders. It resulted in reliability coefficients of 0.91 for the coding of the type of connection, 0.95 for the \ncoding of actors\u2019 country and 0.95 for the coding of actor type  (n=20, Holsti reliability coefficient)  \n14 descriptive metadata like page -categorization and self- descriptions, using FB \u2019s API (Application \nProgramming Interface). To make calls to the API, we used the Python programming language and \ncould henc e compile a list  of all pages that were liked by our pages of interest.   \nTo assess national and cross -country interconnections between our online news providers from the \nfar- and populist right, in the following analyses we focus on direct interconnections  between the \nplatforms included in our sample, leaving connections via bridge - and other actors outside of our \nsample aside. We use  Gephi  (Bastian, Heymann and Jacomy, 2009)  to analyze the networks. Force \nAtlas is chosen to lay out the network graphs.   \n \nDigital News Infrastructures  \nHomepage Structures in Six Countries Compared  \n \nSweden  \nThe right -wing news landscape is quite diversified in Sweden, both in quantity and in quality. All in all, \nten Swedish online n ews sites (i.e. 1 per 1 million inhabitants) met our criteria, ranging from neo -nazi \nNordfront , network -based \u201ctroll factory\u201d Granskning Sverige  and one -man project Ledarsidorna.se to \nwell- established alternative right -wing news sites such as Fria Tider , Nyheter Idag, and Samh\u00e4llsnyt \n(successor to the widely known Avpixlat) . A special case is presented by RedIceTV , a media outlet \nfounded and headquartered in Sweden that meanwhile however targets a mostly  U.S. \nAmerican/international audience. Nya Tider  is the only one of the identified news sites that also exists \nas a print edition. Samtiden is published by a company owned by right -wing populist party \nSverigedemokraterna ( Sweden Democrats); this connection is however not disclosed on the homepage \nitself. Sveg ot, a relatively new site founded by prominent right -wing pundit Ingrid Carlqvist, has in \nAugust 2018 announced that it will close in the near future. Three of the sites ( Ledarsidorna, Nyheter \nIdag, Samtiden) are registered with the Swedish Press Council, the self -disciplinary system of the \nSwedish press . \n \nOrganization, transparency and funding:  8 of the 10 news sites disclose information on their editorial \nstaff; some (like Ledarsidorna)  only disclose the page\u2019s publisher/editor -in-chief, while others ( like \nSamtiden) also name columnists. While this self- disclosed information must be interpreted with \ncaution , the majority of Swedish right -wing online news sites, though small, appear to be  driven by an \nactual editorial team. At the same time, only four ne ws sites disclose a full postal address, while one \nmore site mentions that it is based in Stockholm.  \nIn terms of funding, the Swedish news sites rely on a broad portfolio of sources of income, of which \nadvertisement is only of secondary im portance and only  applies to 50 per cent  of the cases. Rather, \n15 the sites rely on their core readership for financing: 70  per cent of the sites generate income through \nsite subscriptions, 60  per cent  through donations, 50  per cent  through a shop. As no funding sources \ncan b e directly identified on Samtiden\u2019s homepage, it can be assumed that it is in some way or the \nother fund ed through the Sweden Democrats  party. As a print newspaper, Nya Tider  additionally \nreceives state subsidies.  \n \nContent supply on homepage : In a period  of four weeks (June 22 \u2013  July 22), the Swedish homepages \nhave on average published 213 articles, i.e. roughly seven articles per day. The lowest number of \narticles was published by Ledarsidorna (37) and RedIce TV  (55), while Nordfront  (496) and Fria Tider  \n(358) have been particularly active. However, none of the Swedish news sites falls into a group of \nextremely inactive (less than on average one article per day) or extremely active (more than on average \n30 articles per day) news sites.  \n \nContent supply through social media: The Swedish sites are quite active on different social media \nplatforms. All sites are on Twitter, eight out of ten on FB (Nordfront  and Granskning Sverige \u2019s pages \nhave been shut down by FB ), and other social media channels such as YouTube, D -tube and VK are also \nbeing used by several sites. Focusing more closely on content supply through Twitter, n ine of the ten \nnews sites actively use their Twitter account ( Nyheter Idag has last tweeted in August 2017), with an \naverage of 222 tweets (including re -tweets) sent in the month of data collection (min. 18, max. 523; \nexcept for Nya Tider , all sites have sent 100+ tweets in one month).   \n \nUser demand:  Right -wing online news sites are also in Sweden not a mainstream phenomenon , but \nclearly in far higher demand than e.g. in neighboring Denmark. Three of the sites ( Fria Tider, Nyheter \nIdag, Samh\u00e4llsnyt)  feature among the top 200 Swedish websites, based on the Alexa page rank, and \nfour more \u2013 including the extremist Nordfront  - among the top 1,000 websites (no information \navailable for Granskning Sverige) .  \nThe nine  news sites active on Twitter have on average 9088 followers (min. 510, max. 35455). The  \neight sites still active on FB  have in average 28.482 subscribers (min. 1.354, max. 91.451). The site in \nhighest demand on both FB and Twitter is (partly US -based) RedIceTV , in lowest demand is (soon to be \nshut down) Svegot . Apart from these outlier cases, however, the sites in highest demand on FB are not \nnece ssarily also in highest demand on Twitter: On FB , rather \u201cclassical\u201d news outlets Fria Tider (48.096)  \nand Nyheter Idag (44.940) have the highest numbers of subscriptions, while Nordfront and \nLedarsidorna are in highest demand on Twitter, with more than 10.000 followers each.  \n \n \n16 Denmark  \nRight -wing online news sites are only of very limited relevance in Denmark. Only three Danish news \nsites ( Den korte avis, 24nyt, NewSpeek Networks ) qualify as \u201cright -wing online news sites\u201d in \naccordance with the defini tion applied in our study and none of them takes in a particular prominent \nposition in the Danish media landscape. Right -wing news sites generally have a rather short life span \nin Denmark. Only Den korte avis , which has existed since 2012, can be regarded as a rather established \nsite by now, and is used weekly by 5% of the Danish respondents in the 2018 Reuters Digital News \nReport (Newman et al. 2018, 75). Both 24nyt  and NewSpeek Networks  have only been in operation \nsince 2017 and 2016, respectively and market themselves as media outlets \u201cwithout hidden agendas \n(\u2026), false neutrality and mock objectivity\u201d (NewSpeek Networks 2018) that \u201cbring(s) you the news that \nthe mainstream media either suppresses or downgrades\u201d (24nyt 2018). None of the three sites is \nregistered with Pressen\u00e6vnet, a public institution that deals with complaints about Danish mass media. \nRegistration is otherwise mandatory for print and audiovisual media, and very common for online news \nsites.   \n \nOrganization, transparency and funding:  Den k orte avis  and 24nyt  provide information on who is \nbehind the news site on their homepage, disclosing two staff members each. Even though such \ninformation is not disclosed on NewSpeek Networks  homepage, it is indeed a  common feature of all \nthree websites th at their content is produced by few, prominent individuals: both 24nyt  and NewSpeek \nNetworks are founded and driven by Jeppe Juhl, a former award -winning journalist for the tabloid \nEkstra Bladet, whereas the people behind Den korte avis  are two former high -profile (social \ndemocratic) politicians. Only Den korte avis  also discloses a postal address. All sites are \u2013  as judged by \nthe information available on their homepages \u2013 funded through a mix of advertisement and user \ndonations. None of them exists as a pr int edition.  \n \nContent supply on homepage : Based on the data provided by the Media Cloud database, the three \nDanish news sites published on average 134 articles in the month of data collection, i.e. somewhat \nmore than on average four articles per day. 24n yt is by far the most active one with 322 articles, \nwhereas Den korte avis  published 72 and NewSpeek Info  only 9 articles on their homepages in the \nsame time period18.  \n \nContent supply through social media: All Danish sites have a Twitter account and a FB  page. However, \nonly 24nyt  flags their social media platforms consistently on the homepage.  Social media activity \n                                                           \n18 It appears that in particular NewSpeeks extremely low number may have been affected by Danish summer \nvacation. Numbers will be verified by cross -checking with another month for a revised version of this paper.  \n17 beyond Twitter and FB  is very limited, only  NewSpeek Networks  additionally entertains  a YouTube \nchannel . \nOf the three news sites, only 24nyt  and NewSpeek Networks  have been active on Twitter in the month \nof data collection. 24nyt  has been far more active with 313 tweets, whereas NewSpeek Networks sent \nonly 13 tweets (mean: 163).  \n \nUser demand: At the time of data collection, none of the three Danish news sites investigated was in \nvery high demand by the Danish audience. None of the homepages is ranked among the top 2,000 \nDanish homepages, based on the Alexa site rank  (24nyt : 2.349; Den korte avis : 2.681; no rank given for \nNewSpeek  Networks ).  \nOn Twitter, the two active sites are followed by only 28 (!) and 158 users respectively (mean = 93). \nCuriously, the inactive site ( Den korte avis ) has the most followers (503), despite the fact that it has \nonly sent 53 tweets  in total, the lat est one in May 2017. User demand for Danish righ -wing news sites \nis somewhat more substantial on FB : all three news sites are active on FB  and have between 11.494 \n(NewSpeek Networks ) and 47.881 ( Den korte avis ) subscribers (mean: 31.134).  \n \nGermany  \nIn Germany, our search resulted in ten  alternative online news sites that can be classified as extreme \nright or right -wing populist. Among the best -known media  are Junge Freiheit , Compact online , and PI \nNews . Around ten per cent of German i nternet users report that they have heard about those media \n(11 per cent Junge Freiheit , 9 Compact , 7 PI News ), three (JF) to two per cent (CO, PI -News) report they \nhave used the sites  in the last week (Hoelig/Hasebrink 2018). Some have a history as  print offer, such \nas Junge Freiheit  which had been published first in 1986 and went online in 1996. Others, such as PI-\nNews , started as an online blog in 2004 to, as the founder puts it, uncover topics that others don\u2019t \nmention, while critics speak of rac ist propaganda (Reinle 2007). Politically Incorrect  (PI-News ) \npromotes itself with the slogan \u201eNews against the mainstream \u201c.19   \n \nOrganization, transparency and funding:  German right -wing online news sites are rather transparent \nabout their organization. O nly two sites do neither provide a full postal address nor information on \nstaff ( PI News, Politikstube ); Zuerst!  does not list  staff members . In contrast, Freie Welt  extensively \ndiscloses all contributors of the medium (167), while Compact  (7), Junge Freiheit  (15) and Sezession  \n(15) list classical editorial teams .  \nMost (9 out of 10) of the included German news sites rely on advertisement as a form of funding. 80% \nof the sites additionally rely on donations. The most noticeable  exception  to this funding m odel  is \n                                                           \n19 http://www.pi -news.net/leitlinien/ (06.08.2018).  \n18 Zuerst! , an offer that finances itself (according to their homepage) exclusively by subscriptions.  As a \nregistered voluntary association, Journalistenwatch  in principle can seek public funding  and is \nfurthermore finan cially supported by an American conservative think tank, Middle East Forum . Two of \nthe most prominent news sites, Compact online  and Junge Freiheit , stand out by a diverse funding \nstrategy, relying on ads, subscriptions, donat ions as well as their own shop .  \n \nContent supply on homepage : The ten German news sites have on average published 220 articles in \nthe month of data collection, i.e. about seven articles per day. While the majority of homepages \npublished within 150 and 300 articles in the course of a m onth (i.e. about 5 -10 articles per day), some \nhomepages stick out by their high level of activity ( Journalistenwatch with 762 articles) or inactivity \n(Blaue Narzisse, Frauenpanorama and Sezession  have all published less than 30 articles).  \n \nContent supply through social media: All German right -wing online news sites are active on social \nmedia, most of them on FB (all but Politikstube ) and Twitter (all but Blaue Narzisse ). Some of the news \nsites are moreover present on a variety of other social media platforms (such as Instagram, YouTube, \nbut also Russia -based VK), in particular Compact Online , Journalistenwatch and Junge Freiheit .  \nAlthough nine of the news sites thus  maintain a Twitter account, only seven  make actively use of it; \nFreie Welt  and Zuerst! last used it in 2015/2016.  Journalistenwatch stands out by tweeting  (and re -\ntweeting) to an  astonishingly high degree  (1046 tweets in our month of data collection ), while PI News  \n(1 tweet20) and Sezession  were least active (mean: 321).  \n \nUser demand: Measured on the basis of A lexa page rank, three German sites feature among the top \n1.000 of German news sites: PI News  (rank 214), Journalistenwatch (263) and Junge Freiheit  (768). \nThree more sites ( Politikstube , Compact  and Freie Welt ) are among the top 2 .000. At the other end of \nthe scale, Blaue Narzisse  and Frauenpanorama are extreme niche media , featuring on rank 49.972 and \n136.322, respectively.  \nOn social media, user demand for the German right -wing news sites varies substantially, as well. On \nTwitter, Junge Freiheit  (29277  followers ) and Compact (14515  followers ) stand out as the two news \nsites  attracting most attention. The other sites draw between about 1500 to 5000 followers, while \nFrauenpanorama has less than 200 followers  (mean:  8359) .  By far the most relevant  site on FB is the \naccount of Junge Freiheit  with 133.396 subscribers, followed by Compact online  with roughly 100.000 \nsubscribers (93.604). All other FB  pages have  between cir ca 1.600 ( Freie Welt ) and 28.000 \n(Journal istenwatch)  subscribers  (mean: 33.335 ). In contrast to e.g. Sweden, where popularity of \n                                                           \n20 According to th is latest tweet , PI News\u2018  Twitter administrator has stopped by May 31st and a new one needs \nyet to be found \u2013  the site has previously been quite active on Twitter.  \n19 platforms varied between FB and Twitter, two sites ( Junge Freiheit  and Compact ) thus dominate the \nsocial media presence of right -wing online news sites in Germ any.  \n \nAustria  \nIn Austria, eight news sites ( Alles Roger?, Alpenschau, Info Direkt, Unzensuriert, Wochenblick, Zur Zeit, \nContra Magazin, Unser Mitteleuropa) met our selection criteria for alternative online media on the \nextreme and populist right. The best  known among them are, according to the latest Reuters D igital \nNews Report, Unzensuriert , Info Direkt  and Contra Magazin. 19 per cent of respondents have heard of \nUnzensuriert , but only 7 per cent  of Info Direkt  and 5 per cent of  Contra Magazin (Newman et al. 2018: \n65). Unzensu riert  describes itself as medium offering \u201cnews about topics that the mainstream does not \ncover at all or only one -sidedly\u201d21. Info Direkt  sees itself as \u201cmagazine for a free world\u201d which is \u201cnot \ninterested in supporting consensus but want s to fuel dissent  and discussion \u201d. 22 Unser Mitteleuropa \npresents a somewhat special case, as it is not only geared towards Austria, but also focuses on \nGermany and Hungary.  \n \nOrganization, transparency and funding:  The Austrian news sites are very tra nsparent in disclosing \ninformation about their organization. All eight online news sites  provide information on thei r \norganization (name, type) and a postal address for their editorial office. 6 (out of 8) are transparent  \nwith regard to  their staff. Info D irect  provides an extensive list of contributors (82), whereas Alles \nRoger?  (8), Wochenblick (10), Contra Magazin (6), Zur Zeit  (2) and Unser Mitteleuropa (1) only list core \nstaff or even only editors in chief.  Alpenschau and Unzensuriert  provide no infor mation. In terms of \nfunding, all Austrian news sites rely on a combination of advertisement with subscriptions (4 out of 8) \nand/or donations (6 out of 8). Unzensuriert  and Zur Zeit  additionally offer an online shop.  \n \nContent supply on homepage : The ei ght Austrian news sites have on average published 104 articles in \nthe month of data collection and are thus -  together with the UK \u2013 overall the least active ones among \nthe countries included in this study. Only Contra Magazin (216) and Wochenblick  (186) p ublish more \nthan on average five articles per day. In turn, only one of the Austrian news sites, InfoDirekt , qualifies \nas extremely inactive with less than on average one article per day (29).  \n \nContent supply through social media: All Austrian news site s are active on FB , and six out of eight (all \nbut Alles Roger  and Zur Zeit ) also on Twitter. While some of the sites (such as Info Direk t, Contra \nMagazin, Zur Zeit ) flag their social media presence extensively on their homepage, others (such as \n                                                           \n21 https://www.unzensurier t.at/impressum (06.08.2018).  \n22 https://www.info -direkt.eu/ueber -info-direkt/ (06.08.2018).  \n20 Unzensuriert  and Alpenschau) do not promote them at all. Wochenblick , Info Direkt , Contra Magazin  \nand Zur Zeit  are also active on 1 -3 other social media platforms, such as Google Plus, Instagram, \nYouTube or VK.  \nAll six news sites that entertained a Twitter account also used it actively in the month of data collection, \nhowever to varying degrees. Contra Magazin and Unzensuriert were most active on Twitter (235 and \n234 tweets, respectively ), while Info Direkt only tweeted 6 times in the course of a month. On a verage, \nthe sites tweeted and re- tweeted  139 times from June 1st to July 1st 2018.  \n \nUser demand: Measured on the basis of Alexa page rank within Austria, only one of the identified news \nsites ranks among the top 1,000 homepages in Austria: Unzensuriert  (page rank 486). Wochenblick  \n(3.075) and Contra Magazin (3.642) feature among the top 5.000 Austrian homepages, while the \nremaining four sites rank substantially lower (no Alexa information is available for Zur Zeit ). According \nto Alexa page rank, many of t he Austrian news sites actually rank substantially higher in Germany than \nthey do in their country of origin, indicating a substantial degree of transnationality that will be \nanalyzed in more detail in the course of this paper.  \nOn average, the six active  Austrian Twitter pages are followed by 1321 users. Most popular are \nUnzensuriert (3827 ) and Contra Magazin ( 2091), whereas Unser Mitteleuropa only has 178 followers.  \nUnzensuriert  finally also draws the highest number of FB subscriptions (59.431) , but also Wochenblick  \nreaches more than 50.000 people. On average, the FB  pages of Austrian right -wing online news sites \nhave 23.661 subscribers (minimum: 3.309).  \n \nUK \nIn Britain, we included three cases of alternative media on the extreme or populist right: Westmonster , \nSpiked, Heritage and Destiny . Westmonster , a pro -Brexit site which is partly funded by Arron Banks, a \nright -wing businessman (Newman, 2018) , is heard of by 6 per cent and used weekly by 2 per cent of \nrespondents in the latest rou nd of Reuters Digital News report (Newman et al. 2018: 63) . According to \nthis report, it is the second most important alternative news offer on the political far right, after \nBreitbart UK (heard of 19 per cent, weekly use 2 per cent), in our sample included  as a subsite to \nBreitbart US. Spiked, which was originally located on the left of the political spectrum,  describes itself \nas \u201cmetaphorical missile against misanthropy\u201d23. Heritage and Destiny  is primarily a printed magaz ine \nwith an online news section  offering content in a blog like style.  In contrast to  the low number of \ninstitutionalized alternative online media in the UK, reports from watchdog organizations suggest that  \nthe soc ial media accounts of numerous right -wing activists and pundits on FB, Twitter and YouTube \n                                                           \n23 http://www.spiked -online.com/newsite/about/336/ (08.08.2018).  \n21 successfully serve this spectrum , apparently in lieu of dedicated online news sites (HOPE not hate, \n2018) .  \n \nOrganization, transparency and funding:  All three  online news media provide information on their \norganization (at least nam e) and a postal address for their editorial office. Westmonster  refrains from \ngiving information on staff. All three news sites  are financed via a combination of advertisement and \ndonations. Westmonster  and Heritage and Destiny  also finance themselves thro ugh a n online  shop.  \n \nContent supply on homepage : Overall, the UK news sites are equally inactive as the Austrian ones, with \non average 105 articles published in the month of data collection. Differences between the three news \nsites are however far more p ronounced than in the Austrian case. Similar to Denmark, we can account \nfor one rather active homepage, Westmonster (248), one  site that publishes little, but fairly regularly, \nSpiked (72), and one largely inactive site, Heritage & Destiny  (6). The low amo unt of content provided \nby Heritage & Destiny  is hereby also a result of the fact that most content production still appears to \nfeed into the print paper version.  \n \nContent supply through social media: All three UK news sites are active on Twitter. Two o f them \n(Westmonster  and Spiked ) are also on FB, as well as a third social media platform ( Westmonster  on \nYouTube, Spiked on Google Plus ). In the month of data collection (June 1st \u2013 July 1st), Heritage and \nDestiny  only sent 3 tweets, whereas Spiked  and Westmonster  used the account more r egularly \n(Westmonster  682, Spiked  431 tweets ; mean: 372) . \n \nUser demand: Judged by their  Alexa page rank, none of the UK sites is in very high user demand. None \nof the sites ranks within the top 5.000 homepages in th e UK ( Spiked : 5.360; Westmonste r: 5.228; no \nrank given to Heritage and Destiny ). \nIn contrast to the other European countries studied, at least two of the UK sites do attract a significant \nuser base on social media. On both Twitter and FB, Westmons ter attracts the widest userbase with \n45.156 followers on Twitter and 26.131 FB subscriptions . Spiked  is almost equally popular with 28918 \nfollowers on Twitter and 22.801 FB subscriptions . Heritage and Destiny , in contrast, is an insignific ant \nfactor on social media with only 164 followers on Twitter and no FB  page.  \n \nUS \nBased on our criteria, we included a total of 36 cases for the US. The perhaps most well -known \nexamples among our list include Breitbart , The Daily Caller , The Blaze , Townhall  and RedState . The first \nof these three were also included as examples of alternative, partisan brands in the questionnaire for \n22 the Reuters Digital News Report 2018: 45 % of the US population recognized Breitbart , 25 % were \nfamiliar with the Daily Caller , 32 % with The Blaze  (Newman et al 2018, 20). However, only 4 -7 % \nindicated that they used one of the sites on a weekly basis.  \nOn its \u201cAbout\u201d page, Breitbart portrays itself as \u201cthe largest source of breaking news, analysis, thought -\nleading comm entary, and original reporting curated and written specifically for the new generation of \nindependent and conservative thinkers.\u201d Meanwhile, via its Twitter profile\u2019s about section, Breitbart \nannounces that it offers, \u201cNews, commentary, and destruction of the political/media establishment.\u201d \nMeanwhile, the second highest ranking website in our sample, The Western Journal ,\u201d presents itself \nas \u201ca news company that drives positive cultural change by equipping readers with truth\u201d by offering \na platform to \u201cconse rvative, libertarian, free market and pro -family writers and broadcasters.\u201d This \nblend of conservative values, infused with anti -establishment attitudes is a prevalent theme \nthroughout many of the self -descriptions of sites included in the US sample. While  it acknowledges \nbeing founded by figureheads of US conservative / right -wing punditry, The Daily Caller  takes a slightly \ndifferent approach in presenting itself as impartial and \u201ctough on members of both political parties\u201d . \nOther key themes along these li nes are authenticity ( The Blaze  on Twitter: \u201c Authentic. Unfiltered. \nFearless.\u201c ), as well as self- governance  and liberty. World Net Daily , for example, seeks \u201cto stimulate a \nfree-and-open debate about the great moral and political ideas facing the world and  to promote \nfreedom and self- government by encouraging personal virtue and good character.\u201d  \n \nOrganization, transparency and funding:  26 (72 %) of the included news sites  indicated who their staff \nwas as part of their homepage structure. Around half (n=1 7) named a postal address for their main \noffice, while three more at least listed a city in which they were located. Out of our 36 cases in the US \nsample, 32 featured ads on their website. Four offered subscriptions and 11 listed a possibility for \ndonati ons. As far as we could tell from the information provided via the sites, none of them indicated \nthat they received state funding or subsidies. 14 linked to an online shop.   \n \nContent supply on homepage : With an average of 690 articles in the course of o ne month, i.e. more \nthan 22 articles per day, the US sites are by far the most active ones in our sample. Despite the high \naverage number of articles, we can still account for a number of extremely inactive sites with on \naverage less than one article published per day ( gotnews.com, Front PageMag, Disobedient  Media and \nThe Federalist ). 11 sites have on average published 2 -10 articles per day and 14 sites between on \naverage 11 and 30 articles. Six homepages fall into the category of extremely active homepag es (more \nthan 30 articles per day): Townhall  (4537), The Daily Caller  (3514), Breitbart  (2482), NewsMax  (1412), \nDaily Wire  (1114), and WorldNet Daily  (1077).  \n \n23 Content supply through social media: US right -wing online news sites are predominantly present  on FB \n(36 out of 36) and Twitter (35 out of 36, all but Conservative Base). Other social media platforms are \u2013  \nassessed based on links on the homepage \u2013  less universal. 15 sites linked to a YouTube channel, four \nof them to an Instagram account, an d one ( The Teaparty Tribune ) to the Russian social network VK.   \nWithin the month of Twitter activity that we recorded for the 35 accounts we identified, the combined \ntotal of tweets we recorded for the US cases was 34.137. This puts the average amount at 975 tweets \nper month per account \u2013 by far the highest value for any of our six countries. The most active account, \nDailyCaller , sent out a total of 6.989 tweets \u2013  almost twice as many as the next most active handle, \nCDNnow . Other highly active accounts wer e realDailyWire  (n=2.310) and bigleaguepol  (2.433). \nMeanwhile, BasedOps  only tweeted twice during the timespan analyzed, while the TeaPartyTribune  \nonly sent out seven tweets.  \n \nUser demand: According to the Alexa page ranking, Breitbart is the most visite d site within our sample, \ncoming in at rank 65 for all US websites. The top ten within our sample are all ranked below the 2.000 \nmark for popular websites. At the bottom end, five of the websites rank below the top 50.000 of most \nvisited sites in the US:  The least visited sites, Politchicks,  Tea Party Tribune , and Conservative base  are \npast the 400.000 mark when it comes to their rank within the US market. Opslens  and gotnews are just \nabove that at around 200.000 and 275.000.  \nOn average, the Twitter acco unts for the 35 handles included i n our analysis have a follower base of \n102.888 users. The most popular account based on followers is Breitbart News , with a value of about \n950k. Ranking next highest are theblaze, DailyCaller, RedState  and realDailyWire  at around 150k and \nupwards. Only eight sites have 10.000 followers or less.  \nThe average amount of subscriptions on FB for the 36 pages includ ed in our US sample was 858.815.  \nThe highest -ranking site based on numbers of subscription was the Daily Ca ller with around five  million \nfollowers. The Western Journal, Breitbart, the political insider, CNS News, the Daily Wire, Townhall , \nNewsmax , and Lifezette  all ranked at above one million followers.  The lowest ranked sites within our \nsample were the College  Fix, Liberty Nation, Big League Politics, gotnews, Disobediant Media, and \nInformation Liberation \u2013 all of which had under 10.000 followers. Noticeably, except for two news sites \n(Information Liberation and Liberty Nation), the groups of sites with less th an 10.000 \nsubscriptions/followers on FB and on Twitter, respectively, do not overlap. The numbers of FB \nsubscriptions and Twitter followers do thus not only provide information of a site\u2019s popularity with \nusers, but also indicates a site\u2019s social media platform preference from a user perspective.  \n \n \n \n24 TABLE 2: Supply and Demand Indicators by Country  \n  \nSWE  DEN  GER AUT  UK USA  \nSupply  Number of homepages \nincluded  10 3 10 8 3 36 \nHomepages per 1 million \ninhabitants1 1 0.5 0.1 0.9 0.05  0.1 \nAvera ge number of articles \nper month (Mediacloud)  213 134 220 104 105 690 \nHomepages with on \naverage less than 1 article/ \nmore than 30 articles per \nday (Mediacloud)  0/0 1/0 3/0 1/0 1/0 4/6 \nAverage number of tweets \nper month (sites active on \nTwitter) 2 222 (9 ) 163 (2)  321 (7)  139 (6)  372 (3)  975 (35)  \nDemand  Share of sites among the \ntop 1000/5000 sites (Alexa \nrank)  3 8/8 (9)  0/2 (2)  3/6 (9)  1/3 (7)  0/0 (2)  4/16 (36)  \nTwitter followers 2 9088 (9)  163 (2)  8359 (7)  1321 (6)  24.746 (3)  102.888 \n(35) \nFacebook sub scriptions \n(average) 2 28.482  (8) 31.134 (3)  33.335 (9)  23.661 (8)  24.466 (2)  858.815 \n(36) \n1 For the US, overall supply of right- wing news content online may be higher when including regional media, as well ;              \n2 Twitter and Facebook data are ba sed on homepages active in the month of data collection; number of active sites in \nbrackets;  3Alexa data is not available for all included news sites; number of sites included in Alexa in brackets \n \n \nHomepage Categories  \nAs the assessment of the supply an d demand of news content has shown, the different online media \nvary substantially in their news infrastructure, both within and in between countries. How right -wing \nonline news sites are positioned -  and seek to position themselves -  in a given political and media \ncontext can moreover be observed through the topical categories the news site itself has established \nto structure its news content for its readership. While the formulation of topical categories on a \nhomepage does of course not directly translate to how the actual thematic priorities and focus of a \ngiven homepage are, it gives a rather direct indication of how the news site wants to present itself to \nits audience in terms of content.  \nIn this sense, we distinguish two aspects to classify homepages  based on their topical categories24:  \n\u2022 In terms of quantity, we look at the number of categories and sub -categories specified on the \nhomepage, based on the assumption that this number gives a reasonable approximation of \nthe broadness of topics covered on th e homepage.  \n\u2022 In terms of  thematic priority,  we distinguish between classical news categories (such as \nPolitics, International News, Culture, Commentary/Opinion, Sports, Business etc.), news \ncategories that are particular to alternative right -wing media (such as Immigration, Crime, \nFreedom of Opinion, Terror, Mass Media), and non -classical news categories with no clear \n                                                           \n24 Categories not referring to news content (such as About Us, Login, Store etc) are not coded.   \n25 right -wing slant (e.g. Congress, Animal Rights, Military, Survival etc.) 25. For each category on \nthe homepage, we assign a va lue of - 10 for right -wing categories, a value of 0 for non -classical, \nbut not definite right -wing categories and +10 for classical categories.  \n \nFigure 1 presents a scatterplot of all news sites in our study, indicating the total number of categories \nand subcategories on the y -axis (displayed as a potency scale for reasons of visibility) and the average \nscore of all topic categories of a given site on the classical- to-right -wing axis ( -10 to +10). Country of \norigin of a given news site is indicated by color and shape of the markings in the scatterplot.  \n \nFIGURE 1: Classification of News Media based on Topical Categories  \n \n \nAs can be seen in figure 1, only few news sites in our sample include enough topical categories with a \nright -wing slant to outweigh cl assical and other non -traditional news categories (indicated by a \nnegative score on the x- axis). Rather than hailing from one country, these sites represent exceptional \ncases in all countries: PI News  in Germany, Granskning Sverige  in Sweden, NewSpeek Netw orks in \nDenmark, Heritage & Destiny  in the UK and Big League Politics  in the US. With the exception of PI news , \nsuch right -wing slant is the result of few, focused topic categories.  \n                                                           \n25 We have moreover analyzed these topical categories with regard to their transnational focus. This aspect will \nbe taken up in the following section.  \n26 A significant pro portion of our news sites can  be described as non -traditional judged by the topical \ncategories on their website, roughly indicated by a score of 0 to 5 on the x -axis. Such a non -traditional \nappeal can both be the result of a mix of classical and explicit right -wing categories, or simply a \npreference for non -traditional news categories. In both cases, the site hereby signals an alternative \napproach to the classical news site architecture. Many of the US American news sites, as well as the \nremaining sites from Denmark and the UK fall into this category. The non -traditional sites can both be \nfocused and broad in their presentation of news topics . Indeed, it is particularly in this middle group \nwhere we can find sites with an \u201cexcessive\u201d number of topical categories (40+), such as Swedish \nNordfront (which is also  the only site with outright Nazist categories), Austrian Alpenschau or US based \nThe Western Journal  and Liberty Nation.  \nFinally, a significant share of our news sites presents its topical categories in (almost) classical format, \nespecially the Swedish, Austrian, as well as the largest German news sites. Eight of the US sites also fall \ninto this group. Only two of them have more than 20 topic categories ( Fria Tider  and Compact ), \nwhereas especially the US American sites with classical topical categories also feature a very reduced \nrange of categories (as e.g. \u2018News\u2019 as the only content- based category in the case of The Daily Wire ).  \n \nTransnational structures homepages  \nOne base assumption pursued in this paper is that news sites in some countries have a more  \ntransnational outlook than others, given the political and media context they operate in. One \nexpectation is that such transnationality will becom e manifest in the formation of t ransnational \nnetworks; this will be analyzed  in the following  paragraphs. However, one can also expect that the \nhomepage\u2019s site architecture already provides indications of the transnationality of a news site.  \nThe transnational potential of a given news site can become visible in different forms . At the most \nbasic level, online  news sites can feature elements of transnationality  by including news from abroad \nas at least one specific topical category or sub -category on their site. It is important to note that despite \nthe absence of such categories, the news site  may of course feature international news content. Yet, \nthe introduction of a category specifically dedicated to non -national news indicates a more permanent \noutlook beyond the nation state. Second, transnationality can become visible in news categories \nbundling news from specific individual countries. Some of these categories are indeed simply more \ndetailed international news categories (e.g. Middle East, North Korea etc.), whereas others that \nspecifically refer to neighboring and otherwise culturally re lated countries indicate a multi -national \ntarget audience . Third, the multi - and transnationality of a presumed target audience can also become \nevident in the use of foreign languages  on the website. Finally, online news sites may transcend the \nrealm o f the nation -state by a) entertaining editorial offices  abroad or b) placing their main editorial \noffice outside their (main) country of operation. Despite the fact that the latter may often also be due \n27 to legal considerations (such as bypassing national h ate-speech laws), it nevertheless provides an \nelement of transnationality.  \nFor each of the countries studied , table 3  displays the number and share of news sites, for which the \naforementioned criteria of transnationality apply. It becomes imm ediately visible that right -wing \nonline news sites can only be described as transnational in their outlook in two of the countries under \nstudy: Austria and Sweden.  \n \nTABLE 3 : Transnationality I ndicators by C ountry   \nSWE (n=10)  DEN (n=3)  GER (n=10)  AUT (n=8)  UK (n=3)  USA (n=36)  \nLocation (main or second \neditorial office abroad)  2 (20%)  0 (0%)  0 (0%)  5 (63%)  0 (0%)  1 (3%)  \nForeign language  4 (40%)  0 (0%)  2 (20%)  2 (25%)  0 (0%)  0 (0%)  \nNews category: neighboring/ \nrelated country  1 (10%)  0 (0%)  0 (0%)  5 (63%)  0 (0%)  0 (0%)  \nNews category: international  7 (70%)  1 (33%)  4 (40%)  6 (75%)  1 (33%)  10 (28%)  \n \n \nIn Austria, many of the news sites feature both international news categories, as well as categories \npertaining to neighboring countries, in particular Germany, but also central European regions that have \nhistorically formed part of the Austro -Hungarian Empire. A substantial part of the transnationality of \nAustrian homepages is thus attributed to the fact that they are (also) geared towards a German \naudi ence. Inded, as Alexa Webmetrics data shows, 6 out of 7 Austrian right -wing news sites (no \ninformation available for Zur Zeit ) are primarily visited by users based in Germany. Only unzensuriert.at  \nhas a substantial Austrian user base, but even in this case  45% of visits are registered in Germany. In \nline with these findings, the Austrian homepages are not particular transnational when it comes to \nforeign -language content. Strikingly, two thirds of Austrian homepages are either based entirely \nabroad (in Urug uay, the Philippines and Hungary ) or entertain editorial offices abroad (in Germany and \nthe Czech Republic ). \nTransnationality for the Swedish homepages is primarily based on a comparatively high share of sites \nwith foreign language content (primarily E nglish , though Nordfront  additionally features content in the \nNordic languages and Russian)  and the systematic inclusion of international news. The two remaining \ncriteria (location and focus on neighboring/culturally related countries) only apply to select ed \nhomepages. Except for English -language and partly US -based RedIceTV , which has an international \nreadership of which only 3% actually hail from Sweden, all news sites are predominantly, but by no \nmeans exclusively read by a Swedish audience. Other significant groups of users include users from \nother Nordic countries (in some of which, in particular Finland, there exists a significant Swedish \nminority), the US, as well as Spain (Swedish vacationers and exile pensioners?). Curiously, with the \nexception of N ordfront , the sites featuring English language content are almost exclusively used by \npeople based in Sweden (Source: Alexa).  \n28 In the remaining countries, the inter/transnational focus of the analyzed homepages is only present in \nthe (minimal) requirement of an international news category, and even such category is found on less \nthan half of the homepages. While two German sites offer foreign language content ( Compact : \nRussian, Journalistenwatch:  English, French, Spanish), such content is completely absent for the sites \nin Denmark, the UK, and the US. All right -wing online news sites in Denmark and the UK are moreover \nbased exclusively in their country of origin. For the US, in turn, Breitbart  represents the one prominent \nexample of a transnational news sit e based on its location, as it entertains editorial offices in the UK \nand Israel, for which it also features separate subsites on the homepage.  \nIn all four countries, all homepages are predominantly visited by users from the country of origin. Some \nof th e German sites are also visited by users from Switzerland and Austria, whereas many US sites, as \nwell as UK based Spiked  additionally attract a rather international audience. However, even for globally \nknown Breitbart , US American users make up almost 80% of site visits  (Source: Alexa).   \n \nTransnational Networking \nNext, we sought  to find out to what extent our alternative online media  on the political right interact \nwithin and across countries using the unique possibilities of digital technologies to form a (trans -) \nnationally networked ecosystem for spreading right -wing and populist positions. W e start our analysis \nwith the websites and examine to what extent our alternative online news media refer directly to each \nother as \u2018friends\u2019 or \u2018partne rs\u2019. Figure 2 shows that such direct and public linking is rarely the case. \nRoughly a third  of our online media does not provide a special section with links to \u2018friends\u2019 and other \nrelated offers at all ( 22 out of 70 cases ). Especially in t he two Nordic countries, this is not a homepage \nfeature regularly used. The sites with hyperlinks (in total, n=892 links ) do only occasionally  link directly \nto the other media in our sample (n=46 links). Direct (an d sometimes reciprocal) connections  between \nmedia outlets  can only be found in the US.  \nTransnational references  can be traced back exclusively to  German  Journalistenwatch. \nJournalistenwatch, operating as non -profit organization under the heading \u201c Verein f\u00fcr Medienkritik \nund Gegen\u00f6ffentlichkeit e. V., \u201d acts as hub for other media in this alternative spectrum . With respect \nto our cross -national sample, it c an be seen as an integrator of at least the Ge rman -language \nalternative media we scrutinized.  \n \nRegarding F B, we find more or less the same picture. In FB , the administrators of our alternative \nmedias\u2019 FB accounts can publicly nominate other FB pages as their liked pages, what they in general \ndo quite often (66 media run a FB account, 40 point to liked pages, those media establish 615 \nconnections  to other FB accounts). However, direct connections between our alternative media are \nextremely rare, limited to 15 connections, only one of them transnational.  \n29 FIGU RE 2 : Homepage Partner Links Among our News  Media  \n \nHomepage -network, n =70 news media , created with Force Atlas by Gephi. Node size represents in -degree. Colored by \ncountry: US (pink), Germany (green), Austria (orange), Sweden (blue), UK (green), Denmark (brown). \n \n \nWe cons idered Twitter use as another possibility to establish horizontal digital interconnections both \nbetween our different alternative news media within countries and transnationally across country \nborders. Thus, our partisan news providers could align w ith the other alternative media on the far and \npopulist right by mentioning them within their  tweet or by retweeting their  post s in order to increase \nvisibility and attention. 66 of our partisan niche media run a T witter account, 53 interacted with others  \nat least once during our time span of analysis (18.129 tweets with mentions or retweets in total). Less \nthan one fifth (15  %) of the connections directly align our news ecosystem on the far and populist right, \nand most of them (97 % ) are self- referenc es to promote the own news offer. In  only two of our \ncountries - Sweden and the US, the news media directly connect to each other by mentioning or \nretweeting th e other medias\u2019 content, and as f igure 3 shows, those direct interconnections are entirely \nwithin the domestic realm.  \n \n \n \n \n \n \n \n \n \n\n30 FIGURE 3: Twitter Direct Mention - and Retweet Connections Among our News Media  \n \nInteraction n etwork, n=66 news media, created with Force Atlas by Gephi. Node size represents in -degree. Colored by \ncountry: US (pink ), Germany (red), Austria (orange), Sweden (blue), UK (light green), Denmark (dark green). Color of node \nlabel indicates self -references (black) or no self -references (blue).  \n \nAnother way to interconnect the alternative news media ecosystem on the politica l right is to hyperlink \ndirectly to other medias\u2019 websites within a tweet. Hyperlinking to websites is a quite prominent \nfeature : the 41.281  tweets of our media contain 52.901 hyperlinks altogether. In 28.920 tweets, the \naccounts we analyzed establish connections amongst each other  (figure 4). We find a strongly \ninterconnected network of the American partisan news providers , with Breitbart , The Daily Wire  and \nDaily Caller , for example, occupying a central position . Interestingly, we also find some British, \nSwedish, Danish and German -language media integrated in this network.  For example, the British \nSpiked is quite often linked to by American media and it equally points its followers to American \npartisan news media. Th e Swedish media establish domestic connections but also point to the \nAmerican news ecosystem on the political right. Especially Ledarsidorna  is active in this regard. The \nGerman Journalistenwatch appears well integrated in this ecosystem, attrac ting transnational \nattention from various American media. German Politikstube  is interesting for being connected to \nSwedish, Danish and American media. From Austria, Unzensuriert  is the one establishing transnational \nlinks. However, the majority of the Aus trian, German and Danish media is not connected to the other \nalternative media  by direct hyperlinks during the time span we analyzed.  \n\n31 FIGURE 4: Twitter Direct Interconnections Among our N ews Media via H yperlinks to Websites  \nNetwork of hyperlink co nnections , n=66 news media, created with Force Atlas by Gephi. Node size represents in -degree. Colored by country: US (pink), Germany (green), Austria (orange), Sweden \n(blue), UK (red), Denmark (dark green).  \n\n \n32 \n  \nConclusion  \n \nOur paper set out t o assess commonalities and differences in the architectures of right -wing and \npopulist digital news infrastructures in five European countries and the US , as well as to explore to \nwhat extent this digital information environment is intercon nected within and across countries. The \ncountries we selected differ in terms of political context. Sweden, Germany and the UK represent \ncountries in which the electoral success and political acceptance of right -wing populist parties or \npoliticians has \u2013 at least until recently -  been comparatively low , while the acceptance of right -wing \nand right -wing populist views is much more pronounced in Denmark, Austria and the US. In Sweden \nand Germany, the mass media strive for demarcation and dismissal of far right and populist positions, \nand audience polarization  of \u2018mainstream\u2019 online media is comparatively low. This makes Sweden and \nGermany a context in which niche media on the far - and populist right might be more li kely to flourish, \nas well as  to have an incentive to establish transnational connections with like-minded sites , both \nnationally and transnationally . In Denmark and Austria, the legacy media might be se en as at least \nindirectly  supporting and featuring  actors and positions on the far and populist right. Together with a \nmore polarized online news environment, which provides room for right -wing positions within the \n\u2018mainstream\u2019  media landscape, the \u2018need\u2019 for alternative niche media and (trans -)national \ninterconnections might be less pronounced. In the UK and US we observe highly polarized media \ncontexts, where some legacy m edia are seen as more or less directly supporting  right -wing populist \nviews , and where at the same time levels of trust in news in general are extremely low . All in all, we \ntherefore expect ed the alternative right -wing news infrastructure to be flourishing \u2013  both within the \nnational and transnational sphere -  in Sweden and Germany, followed by the UK and US , whereas we \nexpected less activity in Denmark and Austria.  \nOur analysis of the digital news infrastructures on the far and populist right shows  that the right -wing \nonline news landscape in Sweden  as expected  appears well- established and differentiated. Despite \ntheir different user profiles, the identified sites have in common that they are largely geared toward s \na stable, committed user  base, rather than to random snippets of a broader audience, as illustrated by \na funding structure that not primarily rests on advertisement revenues. User rates, as well as the \nclassical news built -up of many of the sites moreove r suggest that they are being used as a regular \nsource of general news consumption for many of these users.  Equally, the right -wing online news \necosystem in Germany is well- developed and diverse, with a mixture of longstanding and digital- only \nnews providers and of thematically focused niche media on one side versus very active and \nthematically diversified media on the other. The German media are transparent about their \norganizational structures and financially based on a diversified funding strategy. Overall, supply and \ndemand data indicate a stable supply structure and a broad and regular user base, although the \n \n33 \n German sites vary substantially with regard to the number of users they can attract and with two sites \ndominating the social media presence of right -wing media in Germany.  \nAs expected, both supply and demand of right -wing online news sites are extremely limited  in \nDenmark.  The existing sites are rather homogeneous with regard to the people behind (former \nmainstream politicians/journalists), the overall political stand -point (none of them belongs to the \nextreme right), and their limited social media use. Despite their limited relevance and size, all \nhomepages have a rather professional make -up (except for the underdeveloped topic categories).  \nThe Austrian news infrastructure is in contrast more established than we would have expected judged \nby the significant number of news media that met our criteria. In terms of content supply , they are \nhowever  - together with the UK -  overall the least active ones among our countries. User demand in \nAustria seems also comparatively low. However, we find a substantial degree of user attention for \nmany Austrian sites in Germany . The f act that the Austrian sites thus largely also cater to a German \naudience, for which we expected a higher level of demand for alternative right -wing news, thus \n\u2018conflates \u2019 our results for the Austrian supply -side \u2013 while at the same time underlining the imp ortance \nof a transnational perspective in the study of right -wing news architectures.  \nFor the UK, in contrast, supply and demand o f the right- wing news homepages are very limited and \nlower than expected , whereas demand and supply on social media are relatively high. T hree  factors \nmay co me into play here: for one, a rather polarized legacy media that allows for the expression of \nright -wing positions, for the other a strong pull of US based and international right -wing news sites  (as \nbest illustrate d by the prominence of Breitbart UK , which in our study judged by the organization  and \nhomepage structure features as a US site) , and finally the important role of right -wing pundits in the \nUK that possibly saturate the market for right -wing content online .  \nThe US represents a stark outlier in many ways , the most obvious of which is the relative  enormity of \nboth the demand and supply sides, marked f irst and foremost by the  sheer amount and the broad \nspectrum of online news providers that meet the selection criteria defined for this project.  Here we \ncertainly  need to account for the countr y\u2019s size and population numbers  which provides a much larger \nmarket for news consumption than any of the other countries analyzed (or all of them put together, \nfor that matter).  While the  total  figures we get for the criteria of supply and demand may thus see m \nmuch higher at first glance, when it comes to their relative value based on population numbers, they \nare in fact lower than in Sweden  or Austria and Germany (when it comes to sites per million inhabitants \nor relative  share of sites among the top 5000).  So w hile population size  may account for some of the \ndeviatio n in terms of how many variations  of this type of medium seem to flourish  in the US , it is \nunlikely to be the only explanation.  And we should note that in terms of the collective content these \nsites produce, as measured  via social media activity and averag es of articles, this group maintains its \nstatus of clear outlier.  The US sample  also stand s out in regard to how well the various sites appear to \n \n34 \n be networked within the national context. This might point towards a more ideologically coherent \nright -wing pu blic sphere, that appear more established  and better  networked than in countries where \nsuch a phenomen on might be considered relatively recent  (e.g. Germany). Another indicator for this \nmight certainly be the central role that populist right -wing politics currently plays in the US  as well as \nthe high levels of polarization among the voting public and media consumers . In contrast to examples \nlike the UK, where individual pundits  with extreme views might still engage via the same forms of more \nmedia  venues, t he US market might be more fragmented  when it comes to an  alternative ecosystem \non the political right.  \nIn the final part of the study, we focused on the transnational networking of the analyzed right -wing \nnews sites. Overall and across the three digital platforms ( Homepage , FB, Twitter) analyzed in detail in \nour stud y, direct  transnational linkages  between our alternative online media are quite sparse. \nHowever, the established horizontal interconnections across countries often connect Swedish and \nGerman media with a domestically networked American news ecosystem on the far right . Moreover, \nwe can account for interconnections across borders between news sites with the same language \n(Germany -Austria, UK -US). However, the low degree of (trans -)national interconnectedness of our \nmedia sample by direct  links among our cases should not be interpreted as a lack of horizontal \nnetworking overall. It might well be that our media are interconnected through longer ties, \nintermediaries and bridge actors -  a question that shall be addressed i n a next step, taking the complete \nnetwork data into account.  \n \n \nReferences  \nAckland, R. and Gibson, R. (2013) \u2018Hyperlinks and networked communication: a comparative study of \npolitical parties online \u2019, International Journal of Social Research Methodology . Routledge, 16(3), pp. \n231\u2013244. doi: 10.1080/13645579.2013.774179.  \nVan Aelst, P. et al.  (2017) \u2018Political communication in a high -choice media environment: a challenge \nfor democracy? \u2019, Annals of the International Communication Association, 41(1), pp. 3 \u201327. \nAkkerman, T. (2011) \u2018Friend or foe? Right -wing populism and the po pular press in Britain and the \nNetherlands \u2019, Journalism , 12(8), pp. 931 \u2013945. doi: 10.1177/1464884911415972.  \nArmingeon, K., Guthmann, K. and Weisstanner, D. (2015) \u2018Wie der Euro Europa spaltet. Die Krise der \ngemeinsamen W \u00e4hrung und die Entfremdung von der D emokratie in der Europ \u00e4ischen Union \u2019, PVS \nPolitische Vierteljahresschrift , 56(3), pp. 506 \u2013531.  \nArzheimer, K. (2009) \u2018Contextual Factors and the Extreme Right Vote in Western Europe, 1980 -2002 \u2019, \nAmerican Journal of Political Science , 53(2), pp. 259\u2013 275. doi : 10.1111/j.1540- 5907.2009.00369.x.  \nArzheimer, K. (2015) \u2018The AfD: Finally a Successful Right -Wing Populist Eurosceptic Party for \nGermany? \u2019, West European Politics . Routledge, 38(3), pp. 535 \u2013556. doi: \n10.1080/01402382.2015.1004230.  \nAtkinson, J. D. and Berg, S. V. L. (2012) \u2018Narrowmobilization and Tea Party Activism: A Study of Right -\nLeaning Alternative Media\u2019 , Communication Studies , 63(5), pp. 519\u2013 535.  \nAtton, C. (2002) Alternative Media. London: SAGE Publications Ltd.  \nAtton, C. (2006) \u2018Far-Right Media on th e Internet: Culture, Discourse and Power \u2019, New Media & Society , \n8(4), pp. 573\u2013 587.  \n \n35 \n Atton, C. (2007) \u2018Current Issues in Alternative Media Research \u2019, Sociological Compass , 1(1), pp. 17 \u201327. \nB\u00e4chler, C. M. and Hopmann, D. N. (2017) \u2018Denmark: The Rise of the Da nish People \u2019s Party \u2019, in Aalberg, \nT. (ed.) Populist political communication in Europe , pp. 29 \u201341. \nBaldauf, J. et al.  (2016) \u2018Monitoringbericht 2015/16. Rechtsextreme und menschenverachtende \nPh\u00e4nomene im Social Web \u2019. Berlin: Amadeu Antonio Stiftung.  \nBaldauf, J. et al.  (2017) Toxische Narrative -  Monitoring rechts -alternativer Akteure , Initiativen f \u00fcr \nZivilgesellschaft und demokratische Kultur . Berlin: Amadeu Antonio Stiftung.  \nBastian, M., Heymann, S. and Jacomy, M. (2009) \u2018Gephi: An Open Source Software for Exploring and \nManipulating Networks \u2019. International AAAI Conference on Weblogs and Social Media.  \nBenkler, Y. (2006) The Wealth of Networks. How Social Production Transforms Markets and Freedom . \nNew Haven [Conn.]: Yale University Press.  \nBenkler, Y. et al.  (2017) \u2018Study: Breitbart -Led Right -Wing Media Ecosystem Altered Broader Media \nAgenda \u2019, Columbia Journalism Review , pp. 1 \u201312. Available at: https://www.cjr.org/analysis/breitbart -\nmedia -trump -harvard -study.php.  \nBerbuir, N., Lewandowsky, M. and Siri, J. (2015)  \u2018The AfD and its sympathisers: Finally a right -wing \npopulist movement in Germany? \u2019, German Politics . Taylor & Francis, 24(2), pp. 157 \u2013178. doi: \n10.1080/09644008.2014.982546.  \nBeyersd \u00f6rfer, A. et al.  (2017) Vernetzer Hass -  Wie Rechtsextreme im Social Web J ugendliche \numwerben. Jugendschutz.net.  \nBorra, E. and Rieder, B. (2014) \u2018Programmed method: Developing a toolset for capturing and analyzing \ntweets \u2019, Aslib Journal of Information Management , 66(3), pp. 262 \u2013278. doi: 10.1108/AJIM -09-2013 -\n0094.  \nBr\u00fcggemann, M.  et al.  (2014) \u2018Hallin and Mancini Revisited: Four Empirical Types of Western Media \nSystems \u2019, Journal of Communication, 64(6), pp. 1037\u2013 1065.  \nBurris, V., Smith, E. and Strahm, A. (2000) \u2018White Supremacist Networks on the Internet\u2019, Sociological \nFocus , 33(2 ), pp. 215 \u2013235.  \nCaiani, M. and Kr\u00f6 ll, P. (2015) \u2018The Transnationalization of the Extreme Right and the Use of the \nInternet\u2019, International Journal of Comparative and Applied Criminal Justice , 39(4), pp. 331\u2013 351. doi: \n10.1080/01924036.2014.973050.  \nCaiani, M . and Parenti, L. (2013) European and American Extreme Right Groups and the Internet . 1st \nedn. Burlington, Vt.: Ashgate.  \nChandler, A. (2015) The \u2018Worst \u2019 German Word of the Year , The Atlantic. Available at: \nhttps://www.theatlantic.com/international/archive/ 2015/01/the -worst -german -word -of-the-\nyear/384493/ (Accessed: 9 March 2018).  \nEsser, F., Stepi \u0144ska, A. and Hopmann, D. N. (2016) \u2018Populism and the Media: Cross -National Findings \nand Perspectives \u2019, in Aarlberg, T. et al. (eds) Populist Political Communication  in Europe . New York and \nLondon: Routledge, pp. 365 \u2013380. doi: 10.4324/9781315623016.  \nEuropean Commission (2017) Standard Eurobarometer 88. Media use in the European Union. European \nCommission.  \nFawzi, N., Obermaier, M. and Reinemann, C. (2016) \u2018Germany - Is the Populism Laggard Catching Up? \u2019, \nin Aalberg, T. (ed.) Populist Political Communication in Europe . New York: Routledge, pp. 111 \u2013126. doi: \n10.4324/9781315623016.  \nGeiges, L., Marg, S. and Walter, F. (2015) Pegida: die schmutzige Seite der Zivi lgesellschaft?  Bielefeld: \ntranscript.  \nHawkins, O., Keen, R. and Nakatudde, N. (2015) General Election 2015 , House of Commons Library . \nAvailable at: http://researchbriefings.parliament.uk/ResearchBriefing/Summary/CBP -7186.  \nHellstr\u00f6 m, A. and Hervik, P. (2014 ) \u2018Feeding the Beast: Nourishing Nativist Appeals in Sweden and in \nDenmark \u2019, Journal of International Migration and Integration. Dordrecht, 15(3), pp. 449 \u2013467.  \nH\u00f6lig, S. and Hasebrink, U. (2018) Reuters Institute Digital News Report 2018. Ergebnisse f \u00fcr \nDeutschland. 44. Hamburg. Available at: www.hans -bredow -institut.de.  \nHolt, K. (2016a) \u2018\u201cAlternativmedier \u201d?: En Intervjustudie om Mediekritik och Mediemisstro \u2019, in \nTruedson, L. (ed.) Migrationen i medierna: Men det f \u00e5r en v \u00e4l inte prata om?  Stockholm: Institu tet f \u00f6r \n \n36 \n mediestudier, pp. 113 \u2013149.  \nHolt, K. (2016b) \u2018Media criticism and mistrust in Swedish anti- immigration alternative media\u2019, in The \n66th Annual Conference of the International Communication Association: Communicating with power, \nFukoka 9 -13 June, 2016 . Available at: http://urn.kb.se/resolve?Urn=urn \u202f:nbn:se:lnu:diva -57364.  \nHolt, K. (2017a) \u2018Completely Different or Versions of the Same?: A comparison of mainstream media \n(MSM) and immigration -critical alternative media (ICAM) in Sweden \u2019, in The 67th Annual Conference \nof the International Communication Association: Communication Research and Practice, San Diego, 25 -\n29 May, 2017. International Communication Association (ICA).  \nHolt, K. (2017b) \u2018Shaking the foundations of the \u201c corridor of opinion \u201d?: Towards a framework for \nanalysing Immigration Critical Alternative Media (ICAM) in Sweden \u2019, in ECPR 2017 General Conference, \nOslo, 6 -9 September . ECPR Press.  \nHOPE not hate (2018) State of Hate 2018. Far Right Terrorism On The Rise . Available at: \nhttps://www.hopenoth ate.org.uk/wp -content/uploads/2018/03/State -of-Hate -2018.pdf.  \nHopkins, D. J. et al.  (2014) \u2018The Consequences of Broader Media Choice: Evidence from the Expansion \nof Fox News * \u2019, Quarterly Journal of Political Science , 9(1), pp. 115 \u2013135. doi: 10.1561/100.00 012099.  \nHumprecht, E. and Esser, F. (2017) \u2018 Diversity in Online News: On the importance of ownership types \nand media system types \u2019, Journalism Studies , 2017, pp. 1\u2013 23. Available at: doi: \n10.1080/1461670X.2017.1308229.  \nJagers, J. and Walgrave, S. (2007) \u2018Populism as political communication style: An empirical study of \npolitical parties \u2019 discourse in Belgium \u2019, European Journal of Political Research, 46(3), pp. 319 \u2013345.  \nJ\u00f8nsson, M. A. (2017) \u2018Fake News \u2019 i Danmark -  Kampen om sandheden. Roskilde University.  \nJugendschutz.net (2017) Moderner Lifestyle und Szene -Rekrutierung bei Instagram . Available at: \nhttp://www.jugendschutz.net/fileadmin/download/pdf/Themenpapier_Moderner_Lifestyle_und_Sz\nene-Rekrutierung_bei_Instagram.pdf (27.08.2018).  \nJungherr, A. (2015) Anal yzing Political Communication with Digital Trace Data: The Role of Twitter \nMessages in Social Science Research. Cham: Springer.  \nKoopmans, R. and Erbe, J. (2004) \u2018Towards a European public sphere? \u2019, Innovation: The European \nJournal of Social Science Research , 17(2), pp. 97\u2013 118. doi: 10.1080/1351161042000238643.  \nKr\u00e4mer, B. (2017a) \u2018Populist and non -populist media: Their paradoxical role in the development and \ndiffusion of a right -wing ideology \u2019, in Heinisch, R., Holtz -Bacha, C., and Mazzoleni, O. (eds) Political \nPopulism . Baden -Baden: Nomos, pp. 405 \u2013420. doi: 10.5771/9783845271491 -405.  \nKr\u00e4mer, B. (2017b) \u2018Populist online practices: the function of the internet in right -wing populism \u2019, \nInformation Communication and Society , 20(9), pp. 1293 \u20131309. doi: \n10.1080/13 69118X.2017.1328520.  \nLewis, C. (2016) The future of journalism in three words: collaboration, collaboration, collaboration, \nAmerican University School of Communication.  \nMancini, P. (2013) \u2018Media Fragmentation, Party System, and Democracy \u2019, The International Journal of \nPress/Politics . SAGE Publications Inc, 18(1), pp. 43 \u201360. doi: 10.1177/1940161212458200.  \nMann, T. E. and Ornstein, N. J. (2012) It \u2019s even worse than it looks \u202f: how the American constitutional \nsystem collided with the new politics of extremism. New York, NY: NY: Basic Books.  \nMitchell, A. et al.  (2014) Political Polarization &amp; Media Habits , Pew Research Center . Available at: \nhttp://www.journalism.org/2014/10/21/political- polarization -media -habits/ (Accessed: 27 August \n2018).  \nMosca, L. and Quar anta, M. (2016) \u2018News diets, social media use and non -institutional participation in \nthree communication ecologies: comparing Germany, Italy and the UK \u2019, Information, Communication \n& Society , 19(3), pp. 325\u2013 345. doi: 10.1080/1369118X.2015.1105276.  \nMukerjee, S., Majo -Vazquez, S. and Gonzalez- Bailon, S. (2018) \u2018Networks of Audience Overlap in the \nConsumption of Digital News \u2019, Journal Of Communication, 68(1), pp. 26 \u201350. \nNewman, N. et al.  (2017) Reuters Institute Digital News Report 2017 . Reuters Institute for the Study of \nJournalism. Available at: https://reutersinstitute.politics.ox.ac.uk/sites/default/files/Digital News \nReport 2017 web_0.pdf.  \nNewman, N. (2018) \u201c They tell the truth I like \u201d  \u2013 Partisan And Alternative News Sites in Europe , \n \n37 \n European Journalism Observatory . \nNewman, N. et al.  (2018) Reuters Institute Digital News Report 2018 . doi: \n10.1017/CBO9781107415324.004.  \nOscarsson, H. (2013) Henrik Ekengren Oscarsson: V \u00e4ljare \u00e4r inga dumbommar . Available at: \nhttp://www.henrikoscarsson.com/2013/12/valjare -ar-inga -dumbommar.html (Accessed: 27 August \n2018).  \nPavan, E. and Caiani, M. (2017) \u2018\u201c Not in my Europe \u201d: Extreme Right Online Networks and Their \nContestation of EU Legitimacy \u2019, in Caiani, M. and  Guerra, S. (eds) Euroscepticism, Democracy and the \nMedia. London: Palgrave Macmillan, pp. 169 \u2013193. doi: 10.1057/978- 1-137-59643 -7. \nPew Research Center (2017) The Partisan Divide on Political Values Grows Even Wider . Available at: \nhttp://assets.pewresearch .org/wp -content/uploads/sites/5/2017/10/05162647/10 -05-2017-\nPolitical- landscape -release.pdf (12.03.2018).  \nPlasser, F. and Ulram, P. A. (2003) \u2018Striking a responsive chord: Mass media and right -wing populism in \nAustria\u2019, in Mazzoleni, G., Stewart, J., and H orsfield, B. (eds) The media and neo -populism: A \ncontemporary comparative analysis . Westport, CT: Praeger, pp. 21 \u201344. \nPolk, J. et al.  (2017) \u2018Explaining the salience of anti- elitism and reducing political corruption for political \nparties in Europe with the  2014 Chapel Hill Expert Survey data\u2019, Research & Politics . London, England, \n4(1 NO -Research & Politics, January 2017, Vol.4(1)).  \nReinemann, C. (2017) \u2018Populismus, Kommunikation, Medien. Ein \u00dc berblick \u00fcber die Forschung zu \npopulistischer politischer Kommun ikation \u2019, Zeitschrift f\u00fc r Politik , 64(2), pp. 167 \u2013190. doi: \n10.5771/0044 -3360 -2017 -2-167.  \nSchmuck, D., Matthes, J. and Boomgaarden, H. G. (2016) \u2018Austria. Candidate -Centered and Anti -\nImmigrant Right -Wing Populism \u2019, in Aarlberg, T. et al. (eds) Populist Pol itical Communication in Europe . \nNew York and London: Routledge, pp. 85 \u201398. \nSeethaler, J. and Melischek, G. (2013) Kommt es in \u00d6 sterreich zu neuen Allianzen zwischen Medien und \nParteien?  Wiesbaden: Springer Fachmedien.  \nSimpson, P. A. and Druxes, H. (2015) Digital Media Strategies of the Far Right in Europe and the United \nStates. Maryland: Lexington Books.  \nStanyer, J., Archetti, C. and Sorensen, L. (2016) \u2018The United Kingdom: Hybrid Populisms, Mixed \nFortunes, and Unstable Support \u2019, in Aalberg, T., Esser, F., and Reinemann, C. (eds) Populist Political \nCommunication in Europe . New York; London: Routledge, pp. 165 \u2013180.  \nSt\u00f6ss, R. (2000) Rechtsextremismus im vereinten Deutschland. 3rd edn. Berlin: Friedrich Ebert Stiftung. \nAvailable at: http://library.fes.de/pdf- files/ostdeutschland/00887.pdf (Accessed: 19 April 2018).  \nStr\u00f6mb\u00e4ck, J., Jungar, A. -C. and Dahlberg, S. (2017) \u2018Exception, Sweden: No Longer the European \u2019, in \nAalberg, T. (ed.) Populist political communication in Europe , pp. 68 \u201384. \nVergeer, M. (2015) \u2018 Twitter and Political Campaigning \u2019, Sociology Compass , 9(9), pp. 745 \u2013760.  \nWayne, M. and Murray, C. (2009) \u2018U.K. Television News \u2019, pp. 416 \u2013433.  \nWebster, J. G. (2014) The Marketplace of Attention -  How Audiences Take Shape in a Digital Age . \nAvailable at: https://e bookcentral.proquest.com/lib/fuberlin -ebooks/detail.action?docID=3339857.  \nWessler, H. and Br\u00fc ggemann, M. (2012) Transnationale Kommunikation. Wiesbaden: VS Verlag f\u00fc r \nSozialwissenschaften. doi: 10.1007/978 -3-531-94190 -5. \nWolf, C. (2014) Mobiler Journalismus: Angebote, Produktionsroutinen und redaktionelle Strategien \ndeutscher Print - und Rundfunkredaktionen (Aktuell. Studien zum Journalismus, Bd. 8).  1. Aufl., Die \nInstitutionalisierung von Mobilem Journalismus . 1. Aufl. Nomos. doi: 10.5771/9783845254654.  \nWolf, T. (2017) Rechtspopulismus. \u00dcberblick \u00fcber Theorie und Praxis . Wiesbaden: Springer VS.  \n ", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Transnational nationalism? Comparing right-wing digital news infrastructures in Western Democracies", "author": ["A Heft", "E Mayerh\u00f6ffer", "S Reinhardt"], "pub_year": "2018", "venue": "Internet, Policy & Politics \u2026", "abstract": "Annett Heft1 (corresponding author) annett. heft@ fu-berlin. de Eva Mayerh\u00f6ffer2 evamay@  ruc. dk Susanne Reinhardt1 s. reinhardt@ fu-berlin. de Curd Kn\u00fcpfer1 curd. knuepfer@ fu-"}, "filled": false, "gsrank": 857, "pub_url": "http://blogs.oii.ox.ac.uk/policy/policy/wp-content/uploads/sites/77/2018/08/IPP2018-Heft.pdf", "author_id": ["", "hLI_ciMAAAAJ", "9XtZh4YAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:scAoWHRJqpoJ:scholar.google.com/&output=cite&scirp=856&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D850%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=scAoWHRJqpoJ&ei=obWsaKLFCqzWieoPic2ZoAU&json=", "num_citations": 4, "citedby_url": "/scholar?cites=11144800991925813425&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:scAoWHRJqpoJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "http://blogs.oii.ox.ac.uk/policy/policy/wp-content/uploads/sites/77/2018/08/IPP2018-Heft.pdf"}}, {"title": "Tgdataset: Collecting and exploring the largest telegram channels dataset", "year": "2025", "pdf_data": "TGDataset: Collecting and Exploring\nthe Largest Telegram Channels Dataset\nMassimo La Morgia\nSapienza University of Rome,\nDepartment of Computer Science\nRome, Italy\nlamorgia@di.uniroma1.itAlessandro Mei\nSapienza University of Rome,\nDepartment of Computer Science\nRome, Italy\nmei@di.uniroma1.itAlberto Maria Mongardini\nSapienza University of Rome,\nDepartment of Computer Science\nRome, Italy\nmongardini@di.uniroma1.it\nAbstract\nTelegram is a widely adopted instant messaging platform. It has\nbecome worldwide popular because of its emphasis on privacy\nand its social network features such as channels\u2014virtual rooms in\nwhich only the admins can post and broadcast messages to all the\nsubscribers. Channels are used to deliver live updates ( e.g.,weather\nalerts) and content to a large audience ( e.g.,COVID-19 announce-\nments) but unfortunately also to disseminate radical ideologies and\ncoordinate attacks such as the Capitol Hill riot.\nThis paper introduces the TGDataset, the most extensive pub-\nlicly available collection of Telegram channels, comprising 120,979\nchannels and over 400 million messages. We outline the data collec-\ntion process and provide a comprehensive overview of the data set.\nUsing language detection, we identify the predominant languages\nwithin the dataset. We then focus on English channels, employing\ntopic modeling to analyze the subjects they cover. Finally, we dis-\ncuss some use cases in which our dataset can be instrumental in\nunderstanding the Telegram ecosystem and studying the diffusion\nof questionable news. Alongside the raw dataset, we release the\nscripts used in our analysis, as well as a list of channels associated\nwith a novel conspiracy theory known as Sabmyk.\nCCS Concepts\n\u2022Information systems \u2192Information retrieval ;Social networks .\nKeywords\nDataset, Telegram, Conspiracy Theories, Copyright Infringement\nACM Reference Format:\nMassimo La Morgia, Alessandro Mei, and Alberto Maria Mongardini. 2025.\nTGDataset: Collecting and Exploring the Largest Telegram Channels Dataset.\nInProceedings of the 31st ACM SIGKDD Conference on Knowledge Discovery\nand Data Mining V.1 (KDD \u201925), August 3\u20137, 2025, Toronto, ON, Canada. ACM,\nNew York, NY, USA, 10 pages. https://doi.org/10.1145/3690624.3709397\n1 Introduction\nIn today\u2019s digital age, instant messaging apps have become ubiq-\nuitous, and Telegram stands out as one of the leading platforms.\nIts focus on user privacy is a significant factor behind its growing\npopularity [ 10]. However, as is often the case with platforms that\nprioritize user privacy, this approach has also attracted malicious\nThis work is licensed under a Creative Commons Attribution 4.0 International License.\nKDD \u201925, August 3\u20137, 2025, Toronto, ON, Canada\n\u00a92025 Copyright held by the owner/author(s).\nACM ISBN 979-8-4007-1245-6/25/08\nhttps://doi.org/10.1145/3690624.3709397users who exploit the platform for illegal activities. While Telegram\nserves legitimate purposes, such as disseminating weather alerts\nor government updates [ 42], it is also misused for spreading radi-\ncal ideologies [ 3], orchestrating violent attacks [ 1], and engaging\nin market manipulations, such as pump-and-dump schemes [ 41].\nThese dual uses underscore Telegram\u2019s complex nature and high-\nlight the need for a deeper exploration of its ecosystem.\nIn this study, we introduce and publicly release [ 38] the TG-\nDataset, a collection of public Telegram channels of over 120,000\nchannels and 400 million messages. To the best of our knowledge,\nthe TGDataset surpasses existing datasets in scale and scope, offer-\ning an unprecedented opportunity to study the Telegram ecosystem\ncomprehensively. Unlike prior datasets focused on specific topics\nor geographic regions, the TGDataset includes diverse channels\ncovering multiple languages and subjects, enabling a more holistic\nunderstanding of the platform. In particular, the TGDataset enables\nthe study of the platform\u2019s political leanings and the sharing of\nquestionable content, topics widely explored on other Online Social\nNetworks (OSNs) but not on Telegram. It also includes numerous\nchannels spreading conspiracy theories, as well as those engaged\nin borderline or illegal activities like carding, inciting violence, and\npromoting Nazi ideologies. Thus, with its scale and diversity, the\nTGDataset represents a valuable resource for researchers willing to\ninvestigate and shed light on both the legitimate and problematic\naspects of Telegram\u2019s ecosystem.\nThe main contributions of this work are the following:\n\u2022We present the largest publicly available dataset of Telegram\nchannels, enabling researchers to explore various phenom-\nena on the platform. We perform analyses such as language\ndetection and topic modeling to characterize the dataset\u2019s\ncontents, revealing dominant languages, prevalent topics,\nand temporal trends in channel creation.\n\u2022We explore several potential use cases of the TGDataset. One\napplication involves analyzing the diffusion of questionable\ncontent and biases across Telegram channels, providing in-\nsights into content moderation and information reliability.\nAnother use case focuses on investigating networks that\npromote conspiracy theories, including emerging phenom-\nena such as the Sabmyk network. Additionally, the dataset\ncan be used to investigate channels engaged in borderline\nor illegal activities, such as carding, copyright infringement,\nand extremist propaganda.\n\u2022Alongside the dataset, we release scripts for analysis, lan-\nguage detection, and topic modeling, fostering reproducibil-\nity and facilitating further research.\nKDD \u201925, August 3\u20137, 2025, Toronto, ON, Canada Massimo La Morgia, Alessandro Mei, and Alberto Maria Mongardini\n1\n2\n435\n6\n(A) (B) (C ) \nFigure 1: Fig. (A) represents the main information about a channel: the title (1), the number of subscribers (2), the description\n(3), and the username (4). Fig. (B) shows the posts published by the channel (5). Fig. (C) displays a forwarded message (6).\n2 Background: Telegram\nStarted in 2013, Telegram is now a popular instant messaging plat-\nform, with more than 500 million active users in 2021 [ 7]. Telegram\nallows users to post content such as text messages, images, audio,\nstickers, videos, and files weighing up to 2 GB. In addition to private\nchats (one-to-one communication), Telegram provides two other\nways to communicate: Through groups and channels.\nGroups : Designed for many-to-many messaging, groups allow\nup to 200,000 members to communicate with each other by posting\ncontent. Groups are identified by a unique username and have a\ndescription and a title. They can be public ( i.e.,can be found with\nTelegram search, and every user can read its content and join the\ngroup) or private ( i.e.,only members can see the posts, and users\nneed an invite link to join it). Besides, a group presents a list of its\nmembers which, if the group is public, is visible to anyone (even\nnon-members).\nChannels : They offer one-to-many communication. Thus, dif-\nferently from groups where every member can post messages, in\nchannels, only administrators can publish posts. Channels have a\nunique username, a title, a description, and can be private or public.\nFig. 1 presents the information displayed by a channel. Contrary\nto groups, a channel can have an unlimited number of subscribers\nand does not display any users\u2019 information ( i.e.,nicknames) other\nthan the number of its subscribers. Thanks to these features, Tele-\ngram channels have become popular for disseminating content to a\nlarge audience. Indeed, several public figures and companies started\nusing official Telegram channels to share news and updates [ 42].\nNonetheless, this tendency caused an increase in the number ofchannels on the platform seeking to impersonate official channels\nor sell counterfeit products and services.\nScam and Verified mark : To tackle this issue, Telegram has\nimplemented the verified and the scam marks. The verified mark\nrequires that channels, groups, and bots prove their verified sta-\ntus on at least two social media platforms( e.g.,TikTok, Facebook,\nTwitter, Instagram) [ 9]. In contrast, the scam status is assigned to\nchannels and groups reported for fraud by multiple users [52].\nThe forward mechanism : Although private chats, groups, and\nchannels can not communicate directly among them, they are not\nisolated but may be linked through message forwarding. Leveraging\nthis feature, users and channels can forward messages to other users,\ngroups, or channels displaying the post\u2019s original author. Fig. 1\nshows an example of message forwarding, where the admin of\n\"Channel A\" (Fig. 1 (C)) forwards in his channel a message from the\nBloomberg\u2019s channel. The message in the red square of Fig. 1 (B)) is\nthe original message, while the one in the red square of Fig. 1 (C) is\nthe forwarded message. As shown in Fig. 1, the forwarded message\ndisplays the name of the original channel of the post, which, if\nclicked, leads to that channel.\n3 Related works\nSeveral studies have been conducted on the Telegram platform\nand related issues. Hashemi et al. [ 27] collected Telegram Iranian\nchannels and groups to distinguish high-quality groups ( e.g.,busi-\nness groups) from low-quality groups ( e.g.,dating groups). They\nfound that high-quality groups had longer messages and more user\nengagement. Jalilvand et al. [ 34] tackled the challenge of ranking\nTGDataset: Collecting and Exploring\nthe Largest Telegram Channels Dataset KDD \u201925, August 3\u20137, 2025, Toronto, ON, Canada\nTable 1: Summary of the number of channels, channel mes-\nsages, and group messages present in both the TGDataset\nand Pushshift.\nDataset # channels # channels msgs Update to\nNobari et al. [20] 2,556 36,928 October 2016\nPushshift [16] 27,801 192,044,689 November 2019\nTGDataset 120,979 498,320,597 July 2022\nchannels related to a user request on Telegram. Ng et al. [ 50] an-\nalyzed a Singapore-based COVID-19 Telegram group with over\n10,000 participants, examining group opinions over time. Their\nwork revealed a peak in engagement when the Ministry of Health\nraised the disease alert level but a subsequent decline in participa-\ntion. Nobari et al. [ 20] performed a structural and topical analysis\nof Telegram messages, building a dataset of over 2,500 channels and\n54 groups and constructing a graph based on mentions. This study\nfound that the PageRank algorithm was not effective in identifying\nhigh-quality Telegram channels. Analyzing the dataset released\nby Nobari et al., the TGDataset contains more than ten times the\nnumber of channels and is significantly more recent (July 2022\nversus October 2016).\nSimilar to our work, Baumgartner et al. [ 16] created the Pushshift\nTelegram dataset, containing both channels and groups. They col-\nlected over 27,800 channels and 317 million messages from 2.2 mil-\nlion unique users updated to November 2019. Differently from [ 16],\nthe TGDataset boasts a more recent dataset, with the message his-\ntory of channels aligned to July 2022, thus almost three years of\nmore data. Moreover, while the Pushshift dataset contains both\nchannels and groups, the TGDaset is made of only channels. Thus,\nnarrowing the comparison on the Telegram channels, the TG-\nDataset includes a significantly higher number of channels (ap-\nproximately four times more) and a greater volume of messages\nposted in channels (more than double). Table 1 provides the exact\nnumber of channels and messages contained in the dataset released\nby [20], Pushshift, and TGDataset. Finally, another important differ-\nence between the two datasets is about the seed choice. Indeed, the\nPushshift dataset used as seed channels only those of right-wing\nextremist politics or cryptocurrencies-related channels, while our\ndataset starts the collection from seed channels covering hetero-\ngeneous topics (see Sec. 4.1). This choice led to building a dataset\nthat should better represent the status of the Telegram channels\necosystem.\nWeerasinghe et al. [ 63] found that Telegram hosts organized\ngroups called \"pods\" where members boost each other\u2019s Instagram\naccount popularity through interaction. Other studies have docu-\nmented the presence of Telegram channels and groups focused on\ncryptocurrency pump and dump scams [ 41,65]. The work of Urman\net al. [ 61] explored far-right networks on Telegram, revealing that\nthe most prevalent communities are those related to 4chan [ 12]\nand Donald Trump\u2019s supporters. Moreover, the authors pointed out\nthat the sudden growth of these networks on Telegram corresponds\nwith the bans of numerous far-right figures on other online social\nnetworks. Additionally, numerous studies have investigated the\n(1) Seed \nchannels (2) Channels \nretrieval \n(5) Channels \nparsing (4) Data \nstoring \nChannels list \n(3) Data \nextraction Figure 2: Data collection flow diagram.\nuse of Telegram by terrorist organizations such as ISIS for content\ndissemination and proselytism [18, 66].\n4 Data collection\nPrevious Telegram datasets have been created with specific research\ngoals in mind, resulting in a limited scope of channels related to\na particular language, country, or topic. For example, [27] only in-\ncludes Iranian channels, [ 32] only contains 151 channels related to\nQAnon, and the PushShift dataset focuses on channels discussing\nright-wing extremism and cryptocurrency. In contrast, our dataset\naims to provide a global snapshot of the Telegram ecosystem. To\nachieve this goal, we require a dataset that provides an up-to-date\nrepresentation of Telegram and encompasses a broad range of pop-\nular and interconnected channels. This is the motivation behind\nthe creation of the TGDataset.\n4.1 Dataset construction\nTo build the TGDataset, we use a snowball approach as previously\ndone in [ 16]. We begin with a set of seed channels related to var-\nious topics and then extend our dataset by including the source\nchannel of each forwarded message. Fig. 2 represents the flow di-\nagram we use to collect the data. To determine the seed channels\n(Step 1 in Fig. 2), we utilize Tgstat [ 6], a popular freemium service\nthat indexes over 150,000 Telegram channels and gathers statistics\nabout them. Tgstat provides information for each channel, such\nas the subscriber count, topic category, growth rate, and language.\nAmong the other metrics, Tgstat lists the top 100 channels by the\nnumber of subscribers. From this rank, we retrieve all the categories\nthese channels belong to, finding the following 18 categories:: Sales ,\nHumor and entertainment ,News and Mass media ,Video & Movies ,\nBusiness & Startups ,Cryptocurrencies ,Politics ,Technologies ,Sport ,\nMarketing ,Economics ,Games ,Religion ,Software and Applications ,\nLifehacks ,Fashion & Beauty ,Medicine , and Adults . Finally, we se-\nlected the ten most popular channels from each category as the seed\nchannels according to their subscriber count. With this approach,\nwe collect 180 seed channels.\nFor each seed channel, we proceed with downloading all its\nmessages by leveraging the Telethon APIs [ 8] (Step (2)), an open-\nsource Python tool that provides access to the official Telegram\nAPIs. Specifically, each call to download messages from a channel\nis performed five seconds after the previous one to avoid flooding\nthe Telegram service. Once we retrieved the data about the channel,\nwe proceeded with the data extraction (Step (3)): in particular, we\nKDD \u201925, August 3\u20137, 2025, Toronto, ON, Canada Massimo La Morgia, Alessandro Mei, and Alberto Maria Mongardini\nField name Description\nChannel ID the ID of Telegram channel\nCreation date the timestamp of the creation date of the channel\nUsername the Telegram username of the channel\nTitle the title of the channel\nDescription the description of the channel\nScam indicates if Telegram marked the channel as a scam\nVerified indicates if Telegram marked the channel as verified\n# subscribers the number of subscribers of the channel\nText messages\nMessage the text of the message\nDate the timestamp of the message publication\nAuthor the ID of who posted the message\nIs forwarded indicates if the message is forwarded\nForwarded from the ID from which the message is forwarded\nOriginal date the timestamp of the first post of the message\nMedia messages\nTitle the title of the content\nMedia ID the ID of the content on Telegram\nDate the timestamp of the content\nAuthor the ID of who posted the content (int)\nExtension the format of the content (string)\nIs forwarded indicates if the content is forwarded\nForwarded from the ID from which the content is forwarded\nOriginal date the timestamp of the first post of the content\nTable 2: Information stored about collected channels\nretained all the information obtained by Telegram API, excluding\nmedia files such as images, videos, or PDFs. The reason behind this\ndecision is to avoid storing copyrighted or illegal content. Anyway,\neven for media-based messages, we collect the name, author, and ID\nof the media content using the Telegram API, and we infer the file\nformat based on the extension of the file name. Next, we store the\nextracted information in MongoDB [ 48], a NoSQL database (Step\n(4)). Finally, we parse the channel messages to identify forwarded\nmessages and their original authors (Step (5)). If the author repre-\nsents a channel that we have never seen, then the channel is added\nto the list of new channels. Conversely, if the author is a user or\nrepresents a group, we ignore the author of the forwarded message.\nTo iteratively expand the TGDataset, we repeat the above procedure\nof channel discovery (Steps 2, 3, 4, and 5) using the newly found\nchannels as new seeds. We stopped the iteration process on July 31,\n2022. Finally, to align our dataset, for each discovered channel, we\ndownload all the missing messages until July 31, 2022.\nFor each channel, we store the following information as listed\nin Tab. 2: title and if it is marked as verified or scam (item 1 in\nFig. 1 (A)), subscriber count (item 2), description (item 3), username\n(item 4), ID, and creation date. For the messages, we retain the\nauthor (the name of the channel), timestamp, and, in the case of\nforwarded messages, original posting date and original channel.\n4.2 Accessing the TGDataset and FAIR\nprinciples\nWe released the TGDataset in alignment with the FAIR (Findable,\nAccessible, Interoperable, Reusable) principles [64].Findable. We publicly released the TGDataset [ 37] on Zen-\nodo [24], an open repository managed by CERN.\nAccessible. The dataset is made of 121 files, each of which con-\ntains a maximum of 1,000 channels. To ease the retrieval of single\nchannels from the dataset, we store them in alphabetical order. In\naddition, each file\u2019s name describes the index of the channels it con-\ntains. Given the large dimension of the dataset, even if compressed\n(approx. 71GB), we divided the dataset into four parts. In this way,\nit is possible to download and explore also a single portion of the\ndataset. Moreover, we released a sample of the dataset on a public\nGitHub repository [ 38]. This enables users to explore the dataset\u2019s\nstructure without the need to download any portion of it.\nInteroperable. All the information is encoded in JSON format\nso that the data can be easily parsed and manipulated with most\nprogramming languages.\nReusable. We have outlined the methodology employed for data\ncollection, and the data is open for anyone to use. We also released\non the public GitHub repository [ 38], Python scripts to load the data\ninto a MongoDB [ 15] database, as well as scripts that show how to\nperform basic queries on the database (such as inserting new chan-\nnels or retrieving channels by username or ID). Furthermore, these\nscripts can also replicate some of the analysis that we performed\nin this work, including Language Detection of the channels (Sec-\ntion 5.1) and Topic Modeling (Section 5.2). Finally, we released as\nCSV files the list of channels belonging to the Sabmyk network and\nthe list of other channels promoting conspiracy theories (Sec. 6),\nthe list of channels annotated with the detected writing language,\nand the one containing the mapping of inferred topics.\n4.3 Dataset overview\nThe data collection for the TGDataset began on 4 January 2021 and\nended on 31 July 2022. The dataset has a total size of about 460 GB\nand includes 498,320,597 messages and 120,979 unique channels.\nOut of these channels, 654 (0.54%) have verified status, while 183\n(0.15%) are flagged as scam channels. For the purpose of clarity,\nwe will refer to the remaining 120,142 channels, which are neither\nscams nor verified, as standard channels .\nTo provide a general characterization of the channels contained\nin the TGDataset, in Fig. 3, we show the CDFs of the number of\nsubscribers, posts published, and the ratio of forwarded messages\nfor verified, scam, and standard channels. As shown in Fig. 3(a),\nverified channels (green line), in general, have more subscribers\nthan scam (dashed orange line) and standard channels (dotted blue\nline). Indeed, the verified channels with more than 1,000 subscribers\nare 98.32%, while the scams and standard are 68.85% and 38.11%, re-\nspectively. Concerning the number of messages published, Fig. 3(b)\nsuggests that verified channels tend to post more content than\nscams and standard ones. The standard channels with at least 1,000\nmessages are 57.16%, those verified are 83.79%, and the scams are\n50.82%. Moreover, we report the extent of use of the forwarding\nfunction among channels of the TGDataset. Fig. 3(c) reveals mes-\nsage forwarding is more prevalent in standard and scam channels.\nThe standard channels with at least a 0.1 ratio of their messages\nthat are forwarded are 33.5%, whereas the scams and the verified\nones are 32.24% and 13.15%, respectively.\nTGDataset: Collecting and Exploring\nthe Largest Telegram Channels Dataset KDD \u201925, August 3\u20137, 2025, Toronto, ON, Canada\n0 2000000 4000000 6000000 8000000\nSubscribers0.00.20.40.60.81.0Fraction of channelsVerified\nScam\nStandard0 2000 4000 6000 8000 100000.00.20.40.60.8\n(a) Subscribers\n0 50000 100000 150000 200000 250000 300000\nMessages0.00.20.40.60.81.0Fraction of channelsVerified\nScam\nStandard 0 2000 4000 6000 8000 100000.00.20.40.60.8 (b) Messages.\n0.0 0.2 0.4 0.6 0.8 1.0\nRatio forwarded msgs0.00.20.40.60.81.0Fraction of channelsVerified\nScam\nStandard (c) Forwarded messages\nFigure 3: CDFs of the number of subscribers for scam, verified, and standard channels (3(a)), the number of messages posted\n(3(b)), and ratio of forwarded messages (3(c)).\n5 Dataset analysis\nIn this section, we first study the languages spoken within our\ndataset, leveraging language detection, and explore the English\nchannels to understand the covered topics using topic modeling.\nThen, we analyze the temporal aspects of the TGDataset.\n5.1 Language detection\nAs a first step in our analysis, we want to understand the language\ncoverage of our dataset. This study gives hints about the popular-\nity of the Telegram platform in different regions of the world. To\nautomatically retrieve the language used in a channel, we leverage\nLanguage Detection [ 54], a language detection library implemented\nin Java by Google with over 99%of precision for 53languages. To get\nmeaningful results dealing with text-based messages, first, the text\nhas to be normalized and polished from useless information [ 62].\nHence, we applied the following preprocessing steps. First, we ex-\ncluded messages shorter than 15 characters, as they do not provide\nsufficient information for accurate analysis [14]. Next, we utilized\nthe RegexpTokenizer developed by NLTK [ 5] to split text-based\nmessages into tokens. Then, we removed all numbers and emojis\nfrom the documents, as they do not contribute to language iden-\ntification. Also, we discarded references and mentions of groups,\nchannels, or users, as usernames typically do not aid in identifying\nthe language used.\nWe assign a channel to a specific language only if over 50% of\nits messages are written in that language. Otherwise, we will not\nassociate a language with that channel. At the end of the analysis,\nwe find that the five most spoken languages in our dataset are Rus-\nsian with 42,983 channels (35.52%), English with 19,768 channels\n(16.34%), Farsi with 16,779 channels (13.86%), German 4,950 (4.09%),\nand Arabic with 2,523 (2.08%). Of particular interest is the strong\npresence of the Russian and Farsi channels, which likely reflects the\npopularity of Telegram in Russia and Iran, despite Russia\u2019s govern-\nment banned Telegram from 2018 to 2020 [ 4], and it is still banned\nin Iran [ 13]. Although Iran banned Telegram on 30 April 2018 [ 2],\nin our dataset, there are 4,635 out of 16,779 (27.62%) channels in\nFarsi created after the date of the ban. Instead, looking at the last\nactivity of Farsi\u2019s channels, we find that more than 66.53% (11,164)\nchannels continued to operate after the ban. Regarding Russian\nchannels, as shown in section Sec. 5.3, they continue to appear also\nafter the ban of 2018.5.2 Topic modeling\nIn this subsection, we investigate the topics covered by the channels\nin our TGDataset using Topic Modeling [ 30]. This is a data mining\ntool that allows finding a brief description of the topic addressed\nby the messages of a channel. For this analysis, we consider only\nchannels that post English content. Thus, we use as input to the\ntopic modeling 19,768 channels (16.34% of our dataset). As in lan-\nguage detection, a preprocessing phase is necessary. In addition to\nthe deletion of numbers, deletion of emoji, and normalization, we\nperform other preprocessing steps. We exclude words with one or\ntwo characters, as they are common in messages (e.g., y, no, ok)\nand do not provide meaningful information about the topic. We\nuse the en_core_web_sm model developed by spaCy [ 31] to reduce\ninflected words to their lemmas, ensuring that different forms of\na word are treated as a single term. Lastly, we employ the English\nstopwords list provided by NLTK [ 51] to discard common words\n(e.g., articles and prepositions) that do not carry significant meaning\nin a sentence [53].\nTo discover the latent topics addressed within the channels, we\nuse the Latent Dirichlet Allocation (LDA) [ 17] as the Topic Modeling\nalgorithm. LDA needs as input the number of topics, so we used\nthe UMass measure [ 47] to select the optimal one. In particular, the\nhigher the coherence of the words representing topics, the closer\nto 0 the value of UMass. In our case, we calculate the best UMass\nvalue reached by selecting the number of topics from 10 to 30.\nThe best UMass value (-0.69) is obtained with 13 topics. Tab. 3\nshows the inferred topics and the top 10 keywords for each of\nthem. Next, we group the channels according to the related topics\nusing LDA. Tab. 5 lists the topics discovered in the TGDataset\nand the number of channels for each. These emerged topics are\nquite different from those covered by the seed channels (see Sec. 4).\nIndeed, some disappeared ( e.g.,Psychology, Marketing), while other\ninteresting topics came up. This shift in topic distribution is due\nto the snowball approach, which adds new channels linked by\nmessage forwarding to the dataset. As a result, channels from larger,\nmore interconnected networks with higher forwarding activity are\nmore likely to be included. This method naturally shifts the dataset\ntoward more viral or widely shared topics.\nAmong the new topics, one is related to carding, the practice\nof selling full details of stolen credit cards or selling prepaid cards\nor other goods purchased with them. Similarly to what happens\nKDD \u201925, August 3\u20137, 2025, Toronto, ON, Canada Massimo La Morgia, Alessandro Mei, and Alberto Maria Mongardini\nTopic Top 10 keywords\nVideo-game\nmoddingpubg, esp, lvl, max, mod, login,\npassword, aimbot, vip, recoil\nCardingiphone, premium, netflix, amazon, samsung,\npaytm, giveaway, hacking, tutorial, vpn\nEntertainmentreddit, artist, submit, edition, meta,\ntil, hire, score, anime, league\nIndian educationindian, upsc, exam, affair, copyright,\ninfringement, unavailable, wildlife, prelim, batch\nReligionjesus, lord, christ, spirit, pray, holy, shall,\nchurch, prayer, bless\nUS newstrump, biden, vaccine, election, covid, joe,\ndonald, court, military, mandate\nSocialtwitter, reuter, tweet, album, telegram, ivurl,\nutc, radio, hashtag, youtube\nWorld Newsrussia, ukraine, independent, minister,\nmilitary, coronavirus, europe, foreign, israel, court\nSoftwareandroid, rupee, enroll, web, udemy, proxy,\nlinux, software, premium, mod\nCOVID-19vaccine, covid19, covid, medical, vaccination,\nvaccinate, pfizer, disease, patient, australia\nCryptobtc, bitcoin, crypto, usdt, binance, usd, token,\ntrading, blockchain, profit\nExtremists\nand radicalsviolate, defense, jews, jewish,\nattacker, defend, jew, defender, hitler, antifa\nAdult contentpornographic, leak, t.me, xxx, meme, wanna,\nsharp, iphone, porn, teen\nTable 3: Top 10 keywords within LDA topics.\nin dark web forums [ 35], carders (the people who own the stolen\ncredit cards) use Telegram channels to place gift cards or goods for\nsale. In the TGDataset, we find 1,489 channels (7.53% of the English\npart of the dataset) offering this service. In particular, Telegram\nmarked 45 carding channels as scams, suggesting that some of them\ndo not deliver the service they offer.\nAnother unusual cluster containing 989 channels (5% of English\nchannels) is the one about extremists and radicals. Here, several\nchannels promote white supremacy, as well as other Nazi ideolo-\ngies and conspiracies against the white race (the title of one of\nthese channels is White Genocide Immigration Anti-White Agenda ).\nInterestingly, there are four channels in this category having the\nverified status. One channel ( \"ISIS Watch\" ) just publishes daily up-\ndates on banned terrorist content. Instead, the other three channels\nare related to official news agencies of the Russian government\nand are no longer accessible on Telegram. Moreover, some of their\nmessages we collected are obscured by the platform. To investigate\nthis aspect deeper, we analyze the messages obscured by Telegram\nas they incited violence, published illegal pornographic content,\nor shared content protected by copyright. In this case, Telegram\nreplaced some or all of the channel\u2019s messages with text explaining\nthe reasons for obfuscation. Interestingly, the channel itself and the\nmetadata ( e.g.,the posting date) related to the original messages\nare still available. As shown in Tab. 4, the service message most\nused by Telegram to obscure a post is the one about the violation\nof Telegram\u2019s Terms of Service (428,793 messages). Follow the one\nabout the spread of pornographic content (263,643 messages), the\n2015/11\n2016/5\n2016/11\n2017/6\n2017/12\n2018/6\n2018/12\n2019/6\n2019/12\n2020/6\n2021/1\n2021/7\n2022/1\nCreation date0100020003000Number of channelsAll\nRussian\nEnglishFigure 4: Creation date of Russian, English, and all the chan-\nnels. The green dot represents the date when Russia banned\nTelegram, while the azure one indicates WhatsApp\u2019s an-\nnouncement about privacy policy.\nviolation of local laws (145,448 messages), and copyright infringe-\nment (48,402 messages). Finally, the other topics are more aligned\nwith the ones covered by the seed channel of the TGDataset.\n5.3 Temporal aspect\nAnother interesting aspect is the creation date of the collected chan-\nnels since, from this information, it is possible to understand how\nTelegram evolved through time. Fig. 4 shows the monthly creation\nrate of the channels contained in the TGDataset. In particular, the\nblue line represents the overall number of channels created on a\ncertain date, while the green and the orange lines the number of\nRussian and English channels, respectively. As we can see, the num-\nber of channels created is steadily increasing, indicating that the\nTelegram platform is becoming more popular daily. Indeed, also\nmany governments choose to use Telegram channels to commu-\nnicate information regarding COVID-19 [ 42]. Until the beginning\nof 2018, the growth of channels is led by Russian-speaking users.\nHowever, in the first months of 2018, it is possible to note a sudden\ndrop in daily created channels, likely due to the Russian ban of\nTelegram (green dot in Fig. 4). Nonetheless, Russian channels, even\nif at a lower rate, continue to appear every day. Finally, in the first\nmonths of 2021, there was an abrupt increase of English-language\nspoken channels that overtook the Russian ones for the first time\nin Telegram history, according to our data. This event coincides\nwith the change of WhatsApp\u2019s privacy policy (azure dot in Fig. 4)\nand the migration of many users from WhatsApp to Telegram [ 11].\n6 Use cases\nThe TGDataset has already been utilized in various studies [ 33,39,\n40]. For instance, La Morgia et al. [ 39] analyzed the problem of\nfake accounts on Telegram using the TGDataset, while Imperati\net al. [ 33] employed the TGDataset to identify 17,829 channels\ndisseminating conspiracy-related content. In the following, this\nsection describes other scenarios that can be explored and analyzed\nusing the TGDataset.\nPolitical leaning and presence of questionable contents.\nPrevious studies show the presence of moderation in OSNs ( e.g.,\nTGDataset: Collecting and Exploring\nthe Largest Telegram Channels Dataset KDD \u201925, August 3\u20137, 2025, Toronto, ON, Canada\nMessage description Number of messages Number of channels\nThis channel can\u2019t be displayed because it violated Telegram\u2019s Terms of Service. 428,793 2,546\nThis channel can\u2019t be displayed because it was used to spread pornographic content. 263,643 969\nThis channel can\u2019t be displayed because it violated local laws. 145,448 847\nThis channel is unavailable due to copyright infringement. 48,402 1,633\nTable 4: Number of posts obscured by each service message and number of channels presenting a specific service message.\nTable 5: Number of channels, scams, and verified ones be-\nlonging to each discovered topic.\nTopic # channels # scam # verified\nReligion 4,725 (23.90%) 0 5\nUS news 2,948 (14.91%) 38 51\nVideo-game modding 1,957 (9.90%) 14 0\nCovid 1,716 (8.68%) 0 5\nCarding 1,489 (7.53%) 45 0\nEntertainment 1,440 (7.28%) 0 3\nWorld news 995 (5.03%) 0 17\nExtremists and radicals 989 (5.00%) 0 4\nIndian education 939 (4.75%) 1 6\nSoftware 871 (4.41%) 2 14\nPorn 830 (4.20%) 5 0\nCrypto 563 (2.85%) 5 10\nSocial 306 (1.55%) 0 4\nTwitter) produces a significant reduction of questionable content,\nwith respect to not moderated OSNs ( e.g.,Gab) [ 21], and that the\ninformation diffusion is biased by the political leaning of the com-\nmunity [ 19]. However, very little is known about the loosely mod-\nerated Telegram platform. Thus, we use the TGDatset to perform\nthe first high-level investigation on Telegram. To this end, as done\nin [21,22], we leverage Media Bias/Fact Check (MBFC) [ 45], an\nindependent fact-checking organization that rates the bias of news\noutlets. In particular, MBFC classifies the political bias of news out-\nlets with one of the following labels: Extreme Left, Left, Left-Center,\nLeast-Biased, Right-Center, Right, Extreme Right . Additionally, MBFC\nprovides a second label to quantify the reliability of the outlet, cat-\negorizing outlets as Reliable andQuestionable .\nFor each English channel in the TGDataset, we label the links it\ncontains according to the Media Bias/Fact Check (MBFC) catego-\nrization. We then assigned each channel the most frequently chosen\nlabel among its categorized links. This approach classifies 9,045\nchannels out of 19,768; the remaining channels did not share news\nor contain sources not present in MBFC. Upon aggregating channels\ninto left-leaning (Left-Center, Left, Extreme Left) and right-leaning\n(Extreme Right, Right, Right-Center) groups, we found a nearly\nbalanced distribution: 4,491 channels shared right-leaning news,\nand 3,900 shared left-leaning news. However, 2,748 channels were\nidentified as spreading extreme right content, while none were\nfound to be spreading extreme left content. Among the top four\ntopics with the most categorized channels (World News, US News,\nReligion, and Covid), World News is the most left-leaning, with\nover 60% of the channels associated with left-leaning outlets. Chan-\nnels on the topic of Religion were almost evenly split between leftand right. Conversely, channels dealing with US News and Covid\nwere predominantly right-leaning. Specifically, the extreme right\nwas underrepresented in World News (76 channels) but predom-\ninant in Religion (590 channels), US News (1,144 channels), and\nCovid (601 channels). These three topics\u2014Religion, US News, and\nCovid\u2014also had the highest number of channels sharing content\nfrom questionable sources, with 1,353, 2,320, and 1,277 channels,\nrespectively. Analyzing the reasons behind their questionable clas-\nsification, we find that 55% of Religion, 80% of US News, and 85% of\nCovid questionable channels shared content from outlets associated\nwith conspiracy theories by MBFC.\nThis analysis reveals a significant presence of Telegram channels\ndisseminating news from unreliable sources. Thus, the TGDataset\ncould be a valuable resource for researchers aiming to understand\nthe spread of misinformation, fake news, and conspiracy theories.\nThis use case involves using the content of the text messages posted\nby the channels (represented by the Message field) to extract links\nfor further processing, and the forwarding information, including\nwhether the message was forwarded and its source (contained in\ntheIs Forwarded andForwarded From fields).\nStudy of channels spreading conspiracy theories. In the\nprevious use case, we discovered that there are channels that spread\nnews related to conspiracy theories. Here, we attempt to identify\nthem through community detection. A community in a graph is\na subset of nodes that are densely connected to each other and\nweakly connected to nodes in other communities.\nFor this study, we represent our dataset as a directed graph\n\ud835\udc3a=(\ud835\udc49,\ud835\udc38)in which nodes in \ud835\udc49are the channels, and edge \ud835\udc62\u2192\ud835\udc63\nin\ud835\udc38represents the presence in channel \ud835\udc62of a message originally\nposted in\ud835\udc63and forwarded to \ud835\udc62by the admin of channel \ud835\udc62. Since the\nusers of channel \ud835\udc62can navigate the forwarded message and land\non channel\ud835\udc63, the edge represents in a natural way the possible flow\nthrough channels of users following forwarded messages. To build\nand analyze our graph, we use the NetworkX library [26].\nThen, we use the Leiden algorithm [ 60], an algorithm for commu-\nnity detection that improves the Louvain algorithm [ 25]. To ensure\nthe accuracy of our partition, we used modularity, a validation met-\nric that measures how much better our partitioning is compared\nto a random partition. Thus, we compute the optimal number of\ncommunities with respect to modularity, achieving a high score\nof 0.78, which indicates a strong community structure remarkably\nbetter than random partitioning. This approach finds a partition\nwith 311 communities, 47 of which with more than one node. One\nof the communities, which consists of 236 channels and where Eng-\nlish is the common language, has the peculiarity that all posts and\nmessages forwarded from one channel to the other are about a new\nconspiracy theory called Sabmyk. Sabmik is a conspiracy theory\nKDD \u201925, August 3\u20137, 2025, Toronto, ON, Canada Massimo La Morgia, Alessandro Mei, and Alberto Maria Mongardini\nthat proposes itself as a better alternative to QAnon. It promotes a\nquasi-religion centered around a messianic figure known as Sab-\nmyk [ 56]. This community of channels has, collectively, more than\n1 million subscribers. The most popular channel in the community\nisGreat Awakening Channel with 119,103 subscribers. According to\nour data, most of these channels were created at the beginning of\n2021\u2014130 of them (55.08%) between January and February\u2014with\nthe latest in our dataset created in February 2022. The nature of\nthese channels is very different: Some of them are fake channels of\ncelebrities ( e.g.,Mel Gibson, Keanu Reeves, Kanye West), while oth-\ners target news outlets or official channels of national bodies ( e.g.,\nU. S. Marines Channel, U. S. Navy Channel) and others conspiracy\ntheories like QAnon. Regardless of the name of the channel in the\ncommunity, the content is always the same. Indeed, they recycle\nand forward messages among them: Out of the 1,203,986 messages\npublished by these 236 channels, only 65,602 are unique. With this\nanalysis we scratch the surface of the Sabmyk network. Still, more\ninvestigation are needed to understand how Sabmyk lures such a\nlarge number of subscribers, its ultimate goal, and its connection\nto other conspiracy theories.\nPerforming this study requires several key elements of the dataset.\nBy analyzing the content of the Message field, it is possible to iden-\ntify the topics within conspiracy theories. With the Is Forwarded\nfield, we can understand if the message has been forwarded, and\nin the case it is, which was the source channel leveraging the For-\nwarded From field. This information makes it possible to build a\ngraph representing connections between channels and to detect\nthe communities as we did for our analysis.\nCarding and underground markets. In Section 5.2, we ex-\namine the main topics within our dataset. Upon investigating the\nchannels associated with these topics, we discovered several en-\ngaging in borderline activities, such as running underground mar-\nketplaces. These channels sell electronics, Netflix accounts, and\nhacking tools for low prices. These types of marketplaces are often\nassociated with carding. Consequently, it is worth delving further\ninto these Telegram channels to determine the types of goods being\nsold, their origins, whether the channels are just an attempt to fraud\nsubscribers or if they are actually engaged in more illegal activities,\nand whether there is any correlation with Dark Web marketplaces.\nFor this analysis, the Message field is crucial for identifying the\ntypes of goods sold within the channels, such as electronics, Netflix\naccounts, and hacking tools. Analyzing the content of the messages\nand extracting the URLs makes it possible to determine whether the\nchannels are involved in fraudulent activities or illegal transactions.\nCopyright Infringement and personal content. Recently,\nTelegram hit the news several times for its use for the distribution\nof copyrighted content ( e.g.,movies and software). For instance, Ital-\nian authorities seized 545 channels for copyright infringement [ 44].\nHowever, the issue extends beyond copyright violations. Indeed,\nthe platform is frequently misused to distribute personal content\nwithout consent, such as the unauthorized distribution and sale\nof an Indian teacher\u2019s course material [ 55]. Even more troubling,\nTelegram is also used to share leaked nude photos [ 43] or facili-\ntate revenge porn [ 36]. Joining the information about the topic of\nthe channels, and the description of the messages removed by the\nplatform (Tab. 4), we can observe that the four categories in which\nis most present the diffusion of copyrighted material are: Carding(448 channels), Indian Edu (219 channels), Video-game modding\n(208 channels), Adult content (157 channels). Starting from these\nchannels, it is possible to study the diffusion of the phenomenon,\nunderstand how these channels are organized, and how they mon-\netize. For this analysis, the Message field is essential for identifying\nillicit content, such as copyrighted material, while the Description\nfield could provide additional context about channel activities.\nCryptocurrencies frauds. We also found several (563) channels\nrelated to the cryptocurrency world. It is well known that Telegram\nchannels are exploited by Pump and Dump groups [ 49,65] that\nperpetrate frauds on the crypto-market. We notice that some of\nthe Pump and Dump channels monitored in [ 41] are also in our\ndataset. Previous works monitored the channels vertically, focusing\non the fraud and the groups\u2019 mechanics. Thus, using the Message ,\nForwarded from , and Description fields, the TGDatast can help under-\nstand how these channels are connected, if they operate together,\nhow they promote their services, and likely discover new channels\nthat carry out similar activities.\nViolence and extremism. According to several newspapers,\nthe Capitol Hill riot of January 2021 was planned months before\nalso leveraging Telegram channels and groups [ 29,46]. In response\nto this event, the platform has intensified its monitoring and ob-\nscured dozens of public channels promoting calls to violence [ 28].\nNonetheless, despite the commitment of Telegram to obfuscate\nthese channels, within our dataset, there are several public chan-\nnels promoting the spread of neo-Nazi ideologies or calls to vio-\nlence ( e.g., White Aryan Woman ,Feuerkrieg Division **OFFICIAL** ).\nTherefore, the problem is still far from being solved. The TGDataset\ncan help study and characterize these channels. Indeed, the main\nproblem with these channels is the absence of a dataset containing\nthem, as they are obscured or blocked once discovered. Instead, the\nTGDataset includes several unblurred channels of this typology that\ncan be used to analyze their features and build a machine-learning\nmodel able to detect them automatically. This study requires the\nMessage andDescription fields to analyze harmful content and ob-\ntain context on the purposes of these channels, and the Forwarded\nfrom field to trace the channel behind it.\nTemporal analyses and information propagation. The TG-\nDataset represents a valuable resource for exploring the temporal\ndynamics of information spread by leveraging message timestamps\nand channels\u2019 creation dates. Message timestamps ( Date field in\nText messages and Media messages) facilitate granular analyses of\ndissemination patterns, enabling researchers to track how content\nspreads within and across channels. Instead, channels\u2019 creation\ndates ( Creation date field) enable the analysis of the correlation\nbetween a channel\u2019s longevity and its influence on information\npropagation. These temporal attributes support a variety of stud-\nies. For example, if combined with the forwarding information ( Is\nforwarded andForwarded from fields in Text messages and Media\nmessages), they allow for tracing the rise and evolution of trending\ntopics, assessing the velocity of information diffusion for different\ncontent types, identifying peak activity periods for specific topics\nor channels, and examining shifts in information flow patterns\nover time. Moreover, beyond individual channels, the communi-\nties identified in the TGDataset present opportunities for studying\ninter-community information diffusion. Investigating these larger\nTGDataset: Collecting and Exploring\nthe Largest Telegram Channels Dataset KDD \u201925, August 3\u20137, 2025, Toronto, ON, Canada\nnetwork structures could provide valuable insights into how infor-\nmation propagates across interconnected groups within Telegram,\nunveiling the mechanisms that drive broader dissemination trends.\n7 Ethical Considerations\nThis paper presents the TGDataset, a new dataset that includes\n120,979 Telegram channels and over 400 million messages. The data\ncollection was conducted carefully to only include information from\nTelegram channels and exclude personal data such as usernames,\nphone numbers, and subscribed channels.\nOur data collection process complies with Telegram\u2019s Terms of\nService [ 58] and Telegram API\u2019s Terms of Service [ 57], as there are\nno clauses that prohibit the collection of public chat data. Addi-\ntionally, we have taken care to avoid flooding the platform with\nrequests during data collection. Moreover, our research complies\nwith the academic research exemptions outlined in Article 85 of\nthe GDPR [ 59], which provide certain flexibilities for processing\npublicly available data in the interest of freedom of expression\nand academic purposes. As our work exclusively involves publicly\naccessible content and does not process private user data, it falls\nunder the legitimate or public interest exemptions. Furthermore, we\nadhere to the principle of data minimization, as emphasized in the\nGDPR\u2019s guidelines [ 23]: We limit our analysis to admin-generated\npublic posts, ensuring that only the information strictly necessary\nfor our research objectives is processed.\nLastly, since the dataset includes channels that discuss contro-\nversial topics, some controversial messages may be present in the\ndataset. To comply with ethical standards, we did not download\nany images or include links in the public dataset as they may con-\ntain adult content or copyrighted material. Hence, according to our\nIRB\u2019s policy, we did not require explicit authorization to conduct\nour experiments.\n8 Limitation\nTo create the TGDataset, we began with 180 seed channels and then\nemployed a snowball technique to grow the dataset. This approach\nis limited to only reaching channels that are linked by message\nforwarding. Despite this constraint, we were able to uncover over\n100,000 channels and could potentially discover even more through\ncontinued iterations. Nonetheless, there may be groups of channels\nthat remain inaccessible from our seed channels.\nIn the TGDataset, channels are represented as a snapshot of their\ncurrent state. Although some historical details about the channels\nare available in the dataset, such as their creation date and times-\ntamp of messages, other information is not present. For instance,\na channel during time can change its name, description, and of\ncourse, the number of subscribers. This information could be useful\nfor reconstructing the evolution of the channels. In the current\nrelease of the TGDataset, we do not retrieve the comments posted\nby users on channels\u2019 messages or the reaction emojis they may\nhave used (such as the \u2019like\u2019 button on Facebook). While we have\nobserved that many Telegram channels do not use these features,\nthey can still offer valuable insights for future analyses.9 Conclusions and Future works\nTelegram has gained significant popularity in recent years. As a\nresult, it is crucial to study and understand the activity taking place\non the platform.\nIn this work, we present the TGDataset [ 38], a collection of\nmore than 120,000 public Telegram channels that, to the best of our\nknowledge, is the largest collection of channels publicly available.\nAfter characterizing the main quantitative aspect of the TGDataset,\nwe performed language detection to understand which are the most\npopular languages on the dataset. Then, we investigate the main\ntopics covered by the English channels. Additionally, we publicly\nreleased the script we used to analyze it and the labeling we obtained\n(language and topic of the channels). In this paper, we investigate a\nfew possible use cases in which our dataset can be extremely useful.\nIn particular, our preliminary study of the TGDataset revealed some\nTelegram channels spread questionable content and conspiracy\ntheories. Moreover, we observed the presence of several borderline\nactivities and channels dealing with dubious ethical content. With\nthe release of the TGDataset, we aim to provide a valuable resource\nto researchers that enables further investigation into these areas,\nleading to a more refined understanding of Telegram and helping\nto mitigate potential risks to users.\nAs future work, we plan to continue running our data collector\nand further enlarge the TGDataset, releasing new versions of the\ndataset at regular intervals of time. Moreover, we intend to over-\ncome the actual limitations by recording channel updates (channel\u2019s\nname, subscribers, and description), adding to the list of channels\nto monitor also those referenced by link, inserting the possibility\nto add new seed channels, and collecting replies to messages.\n10 Acknowledgments\nThis work has been partially funded by projects: MUR National\nRecovery and Resilience Plan, SERICS (PE00000014); and ST3P\n(B83C24003210001) under the \"Young Researchers 2024-SoE\" Pro-\ngram funded by the Italian Ministry of University and Research\n(MUR).\nReferences\n[1]2017. Telegram to block terror channels after Indonesian ban. https://www.bbc.\ncom/news/business-40627739.\n[2]2018. Iran has banned Telegram after claiming the app encourages \u2018armed\nuprisings\u2019. https://www.theverge.com/2018/5/1/17306792/telegram-banned-iran-\nencrypted-messaging-app-russia.\n[3]2019. Telegram the latest safe haven for white supremacists. https://www.adl.\norg/blog/telegram-the-latest-safe-haven-for-white-supremacists.\n[4]2020. Russia lifts ban on Telegram messaging app after failing to block it. https:\n//www.reuters.com/article/us-russia-telegram-ban-idUSKBN23P2FT.\n[5]2021. NLTK RegexpTokenizer. https://www.nltk.org/_modules/nltk/tokenize/\nregexp.html.\n[6] 2021. Telegram Analytics. https://tgstat.com/.\n[7]2021. Telegram FAQ. https://telegram.org/faq#q-what-is-telegram-what-do-i-\ndo-here.\n[8] 2021. Telethon\u2019s Documentation. https://docs.telethon.dev/en/latest/.\n[9] 2022. Page Verification Guidelines. https://telegram.org/verify.\n[10] Jan. 2021. WhatsApp delays privacy policy changes after users defect to rivals\nSignal and Telegram. https://fortune.com/2021/01/15/whatsapp-delays-privacy-\npolicy-changes-after-users-defect-to-rivals-signal-and-telegram/.\n[11] May 2021. WhatsApp privacy policy change: Telegram, Signal saw massive\nspike in January, shows data. https://indianexpress.com/article/technology/\nsocial/whatsapp-privacy-policy-change-telegram-signal-saw-massive-spike-\nin-january-shows-data/.\n[12] 4chan. 2023. 4chan. https://www.4chan.org/.\nKDD \u201925, August 3\u20137, 2025, Toronto, ON, Canada Massimo La Morgia, Alessandro Mei, and Alberto Maria Mongardini\n[13] Azadeh Akbari and Rashid Gabdulhakov. 2019. Platform surveillance and resis-\ntance in Iran and Russia: The case of Telegram. Surveillance & Society 17, 1/2\n(2019), 223\u2013231.\n[14] Timothy Baldwin and Marco Lui. 2010. Language identification: The long and the\nshort of the matter. In Human language technologies: The 2010 annual conference\nof the North American chapter of the association for computational linguistics .\n229\u2013237.\n[15] Kyle Banker, Douglas Garrett, Peter Bakkum, and Shaun Verch. 2016. MongoDB\nin action: covers MongoDB version 3.0 . Simon and Schuster.\n[16] Jason Baumgartner, Savvas Zannettou, Megan Squire, and Jeremy Blackburn.\n2020. The Pushshift Telegram Dataset. In Proceedings of the International AAAI\nConf. on Web and Social Media , Vol. 14. 840\u2013847.\n[17] David M Blei, Andrew Y Ng, and Michael I Jordan. 2003. Latent dirichlet allocation.\nthe Journal of machine Learning research 3 (2003), 993\u20131022.\n[18] Zhenfeng Cao, Minzhang Zheng, Yulia Vorobyeva, Chaoming Song, and Neil\nJohnson. 2017. Dynamical patterns in individual trajectories toward extremism.\nAvailable at SSRN 2979345 (2017).\n[19] Matteo Cinelli, Gianmarco De Francisci Morales, Alessandro Galeazzi, Walter\nQuattrociocchi, and Michele Starnini. 2021. The echo chamber effect on social\nmedia. Proceedings of the National Academy of Sciences 118, 9 (2021), e2023301118.\n[20] Arash Dargahi Nobari, Negar Reshadatmand, and Mahmood Neshati. 2017. Anal-\nysis of Telegram, an instant messaging service. In Proceedings of the 2017 ACM\non Conf. on Information and Knowledge Management . 2035\u20132038.\n[21] Gabriele Etta, Matteo Cinelli, Alessandro Galeazzi, Carlo Michele Valensise,\nWalter Quattrociocchi, and Mauro Conti. 2022. Comparing the Impact of Social\nMedia Regulations on News Consumption. IEEE Transactions on Computational\nSocial Systems (2022), 1\u201311. https://doi.org/10.1109/TCSS.2022.3171391\n[22] Gabriele Etta, Alessandro Galeazzi, Jamie Ray Hutchings, Connor Stirling\nJames Smith, Mauro Conti, Walter Quattrociocchi, and Giulio Valentino Dalla\nRiva. 2022. COVID-19 infodemic on Facebook and containment measures in Italy,\nUnited Kingdom and New Zealand. PloS one 17, 5 (2022), e0267022.\n[23] Your Europe. November 19, 2024. Data protection under GDPR.\nhttps://europa.eu/youreurope/business/dealing-with-customers/data-\nprotection/data-protection-gdpr/index_en.htm.\n[24] European Organization For Nuclear Research and OpenAIRE. 2013. Zenodo.\nhttps://doi.org/10.25495/7GXK-RD71\n[25] Sayan Ghosh, Mahantesh Halappanavar, Antonino Tumeo, Ananth Kalyanara-\nman, Hao Lu, Daniel Chavarria-Miranda, Arif Khan, and Assefaw Gebremedhin.\n2018. Distributed louvain algorithm for graph community detection. In 2018\nIEEE international parallel and distributed processing symposium (IPDPS) . IEEE,\n885\u2013895.\n[26] Aric Hagberg, Pieter Swart, and Daniel S Chult. 2008. Exploring network structure,\ndynamics, and function using NetworkX . Technical Report. Los Alamos National\nLab.(LANL), Los Alamos, NM (United States).\n[27] Ali Hashemi and Mohammad Ali Zare Chahooki. 2019. Telegram group quality\nmeasurement by user behavior analysis. Social Network Analysis and Mining 9, 1\n(2019), 1\u201312.\n[28] Taylor Hatmaker. 2021. Telegram blocks \u2018dozens\u2019 of hardcore hate channels\nthreatening violence. https://techcrunch.com/2021/01/13/telegram-channels-\nbanned-violent-threats-capitol/.\n[29] Rebecca Heilweil. Jan. 2021. How Trump\u2019s internet built and broadcast the Capitol\ninsurrection. https://www.vox.com/recode/22221285/trump-online-capitol-riot-\nfar-right-parler-twitter-facebook.\n[30] Thomas Hofmann. 2001. Unsupervised learning by probabilistic latent semantic\nanalysis. Machine learning 42, 1 (2001), 177\u2013196.\n[31] Matthew Honnibal and Ines Montani. 2017. spaCy 2: Natural language under-\nstanding with Bloom embeddings, convolutional neural networks and incremen-\ntal parsing. (2017). To appear.\n[32] Mohamad Hoseini, Philipe Melo, Fabricio Benevenuto, Anja Feldmann, and\nSavvas Zannettou. 2023. On the globalization of the QAnon conspiracy theory\nthrough Telegram. In Proceedings of the 15th ACM Web Science Conf. 2023 . 75\u201385.\n[33] Vincenzo Imperati, Massimo La Morgia, Alessandro Mei, Alberto Maria Mongar-\ndini, and Francesco Sassi. 2025. The Conspiracy Money Machine: Uncovering\nTelegram\u2019s Conspiracy Channels and their Profit Model. In 34th USENIX Security\nSymp. (USENIX Security 25) .\n[34] Asal Jalilvand and Mahmood Neshati. 2020. Channel retrieval: finding relevant\nbroadcasters on Telegram. Social Network Analysis and Mining 10, 1 (2020), 1\u201316.\n[35] Alex Kigerl. 2020. Behind the Scenes of the Underworld: Hierarchical Clustering\nof Two Leaked Carding Forum Databases. Social Science Computer Review (2020),\n0894439320924735.\n[36] Rachel Kraus. October 29, 2020. Telegram\u2019s massive revenge porn problem has\nmade these women\u2019s lives hell. https://mashable.com/article/nudes-revenge-\nporn-crime-telegram.\n[37] Massimo La Morgia, Alessandro Mei, and Alberto Maria Mongardini. 2024. TG-\nDataset. https://zenodo.org/records/7640712.\n[38] Massimo La Morgia, Alessandro Mei, and Alberto Maria Mongardini. 2024. TG-\nDataset repository. https://github.com/SystemsLab-Sapienza/TGDataset.[39] Massimo La Morgia, Alessandro Mei, Alberto Maria Mongardini, and Jie Wu.\n2023. It\u2019sa Trap! Detection and Analysis of Fake Channels on Telegram. In 2023\nIEEE International Conf. on Web Services (ICWS) . IEEE, 97\u2013104.\n[40] Massimo La Morgia, Alessandro Mei, Alberto Maria Mongardini, and Jie Wu.\n2024. Pretending to be a VIP! Characterization and Detection of Fake and Clone\nChannels on Telegram. ACM Transactions on the Web (2024). https://doi.org/10.\n1145/3705014\n[41] Massimo La Morgia, Alessandro Mei, Francesco Sassi, and Julinda Stefa. 2020.\nPump and Dumps in the Bitcoin Era: Real Time Detection of Cryptocurrency Mar-\nket Manipulations. In 2020 29th International Conf. on Computer Communications\nand Networks (ICCCN) . IEEE, 1\u20139.\n[42] Dymples Leong. May 2020. Telegram, the powerful COVID-19 choice of\ncommunications by many governments. https://www.channelnewsasia.com/\ncommentary/coronavirus-covid-19-government-telegram-whatsapp-fake-\nnews-info-936061.\n[43] Hannah Gelbart Maria Korenyuk Lucy Swinnen, Jack Goodman and Juliana\nGragnani. 16 February 2022. Telegram: Where women\u2019s nudes are shared without\nconsent. Telegram:Wherewomen\u2019snudesaresharedwithoutconsent.\n[44] Andy Maxwell. October 10, 2022. Telegram Piracy: Police Target 545 Channels\n& Eight Suspected Admins. https://torrentfreak.com/telegram-piracy-police-\ntarget-545-channels-eight-suspected-admins-221010/.\n[45] MBFC. 2023. Media Bias Fact Check. https://mediabiasfactcheck.com/.\n[46] Jemima McEvoy. Jan. 2021. Capitol Attack Was Planned Openly Online For\nWeeks\u2014Police Still Weren\u2019t Ready. https://www.forbes.com/sites/jemimamcevoy/\n2021/01/07/capitol-attack-was-planned-openly-online-for-weeks-police-still-\nwerent-ready/?sh=1b06696376e2.\n[47] David Mimno, Hanna Wallach, Edmund Talley, Miriam Leenders, and Andrew\nMcCallum. 2011. Optimizing semantic coherence in topic models. In Proceedings\nof the 2011 conference on empirical methods in natural language processing . 262\u2013\n272.\n[48] MONGODB. November 19, 2024. MongoDB. https://www.mongodb.com/.\n[49] Massimo La Morgia, Alessandro Mei, Francesco Sassi, and Julinda Stefa. 2021. The\ndoge of wall street: Analysis and detection of pump and dump cryptocurrency\nmanipulations. ACM Transactions on Internet Technology (TOIT) (2021).\n[50] Lynnette Hui Xian Ng and Loke Jia Yuan. 2020. Is this pofma? Analysing public\nopinion and misinformation in a COVID-19 Telegram group chat. arXiv preprint\narXiv:2010.10113 (2020).\n[51] NLTK Project. 2023. NLTK stopwords. https://www.nltk.org/search.html?q=\nstopwords&check_keywords=yes&area=default.\n[52] Jack Ricle. Aug. 2022. Scammers in telegram and how to report. https://www.\ntelegramadviser.com/scammers-in-telegram-and-how-to-report/.\n[53] Hinrich Sch\u00fctze. 1998. Automatic word sense discrimination. Computational\nlinguistics 24, 1 (1998), 97\u2013123.\n[54] Nakatani Shuyo. 2010. Language Detection Library for Java. http://code.google.\ncom/p/language-detection/\n[55] Manish Singh. November 30, 2022. Telegram shares users\u2019 data in copyright\nviolation lawsuit. https://techcrunch.com/2022/11/29/telegram-shares-data-of-\nusers-accused-of-copyright-violation-following-court-order/.\n[56] Joe Sommerlad. March 2021. Sabmyk Network: Founder of bizarre\nnew religion targeting QAnon believers \u2018unmasked\u2019 by Hope Not Hate.\nhttps://www.independent.co.uk/news/world/europe/sabmyk-network-qanon-\nconspiracy-theories-b1820639.html.\n[57] Telegram. November 19, 2024. Telegram API Terms of Service. https://core.\ntelegram.org/api/terms.\n[58] Telegram. November 19, 2024. Telegram Terms Of Service. https://telegram.org/\ntos/.\n[59] GDPR TEXT. November 19, 2024. Article 85 GDPR. Processing and freedom of\nexpression and information. https://gdpr-text.com/read/article-85/.\n[60] Vincent A Traag, Ludo Waltman, and Nees Jan Van Eck. 2019. From Louvain to\nLeiden: guaranteeing well-connected communities. Scientific reports 9, 1 (2019),\n1\u201312.\n[61] Aleksandra Urman and Stefan Katz. 2022. What they do in the shadows: examin-\ning the far-right networks on Telegram. Information, communication & society\n25, 7 (2022), 904\u2013923.\n[62] Alper Kursat Uysal and Serkan Gunal. 2014. The impact of preprocessing on text\nclassification. Information Processing & Management 50, 1 (2014), 104\u2013112.\n[63] Janith Weerasinghe, Bailey Flanigan, Aviel Stein, Damon McCoy, and Rachel\nGreenstadt. 2020. The pod people: Understanding manipulation of social media\npopularity via reciprocity abuse. In Proceedings of The Web Conf. 2020 . 1874\u20131884.\n[64] Mark D Wilkinson, Michel Dumontier, IJsbrand Jan Aalbersberg, Gabrielle Apple-\nton, Myles Axton, Arie Baak, Niklas Blomberg, Jan-Willem Boiten, Luiz Bonino\nda Silva Santos, Philip E Bourne, et al .2016. The FAIR Guiding Principles for\nscientific data management and stewardship. Scientific data 3, 1 (2016), 1\u20139.\n[65] Jiahua Xu and Benjamin Livshits. 2019. The anatomy of a cryptocurrency pump-\nand-dump scheme. In 28th{USENIX}Security Symp. ({USENIX}Security 19) .\n1609\u20131625.\n[66] Ahmet S Yayla and Anne Speckhard. 2017. Telegram: The mighty application\nthat ISIS loves. International Center for the Study of Violent Extremism (2017).", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Tgdataset: Collecting and exploring the largest telegram channels dataset", "author": ["M La Morgia", "A Mei"], "pub_year": "2025", "venue": "Proceedings of the 31st \u2026", "abstract": "Telegram is a widely adopted instant messaging platform. It has become worldwide popular  because of its emphasis on privacy and its social network features such as channels\u2014"}, "filled": false, "gsrank": 858, "pub_url": "https://massimolamorgia.com/assets/pdf/TGDataset_KDD_25.pdf", "author_id": ["G-P8k7MAAAAJ", "eCiUVHcAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:fmG24KR5WNUJ:scholar.google.com/&output=cite&scirp=857&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D850%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=fmG24KR5WNUJ&ei=obWsaKLFCqzWieoPic2ZoAU&json=", "num_citations": 3, "citedby_url": "/scholar?cites=15373171077080834430&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:fmG24KR5WNUJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://massimolamorgia.com/assets/pdf/TGDataset_KDD_25.pdf"}}]