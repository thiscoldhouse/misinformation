[{"title": "Analyzing user ideologies and shared news during the 2019 argentinian elections", "year": "2024", "pdf_data": "delPozoetal. EPJDataScience           (2024) 13:54 \nhttps://doi.org/10.1140/epjds/s13688-024-00493-y\nRESEARCH OpenAccess\nAnalyzinguserideologiesandsharednews\nduringthe2019argentinianelections\nSof\u00edaM.delPozo1,2,Sebasti\u00e1nPinto1,2,MatteoSera\ufb01no3,LucioGarcia1,2,Hern\u00e1nA.Makse3and\nPabloBalenzuela1,2*\n*Correspondence: balen@df.uba.ar\n1UniversidaddeBuenosAires,\nFacultaddeCienciasExactasy\nNaturales,DepartamentodeF\u00edsica,\nBuenosAires,Argentina\n2CONICET-UniversidaddeBuenos\nAires,InstitutodeF\u00edsica\nInterdisciplinariayAplicada\n(INFINA),BuenosAires,Argentina\nFulllistofauthorinformationis\navailableattheendofthearticleAbstract\nTheextensivedatageneratedonsocialmediaplatformsallowustogaininsightsover\ntrendingtopicsandpublicopinions.Additionally,ito\ufb00ersawindowintouser\nbehavior,includingtheircontentengagementandnewssharinghabits.Inthisstudy,\nweanalyzetherelationshipbetweenusers\u2019politicalideologiesandthenewsthey\nshareduringArgentina\u2019s2019electionperiod.Our\ufb01ndingsrevealthatusers\npredominantlysharenewsthatalignswiththeirpoliticalbeliefs,despiteaccessing\nmediaoutletswithdiversepoliticalleanings.Moreover,weobserveaconsistent\npatternofuserssharingarticlesrelatedtotopicsbiasedtotheirpreferredcandidates,\nhighlightingadeeperlevelofpoliticalalignmentinonlinediscussions.Webelieve\nthatthissystematicanalysisframeworkcanbeappliedtosimilarscenariosindi\ufb00erent\ncountries,especiallythosemarkedbysigni\ufb01cantpoliticalpolarization,akinto\nArgentina.\nKeywords: Newssharing;Socialmedia;Politicalpolarization;Con\ufb01rmationbias;\nNewscontentanalysis\n1 Introduction\nIn1998RichardFeynmanwrote \u201cThe\ufb01rstprincipleisthatyoumustnotfoolyourself,and\nyou are the easiest person to fool.\u201d [1]. How we perceive things and subsequently respond\ntothemisaphenomenapotentiallyin\ufb02uencedbypersonalbiases.\nThe widespread use of social media platforms generates a large amount of data which,\nthrough careful interrogation and analysis, could re\ufb02ect extensive and valuable informa-\ntion[2\u20134].Thisdatanotonlyshedslighton,forinstance,trendingtopics[ 5,6]andpublic\nopinions[ 7\u201310]butalsoprovidesinsightsintotheindividualcharacteristicsofusersbased\non their behavior, such as their interactions and the news they share [ 11,12]. In particu-\nlar,newssharingbehavioronsocialmediaisaphenomenonworthyofstudy[ 13\u201315],not\nonlyforitspotentialtoinferusers\u2019informationbutalsoforitssigni\ufb01cantpotentialtoin\ufb02u-\nencesociety.Concerningtheaccuracyofsharednews,thepropagationoffakenewscould\nhaveseriousimplications,suchasduringelections[ 16,17]andtheCOVID-19pandemic,\nwheremisinformationheightenedanxietyandpsychologicaldistress[ 18].\nNumerous factors can in\ufb02uence the process of news sharing behavior [ 15,19,20]. For\nexample, Osmundsen et al. [ 21] demonstrated in their study that partisan polarization is\n\u00a9TheAuthor(s)2024. OpenAccess ThisarticleislicensedunderaCreativeCommonsAttribution4.0InternationalLicense,which\npermits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit\ntotheoriginalauthor(s)andthesource,provide a linktotheCreative Commonslicence,and indicateifchangeswere made.The\nimagesorotherthirdpartymaterialinthisarticleareincludedinthearticle\u2019sCreativeCommonslicence,unlessindicatedotherwise\nin a credit line to the material. If material is not included in the article\u2019s Creative Commons licence and your intended use is not\npermitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright\nholder.Toviewacopyofthislicence,visit http://creativecommons.org/licenses/by/4.0/ .\ndelPozoetal. EPJDataScience           (2024) 13:54 Page2of18\nthe primary psychological motivation behind the sharing of political fake news on Twit-\nter.Westerwicketal.[ 22]examinedtherelationshipbetweensourcesandcontentcuesfor\ncon\ufb01rmationbias,revealingthatcon\ufb01rmationbiasemergedirrespectiveofsourcequality[22]. In this sense, we can observe that user characteristics, in particular their political\nleaningorbiases,canserveasbothanexplanationofnewssharingbehaviorandasinfor-mationresultingfromthisbehavior.\nBiasisde\ufb01nedast het endencyt ofa vourordis lik eapersonort hing,especiallyasar e-\nsultofapreconceivedopinion[ 23].Whilebiascanmanifestindi\ufb00erentways[ 24\u201327],the\ntwo types of biases that speci\ufb01cally concern us in this study are those in\ufb02uencing newsconsumption behavior and those a\ufb00ecting the media on social networks, known as con-\ufb01rmationbiasandmediabias,respectively.AsRaymondNickersonexplainedin[ 28],con-\n\ufb01rmationbiasreferstotheinclinationtosearchfororinterpretevidenceinamannerthat\nalignswithpre-existingbeliefs,expectations,oracurrentlyheldhypothesis.Inessence,itrepresentsanunintentionalshapingoffactsto\ufb01tone\u2019shypothesesorbeliefs.Inthecon-text of our research, con\ufb01rmation bias can be recognized as an instance of the selective\nexposuretheory ,asdescribedbyStroud(2010)[ 29],whichelucidatesindividuals\u2019propen-\nsity to prefer information that conforms to their pre-existing beliefs, while consciouslyavoidingcontradictorycontent.Regardingnewsconsumptionresearch,mediabiastakeson a prominent role. Media bias is de\ufb01ned as a deliberate and intentional tendency thatfavorsaparticularperspective,ideology,ordesiredoutcome[ 27,30].\nAswementionedabove,socialmediaservesasachannelfornewsconsumption,where\nseveral factors in\ufb02uence the dynamics of how these news are shared. In particular, bothcon\ufb01rmationbiasandmediabiascaninterplaywhenthenewsthatsocialmediausersread\naresharedbyotherswhopossesstheirownideologicalbiases.Therefore,thestudyofthis\ndynamicisofsigni\ufb01cantimportanceduetotheimpactofnewsconsumptiononpeople\u2019sopinions[ 31\u201334],forexampletheconsumptionofbiasednewscanin\ufb02uencevoters\u2019deci-\nsions [35]. Additionally, the interaction between social media, political polarization, and\npolitical disinformation can signi\ufb01cantly shape a society\u2019s future, a\ufb00ecting the quality ofpublicpolicyanditsdemocraticprinciples[ 36].\nIn this study, we examine the relationship between shared news and the ideologies of\nsocialmediauserswhodisseminatethemduringthe2019generalelectionsinArgentina.Speci\ufb01cally, we explore whether factors such as the news source, bias, or topics sharedbyusersareassociatedwiththeirpoliticalideology.Ouranalysisincorporatesdataonthecontentofthesharednewsandthepoliticala\ufb03liationsoftheusers,previouslycategorizedinto Center-Left (CL) and Center-Right (CR) groups. The Twitter activity and partisanlabels were obtained from the research conducted by Zhou et al. (2021) as referenced in\n[37].\nThefocalpointofthisstudyliesinexaminingthenewssharedbyuserswithintheexist-\ningdatasetfrom[ 37].Tocollectthisdata,weperformedwebscrapingofthetextfromthe\nlinksofnewsarticlessharedbyusers.Followingthis,weevaluatedthebiasofthesenewsarticles,alongwiththebiasofthenewsmediaandthetopicstheycover.Subsequently,weanalyzedthecorrelationbetweenthesefactorsandtheusers\u2019biastowardsthecandidatesfromthetwoprimarycoalitionscompetingforthepresidency.\ndelPozoetal. EPJDataScience           (2024) 13:54 Page3of18\n2 Background\n2.1 Argentiniancontext\nThe systematic framework introduced in this work, aimed at quantifying both user and\nmedia outlet preferences, \ufb01lls a signi\ufb01cant gap in understanding, especially within theArgentine context. While some of the main Argentine media outlets are listed on MediaBias/FactCheckorganization[ 38],currently,thereisnocentralizedsourceforevaluating\nthemediabiasofalloutletsinthecountry.AsweapplythisframeworktoArgentinaduringthe2019presidentialelectioncampaign,thissectiono\ufb00ersanoverviewofthepoliticalandmedialandscapeduringthisperiodtoprovidecontextualization.\nOver the past decade, Argentina\u2019s political scene has been characterized by the pre-\ndominanceoftwomajorcoalitions:one,acenter-Checkleftcoalition(CL)ledbyCristinaFern\u00e1ndez de Kirchner, known as Frente de Todos , and the other, a center-right coalition\n(CR)ledbyMauricioMacri,referredtoas JuntosporelCambio .CristinaKirchnerheldthe\npresidencyinArgentinaduringtheperiodsof2007\u20132011and2011\u20132015,whileMauri-cioMacriservedaspresidentfrom2015to2019,asdocumentedin[ 39].Duringthe2019\nelections, the center-left coalition presented Alberto Fern\u00e1ndez and Cristina Fern\u00e1ndezde Kirchner as their candidates. Meanwhile, the center-right coalition sought a secondtermforMauricioMacriaspresident,withMiguel\u00c1ngelPichettoashisvice-presidentialcandidate. National elections in Argentina comprise two obligatory phases: the primaryelection,knownasPASO(whichstandsfor Primarias,Abiertas,Simult\u00e1neasyObligato-\nriasinSpanish,translatingtoOpen,Simultaneous,andObligatoryPrimariesinEnglish),\nandthegeneralelection.Intheyear2019,theseeventsoccurredonAugust11thandOc-tober27th,respectively.Additionally,iftheresultsofthegeneralelectionnecessitateit,athirdround,referredtoasa ballotage ,mayalsobeconducted.\nRegarding themedialandscape,thedigital mediasceneinArgentinaisprimarilychar-\nacterized by three major players: Infobae,Clar\u00ednandLa Naci\u00f3n , each boasting approx-\nimately 20 million unique users in 2020, as reported by Comscore data [ 40]. Following\nclosely are a second tier of media outlets with audience numbers ranging from 6 to 13million unique visitors. Prominent among this group are P\u00e1gina 12 ,\u00c1mbito Financiero ,\nTNNoticias andElDestapeWeb .\nIn Argentina, a pronounced polarization has been reported through the distinct ideo-\nlogical orientations of the country\u2019s primary media outlets [ 4,41]. For instance, P\u00e1gina\n12 is recognized as a left-of-center broadsheet newspaper, while Clar\u00edn is considered acentristtabloidandLaNaci\u00f3nischaracterizedasacenter-rightnewspaper[ 42].Between\n2008and2014,aconfrontationoccurredbetweenthegovernmentofCristinaFern\u00e1ndezdeKirchner(Center-Left)andmajormediacorporations[ 43].Duringthisperiod,acon-\n\ufb02ictarose,leadingtotheestablishmentofasetofnewspapersalignedwiththepoliciesoftheKirchnergovernment(e.g.,P\u00e1gina12).Simultaneously,anotherclusterofnewspapersemerged,knownfortheirvehementeditorialcriticismofthegovernment\u2019sactionsduringthisera(e.g.,Clar\u00ednandLaNaci\u00f3n,amongothers)[ 43\u201345].\nWhile the examination of media outlet bias is increasing, particularly among English-\nbased outlets, the scenario is di\ufb00erent in countries like Argentina. Notably, only threeof the main outlets in Argentina have de\ufb01nitive bias classi\ufb01cations provided by MediaBias/Fact Check [ 46\u201348]. In this context, our study not only classi\ufb01ed Argentine news\noutlets but also introduced a versatile bias index for situations where speci\ufb01c classi\ufb01ca-tionsarelacking.\ndelPozoetal. EPJDataScience           (2024) 13:54 Page4of18\n3 Materialandmethods\nThis section provides an overview of the data and methods utilized in this study. Fig-\nure1illustrates the progression of our pipelines, starting with the raw tweets (top panel\nofFig.1).Usersareclassi\ufb01edassupportersofaparticularcandidatebasedonthecontent\nof their tweets [ 37]. Additionally, tweets containing URLs to external media outlets un-\ndergo scraping (right panel of Fig. 1), allowing for the analysis of news outlet bias, news,\nandtopicbiasbasedonthetextofthenews,ratherthanthetextofthetweetsthemselves.\nBelowisadetaileddescriptionofourmethods.\n3.1 Users\u2019classi\ufb01cation\nTheusersclassi\ufb01cationprocessbeginswithamanuallyclassi\ufb01edsetofhashtags,collecting\nand categorizing the most frequent hashtags as Pro-Fernandez, Pro-Macri, or Neutral.\nTweetscontainingonlytheseclassi\ufb01edhashtagsarethenselectedtocreateatrainingset,\ncomprising253482tweets,whichwasthenemployedtotrainaclassi\ufb01er(depictedinthe\nleftpanelofFig. 1).\nTo identify the best classi\ufb01er, Zhou et al. [ 37] tested \ufb01ve di\ufb00erent models: Logistic Re-\ngression(LR)withL2regularization,SupportVectorMachine(SVM),NaiveBayes(NB),RandomForest(RF),andDecisionTree(DT).Thesemodelswerevalidatedon10%ofthe\nclassi\ufb01ed tweets. As shown in Table 4 of [ 37], the Logistic Regression model performed\nthe best, with an average group accuracy, recall, and F1-score all at 83%. The SVM fol-\nlowed with an 81% accuracy, then Naive Bayes with 79.5%, and \ufb01nally Random Forest\nand Decision Tree. Logistic Regression assigns a probability pto each tweet, indicating\nitslikelihoodofsupportingeithercandidate.Aprobabilityclosertooneindicatessupport\nfor Macri, while a probability closer to zero indicates support for Fernandez. Ultimately,users\u2019 opinions are inferred based on the latest number of tweets classi\ufb01cation, de\ufb01ning\nFigure1 Methodologypipeline. Top:exampleofrawdataoftweetsfromsocialmediaTwitter(nowX). Inthe\nleft:hashtagswereutilizedtotrainalogisticregressionmodelforclassifyingtweetsassupportiveofone\ncandidateortheother.Usersareassignedtothecandidateforwhomtheyexhibitthehighestnumberof\nsupportivetweets(seemoredetailsin[ 37]).Intheright: thenewsURLsinthetweetsareutilizedtoextractthe\ntextbywebscrappingtoexecutethenallthenecessarystepsleadingtoperformsentimentandtopicanalysis\ndelPozoetal. EPJDataScience           (2024) 13:54 Page5of18\nloyaltyclasses.Themethodologyprovesrobustevenwhenvaryingthenumberoftweets\nconsideredtodetermineuserloyalty.\nIt\u2019simportanttonotethatbothinthetrainingprocessandintheclassi\ufb01cationprocess,\nthemodelemployedin[ 37]onlyconsidersthetextofthetweet;anyexternalinformation\ncontained in the tweet, such as references to a news outlet, is not taken into account.Furtherdetailscanbefoundin[ 37].\n3.2 Data\nThisstudystartswithanexistingTwitterdataset[ 37]containingtweetscollectedbetween\nMarch 1, 2019, and August 27, 2019. The data was obtained using keywords associated\nwithcandidatesforthe2019Argentinaprimaryelection,includingalferdez,CFK,CFKAr-gentina,Kirchner,mauriciomacri,Macri,andPichetto.Abotsandfakeaccountscleaningprocesswasperformedoverthisdatasetintheoriginalwork(seedetailsin[ 37]).However,\nwehaverunanadditionalanalysisoftheimpactofpotentialbotsbasedonBotometerAPI\n[49],whosedetailscanbefoundinAdditional\ufb01le 1.\nWere\ufb01nedtheoriginaldatasetbya)includingonlytweetscontaininganexternalURL\nlinkingtoanArgentiniannewsoutletandb)consideringusersinvolvedincomputingthe\n\ufb01nal vote intention. This process yielded 65,971 tweets from 17,466 users intending tovotefortheCenter-Left(CL)coalition(Fern\u00e1ndez-Fern\u00e1ndez)andapproximately40,211\ntweets from 15,425 users intending to vote for the Center-Right (CR) coalition (Macri-\nPichetto). Intending CL coalition voters shared 19,395 news articles, while intending CRvotersshared10,219.Thetweetsconsideredinthisworkrepresentapproximately0.1 %of\ntherawdata(seeSupplementaryInformationof[ 37]).\nIt\u2019s noteworthy that the while users\u2019 political orientation was computedin [ 37]byc on-\nsidering all the tweets of a user (with and without a URL), and the model was trainedusing a set of hashtags, in this paper, we concentrate on a subset of those tweets (those\ncontainingaURL)andonthetextofthenewsarticlesthemselves,whichwasnotutilized\nin[37].\n3.3 Data\ufb01ltering\nIn order to acquire the primary dataset for our analysis, we implemented the following\nprocedures:\n1.Tweetswithsharednewsselection: We\ufb01lteralltweetsfromthedatacollectedby\nZhouetal.(2021)[ 37]thatcontainedaURLinthe url_expanded Twitter\ufb01eld.This\nincludedtweets,retweets,andquotes.\n2.Urls expansion: Requestspythonlibrary[ 50]isusedtoexpandtheurls,applying\nmultiprocessing.Pool.map()[ 51]toparallelizetheprocess.\n3.Urls \ufb01lter by media: WeretainonlytheURLscorrespondingtonewsfrom\nArgentinemediaoutletsbasedonABYZNewsLinksGuide[ 52].\n4.Scrapingnewsarticles: Foreachmediaoutlet,wedevelopadedicatedcodeto\nscrapethecontentfromtheirrespectivewebpagesbasedonthepythonlibrariesRequests[ 50],Selenium[ 53]andBeautifulSoup[ 54].Weacquirethetextsofthe\nnewsarticlessharedbyusers.\n3.4 Newsarticlessentimentanalysis\nAfterscraping,weperformsentimentanalysisonthetextofthesharednewsarticles.We\ndecompose each article into multiple sentences and apply Pysentimiento algorithm [ 55]\ndelPozoetal. EPJDataScience           (2024) 13:54 Page6of18\ntoeachsentencewithineveryarticle.Thisallowsustocalculatepositivity,neutrality,and\nnegativitylevelswithregardtothetwomainelectioncandidates.Sentimentisde\ufb01nedonly\nforsentencesthatmentionthecandidates.Ifthereisasinglemention,itiscountedasone.\nIf there are multiple mentions, sentiment is calculated separately for each mention, cat-\negorizing them as neutral, positive, or negative. Given potential misleading in sentimentclassi\ufb01cationandtheroleofirony,weperformedahand-labeledclassi\ufb01cationinorderto\nmeasurethe accuracyof the model and the potential presence of ironic mentions, which\ncanbefoundinAdditional\ufb01le 1.\n3.4.1 Sentimentbias\nWede\ufb01netheSentimentBias( SB)[41,56]ofanewsarticleasthebalancebetweenpositive\nandnegativementionsofthecandidatesofthe CLcoalition(Fern\u00e1ndez-Fern\u00e1ndez)versus\nthecandidatesofthe CRcoalition(Macri-Pichetto)usingthefollowingformula:\nSB=(#CR\n+\u2013#CR\u2013)\u2013(#CL+\u2013#CL\u2013)\n#CRtotal+#CLtotal(1)\nwhere each mention is de\ufb01ned per sentence and the total number of mentions counts\npositive,negativeandneutralones.\nFor example, if an article has six sentences with mentions to candidates: one negative\nmentionofCRcandidates( #CR\u2013=1),twopositivementionofCLcandidates( #CL+=2),\nand three neutral mention to CL candidates, then #CR+=0, #CL\u2013=0, #CRtotal=1a n d\n#CLtotal=5. The Sentiment Bias of the article is calculated as calculate SB=(0\u20131)\u2013(2\u20130)\n1+5=\n\u20133\n6=\u20130.5.\n3.4.2 Interpretationofthesentimentbias\nSinceSentimentBias( SB)isafundamentalmetricinthisstudy,thissectiondelvesintoits\nanalysisandprovidesadetailedinterpretation.Toconductthisanalysis,we\ufb01rstmanually\nclassi\ufb01edagroupofarticlesbyselectingarandomsampleof120articleswithwell-de\ufb01ned\nSB,thatis,articlesinwhichcandidatesfromeithertheCenter-Left(CL)orCenter-Right\n(CR) coalitions are mentioned. We then applied the majority rule to this manual classi-\n\ufb01cations to obtain a unique label for each coalition. For instance, if an article received\nclassi\ufb01cationsoftwopositive,twonegative,andtwoneutralwithrespecttoagivencoali-\ntion,welabeledthearticleasneutralforthatcoalition.Finally,wedeterminedtheoverallconnotationofthearticlebasedonthecriteriashowninTable 1.\nTable 1Criteriatodeterminetheoverallconnotationofeacharticle\nConnotationoverCL ConnotationoverCR Overallconnotation\n\u20131 \u20131 Neutral(0)\n\u20131 0 FavorableCR(1)\n\u20131 1 FavorableCR\n0\u2013 1 F a v o r a b l e C L ( \u2013 1 )\n00N e u t r a l\n01F a v o r a b l e C R\n1\u2013 1 F a v o r a b l e C L\n10F a v o r a b l e C L\n11N e u t r a l\ndelPozoetal. EPJDataScience           (2024) 13:54 Page7of18\nFigure2 InterpretationoftheSB.This\ufb01guredisplaystheprobabilityofanarticlebeingfavorabletowardsCL,\nCR,orneutral,giventhevalueofSBmeasuredoverthearticlecontent.Theshadedregionsrepresentthe90%\ncon\ufb01denceintervalscalculatedbybootstrapping\nGiventheoverallconnotationofeacharticle,weappliedlogisticregressiontocorrelate\ntheSBvalueassignedtoanarticlewithitslabel.Speci\ufb01cally,wepropose:\nP(l=i|SB)=eaiSB\n/summationtext\nieaiSB\nwherelis the connotation of the article, and i= \u20131,0,1 represents being favorable to-\nwardsCL,neutral,andfavorabletowardsCR,respectively.Thecoe\ufb03cients aiareinferred\nby \ufb01tting the model to the labeled data. In order to keep the model as simple as possible,\nwe chose not to include intercepts biin the exponent of the exponential functions (i.e.,\naiSB+bi), after \ufb01nding them to be insigni\ufb01cantly di\ufb00erent from zero. The estimated co-\ne\ufb03cientsareasfollows: a\u20131=\u20130.89 [\u20131.44,\u20130.44 ],a0=\u20130.37 [\u20130.82,0.07 ],anda1=1.26\n[0.82,1.94 ]. The numbers in brackets denote the 90% con\ufb01dence intervals, which were\ncalculatedusingbootstrapping.\nIn Fig.2, we present the inferred probability of an article\u2019s connotation based on the\nmeasured value of SB. This \ufb01gure facilitates the interpretation of the SBvalue. For in-\nstance,aSB=0indicatesanequalprobabilityforanarticletobeeitherneutralorpositive\ntowards a given coalition. An article with a SBslightly deviating from zero already indi-\ncates a clearly favorable trend towards a speci\ufb01c coalition. On the other hand, extreme\nvalues(SB=\u20131orSB=1)donotnecessarilyrepresentaprobabilityequalto1ofbeingfa-\nvorabletoacertaincoalition.Instead,thereisasigni\ufb01cantfractionofneutralarticleswiththeseSBvalues, and a small fraction of articles that express the opposite opinion, likely\ndue to misclassi\ufb01cations by the sentiment detection algorithm [ 55]. Additionally, we ob-\nserved a slight asymmetry for extreme SBvalues, with a higher probability of an article\nbeingneutralwhen SB=\u20131comparedtowhen SB=1.\n3.5 Topicdecomposition\nWe process the content of the articles by describing the texts within the bag-of-words\nframework. Speci\ufb01cally, we represent the corpus as a matrix of documents and terms,\nallowingsubsequenttopicdescription.Todothis,weproceedwiththefollowingsteps:\ndelPozoetal. EPJDataScience           (2024) 13:54 Page8of18\n\u2022Pre-ProcessingText.\nGiventhatweuseatextrepresentationbasedonwordfrequency,itisimportantto\ndelete,ononehand,thosewordsthatareredundantand,ontheotherhand,those\nwordsthatarenon-informative,suchprepositionsandarticles,inordertorepresent\ntextsonareducedsetofmeaningfulwords.Thissetofwordswillconstituteour\u201cvocabulary\u201d.\nWiththisinmind,weperformtwothings:First,weapplylemmatizationonthe\ntextsusingthepythonlibrarySpacy[ 57],speci\ufb01callyweuse es_core_news_md model\n[58].Lemmatizationtransformsallthewordstotheirroots,forinstance,allverbsare\ntransformedtotheirin\ufb01nitiveformandallsubstantivesaretransformedtotheirsingularform.Then,weremovestopwordsde\ufb01nedinNLTKpythonlibrary[ 59]\n(which,forinstance,includesarticlesandprepositions),aswellasrarewords(thatwe\nde\ufb01nedasthosethatappearsinonlyonetextofthecorpus)andveryfrequentwordsthatwerenotincludedinthestopwordlistbutwerepresentinmorethan70 %ofthe\nnewsarticles.\n\u2022TF-IDF\nAfterde\ufb01ningthevocabulary,weproceedtodescribetextsinthebag-of-words\nframework.\nWestartbydescribingeacharticlebyaterm-frequency(TF)vector.This\ndescriptiontransformsagiventexttoavectorwhereeachcomponentpointsoutthenumberoftimesagivenwordofthevocabularyappearsinthetext.Weconstructthisrepresentationthroughtheobject CountVectorizer fromthepythonscikit-learn\nlibrary[60].\nMoreover,toreducewordfrequencybiasandboosttheimpactofmeaningful\nwords,wecomputeforeachwordtheInverseDocumentFrequency(IDF)coe\ufb01cient,\nde\ufb01nedasidf\nj=log(N\nNj),whereNrepresentsthetotalnumberofarticleswithinthe\ncorpus,while Njdenotesthecountofarticlescontainingthe j-thterm.Todothis\ncalculation,weapplytheobject T\ufb01dfTransformer from[60].\nWiththeseingredients,eachtextis\ufb01nallydescribedwiththeTermFrequency-\nInverseDocumentFrequency(TF-IDF)coe\ufb01cients[ 61],wherethe j-thcomponentof\nthe\u201carticlevector\u201d iisgivenby:\nvij=fij\u00b7log/parenleftbiggN\nNj/parenrightbigg\nwherefijisthefrequencyofterm jinarticle iandNjisthenumberofdocuments\nwheretheterm jappears,asitwasstatedbefore.\nT henthearticlescorpusisdescribedasamatrix M\u2208Rn\u00d7m,withnthenumberof\narticlesinthecorpusand mthenumberoftermsincludedinthevocabulary.This\nmatrixisaconciserepresentationofthecorpuswherethemeaningfulwords(both\nfrequentandspeci\ufb01cwords)areenhancedforeachtext.\n\u2022TopicDecomposition.\nInthisstep,inordertoidentifythemaintopicsofthecorpusofnewsarticles,we\napplytheunsupervisedtopicdetectionalgorithmNon-negativeMatrixFactorization\n(NMF)modelfromscikit-learnpythonlibrary[ 60]onthenews-termmatrix M\nconstructedinthepreviousstep.NMFdecomposesmatrixMintotheproductoftwo\ndelPozoetal. EPJDataScience           (2024) 13:54 Page9of18\nmatrices,ensuringthatallelementsarenon-negative:\nM\u2248H\u00b7W,whereH\u2208Rn\u00d7tandW\u2208Rt\u00d7m\nHere,trepresentstheselectednumberoftopics,and HandWdenotetheresulting\nmatricesofthedecomposition.Inparticular, Hde\ufb01neshoweacharticleisdescribed\nintermsoftopics.Theelement hijpointsouttheweightoftopic jonarticle i.Inother\nwords,itquanti\ufb01eshowmucharticle ibelongstotopic j.Inordertointerpretthese\nweightsintermsofprobabilities,eachrowisnormalizedsuchas/summationtextt\njhij=1.\nOntheotherhand,rowsofmatrix Wspecifythedescriptionofeachtopicinterms\nofthevocabularybuiltabove.Inthiscase,theelement wijdenotestheweightofterm j\nintopici,i.e,howwellterm jdescribestopic i.Inthiscase,byonlyidentifyingthe\nweightiesttermsallowstointerpretwhatthetopictalksabout.\n3.5.1 Mediaagenda\nFollowingtheprocedureoutlinedin[ 8],wede\ufb01nethemediaagendaastheproportionof\narticlesassociatedwitheachtopic.Speci\ufb01cally,wede\ufb01netheweightoftopic j,Tj,as:\nTj=1\nnn/summationdisplay\nihij (2)\nwithhijbeing the weight of topic jon article i(as de\ufb01ned earlier) and nthe number of\nunique articles shared by the media outlets. We interpret Tjas the collective interest of\nmedia outlets in topic j. This measure indicates the likelihood of \ufb01nding an article as-\nsociated with topic jin our dataset. (in this case, we are not considering the number of\ntimeseacharticlewassharinginsocialmedia. Therefore,thisde\ufb01nitionholdsforunique\narticles).\n3.5.2 Partisansagenda\nIn order to distinguish the interest of partisans groups over the topics found above, we\nde\ufb01ne the interest of partisan group pover topic jas the average of elements hij(weight\noftopicjonarticle i)weightedbythenumberoftimesgroup psharesarticle i(spi):\nTj\np=/summationtextn\nispihij/summationtextnispi(3)\nwhere/summationtextn\nispiiseq ua lt ot h et o ta ln u m be ro ft i m esuse r sfr o mgr o u p pshared an article i\nandnbeingthetotalnumberofarticles. Tj\nptellsustheprobabilitythatanarticleassociated\nwithtopic jissharedbyanuseridenti\ufb01edwithgroup p.\n4R e s u l t s\nAs outlined in the Introduction, the aim of this study is to investigate how and which\ncharacteristicsofsharednews,andtowhatextent,correlatewiththepoliticalideologiesof\ntheuserssharingthem.Toachievethis,weanalyzevariouscharacteristicsofnewsarticles\nsharedbyuserswithidenti\ufb01edpoliticalleaning,encompassingtheirsources,distribution\noftopics,andthepoliticalbiasesthatmanifestatseverallevels.\ndelPozoetal. EPJDataScience           (2024) 13:54 Page10of18\nFigure3 DistributionofNewsArticlesbyMediaOutlet.GreybarsshowtheuniquearticlesonTwitterby\nmediaoutlet( uniquemeanscountedonce),ordereddescending.Greenbarsshowthedistribution\nconsideringeachinstanceofsharing,highlightinguserpreferences\n4.1 Datadescription\nAn essential characteristic of news, potentially informative for analyzing the relation-\nship between users\u2019 ideologies and the news they share, is the source from which they\noriginate\u2014the media outlet. We begin by analyzing the distribution of news articles onTwitter categorized by their originating media outlets, as illustrated in Fig. 3.T h eg r e y\nbars represent the descending order of the number of unique articles shared from each\nmediaoutlet,where uniqueindicatesthateacharticleiscountedonlyonce,regardlessof\nhowmanytimesitwasposted.Meanwhile,thegreenbarsdepictthedistributionofnews\narticlessharedbyTwitterusers,takingintoaccountthefrequencyofeacharticle\u2019ssharing.\nFrom the grey bars, it can be deduced that approximately 60% of the articles originate\nfromaspeci\ufb01csetofoutlets:Infobae,Clar\u00edn,LaNaci\u00f3n,ElDestape,Per\ufb01l,andP\u00e1gina12,listed in descending order by count. This distribution mirrors the activity level of these\noutlets,withInfobaebeingthemostactiveintermsofarticlespublished.\nOntheotherhand,thegreenbarshighlighttheimpactofuserpreferencesonthedistri-\nbution.Forinstance,articlesfromElDestapeconstituteabout30%ofthesharedcontent,\nunderscoring its signi\ufb01cance despite not being the highest in publication volume. The\nsamesixoutlets(withPer\ufb01lreplacedbyTodoNoticias)accountforapproximately80%of\nthesharedarticles.\n4.2 Sentimentbias\nWe then analyze the political bias of these media outlets using the Sentiment Bias ( SB)\nmetricintroducedinSect. 3.Thismetricmeasuresthetendencyofanarticletoleanpos-\nitively or negatively towards one of two political coalitions, CL and CR. The SBmetric\nprovidesascorebetween \u20131and1 foreachart iclethatmentionsacandidatefromeither\ncoalition.Ascorecloserto\u20131indicatesafavorablestancetowardsCL,whileascorecloser\nto1indica tesafa vorablestancetowardsCR.T hismetriche lpsusde\ufb01nethebiasofeach\narticleand,consequently,ofeachmediaoutlet.\nFigure4showstheaveragesentimentbias( \u00afSB)foreachmediaoutlet,calculatedasthe\nmeanofall SBscoresfromtheirrespectivearticles.Forinstance,P\u00e1gina12andElDestape\nexhibit \u00afSBvalues favoring CL, whereas La Naci\u00f3n and Clar\u00edn show \u00afSBvalues favoring\nCR. Notably, Infobae, shared by both supporter groups, falls between these two groups\nof outlets. Regarding the absolute value of \u00afSB,w ei n t e r p r e t \u00afSB= 0 as a neutral position\ndelPozoetal. EPJDataScience           (2024) 13:54 Page11of18\nFigure4 MeanSentimentBias( \u00afSB)bymediaoutlet. \u00afSBrepresentstheaverageSBacrossallarticlesfroma\nspeci\ufb01cmediaoutlet.Mediaoutletspositionedontheleftsideareinterpretedashavingabiastowardsthe\nCenter-Left(CL),whilethoseontherightsideareconsideredtohaveabiastowardstheCenter-Right(CR).\nGraybarsindicatethecentered99%quantileoftheestimatordeterminedthroughbootstrapping,andstars\ndenotethoseestimatessigni\ufb01cantlydi\ufb00erentfromzero\n(see Sect. 3.4.2), meaning most outlets slightly favor CL during the analyzed period. El\nDestape and P\u00e1gina 12 are more extreme in their positions and can be certainly con-\nsidered as Center-Left outlets, while Clar\u00edn, and La Naci\u00f3n, closer to the center, can bealsoconsideredcentristmediabutslightlyleantowardstheCenter-Rightposition.Forall\nmentionedmediaoutlets, \u00afSBsigni\ufb01cantlydeviatesfromzeromarkedwithstarsinFig. 4),\nunlikeInfobae,whichunderscoresitsapparentcentristposition.\n4.2.1 Selectivesharing\nAfteridentifyingthebiasofthearticles,wefurtherexploretherelationshipbetweenusers\u2019\npoliticalideologiesandthenewstheyshareonsocialmediabyincorporatingtheirpoliticalleaningatthetimeofsharing.Thisleaning,ascomputedbyZhouetal.[ 37],identi\ufb01esusers\nasbelongingtoeithertheCenter-Left(CL)orCenter-Right(CR)factionsduringthe2019\nArgentinepresidentialelections.\nIn order to incorporate this information and motivated by studying con\ufb01rmation bias,\ninFig.5weexaminethebehaviorofCLandCRusergroupsinrelationtosharingmedia\noutlets,previouslyidenti\ufb01edwithspeci\ufb01cpoliticalbiasesinFig. 4,andthebiasofthenews\neach group shares. We select media outlets with at least 100 articles shared by each user\ngroup, ordered by increasing SB, as shown in left panel of Fig. 5. We then examine the\npartisans\u2019 media preferencesby calculatingthe percentage of each media outlet\u2019s articles\nsharedbyCLandCRusers,asshowninthemiddlepanelofFig. 5.Thispaneldepictshow\nthe100%ofnewsforeachmediaoutletisdistributed,witharticlessharedbyCLusersinred and by CR users in blue. The percentage of the majority group is speci\ufb01ed in white\nwithin each bar. The right panel displays the average SBof articles shared by each group\nandcategorizedbyoutlet.Detailedobservationsfromeachpanelarediscussedbelow.\nA pattern that is, to some extent, anticipated emerges upon examining users\u2019 media\npreferences, in Fig. 5middle panel. We can see that media outlets with strong biases to-\nwardsCL,suchasP\u00e1gina12,ElDestapeandLaIzquierdaDiario,areprimarilysharedbyCL supporters (for instance, in the \ufb01rst two outlets, CL users share 95% of the articles).\nConversely, outlets with biases on the other end of the spectrum, such as La Naci\u00f3n and\nClar\u00edn, are mostly shared by CR users. We also observe this tendency when examining\ndelPozoetal. EPJDataScience           (2024) 13:54 Page12of18\nFigure5 Con\ufb01rmationbiasanalysis. Left:MeanSentimentBias( \u00afSB)ofmediaoutletswithatleast100articles\nsharedbyuserslabeledasCLandCR. Middle:PercentageofnewsarticlessharedbyCL(blue)andCR(red)\nsupportersfromeachmediaoutlet. Right:AverageSentimentBiasofnewsarticlessharedbyCLandCR\npartisansacrossmediaoutlets.Eachpointrepresentstheaveragesentimentbiasacrossallarticlesfroma\ngivenmediaoutletsharedbyeachusergroup,withCLinblueandCRinred.Onlymediaoutletswithatleast\n100articlessharedbyeachgroupareincluded(seeAdditional\ufb01le 1).Thehorizontalbarsindicatethe\ncentered99%quantileoftheestimateobtainedviabootstrapping.Blackstarshighlightinstanceswherethe\ndi\ufb00erencein \u00afSBbetweenCLandCRsupportersisstatisticallysigni\ufb01cant,with p<0.01\ntheSBof all articles shared by Center-Left (CL) and Center-Right (CR) supporters (see\nSupplementary Information for more details). These observations reinforce the selectiveexposure theory [ 29], suggesting that users tend to select news from media that favor or\nalign with their pre-existing ideologies. However, the proportion of users sharing newsfrom media outlets with biases similar to their own di\ufb00ers between the two groups. It\u2019snoteworthy that while CR users predominantly share CR-favored media, a considerablenumberofCR-biasednewsarticlesarealsosharedbyuserswithopposingbiases(CL).\nWhatismostinterestingiswhenwebreakdownthesentimentbiasofeachmediaoutlet\nintotwogroups:newssharedbyCLusersandtheonessharedbyCRusers.Asdiscussedabove,althoughcertaingroupsofmediaoutletstendtobemoresharedbyeachpoliticalcoalition, there is a subset (such as Clar\u00edn, La Naci\u00f3n, and Infobae) which is signi\ufb01cantlyshared by both coalitions. However, the content extracted by each coalition from theseoutletsdi\ufb00ers. TherightpanelofFig. 5displaystheaverage SBofarticlessharedbyeach\ngroupforeachoutlet.Thisillustratesthephenomenonknownas\u201ccherrypicking\u201d,whereusers share news that align with their political beliefs, even from opposing outlets. Forexample, left-leaning supporters share news from La Naci\u00f3n (identi\ufb01ed as a right-biasednews outlet in Fig. 4) with an average SBc l o s et oz e r o ,w h i l er i g h t - l e a n i n gs u p p o r t e r s\nsharenewsfromthesameoutletwithahigheraverage SB.Similartrendsareobservedin\nClar\u00edn(Center-Right),Infobae(Centrist),andLaIzquierdaDiarioand\u00c1mbitoFinanciero(Center-Left).Wehavestatisticallyvalidatedsigni\ufb01cantdi\ufb00erencesbetweenthegroupsfor\neachoutlet,withap-valuebelow0.01.Statisticallysigni\ufb01cantdi\ufb00erencesinnewssharing\nbiasesaremarkedwithastar.\n4.3 Topicsinterest\nThis section delves into whether users\u2019 political inclinations also a\ufb00ect the topics of thenews they share. The \ufb01ndings in previous section establish a link between the users\u2019 ide-ologies and the political bias in the news they share. Here, we aim to determine whether\ndelPozoetal. EPJDataScience           (2024) 13:54 Page13of18\nFigure6 (A)AverageSentimentBiasofemergenttopics.Topicsareenumeratedforsubsequentreference.\nColorsindicatethesignofthe SBtohighlightitsorientation:bluesigni\ufb01esapositivebiastowardsCL,andred\nindicatesapositivebiastowardsCR.(B)MediaOutletAgendas.Numberscorrespondtothetopicsidenti\ufb01ed\ninpanelA,withcolorsre\ufb02ectingtheirrespectivebiases.Theoutletsdisplayedarethosewithaclearleaning\ntowardsCR(LaNaci\u00f3nandClar\u00edn)andCL(ElDestapeandP\u00e1gina12),asdemonstratedinFig. 4\nspeci\ufb01c themes are more supportive of particular candidates and if supporters of each\ncoalitionshowapreferenceforthesetopics.\nWe initially conduct a topic decomposition of the news articles to identify the princi-\npal themes within the dataset, as detailed in Sect. 3. We identi\ufb01ed two main families of\ntopics: the \ufb01rst related to economic issues, such as Wage/In\ufb02ation andEconomy/Dollar ;\nthe second pertains to topics associated with the presidential elections occurring during\ntheanalyzedperiod,including PoliticsCR ,PoliticsBAProvince ,3rdParty ,Elections,Pol-\niticsCL,andJustice.Descriptionsofthesetopics,includingwordcloudsandexamplesof\nrelatednewsarticles,areavailableintheAdditional\ufb01le 1.\nRegardlessoftheinterpretationofthesetopics,whichdependsheavilyoncontext,panel\nAo fF i g. 6provides insight into which topics are supportive or against each coalition by\ndisplayingtheestimated \u00afSBforeachtopic.Giventhateacharticleisassociatedwitheach\ntopictoavaryingdegree(refertoSect. 3),\u00afSBre\ufb02ectstheweightedaverage SBofeacharti-\ncleaccordingtothisassociation.Forexample,thispanelindicatesthatthetopic Wage/In-\n\ufb02ationsupportstheCLstance,while JusticeleanstowardsCR.Notably,topicslabeledas\nPoliticsCR andPoliticsCL appeartofavorthecoalitioncontrarytowhattheirlabelssug-\ngest, likely because they group articles critical of those coalitions. The remaining topics\nexhibitaslightpreferencetowardsCL,aligningwiththeoveralltendencyobservedduringtheanalyzedperiod(referto,forinstance,Fig. 4).\nFurthermore, we explore the topics covered in news articles to discern the \u201cagenda\u201d of\neach media outlet (referred to as the \u201cmedia agenda\u201d in Sect. 3). This agenda essentially\nrepresents how each outlet distributes itscoverage acrossthedetected topics. Panel B of\nFig.6showcases the agendas of four media outlets, two with a right-leaning bias (Clar\u00edn\nandLaNaci\u00f3n)andtwowithaleft-leaningbias(ElDestapeandP\u00e1gina12).Uponinspect-ing this panel, clear similarities and di\ufb00erences emerge. Much of this coverage behavior\ncan be understood by considering the overall bias of each topic as shown in panel A of\nFig.6andthebiasofeachmediaasdepictedinFig. 4.Forinstance,Clar\u00ednandLaNaci\u00f3n\ndelPozoetal. EPJDataScience           (2024) 13:54 Page14of18\nFigure7 (A)Partisanagendas.Distributionoftopicinterestsforeachpartisangroup.Romannumeralsrefer\ntotopicsoutlinedinpanelAofFig. 6andalsoinpanelBofthis\ufb01gure. (B)Di\ufb00erenceintopicinterests. This\ndi\ufb00erenceiscalculatedusingequation( 4).(C)Partisanagendasbymediaoutlet. Theoutletsdepictedarethose\nsigni\ufb01cantlysharedbybothcoalitiongroups(seeFig. 5midlepanel)\nshow a priority for covering Justicecompared to the other two outlets, whereas P\u00e1gina\n12 exhibits a stronger focus on Wage/In\ufb02ation , and El Destape on Politics CR ,r e la t i v et o\nothertopics.\n4.3.1 Partisansagenda\nThetopicsdescribedabovein\ufb02uencesocialmediausersaccordingtotheirpoliticallean-\nings.Theseleaningsmayconstrainuserstoprefersharingcertaintopicsoverothers.Panel\nAofF ig.7providesinsightsintothepreferredtopicsforeachpartisangroup,delineating\nwhatwetermthe\u201cpartisanagendas\u201d.Inthis\ufb01gure,itisevidentthatCL(Center-Left)usersdemonstrateagreaterinterestintopicslike PoliticsCR andWage/In\ufb02ation ,whichexhibits\na positive inclination towards the CL coalition, whereas CR (Center-Right) users show a\npreferenceforthetopic Justice,withapositivebiastowardstheCRcoalition.PanelBfur-\ntherclari\ufb01esthedisparityintheseinterests.Wede\ufb01nethisdi\ufb00erenceas\n/Delta1T\nj=Tj\nCL\u2013Tj\nCR (4)\nwhereTj\nCLdenotestheinterestofCLpartisansintopic j.AsillustratedinpanelBofFig. 6,\nthespeci\ufb01edtopicssigni\ufb01cantlyalignwiththecoalitionofuserswhosharethem,indicatedby a Spearman correlation coe\ufb03cient of \u20130.78 (with a 90% con\ufb01dence interval of [\u20131,\n\u20130.24]). The sole noticeable exception is the topic Politics CL , in which both coalitions\nappeartohaveanequalinterest,yetitdemonstratesanoverallinclinationtowardsCR.\nFinally,Fig. 5middle panel showcases the distribution ofnews shared by each partisan\ngroup,thistimesegmentedbymediaoutlet.Thispanelunveilsanotherdimensionofthe\ndelPozoetal. EPJDataScience           (2024) 13:54 Page15of18\ncherry-pickingbehavioroutlinedinFig. 5rightpanel.Forexample,whileusersfromboth\ncoalitionsdistributenewsfromClar\u00ednandLaNaci\u00f3n,CRuserspredominantlysharecon-\ntentrelatedtothetopic Justice,whichexhibitsaCR-favorablebias,whereasCLusersare\nmore inclined to share information on Wage/In\ufb02ation , which aligns with a CL-favorable\nbiasasindicatedinpanelAofFig. 6.Nevertheless,thischerry-pickingbehaviorseemsto\nbe absent in the topic dissemination from the centrist outlet Infobae, in contrast to theobservationsmadeintherightpanelofFig. 5,whereeachgroupdistinctlysharedarticles\nfromthismediaoutletthatwerebiasedtowardstheirrespectivepreferences.\n5 Discussionandconclusions\nIn this work, we investigated the relation between shared news on social media and the\nideologiesoftheuserswhosharethem.Weanalyzedboththesourceofthenewsarticles,\ntheir intrinsic bias, and the topics covered, and we related each of these characteristics\ntotheuserspoliticalideologiesfrom[ 37].Toaccomplishthis,weanalyzedthecontentof\nnewsarticlessharedbypoliticallyaligned usersonX (ex-Twitter), scraping their content\nandquantifyingboththebiasandthetopicscovered.\nOur initial analysis focused on sources (i.e. media outlets). This analysis revealed that\nthe sharing behavior of news by users did not exhibit a distinctly polarized distribution.\nWhilecertainmediaoutletsmaybeassociatedwithparticularpoliticalideologies(CLandCR), we observed a signi\ufb01cant percentage of news from Center-Right (CR) outlets being\nsharedbyusersidenti\ufb01edasCenter-Left(CL).SeeFig. 5middlepanel.Thissuggeststhat\nthesourcesofnewssharedbyusersonsocialmediamaynotnecessarilyindicatetheiride-ology. Our data indicates that Center-Right (CR) media outlets are the most widely con-\nsumedinthecountry,aligningwith\ufb01ndingsfrom[ 40].Additionally,ourresultshighlight\nthatCenter-Right(CR)mediaoutletsreachamorediverseaudienceintermsofideologicalspectra.\nWe delve deeper into the analysis of the relationship between users\u2019 ideologies and the\nnews they share, by examining the bias of news content using the previously introduced\nSentiment Bias index [ 41,56]. This index e\ufb00ectively categorizes biases of news outlets\nwithout making any assumptions, as depicted in Fig. 4. Our \ufb01ndings are consistent with\nexternalclassi\ufb01cations,whereavailable,validatingtheaccuracyofourapproach[ 38].\nWhen analyzing the average Sentiment Bias ( \u00afSB) alongside social media data, a signif-\nicant trend emerges: users on social platforms tend to share news that aligns with theirpolitical beliefs This tendency can be interpreted as indicative of the selective exposure\ntheory[29].The\ufb01ndingsaresupportedbyFig. 5rightpanel,con\ufb01rminga\u201ccherry-picking\u201d\ntrend:usersengagewithvariousjournalsregardlessoftheirpoliticalalignment,yetselec-tivelychoosenewsthatresonateswiththeirideologies.Thisunderscorestheirpreference\nforcontentreinforcingtheirexistingbeliefs.Furthermore,ouranalysisextendsthesepat-\nterns to speci\ufb01c topics, as demonstrated in Fig. 7. Users distinctly favor sharing articles\nrelatedtosubjectsaligningwiththeirpreferredcandidates.\nWhileit\u2019sexpectedforuserswithde\ufb01nedideologicalleaningstosharenewsthataligns\nwith their biases, the analysis presented here highlights that this tendency is only appar-\nentwhenassessing thebiasofthecontentitself,ratherthansolelyrelyingonmediabias.\nWhilethisphenomenonispredictable,theaimofthisstudyistointroduceamethodforquantifyingsuchbehavior.\nFinally, we\u2019d like to address some remarks and potential limitations of our study. The\ndataset,whilefouryearsoldandspeci\ufb01ctoArgentina,providesuniqueinsightsintousers\u2019\ndelPozoetal. EPJDataScience           (2024) 13:54 Page16of18\npolitical leanings not found in other datasets. User classi\ufb01cation was achieved through a\nmachine learning model,enhancing thedataset\u2019s valueand enabling ustoexplorehowit\ncorrelateswiththepoliticalbiasofsharednewscontent.Webelievethisanalyticalframe-workcouldbevaluableinothercountries,especiallythosewithpronouncedpoliticalpo-\nlarizationlikeArgentina,andcouldbeadaptedtomultipolarizedscenarios[ 62].\nAbbreviations\nCL,Center-Left;CR,Center-Right;SB,SentimentBias; \u00afSB,MeanSentimentBias.\nSupplementaryinformation\nSupplementaryinformation accompaniesthispaperat https://doi.org/10.1140/epjds/s13688-024-00493-y .\nAdditional\ufb01le1 .(PDF2.4MB)\nAcknowledgements\nWewouldliketoexpressoursinceregratitudetoAlejandroPardoPintos,FavioDiCiocco,andFedericoMossfortheir\nvaluablecontributionsduringthepreparationofthispaper.\nAuthorcontributions\nSMdP,SP,LG,andMSwereresponsibleforcollectingtherawdata.SMdPdevelopedthecomputationalcodeutilized\nconsistentlythroughoutthepaper.SMdPandSPmadecontributionstothestatisticalanalysis.PBandHAMconceptualizedtheresearch.Allauthorsengagedindiscussionsabouttheresultsandcollaboratedonthedevelopment\nofthemanuscript.Allauthorsreadandapprovedthe\ufb01nalmanuscript.\nFunding\nHAMandMSweresupportedbyNSFGrantNo.2214217.PB,SMdP,SPandLGweresupportedby\nPICT-2020-SERIEA-00966.\nDataavailability\nThedatasetsgeneratedandanalysedduringthecurrentstudyareavailableintheOSFrepositoryin https://osf.io/sxwmj/ .\nCodeavailability\nThecorrespondingcodesareavailablein https://github.com/so\ufb01adelpozo/SocialMediaBiasAndPolarization .\nDeclarations\nCompetinginterests\nTheauthorsdeclarenocompetinginterests.\nAuthordetails\n1UniversidaddeBuenosAires,FacultaddeCienciasExactasyNaturales,DepartamentodeF\u00edsica,BuenosAires,Argentina.\n2CONICET-UniversidaddeBuenosAires,InstitutodeF\u00edsicaInterdisciplinariayAplicada(INFINA),BuenosAires,Argentina.\n3LevichInstituteandPhysicsDepartment,CityCollegeofNewYork,10031,NewYork,USA.\nReceived:25April2024 Accepted:30July2024\nReferences\n1. FeynmanRP(1998)Cargocultscience.In:WilliamsJ(ed)Theartandscienceofanalogcircuitdesign.EDNseriesfor\ndesignengineers.Newnes,Amsterdam,pp55\u201361\n2. BarbierG,LiuH(2011)Datamininginsocialmedia.Socialnetworkdataanalytics,327\u2013352\n3. NewmanN,FletcherR,SchulzA,AndiS,RobertsonCT,NielsenRK(2021)Reutersinstitutedigitalnewsreport2021.\nReutersInstituteforthestudy.Journalism\n4. NewmanN,FletcherR,EddyK,RobertsonCT,NielsenRK(2023)Digitalnewsreport.2023\n5. ChandrasekaranR,MehtaV,ValkundeT,MoustakasE(2020)Topics,trends,andsentimentsoftweetsaboutthe\ncovid-19pandemic:temporalinfoveillancestudy.JMedInternetRes22(10):22624\n6. LeeK,PalsetiaD,NarayananR,PatwaryMMA,AgrawalA,ChoudharyA(2011)Twittertrendingtopicclassi\ufb01cation.In:\n2011IEEE11thinternationalconferenceondataminingworkshops.IEEE,pp251\u2013258\n7. FalkenbergM,GaleazziA,TorricelliM,DiMarcoN,LarosaF,SasM,MekacherA,PearceW,ZolloF,QuattrociocchiW,et\nal(2022)Growingpolarizationaroundclimatechangeonsocialmedia.NatClimChange12(12):1114\u20131121\n8. PintoS,AlbaneseF,DorsoCO,BalenzuelaP(2019)Quantifyingtime-dependentmediaagendaandpublicopinionby\ntopicmodeling.PhysA,StatMechAppl524:614\u2013624. https://doi.org/10.1016/j.physa.2019.04.108\n9. AnsteadN,O\u2019LoughlinB(2015)Socialmediaanalysisandpublicopinion:the2010ukgeneralelection.J\nComput-MediatCommun20(2):204\u2013220\n10. Kla\u0161njaM,Barber\u00e1P,BeauchampN,NaglerJ,TuckerJA(2015)Measuringpublicopinionwithsocialmediadata\ndelPozoetal. EPJDataScience           (2024) 13:54 Page17of18\n11. TadesseMM,LinH,XuB,YangL(2018)PersonalitypredictionsbasedonuserbehaviorontheFacebooksocialmedia\nplatform.IEEEAccess6:61959\u201361969\n12. AnJ,QuerciaD,ChaM,GummadiK,CrowcroftJ(2014)Sharingpoliticalnews:thebalancingactofintimacyand\nsocializationinselectiveexposure.EPJDataSci3:12\n13. KalsnesB,LarssonAO(2018)Understandingnewssharingacrosssocialmedia:detailingdistributiononFacebook\nandTwitter.JournalismStudies19(11):1669\u20131688\n14. K\u00fcmpelAS,KarnowskiV,KeylingT(2015)Newssharinginsocialmedia:areviewofcurrentresearchonnewssharing\nusers,content,andnetworks.SocMediaSoc1(2):2056305115610141\n15. LeeCS,MaL(2012)Newssharinginsocialmedia:thee\ufb00ectofgrati\ufb01cationsandpriorexperience.ComputHum\nBehav28(2):331\u2013339\n16. AllcottH,GentzkowM(2017)Socialmediaandfakenewsinthe2016election.JEconPerspect31(2):211\u201323617. BovetA,MakseHA(2019)In\ufb02uenceoffakenewsinTwitterduringthe2016uspresidentialelection.NatCommun\n10(1):7\n18. RochaYM,MouraGA,Desid\u00e9rioGA,OliveiraCH,Louren\u00e7oFD,FigueiredoNicoleteLD(2021)theimpactoffakenews\nonsocialmediaanditsin\ufb02uenceonhealthduringthecovid-19pandemic:asystematicreview.JournalofPublic\nHealth,1\u201310\n19. KimDH,Jones-JangSM,KenskiK(2021)Whydopeoplesharepoliticalinformationonsocialmedia?DigJournal\n9(8):1123\u20131140\n20. KarnowskiV,LeonhardL,K\u00fcmpelAS(2018)Whyuserssharethenews:atheoryofreasonedaction-basedstudyon\ntheantecedentsofnews-sharingbehavior.CommunResRep35(2):91\u2013100\n21. OsmundsenM,BorA,VahlstrupPB,BechmannA,PetersenMB(2021)Partisanpolarizationistheprimary\npsychologicalmotivationbehindpoliticalfakenewssharingonTwitter.AmPolitSciRev115(3):999\u20131015\n22. WesterwickA,JohnsonBK,Knobloch-WesterwickS(2017)Con\ufb01rmationbiasesinselectiveexposuretopolitical\nonlineinformation:sourcebiasvs.contentbias.CommunMonogr84(3):343\u2013364\n23. OxfordEnglishDictionary. https://www.oed.com\n24. SmithJ,NobleH(2014)Biasinresearch.Evid-BasedNurs17(4):100\u201310125. Delgado-RodriguezM,LlorcaJ(2004)Bias.JEpidemiolCommunityHealth58(8):635\u201364126. KundaZ(1990)Thecaseformotivatedreasoning.PsycholBull108(3):48027. WilliamsA(1975)Unbiasedstudyoftelevisionnewsbias.JCommun25(4):190\u2013199\n28. NickersonRS(1998)Con\ufb01rmationbias:aubiquitousphenomenoninmanyguises.RevGenPsychol2(2):175\u2013220\n29. StroudNJ(2010)Polarizationandpartisanselectiveexposure.JCommun60(3):556\u201357630. SpindeT,RudnitckaiaL,Mitrovi \u00b4cJ,HamborgF,GranitzerM,GippB,DonnayK(2021)Automatedidenti\ufb01cationofbias\ninducingwordsinnewsarticlesusinglinguisticandcontext-orientedfeatures.InfProcessManag58(3):102505\n31. McCombsME,ShawDL(1972)Publicopinionquarterly.PublicOpinQ36(2):176\u2013187. https://doi.org/10.1086/267990\n32. GuoL,McCombsM(2015)Thepowerofinformationnetworks:newdirectionsforagendasetting.Routledge,\nLondon\n33. Diaz-DiazF,SanMiguelM,MeloniS(2022)Echochambersandinformationtransmissionbiasesinhomophilicand\nheterophilicnetworks.SciRep12(1):9350\n34. WeiD,ZhouT,CiminiG,WuP,LiuW,ZhangY-C(2011)E\ufb00ectivemechanismforsocialrecommendationofnews.Phys\nA,StatMechAppl390(11):2117\u20132126\n35. DruckmanJN,ParkinM(2005)Theimpactofmediabias:howeditorialslanta\ufb00ectsvoters.JPolit67(4):1030\u2013104936. TuckerJA,GuessA,Barber\u00e1P,VaccariC,SiegelA,SanovichS,StukalD,NyhanBSocialmedia,politicalpolarization,\nandpoliticaldisinformation:areviewofthescienti\ufb01cliterature.Politicalpolarization.Andpoliticaldisinformation:areviewofthescienti\ufb01cliterature(March19,2018)(2018)\n37. ZhouZ,Sera\ufb01noM,CohanL,CaldarelliG,MakseHA(2021)Whypollsfailtopredictelections.JBigData8(1):1\u201328\n38. MediaB(2024)Check. https://mediabiasfactcheck.com/ .Accessed:19thMarch2024\n39. CantamuttoF(2016)KirchnerisminArgentina:apopulistdisputeforhegemony.IntCritThought6(2):227\u2013244.\nhttps://doi.org/10.1080/21598282.2016.1172325\n40. TodoMedios(Comscoredata). https://rb.gy/a56hq9\n41. CicchiniT,DelPozoSM,TagliazucchiE,BalenzuelaP(2022)NewssharingonTwitterrevealsemergentfragmentation\nofmediaagendaandpersistentpolarization.EPJDataSci11(1):48\n42. BonnerMD(2018)MediaandpunitivepopulisminArgentinaandChile.BullLatAmRes37(3):275\u2013290\n43. MitchelsteinE,BoczkowskiPJ(2017)Information,interest,andideology:explainingthedivergente\ufb00ectsof\ngovernment-mediarelationshipsinArgentina.IntJCommun11:20\n44. BecerraM,MarinoS,MastriniG,DragomirM,ThompsonM,BermejoF,ChanY-Y,NissenCS,ReljicD,SouthwoodR,et\nal(2012)Mappingdigitalmedia.ArgentinaObservatorioLatinoamericanodeRegulaci\u00f3n,MediosyConvergencia(OBSERVACOM)\n45. YeagerRL(2014)Governmentcontrolofandin\ufb02uenceonthepressinLatinAmerica:thecaseofArgentinaduring\nthepresidencyofCristinaFern\u00e1ndezdeKirchner(2007-2014).Inquiry17(1):5\n46. Clar\u00ednBias. https://mediabiasfactcheck.com/clarin-bias/ .Accessed:19thMarch2024\n47. LaNaci\u00f3nArgentinaBias. https://mediabiasfactcheck.com/la-nacion-argentina-bias/ .Accessed:19thMarch2024\n48. InfobaeBias. https://mediabiasfactcheck.com/infobae/ .Accessed:19thMarch2024\n49. YangK-C,FerraraE,MenczerF(2022)Botometer101:socialbotpracticumforcomputationalsocialscientists.J\nComputSocSci5(2):1511\u20131528\n50. RequestsPythonLibrary. https://pypi.org/project/requests/\n51. MultiprocesingPythonPackage. https://docs.python.org/3/library/multiprocessing.html\n52. ABYZWebLinksInc. http://www.abyznewslinks.com/\n53. SeleniumPythonLibrary. https://pypi.org/project/selenium/\n54. BeautifulSoupPythonLibrary. https://pypi.org/project/beautifulsoup4/\n55. P\u00e9rezJM,GiudiciJC,LuqueF(2021)pysentimiento:aPythontoolkitforsentimentanalysisandSocialNLPtasks56. AlbaneseF,PintoS,SemeshenkoV,BalenzuelaP(2020)Analyzingmassmediain\ufb02uenceusingnaturallanguage\nprocessingandtimeseriesanalysis.JPhysComplex1(2):025005\ndelPozoetal. EPJDataScience           (2024) 13:54 Page18of18\n57. HonnibalM,MontaniI(2017)spaCy2:NaturallanguageunderstandingwithBloomembeddings,convolutional\nneuralnetworksandincrementalparsing.Toappear\n58. Lemmatizationmodel. https://github.com/explosion/spacy-models/releases/tag/es_core_news_md-3.6.0\n59. BirdELS,KleinE(2019)NaturallanguageprocessingwithPython60. PedregosaF,VaroquauxG,GramfortA,MichelV,ThirionB,GriselO,BlondelM,PrettenhoferP,WeissR,DubourgV,\nVanderplasJ,PassosA,CournapeauD,BrucherM,PerrotM,DuchesnayE(2011)Scikit-learn:machinelearninginPython.JMachLearnRes12:2825\u20132830\n61. NguyenE(2014)Chapter4-TextminingandnetworkanalysisofdigitallibrariesinR.In:Dataminingapplications\nwithR,pp95\u2013115\n62. Martin-GutierrezS,LosadaJC,BenitoRM(2023)Multipolarsocialsystems:measuringpolarizationbeyond\ndichotomouscontexts.ChaosSolitonsFractals169:113244\nPublisher\u2019sNote\nSpringerNatureremainsneutralwithregardtojurisdictionalclaimsinpublishedmapsandinstitutionala\ufb03liations.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Analyzing user ideologies and shared news during the 2019 argentinian elections", "author": ["SM del Pozo", "S Pinto", "M Serafino", "L Garcia"], "pub_year": "2024", "venue": "EPJ Data \u2026", "abstract": "The extensive data generated on social media platforms allow us to gain insights over trending  topics and public opinions. Additionally, it offers a window into user behavior, including"}, "filled": false, "gsrank": 339, "pub_url": "https://epjds.epj.org/articles/epjdata/abs/2024/01/13688_2024_Article_493/13688_2024_Article_493.html", "author_id": ["ZpXsRWgAAAAJ", "Q9ssI9cAAAAJ", "YB_5JtoAAAAJ", "R8OeXTsAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:FxmD42c9LXwJ:scholar.google.com/&output=cite&scirp=338&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D330%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=FxmD42c9LXwJ&ei=QLWsaMqsGZXUieoPmrax2A8&json=", "num_citations": 7, "citedby_url": "/scholar?cites=8947875551062989079&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:FxmD42c9LXwJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://link.springer.com/content/pdf/10.1140/epjds/s13688-024-00493-y.pdf"}}, {"title": "Conflicts, villains, resolutions: Towards models of narrative media framing", "year": "2023", "pdf_data": "Conflicts, Villains, Resolutions:\nTowards models of Narrative Media Framing\nLea Frermann1Jiatong Li2Shima Khanehzar1,3Gosia Mikolajczak4\n1School of Computing and Information Systems, The University of Melbourne\n2Department of Computing, The Hong Kong Polytechnic University3CSIRO Data61\n4The Global Institute for Women\u2019s Leadership, The Australian National University\nlfrermann@unimelb.edu.au jiatong.li@connect.polyu.hk\nshima.khanehzar@data61.csiro.au Gosia.Mikolajczak@anu.edu.au\nAbstract\nDespite increasing interest in the automatic de-\ntection of media frames in NLP, the problem\nis typically simplified as single-label classifi-\ncation and adopts a topic-like view on frames,\nevading modelling the broader document-level\nnarrative. In this work, we revisit a widely used\nconceptualization of framing from the commu-\nnication sciences which explicitly captures el-\nements of narratives, including conflict and its\nresolution , and integrate it with the narrative\nframing of key entities in the story as heroes ,\nvictims orvillains . We adapt an effective an-\nnotation paradigm that breaks a complex an-\nnotation task into a series of simpler binary\nquestions, and present an annotated data set\nof English news articles, and a case study on\nthe framing of climate change in articles from\nnews outlets across the political spectrum. Fi-\nnally, we explore automatic multi-label predic-\ntion of our frames with supervised and semi-\nsupervised approaches, and present a novel\nretrieval-based method which is both effective\nand transparent in its predictions. We con-\nclude with a discussion of opportunities and\nchallenges for future work on document-level\nmodels of narrative framing.1\n1 Introduction\nMedia discourse around contested issues is often\nbiased by experiences or interests of the news\noutlets and different stakeholders they give voice\nto. News framing by the media has been formal-\nized and examined on many levels in communi-\ncation and social sciences, ranging from selec-\ntion of information (Levitt, 1981) over discourse-\ncentric (Pan and Kosicki, 1993) and entity focused\napproaches (Lawlor and Tolley, 2017). While a\ngrowing body of work in NLP attempts to auto-\nmatically detect framing in the news or social me-\ndia, most work adopts well-defined yet oversim-\nplifying approaches like topic modeling or simple\n1Code and data are available at https://github.\ncom/phenixace/narrative-framing .Resolution : solution/alleviation of the issue\nConflict : disagreements between individuals, groups, in-\nstitutions, countries, etc.\nHuman Interest : emotionalization and dramatization of\nan issue through the lens of affected individuals\nMoral : moral or religious references\nEconomic : economic consequences for individuals, groups,\ninstitutions, countries, etc.\nHero : entity contributing to/responsible for issue resolution\nVillain : entity contributing to/responsible for issue cause\nVictim : entity suffering the consequences of an issue\nTable 1: Five frames (top) and three narrative roles\n(bottom) considered in this paper.\nclassifiers (see Ali and Hassan (2022) for a recent\nreview); formalize the task as single-label classi-\nfication ignoring co-existence and interactions of\ndifferent frames, and focus on localized emphasis\nframes rather than the full story (Card et al., 2015;\nField et al., 2018; Khanehzar et al., 2021).\nThis paper addresses the above shortcomings\nby considering framing through the lens of narra-\ntives. We adopt a small set of high-level framing\ndevices established in the communication litera-\nture (Neuman et al., 1992; Semetko and Valken-\nburg, 2000), and integrate them with narrative roles\nassigned to key actors (entities) in the discourse.\nTable 1 defines the frames and associated entity\nroles. We argue that more nuanced and transpar-\nent automated models of framing are essential to\nmeaningfully support social studies into a system-\natic understanding of the viewpoints presented by\ndifferent stakeholders in contested issues such as\nclimate change. Our contributions to this end are\n(1) introducing an established frame inventory and\nannotation procedure from the communication sci-\nences into NLP; (2) a labeled data set; (3) a case\nstudy on the framing of climate change, showcas-\ning the potential of our annotations for large-scale\nmedia analysis; and (4) experiments on automatic\nframe prediction, including an effective and trans-\nparent retrieval-based classifier to predict multiplearXiv:2306.02052v2  [cs.CL]  3 Jan 2024\nframes per article.\nTable 1 (top) summarizes the frames used in our\nwork. Our framework departs from existing NLP\napproaches in two ways: first, we adopt a multi-\nlabel classification paradigm, allowing for a more\nnuanced analysis and avoiding the oversimplifica-\ntion of framing to a single label per item. Secondly,\nour framework emphasizes the narrative structure\nof the fullarticle: frames such as conflict ,resolu-\ntionorhuman interest are central building blocks\nof narratives, and are dominant in news coverage of\ncontested issues (Semetko and Valkenburg, 2000).\nBuilding on components of the Narrative Policy\nFramework (Shanahan et al., 2018), we identify\nthe key entities responsible for the issue ( villains ),\nthose who are affected ( victims ) and those who can\nresolve the issue ( hero); see Table 1 (bottom).\nWe apply our framework to the issue of climate\nchange, a pressing global challenge with wide-\nreaching impacts (Pew Research Center, 2022),\nwhich remains politically contested in terms of\nthe understanding of its urgency, causes, and pos-\nsible solutions (Sparkman et al., 2022). Impor-\ntantly, studies show that climate \u2018skeptics\u2019 (and\nthose lacking scientific backing) are cited almost\ntwice as often in the mainstream news media as\nthose calling for climate action (Wetts, 2020), ren-\ndering the examination of media framing and its\neffects on public support for climate change miti-\ngation a pressing goal. While a substantive body\nof work on climate change framing emerged in the\nsocial and communication sciences (Nisbet, 2009;\nWolters et al., 2022), the issue has attracted surpris-\ningly little attention in the NLP community to date.\nExceptions include work on stance detection in\nnews (Luo et al., 2020) or social media (Vaid et al.,\n2022) or models of scepticism detection (Bhatia\net al., 2021), whereas we focus on the narrative\nframing of the issue across political leanings. To\nrecap, in this paper we present:\n\u2022The concept of \u201cNarrative Media Framing\u201d\nformalized through a set of frames about con-\nflicts, their effects and resolutions which are\nintegrated with narrative roles assigned to key\nactors (Section 3).\n\u2022The narrative frames corpus of 428 English\nnews articles on climate change labeled with\nframe devices (Table 1). Following Semetko\nand Valkenburg (2000), annotators answered\nbinary indicator questions, and the final framelabels were derived from the answer set (Sec-\ntion 3).\n\u2022A detailed analysis of our annotated data set,\nhighlighting the interaction of frames and nar-\nrative roles, and differences across media out-\nlets with different political bias (Section 4).\n\u2022Experiments on automatic frame prediction,\nincluding semi-supervised and supervised\nmethods, including a new simple and trans-\nparent, yet effective method which combines\nretrieval with classification (Section 5).\n2 Background\nMedia framing refers to the deliberate presentation\nof information in order to elicit a desired response\nor shift in reader\u2019s attitude. We introduce into\nNLP five high-level frames (Table 1 top), identified\nby Semetko and Valkenburg (2000) as covering the\ndominant framing in reporting on contested issues\nwith the aim to attract reader\u2019s attention (Mendel-\nsohn et al., 2021). These categories have been\napplied via manual content analysis to a variety of\nissues and events, ranging from the media cover-\nage of the Egyptian revolution (Fornaciari, 2012),\nover the MH370 crash (Bier et al., 2018) to climate\nchange (Dotson et al., 2012; Feldman et al., 2017).\nTo identify each frame, Semetko and Valkenburg\n(2000) proposed a set of binary indicator questions\nwhich improved annotation quality and portabil-\nity of the framework across studies. We construct\nthe first publicly available data set annotated with\nthis framework, cover a larger and more diverse\nset of news articles than prior work, and link the\nframes with narrative roles assigned to key entities\nappearing in the story.\nMedia framing may manifest through the nar-\nrative roles \u2013 Hero ,Villain orVictim \u2013 as-\nsigned to key entities in a document, and this phe-\nnomenon has been widely studied in the communi-\ncation sciences in general (Shanahan et al., 2018)\nand in the context of climate change in particu-\nlar (L\u00fcck et al., 2018). We draw on this work as\nwell as work which identified key stakeholder cate-\ngories in the climate change discourse (Haigh and\nGriffiths, 2009; Ahchong and Dodds, 2012; Chen\net al., 2023) to analyze the framing of entities in\nnews articles along the political spectrum.\nNLP studies on framing have predominantly fo-\ncused emphasis framing , the strategic inclusion or\nomission of aspects of an issue, such as legality\nor public opinion (Card et al., 2015) or, to a lesser\nextent, on equivalence framing as different expres-\nsions of identical concepts (\u201calien\u201d vs \u201cimmigrant\u201d,\nLee et al. (2022); Ziems et al. (2022a)). Both per-\nspectives focus on local, lexical signals. Emphasis\nframing is typically formalized as a single-label\nprediction of the most dominant frame in a news ar-\nticle (Card et al., 2015), headline (Liu et al., 2019;\nAky\u00fcrek et al., 2020), or a social media post (John-\nson et al., 2017; Hartmann et al., 2019). The media\nframes corpus (Card et al., 2015) is one of the\nmost comprehensive frame-labeled data sets com-\nprising several thousand news articles across five\ncontested issues. While the data includes span-\nlevel labels which could be used for multi-label\nclassification, work using the MFC predominantly\nattempts document-level prediction of a single \u201cpri-\nmary\u201d article frame, disregarding span labels (Ji\nand Smith, 2017; Khanehzar et al., 2021).2More\nbroadly, our work complements emphasis frames\nby considering more abstract frames around con-\nflict, resolution, and personal, moral and economic\nimpacts. Both formalizations of framing have a\nstrong foundation in the communication literature,\nand studying their interaction at scale with NLP\nmethodology is an interesting avenue for future\nwork.\nMendelsohn et al. (2021) consider a variety of\nframing strategies in the context of tweets, but with\nless of a focus on story structure due to the short\ndocument lengths. Our framework complements\ntheir work in three ways: i) we approach framing as\nmulti-label classification, relaxing the assumption\nof a single frame per article; ii) we present a set of\nframes that are abstract with evidence distributed\nacross a document, requiring higher-level docu-\nment model; and iii) we link frames with narratives\nvia entity roles in a unified annotation framework\nconsisting of a series of binary indicator questions,\nallowing us to study the interplay of framing and\nnarratives.\n3 The Narrative Frames Corpus\nWe identified 17.9K English-language news arti-\ncles on climate change published in 2017\u20132019\nin the UK and in the US by matching a set of cli-\nmate change-specific keywords in articles from the\nNELA corpora (Horne et al., 2018; N\u00f8rregaard\net al., 2019; Gruppi et al., 2020). See Appendix A\nfor more details. For each article, NELA provides\n2Although see Field et al. (2018) for an exception.metadata about its publication date, media outlet,\nand its associated political leaning as identified by\nthe Media Bias Fact Check (MBFC) website.3We\nmanually annotated a subset of 428 articles of this\ndata set, balanced across the three years and the\nfour most dominant MBFC categories: left, center-\nleft, right and questionable source.4\nWe recruited four on-site annotators, all En-\nglish native speakers with a background in the\nsocial/political sciences. The annotators went\nthrough an extensive training phase including sev-\neral rounds of feedback. Details of annotator remu-\nneration can be found in the Ethics statement.\nFrame annotations We adapted Semetko and\nValkenburg (2000)\u2019s frame indicator questions. We\nadded a pre-screening question to confirm that\nan article is predominantly ( >70%) about climate\nchange, removed one question about visual infor-\nmation (as we focus on text only), and changed\nwording specific to the \u2018government\u2019 to \u2018any entity\u2019\nto align with our broad definition of stakeholder\nentities, discussed below. The full questionnaire is\nshown in Appendix B. Annotators were presented\nwith the full article text together with the ques-\ntionnaire, but no explicit meta information such as\noutlet name or date of publication.\nThe raw annotations provided answers to a list\nof binary indicator questions. We verified that the\nmapping (i.e., the factor structure) between the five\nframes in Table 1 and their associated indicator\nquestions in Semetko and Valkenburg (2000) repli-\ncates in our annotated data set. To do so we ran\na confirmatory factor analysis (CFA; Brown and\nMoore (2012)).5We removed all items with a fac-\ntor loading <0.3(as not fitting well into any of the\nfive factors), retaining a total of 13 indicators, with\n2-3 indicators loading on a given frame. These\nquestions are listed in Table 2. The final model\nfitted the data well (CFI=.945; RMSEA=.052[.039,\n.065], p=.370; SRMR=.059), confirming the five-\nfactor structure. An article was then labeled with a\nframe if \u22652indicator questions for that frame were\nanswered \u2018yes\u2019 by \u22652annotators.6This resulted\n3https://mediabiasfactcheck.com/\n4The \u2018center-right\u2019 category was very rare in the set of\nsampled articles, and hence merged with \u2018right\u2019.\n5The input data for the CFA is based on majority voting,\ni.e., at least two out of three annotators agreeing on a given\nresponse. Prior to the main analysis, we converted raw di-\nchotomous (0-1) scores into a polychoric correlation matrix\nwhich served as an input into CFA.\n6Except for Moral , where only 1 question had be an-\nswered \u2018yes\u2019 by a majority of annotators due to the rarity of\nRE(1) Does the story suggest a solution(s) to the issue/problem?; (2) Does the story suggest that some entity could\nalleviate the problem?CO(1) Does the story reflect disagreement between political parties/individuals/groups/countries?; (2) Does one\nparty/individual/group/country reproach another?; (3) Does the story refer to two sides or more than two sides of the\nproblem or issue?HI(1) Does the story provide a human example or a \"human face\" on the problem/issue?; (2) Does the story employ\nadjectives or personal vignettes that generate feelings of outrage, empathy-caring, sympathy, or compassion?; (3)\nDoes the story go into the private or personal lives of the entities involved?MO(1) Does the story contain any moral message?; (2) Does the story make reference to morality, God, and other\nreligious tenets?EC(1) Is there a mention of financial losses or gains now or in the future?; (2) Is there a mention of the costs/degree of\nthe expense involved?; (3) Is there a reference to the economic consequences of pursuing (or not) a course of action?\nTable 2: Binary indicators for the five frames: Resolution (RE), Conflict (CO), Human Interest (HI),\nMoral (MO), Economic (EC).\nin a multi-label data set with articles covering zero\n(12%), one (39%), two (32%) three (15%) or four\n(3%) frames. See Appendix F for additional data\nset statistics.\nEntity annotations Entities were annotated as\npart of the binary indicator questionnaire intro-\nduced above. Three indicator questions assessed\nwhether an article contained an entity that could\nalleviate the problem (Hero );was responsible for\nthe problem (Villain ) orwas negatively affected\nby the issue (Victim ). If an annotator answered\n\u2018yes\u2019 to any of these questions, they were asked to\nidentify the most appropriate entity in the text. An\nentity was meant to be selected only if the article\nwas explicit about that entity\u2019s role (e.g., a politi-\ncian was depicted as \"the only person who could\nsave the planet\") and strictly based on the entity\u2019s\npresentation in the article, rather than the annota-\ntor\u2019s opinion about that entity.7We included all\nentities extracted by our annotators as part of our\npublished data set.\nAnnotator agreement Krippendorff\u2019s \u03b1across\nfour annotators and 13 frame indicator questions\nis 0.52, indicating fair agreement as expected for\na complex task like frame annotation. Average\npairwise agreement without chance-correction is\n0.78 (min=0.75, max=0.81).\nA total of 2,185 entities were extracted across\nall narrative roles. Average pairwise agreement on\nexistence of a role in an article was 0.59 (Krippen-\ndorff\u2019s \u03b1= 0.40). To assess agreement on the iden-\nthe label.\n7E.g., if an article presented Trump as a person who could\nmitigate climate change, the annotator was supposed to tag\nhim as a Hero , even if they didn\u2019t personally agree with that\ninterpretation.tityof entities for roles which were attested by at\nleast two annotators, we computed the exact string\nmatch of associated entities, after basic text nor-\nmalization. Entities match exactly 41% of the time.\nWe also computed more lenient metrics based on\ntoken overlap (average Rouge-L=0.45) and embed-\nding similarity (average. BertScore=0.91) between\npairs of extracted entities.\nThe agreement for both role detection and entity-\nrole assignment was low overall, suggesting that\nthe task is challenging. In this paper, we use the\nnarrative role labels in the exploratory analysis in\nSection 4 and discuss future work on computational\nmodeling of narrative roles in Section 6.\n3.1 Stakeholder categories\nWe grouped the >2Kextracted entities into\na smaller set of stakeholder categories to ease\nanalysis. We identified 10 such categories from the\nprevious literature (Ahchong and Dodds, 2012;\nBlair and McCormack, 2016; Chen et al., 2023;\nHaigh and Griffiths, 2009), adopting a broad\ndefinition of stakeholders which includes groups\nor entities that \u2018affect or are affected by\u2019 the issue\nof climate change (Freeman, 1984). The set of\nstakeholder categories is shown in Figure 1b,\nand Appendix E provides additional details. One\nannotator assigned each unique extracted entity\nto its most appropriate stakeholder category (or a\ngeneric category \u2018Other\u2019 if no other category fit).\nIn sum, the narrative frames corpus consists\nof 428 English news articles labeled with\n(1) multi-label frame categories; (2) narrative\nroles for specific entities; and (3) their associated\nstakeholder category; as well as meta-data about\nthe article\u2019s date of origin, outlet, and associated\npolitical leaning.\n4 Narrative Framing of Climate Change\nWe conduct an exploratory analysis on the framing\nof climate change in media outlets with different\npolitical leaning, as well as the interplay of frames,\nnarrative roles and stakeholder categories.\nFraming and political leaning Figure 2 shows\nthe proportion of articles mentioning each frame by\nthe media outlets\u2019 political leaning.8Conflict\n(CO) and Resolution (RE) are most prevalent\nacross all leanings. The Moral frame (MO) is\nleast prevalent throughout. This pattern is par-\ntially consistent with previous research. Dirikx\nand Gelders (2010) found Resolution , but not\nConflict , to dominate in climate change report-\ning in the Netherlands and France in early 2000s,\nwhich might suggest that the discourse on climate\nchange has become more polarized over time, in\nparticular in our data set of US and UK news cover-\nage where the media landscape is strongly partisan.\nFor example, in a more recent study involving four\nmajor US newspapers, Kim and Wanta (2018) show\nthatConflict is the most common frame in the\ncontext of US immigration.\nResolution (RE) is more prevalent in the left-\nleaning outlets (left, left_center), while the opposite\nis true for Human Interest (HI): right-leaning\n(and questionable) outlets are more likely to refer\nto personal stories and use language evoking em-\npathy. These findings are partially consistent with\nprior work, e.g, Feldman et al. (2017) show that\nbothEconomic andConflict are more likely\nto be used in conservative outlets, while we find\nConflict prevalent across the board. However,\nFeldman et al. (2017) only included three major\nUS news papers, in contrast to 41 in our analysis.\nFrames, roles and stakeholders Figure 1 illus-\ntrates the association of narrative roles with differ-\nent frames (1a) and stakeholders (1b). Unsurpris-\ningly, the Hero , an entity presented with the ability\nto fix or alleviate the issue under discussion, is the\nmost prevalent role in the Resolution frame.\nTheVillain dominates most other frames, ex-\ncept for the Human Interest frame where\nVictim is equally dominant. This aligns with\na well-known \u201cnegativity bias\u201d in news reporting,\ni.e., a dominance of negative content with a focus\n8Noting that the numbers do not sum to one due to the\nmulti-label nature of our annnotations.on problems, conflicts and their causes and vic-\ntims (Soroka et al., 2019).\nWe explore the distribution of roles across stake-\nholder categories in Figure 1b. Overall, Gov-\nernments & Politicians are the most dominant\nstakeholder category, typically depicted as the\nVillain (of all stakeholder categories they are\nalso most likely to be depicted as the Hero point-\ning to ambivalent attitudes toward this category).\nThe Environment and the General Public domi-\nnate the Victim role, somewhat unexpectedly fol-\nlowed by Governments & Politicians and Industry\n& Emissions. We explain this phenomenon next by\ndisentangling the labels by political leaning.\nFigure 3 reveals how the framing of a particular\nstakeholder category can vary with political leaning\nof the source. Right-leaning media are more likely\nto depict Environmental Activists & Organisations,\nand Legislation as the Villain and Industry and\nEmissions as either the Hero or the Victim in\nthe context of climate change news. Conversely,\nleft-leaning media are more likely to frame Legis-\nlation as a Hero , cover Environmental Activists\nless frequently overall, and predominantly frame\nthe Industry as a Villain .\n5 Narrative Frame Prediction\nPredicting narrative frames automatically and with\nhigh quality would open new possibilities for scal-\ning media framing analyses to larger data sets,\nlonger time spans or more languages. Given the\npolitical sensitivity of automated media analysis,\nmodels should not only be reliable but also trans-\nparent in their predictions. To this end, we present\nRetrieval-Based Frame prediction (RBF), which\nincorporates an embedding-based retrieval mod-\nule into supervised classifiers. We compare RBF\nagainst a range of neural classifiers on multi-label\nframe prediction. RBF not only outperforms off-\nthe-shelf fine-tuned transformers on this task, but\nalso increases interpretability by predicting frames\nfor a given article together with the most relevant ar-\nticle sentences for the frame as evidence. Section 6\ndiscusses additional modelling tasks supported by\nour data set to be addressed in future work.\n5.1 RBF: Retrieval-Based Frame Prediction\nWe propose a simple method, retrieval-based frame\nprediction (RBF), which combines pre-trained lan-\nguage model embeddings with a retrieval objec-\ntive. Similar approaches have been previously pro-\nRE CO HI MO EC0100200300400500CountHERO VILLAIN VICTIM(a) Co-occurrence (count) of roles with frames.\nENVIRONMENTCLIMATECHANGEENV.ACTIVISTSGENERAL-\nPUBLIC GOVERNMENTSPOLITICIANSGREEN-\nTECHNOLOGYINDUSTRY\nEMISSIONSLEGISLATIONPOLICIESMEDIASCIENCE\nEXPERTS050100150200250300350400CountHero Villain Victim\n(b) Co-occurrence (count) of roles with stakeholder groups.\nFigure 1: Association of roles with different frames (top) and stakeholder groups (bottom).\nRE CO HI MO EC0.00.20.40.6% frame per leaningLeft\nCenter-leftRight\nQuestionable src\nFigure 2: Distribution of frames across political leanings\nof news outlets (as attested by MBFC).\nposed in the context of word-sense disambigutaion\nand semantic frame predictions (Jiang and Riloff,\n2021; Blevins and Zettlemoyer, 2020). We embed\n(i) short frame descriptions f1. . . f C9and (ii) sen-\ntences from an input news article s1. . . s Nin a\njoint space, and retrieve sentences most proximate\nto the frame embedding:\nhs\ni=emb (si)\nhf\nj=emb (fi)\nrel(si, fj) =cos(hs\ni, hf\nj),(1)\nwhere hs\niandhf\njare the embeddings of sentence\nsiand frame fj, respectively, the relevance relof\nsitofjcorresponds to their cosine similarity. We\n9RE: Solution or alleviation of the problem, CO: Human\ninterest, emotion or dramatization of events, HI: Conflict or\ndisagreement between two or more sides, MO: Morality or\nreligion, EC: Economic consequencesuse SentenceBert (Reimers and Gurevych, 2019)\nas our embedding method emb. Given an article,\nwe obtain Jframe-specific relevance-rankings of\nall sentences in the input article.\nWe then train a linear classifier to predict the\npresence or absence of a frame in an article based\non the most relevant sentences by our measure\nabove. We include five input channels: channels\n(1)\u2013(3) are the three sentences most relevant for a\nframe according to RBF relevance; channel (4) in-\ncludes all sentences exceeding relevance threshold\n\u03b8 > 0.15, except for sentences (1)\u2013(3), concate-\nnated with a [SEP] token;10and (5) contains the\nnews article truncated at 256 tokens. Each chan-\nnel is encoded with the Longformer (Beltagy et al.,\n2020), final hidden state embeddings are concate-\nnated and passed into the classifier. Longformer pa-\nrameters are fine-tuned during the training process.\nWe evaluate the importance of different channels\nby ablating the impact of the full article channel (5)\n(RBF -a) and additionally the threshold sentence\nchannel (4) (RBF -a,t).\nRBF combines two desiderata: First, it identi-\nfies multiple sentences relevant to a target frame,\ncapturing key evidence that may be distributed\nacross the article rather than locally. Second, RBF\u2019s\nframe-based sentence retrieval backbone can be\n10The threshold \u03b8was tuned on the dev set in preliminary\nexperiments.\nHERO VILLAIN VICTIM051015202530Count(a) Environmental activists & orgs.\nHERO VILLAIN VICTIM01020304050 (b) Industry & Emissions\nHERO VILLAIN VICTIM0102030405060\nleft\nleft_centerright\nqst_source (c) Legislation & Policies\nFigure 3: Narrative roles assigned to stakeholder categories in news outlets with different political leaning.\nModel Macro-Pr Macro-Re F1\nRandom 0.33 ( \u00b10.025) 0.49 ( \u00b10.023) 0.39\nMajority 0.14 ( \u00b10.030) 0.24 ( \u00b10.080) 0.18\nKNN 0.40 ( \u00b10.049) 0.61 ( \u00b10.071) 0.49\nBERT 0.44 ( \u00b10.109) 0.63 ( \u00b10.059) 0.52\nLongformer 0.48 ( \u00b10.054) 0.63 ( \u00b10.052) 0.53\nSnippext 0.56 (\u00b10.074) 0.65 ( \u00b10.074) 0.60\nRBF 0.51 ( \u00b10.044) 0.76 (\u00b10.131) 0.61\nRBF -a 0.50 ( \u00b10.047) 0.70 ( \u00b10.077) 0.58\nRBF -a,t 0.48 ( \u00b10.041) 0.63 ( \u00b10.085) 0.55\nTable 3: Frame prediction results of baselines (top) rep-\nresentative supervised and semi-supervised methods,\nand RBF (middle), as well as an ablation of RBF chan-\nnels (bottom). We report macro-averaged precision and\nrecall across the five labels with standard deviation (in\nbrackets), and their harmonic mean (F1).\ninterpreted as an \u2018explicit attention mechanism\u2019,\ncustomized to the frame label to be predicted, with\nsentences serving as evidence. We evaluate the re-\ntrieved sentences in terms of their interpretability\nin Section 5.3.1.\n5.2 Experimental Setup\nGiven the small size of the Narrative Frames Cor-\npus, we adopt the simplest formalization of multi-\nlabel classification: for each model class (row in\nTable 3) we train five individual binary classifiers,\none per frame label.11\nData set We split the Narrative Frames Corpus\nset into five random folds of 60/20/20 train/dev/test\ndata. As the proportion of articles mentioning each\nframe varies widely (see Appendix F), within each\nfold, we balanced the number of articles that do/do\nnot contain each frame. E.g., for a frame that was\nfeatured in the majority of articles, we randomly\n11This outperformed multi-label classifiers which shared a\nsubset of parameters in preliminary experiments, presumably\nbecause the small number of article prevented models from\nlearning useful interactions.up-sampled articles notfeaturing the frame to a\nratio of 1:1.\nComparison models We compare our method\nagainst 1. a Random baseline; 2. a Majority base-\nline which predicts the majority class per frame (1\nfor frames which occur in the majority of labelled\narticles, 0 for others); 3. a non-neural method\nwhich embeds articles based on TF-IDF represen-\ntations, and trains one KNN classifier per frame;\n4.BERT-medium (Devlin et al., 2019) fine-tuned\nfor binary frame prediction; 5. Longformer-base-\n4096 (Beltagy et al., 2020) fine-tuned for binary\nframe prediction; and 6. an adaptation of the\nSnippext model (Miao et al., 2020; Berthelot et al.,\n2019), a method for semi-supervised fine-tuning of\npre-trained language models which was originally\nproposed in computer vision, but recently adapted\nto semi-supervised opinion mining (Miao et al.,\n2020). Snippext fine-tunes BERT using an interpo-\nlation of a small amount of gold-labeled data, and\na much larger set of unlabeled data with predicted,\nsoft labels,12drawing on the MixMatch strategy re-\ncently proposed in computer vision (Berthelot et al.,\n2019). We augment our small labeled training data\nset with the \u224817.5K unlabelled climate-related ar-\nticles (cf., Section 3). The input to all transformer\nmodels is truncated to 256 tokens.13Detailed train-\ning settings and model parameters are provided in\nAppendix G.\nMetrics We evaluate models on correctly predict-\ning the presence of frames in articles. We report\nmacro-averaged precision and recall over the five\n12The original MixMatch additionally applies data augmen-\ntation to enhance consistency, which we disable due to the\ndifficulty of DA in language, and for model simplicity.\n13In preliminary experiments we tested truncation at {125,\n256, 512 and 1024}. We found that 256 worked best, presum-\nably reflecting the pyramid structure of news with important\ninformation presented upfront/in the lead paragraphs. Very\nfew articles were longer than 1024 tokens.\nframes, assigning equal importance to each frame\nlabel; as well as their harmonic mean (F1 score).\n5.3 Main results\nTable 3 shows the frame prediction results. All\nmodels significantly outperform the random and\nmajority baselines. All neural methods perform\nbetter than the non-neural KNN. BERT performs\nworse than the Longformer, presumably due to the\nLongformer\u2019s higher capacity with 1.5 \u00d7the pa-\nrameters of BERT. RBF is best overall, suggesting\nthat combining Longformer embeddings with a rel-\nevance based sentence retrieval backbone helps the\nmodels to focus on frame-relevant context.\nWe ablate the impact of the different channels in\nRBF in Table 3 (bottom). The model performance\ndrops with the removal of each input channels, sug-\ngesting that the input channels are complementary\nand each contributes to the performance. Snippext\nand RBF perform comparably, with inverse em-\nphasis on precision and recall, however, only RBF\noffers explicit evidence for prediction (which we\nexplore in the next section). A semi-supervised\nextension of RBF is a promising avenue for future\nwork.\nGiven the multi-label nature of our data set, a\nnatural question is how often models predict all\nand only the annotated frames for an article (exact\nmatch). RBF does so 18% of the time. Appendix H\nprovides more detailed results and analyses of per-\nframe and per-label performance.\n5.3.1 Qualitative analysis\nFor each frame, we inspect sentences retrieved as\nhighly relevant by RBF. Table 4 displays these sen-\ntences. We boldfaced the most relevant phrases\nfor ease of exposition. The selected sentences\nalign closely with the definition of each frame:\nforHuman Interest , they refer to the strug-\ngle of affected individuals and evoke empathy; for\nMoral they refer to god, religion and moral val-\nues; and for Resolution they mention explicit\nsolutions. One intriguing direction for future work\nwill be to study the differences in manifestation of\ndifferent frames across outlets from different sides\nalong the political spectrum.\n6 Discussion\nWhat are the recurring narratives that frame the\npublic discourse about contested issues like cli-\nmate change? Existing NLP approaches to frame\nprediction fall short of answering this question dueto a focus on localized signals. Drawing on theo-\nries from the social and communicative sciences,\nwe introduced a set of narrative framing devices\nto NLP, and integrated them with narrative roles\nassigned to the central entities in the news articles.\nWe applied our framework to the issue of climate\nchange, and annotated >400 English-language\nnews articles from major outlets with different polit-\nical leanings with multi-label frames and narrative\nroles of entities and their stakeholder categories.\nOur exploratory analysis demonstrated how our\nframework can be utilized to study multiple levels\nof framing, including differences across outlets;\nco-occurrence of frames and narrative roles; and\nassignment of narrative roles to stakeholder cate-\ngories.\nWith the ultimate goal of scaling such analyses\nto larger, unlabeled data sets, we introduced RBF,\nan effective and interpretable retrieval-based frame\nclassifier. The \u2018explicit attention\u2019 module of RBF\nnot only improved performance over its backbone,\nthe vanilla Longformer, but also naturally provides\nevidence for its predictions as a list of relevance-\nranked article sentences.\nOur work addresses a disconnect between the\ncomplexity of framing acknowledged in the com-\nmunication science literature, and models of fram-\ning in NLP. As recently surveyed by Ali and Hassan\n(2022), NLP approaches to framing predominantly\nfocus on topic models or frequency-based methods,\nleaning heavily on local lexical signals as indicators\nfor the presence or absence of a single frame per\nunit of analysis. However, the framing of a news\narticle typically emerges from indicators spread\nthroughout the text; frames can co-exist and inter-\nact with each other within a single news story. This\npaper takes one step towards such an integrated\nnotion of framing in NLP in considering narrative\nframes and roles at the article level and adopting\nmulti-label task formalization.\nOur work and results suggest many avenues for\nfuture research. The Narrative Frames Corpus sup-\nports research on joint models of framing and entity\nroles: the presence of an entity with a specific role\n(e.g., the Hero ) should render the presence of cer-\ntain frames (e.g., Resolution ) more likely. Con-\nversely, frames like Conflict impact the proba-\nbility of the existence of the number and kind of\ndifferent roles (e.g., the Hero and the Villain ).\nA joint model of frames and narrative roles could\nincorporate role labels with soft confidence weights\nRE (1) However the study finds that no single solution will avert the dangers, so a combined approach is needed . (2)\nThe key element is that these three solutions must be implemented together. \" (3) We also looked at increasing the\nefficiency of water use , and we looked at better monitoring and recycling of fertiliser - lots of it is lost and it runs\noff into rivers and causes dead zones in the oceans.\"\nCO (1)Their answers \u2013 and reactions to them \u2013 foreshadowed the fight ahead with conservatives and industry\nregardless of who becomes the next president. (2) Democrats vying for president revealed a fundamental split\nover how aggressively the US should tackle climate change [. . . ] in a seven-hour town hall meeting on Wednesday.\n(3) [. . . ] held after the Democratic National Committee refused to sanction an official climate debate between\ncandidates and amid unprecedented pressure from young activists and the Democratic voting base to tackle the\nclimate crisis.\nHI (1)To Janet , this is a moral issue. (2) These were matters that we have historically agreed on, if for no other reason\nthan the sake of our children and grandchildren\u2019s future. (3) And in Jordan\u2019s case , that would be Social Security,\nMedicare, education, health care and the like: Programs that benefit folks in his district.\nMO (1) It is, after all, the measure of one\u2019s moral fitness to value some things (say, forgiveness) over others (vengeance).\n(2)When organized religion fades and its would-be adherents are left to search for meaning, does the god of the\nenvironment end their search for a moral authority ? (3) That statement not only describes Judas\u2019s moral disorder\nbut also reminds the audience that any concern, holy as it may be \u2014 poverty reduction, environmental protection, or\nany other | earthly mission \u2014 that does not give a preferential deference to God, His creation, and acts of beauty\nsuch as that of Mary Magdalene are sure signs of misaligned priorities.\nEC (1) Both can impact the relative financial attractiveness of future energy options. (2) \"Even Milton Friedman\nunderstood the existence of market externalities, the fact that damage to our environment is not accounted for in the\nfree market without placing some sort of price signal .\" (3) They end up helping certain wealthy people to the\ndisadvantage of the less fortunate. \"\nTable 4: Three top relevant sentences (right) extracted by RBF for articles which were correctly predicted as\ncontaining the frame (left), in order of decreasing relevance. Highlights of relevant phrases manually added in bold.\nas latent signal into a frame classification model.\nAnnotator (dis)agreement and aggregation of an-\nswers to indicator questions into frame tags provide\nfertile grounds for future work. We echo a line of\nrecent work on acknowledging label variation as\na signal of genuine complexity rather than noise.\nThis holds true particularly for complex tasks like\nframe annotation which inevitably retain a level\nof subjective variation (Pavlick and Kwiatkowski,\n2019; Plank, 2022). In this paper we aggregated\nindicator labels into a hard frame label by voting,\nhowever we release the raw annotations as part of\nour data set. Future work could explore soft aggre-\ngation methods, delineate genuine variation from\nnoise, and adopt disagreement-aware models and\nevaluation metrics.\nThe comparatively small size of the Narra-\ntive Frames Corpus and the competitive semi-\nsupervised Snippext suggest further exploration of\nsemi-supervised approaches. Integrating RBF with\na Snippext-inspired semi-supervised framework,\nmost simply by soft labeling articles as a func-\ntion of their retrieved sentences and RBF relevance\nscores, would allow to leverage large unlabeled\ndata sets while retaining RBF\u2019s interpretability. Al-\nternatively, one could adapt models from different\ndomains, for instance by drawing on the literature\nof modeling narrative roles in folk tales (Valls-Vargas et al., 2014; Jahan et al., 2021).\n7 Limitations\nWe acknowledge a range of limitations of our work.\nAs discussed in Sections 3 and 6, overall annota-\ntor agreement ranged from fair (frame annotations)\nto low (entity role annotations). We do not view\nthis as a limitation per se, again pointing to the re-\ncent literature on the value of human label variance\npointing at a potential loss of valuable information\nif we overly focus on arriving at a single gold label\nper instance, with high confidence (Plank, 2022;\nPavlick and Kwiatkowski, 2019). Future model-\ning work involving entity labels should, however,\ncarefully inspect the role label variation, and po-\ntentially remove or aggregate selected annotations,\nbefore incorporating the labels as signal into predic-\ntive models. We explicitly refrained from training\nmodel in this paper to avoid the risk of training a\npredictor on an unfavorable noise-to-signal ratio.\nOur data set focuses on English-language news\nreports, sampled from 2017 to 2019 in mainstream\nmedia outlets in the US and UK, and as such fo-\ncuses on cultures and communities which are al-\nready well-resourced and well studied. With cli-\nmate change being a global challenge, broaden-\ning data sets, annotations and models to more lan-\nguages is an important direction for future work.\nWe explicitly caution against projecting annota-\ntions across languages without careful validation\nas we expect the manifestation of framing, views\non entities (or sheer set of dominant entities) to\nvary widely across countries and communities.\nEven within our English study, we acknowledge\nthat the size of annotated data is small for NLP\nscales, and an extension in the future is desirable.\nA related current limitation is the focus on just a\nsingle issue (climate change) and validation of our\nnarrative framing framework for other issues is an\nimportant direction for the future. Finally, the an-\nnotation process was slow and costly, relying on\ntrained, highly educated annotators with constant\nmonitoring, rendering larger scale annotations chal-\nlenging, on the one hand. On the other hand, we\nwill release upon acceptance our annotation proce-\ndure including the full codebook with instructions,\nwhich have been optimized over several rounds of\nannotations and we hope can support more efficient\nannotation in the future.\nEthics statement\nThis study was approved by the University of Mel-\nbourne ethics board (Human Ethics Committee\nLNR 3B), Reference Number 2023-22109-37029-\n4, and data acquisition and analysis has been taken\nout to the according ethical standards. We hired\nfour local annotators who were paid an hourly rate\nof $53 AU in line with the casual research assistant\nhourly rates set up in the University of Melbourne\ncollective agreement.\nWe will release the Narrative Framing Corpus\ncomprising of 428 news articles annotated with\nframe labels, entities, their narrative roles and stake-\nholder categories. We also publish the raw (non-\naggregated) annotations. Our data set builds on\nnews articles from the NELA corpora 2017-2019,\nwhich were released to the public domain (license\nCC0 1.0).14We release our code and Narrative\nFrames Corpus under a MIT license.\nAcknowledgements\nWe gratefully acknowledge the work of our an-\nnotators Candy Chu, Aarushi Kaul, Dana Pjanic,\nand Lloyd Rouse and the helpful feedback of the\nanonymous reviewers.\n142017: https://doi.org/10.7910/DVN/\nZCXSKG ; 2018: https://doi.org/10.7910/DVN/\nULHLCB ; 2019: https://doi.org/10.7910/DVN/\nO7FWPOReferences\nKatrina Ahchong and Rachel Dodds. 2012. Anthro-\npogenic climate change coverage in two canadian\nnewspapers, the toronto star and the globe and mail,\nfrom 1988 to 2007. Environmental Science & Policy ,\n15(1):48\u201359.\nAfra Feyza Aky\u00fcrek, Lei Guo, Randa Elanwar, Prakash\nIshwar, Margrit Betke, and Derry Tanti Wijaya. 2020.\nMulti-label and multilingual news framing analysis.\nInProceedings of the 58th Annual Meeting of the As-\nsociation for Computational Linguistics , pages 8614\u2013\n8624, Online. Association for Computational Lin-\nguistics.\nMohammad Ali and Naeemul Hassan. 2022. A survey\nof computational framing analysis approaches. In\nProceedings of the 2022 Conference on Empirical\nMethods in Natural Language Processing , Abu Dhabi\nUAE. Association for Computational Linguistics.\nIz Beltagy, Matthew E Peters, and Arman Cohan. 2020.\nLongformer: The long-document transformer. arXiv\npreprint arXiv:2004.05150 .\nDavid Berthelot, Nicholas Carlini, Ian Goodfellow,\nNicolas Papernot, Avital Oliver, and Colin A Raf-\nfel. 2019. Mixmatch: A holistic approach to semi-\nsupervised learning. Advances in neural information\nprocessing systems , 32.\nShraey Bhatia, Jey Han Lau, and Timothy Baldwin.\n2021. Automatic classification of neutralization tech-\nniques in the narrative of climate change scepticism.\nInProceedings of the 2021 Conference of the North\nAmerican Chapter of the Association for Computa-\ntional Linguistics: Human Language Technologies ,\npages 2167\u20132175, Online. Association for Computa-\ntional Linguistics.\nLindsey M Bier, Sejin Park, and Michael J Palenchar.\n2018. Framing the flight mh370 mystery: A content\nanalysis of malaysian, chinese, and us media. Inter-\nnational Communication Gazette , 80(2):158\u2013184.\nBenjamin D Blair and Larkin McCormack. 2016. Ap-\nplying the narrative policy framework to the is-\nsues surrounding hydraulic fracturing within the\nnews media: A research note. Research & Politics ,\n3(1):2053168016628334.\nTerra Blevins and Luke Zettlemoyer. 2020. Moving\ndown the long tail of word sense disambiguation\nwith gloss informed bi-encoders. In Proceedings\nof the 58th Annual Meeting of the Association for\nComputational Linguistics , pages 1006\u20131017, Online.\nAssociation for Computational Linguistics.\nTimothy A Brown and Michael T Moore. 2012. Con-\nfirmatory factor analysis. Handbook of structural\nequation modeling , 361:379.\nDallas Card, Amber E. Boydstun, Justin H. Gross, Philip\nResnik, and Noah A. Smith. 2015. The media frames\ncorpus: Annotations of frames across issues. In Pro-\nceedings of the 53rd Annual Meeting of the Asso-\nciation for Computational Linguistics and the 7th\nInternational Joint Conference on Natural Language\nProcessing (Volume 2: Short Papers) , pages 438\u2013\n444, Beijing, China. Association for Computational\nLinguistics.\nKaiping Chen, Amanda L Molder, Zening Duan, Shel-\nley Boulianne, Christopher Eckart, Prince Mallari,\nand Diyi Yang. 2023. How climate movement ac-\ntors and news media frame climate change and strike:\nevidence from analyzing twitter and news media dis-\ncourse from 2018 to 2021. The International Journal\nof Press/Politics , 28(2):384\u2013413.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. Bert: Pre-training of deep\nbidirectional transformers for language understand-\ning. In Proceedings of the 2019 Conference of the\nNorth American Chapter of the Association for Com-\nputational Linguistics: Human Language Technolo-\ngies, Volume 1 (Long and Short Papers) , pages 4171\u2013\n4186.\nAstrid Dirikx and Dave Gelders. 2010. To frame is to\nexplain: A deductive frame-analysis of dutch and\nfrench climate change coverage during the annual un\nconferences of the parties. Public understanding of\nscience , 19(6):732\u2013742.\nDevin M Dotson, Susan K Jacobson, Lynda Lee Kaid,\nand J Stuart Carlton. 2012. Media coverage of cli-\nmate change in chile: A content analysis of conserva-\ntive and liberal newspapers. Environmental Commu-\nnication: A Journal of Nature and Culture , 6(1):64\u2013\n81.\nLauren Feldman, P Sol Hart, and Tijana Milosevic. 2017.\nPolarizing news? Representations of threat and effi-\ncacy in leading US newspapers\u2019 coverage of climate\nchange. Public Understanding of Science , 26(4):481\u2013\n497.\nAnjalie Field, Doron Kliger, Shuly Wintner, Jennifer\nPan, Dan Jurafsky, and Yulia Tsvetkov. 2018. Fram-\ning and agenda-setting in Russian news: a computa-\ntional analysis of intricate political strategies. In Pro-\nceedings of the 2018 Conference on Empirical Meth-\nods in Natural Language Processing , pages 3570\u2013\n3580, Brussels, Belgium. Association for Computa-\ntional Linguistics.\nFederica Fornaciari. 2012. Framing the Egyptian Revo-\nlution: A content analysis of Al Jazeera English and\nthe BBC. Journal of Arab & Muslim Media Research ,\n4(2-3):223\u2013235.\nR Edward Freeman. 1984. Stakeholder management:\nframework and philosophy. Pitman, Mansfield, MA .\nMaur\u00edcio Gruppi, Benjamin D. Horne, and Sibel Adal\u0131.\n2020. Nela-gt-2019: A large multi-labelled news\ndataset for the study of misinformation in news arti-\ncles.Nardia Haigh and Andrew Griffiths. 2009. The natural\nenvironment as a primary stakeholder: the case of cli-\nmate change. Business Strategy and the Environment ,\n18(6):347\u2013359.\nMareike Hartmann, Tallulah Jansen, Isabelle Augen-\nstein, and Anders S\u00f8gaard. 2019. Issue framing in\nonline discussion fora. In Proceedings of the 2019\nConference of the North American Chapter of the\nAssociation for Computational Linguistics: Human\nLanguage Technologies, Volume 1 (Long and Short\nPapers) , pages 1401\u20131407, Minneapolis, Minnesota.\nAssociation for Computational Linguistics.\nBenjamin D Horne, Sara Khedr, and Sibel Adali. 2018.\nSampling the news producers: A large news and\nfeature data set for the study of the complex media\nlandscape. In Twelfth International AAAI Conference\non Web and Social Media .\nLabiba Jahan, Rahul Mittal, and Mark Finlayson. 2021.\nInducing stereotypical character roles from plot struc-\nture. In Proceedings of the 2021 Conference on Em-\npirical Methods in Natural Language Processing ,\npages 492\u2013497.\nYangfeng Ji and Noah A. Smith. 2017. Neural dis-\ncourse structure for text categorization. In Proceed-\nings of the 55th Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long Papers) ,\npages 996\u20131005, Vancouver, Canada. Association for\nComputational Linguistics.\nTianyu Jiang and Ellen Riloff. 2021. Exploiting defini-\ntions for frame identification. In Proceedings of the\n16th Conference of the European Chapter of the Asso-\nciation for Computational Linguistics: Main Volume ,\npages 2429\u20132434, Online. Association for Computa-\ntional Linguistics.\nKristen Johnson, Di Jin, and Dan Goldwasser. 2017.\nModeling of political discourse framing on Twitter.\nInEleventh International AAAI Conference on Web\nand Social Media .\nShima Khanehzar, Trevor Cohn, Gosia Mikolajczak, An-\ndrew Turpin, and Lea Frermann. 2021. Framing un-\npacked: A semi-supervised interpretable multi-view\nmodel of media frames. In Proceedings of the 2021\nConference of the North American Chapter of the\nAssociation for Computational Linguistics: Human\nLanguage Technologies , pages 2154\u20132166.\nJeesun Kim and Wayne Wanta. 2018. News framing of\nthe us immigration debate during election years: Fo-\ncus on generic frames. The Communication Review ,\n21(2):89\u2013115.\nAndrea Lawlor and Erin Tolley. 2017. Deciding who\u2019s\nlegitimate: News media framing of immigrants and\nrefugees. International Journal of Communication ,\n11:25.\nNayeon Lee, Yejin Bang, Tiezheng Yu, Andrea Madotto,\nand Pascale Fung. 2022. NeuS: Neutral multi-news\nsummarization for mitigating framing bias. In Pro-\nceedings of the 2022 Conference of the North Amer-\nican Chapter of the Association for Computational\nLinguistics: Human Language Technologies , pages\n3131\u20133148, Seattle, United States. Association for\nComputational Linguistics.\nCyril Levitt. 1981. \"The Whole World Is Watching:\nMass Media in the Making and Unmaking of the\nNew Left. JSTOR.\nSiyi Liu, Lei Guo, Kate Mays, Margrit Betke, and\nDerry Tanti Wijaya. 2019. Detecting frames in news\nheadlines and its application to analyzing news fram-\ning trends surrounding U.S. gun violence. In Pro-\nceedings of the 23rd Conference on Computational\nNatural Language Learning (CoNLL) , pages 504\u2013\n514, Hong Kong, China. Association for Computa-\ntional Linguistics.\nJulia L\u00fcck, Hartmut Wessler, Antal Wozniak, and Di\u00f3-\ngenes Lycari\u00e3o. 2018. Counterbalancing global me-\ndia frames with nationally colored narratives: A com-\nparative study of news narratives and news framing in\nthe climate change coverage of five countries. Jour-\nnalism , 19(12):1635\u20131656.\nYiwei Luo, Dallas Card, and Dan Jurafsky. 2020. De-\ntecting stance in media on global warming. In Find-\nings of the Association for Computational Linguistics:\nEMNLP 2020 , pages 3296\u20133315.\nJulia Mendelsohn, Ceren Budak, and David Jurgens.\n2021. Modeling framing in immigration discourse on\nsocial media. In Proceedings of the 2021 Conference\nof the North American Chapter of the Association\nfor Computational Linguistics: Human Language\nTechnologies , pages 2219\u20132263, Online. Association\nfor Computational Linguistics.\nZhengjie Miao, Yuliang Li, Xiaolan Wang, and Wang-\nChiew Tan. 2020. Snippext: Semi-supervised opin-\nion mining with augmented data. In Proceedings of\nThe Web Conference 2020 , pages 617\u2013628.\nW Russell Neuman, Russell W Neuman, Marion R Just,\nand Ann N Crigler. 1992. Common knowledge: News\nand the construction of political meaning . University\nof Chicago Press.\nMatthew C Nisbet. 2009. Communicating climate\nchange: Why frames matter for public engagement.\nEnvironment: Science and policy for sustainable de-\nvelopment , 51(2):12\u201323.\nJeppe N\u00f8rregaard, Benjamin D Horne, and Sibel Adal\u0131.\n2019. Nela-gt-2018: A large multi-labelled news\ndataset for the study of misinformation in news arti-\ncles. In Proceedings of the international AAAI con-\nference on web and social media , volume 13, pages\n630\u2013638.\nZhongdang Pan and Gerald M Kosicki. 1993. Framing\nanalysis: An approach to news discourse. Political\ncommunication , 10(1):55\u201375.Ellie Pavlick and Tom Kwiatkowski. 2019. Inherent\nDisagreements in Human Textual Inferences. Trans-\nactions of the Association for Computational Linguis-\ntics, 7:677\u2013694.\nPew Research Center. 2022. Climate change remains\ntop global threat across 19-country survey. Technical\nreport, Washington, D.C.\nBarbara Plank. 2022. The\u2019problem\u2019of human label vari-\nation: On ground truth in data, modeling and eval-\nuation. In Proceedings of the 2022 Conference on\nEmpirical Methods in Natural Language Processing .\nNils Reimers and Iryna Gurevych. 2019. Sentence-bert:\nSentence embeddings using siamese bert-networks.\nInProceedings of the 2019 Conference on Empirical\nMethods in Natural Language Processing and the 9th\nInternational Joint Conference on Natural Language\nProcessing (EMNLP-IJCNLP) , pages 3982\u20133992.\nHolli A Semetko and Patti M Valkenburg. 2000. Fram-\ning european politics: A content analysis of press and\ntelevision news. Journal of communication , 50(2):93\u2013\n109.\nElizabeth A Shanahan, Michael D Jones, Mark K Mc-\nBeth, and Claudio M Radaelli. 2018. The narrative\npolicy framework. In Theories of the policy process ,\npages 173\u2013213. Routledge.\nStuart Soroka, Patrick Fournier, and Lilach Nir. 2019.\nCross-national evidence of a negativity bias in psy-\nchophysiological reactions to news. Proceedings of\nthe National Academy of Sciences , 116(38):18888\u2013\n18892.\nGregg Sparkman, Nathan Geiger, and Elke U Weber.\n2022. Americans experience a false social reality by\nunderestimating popular climate policy support by\nnearly half. Nature communications , 13(1):1\u20139.\nRoopal Vaid, Kartikey Pant, and Manish Shrivastava.\n2022. Towards fine-grained classification of climate\nchange related social media text. In Proceedings\nof the 60th Annual Meeting of the Association for\nComputational Linguistics: Student Research Work-\nshop , pages 434\u2013443, Dublin, Ireland. Association\nfor Computational Linguistics.\nJosep Valls-Vargas, Jichen Zhu, and Santiago Ontan\u00f3n.\n2014. Toward automatic role identification in unan-\nnotated folk tales. In Tenth Artificial Intelligence and\nInteractive Digital Entertainment Conference .\nRachel Wetts. 2020. In climate news, statements from\nlarge businesses and opponents of climate action re-\nceive heightened visibility. Proceedings of the Na-\ntional Academy of Sciences , 117(32):19054\u201319060.\nErika Allen Wolters, Michael D. Jones, and Kathryn\nDuvall. 2022. A narrative policy framework solution\nto understanding climate change framing research.\nIn Michael D. Jones, Mark K. McBeth, and Eliza-\nbeth A. Shanahan, editors, Narratives and the Policy\nProcess: Applications of the Narrative Policy Frame-\nwork , chapter 9, pages 218\u2013239. MT: Montana State\nUniversity Library.\nJing Yi Xie, Renato Ferreira Pinto Junior, Graeme Hirst,\nand Yang Xu. 2019. Text-based inference of moral\nsentiment change. In Proceedings of the 2019 Confer-\nence on Empirical Methods in Natural Language Pro-\ncessing and the 9th International Joint Conference\non Natural Language Processing (EMNLP-IJCNLP) ,\npages 4654\u20134663, Hong Kong, China. Association\nfor Computational Linguistics.\nCaleb Ziems, Minzhi Li, Anthony Zhang, and Diyi Yang.\n2022a. Inducing positive perspectives with text re-\nframing. In Proceedings of the 60th Annual Meet-\ning of the Association for Computational Linguistics\n(Volume 1: Long Papers) , pages 3682\u20133700, Dublin,\nIreland. Association for Computational Linguistics.\nCaleb Ziems, Jane Yu, Yi-Chia Wang, Alon Halevy, and\nDiyi Yang. 2022b. The moral integrity corpus: A\nbenchmark for ethical dialogue systems. In Proceed-\nings of the 60th Annual Meeting of the Association\nfor Computational Linguistics (Volume 1: Long Pa-\npers) , pages 3755\u20133773, Dublin, Ireland. Association\nfor Computational Linguistics.\nA Article selection\nWe identify climate-related news articles in the NELA corpora (2017\u20132019) by searching for keywords\nidentified in the Wikipedia climate change glossary15. A few generic terms were removed (\u2018weather\u2019) as\ntoo broad for our query. We consider an article as relevant either if >=1 keywords are found in the article\ntitle or >=3 mentions of climate keywords are found in the article body.\nB Codebook\nOur full codebook of 22 fine-grained questions presented to annotators. The questions used in the final\nfactor analysis model and subsequent analyses are boldfaced. We show the indicator distribution, i.e.,\nthe fraction of annotated articles in which two or more annotators answered \u2019yes\u2019 to a given question, in\nbrackets.\nID Question Annotation rules\nRE1\n(0.51)2. Does the story suggest a so-\nlution(s) to the issue/problem?Mark \u2018yes\u2019 if (a) solution(s), or a strategy to mitigate the\nproblem, is explicitly mentioned.\nRE2 3. Is this problem/issue resolved\nin the story?Mark \u2018yes\u2019 if the story explicitly mentions that the problem\nhas been resolved.\nRE3 4. Is there any hope in the story\nfor future resolution of the prob-\nlem/issue?Mark \u2018no\u2019 if the story is about a failed attempt to tackle the\nissue under discussion.\nRE4 5. Does the story suggest that\nthe issue/problem requires urgent\naction?Mark \u2018yes\u2019 if there is an explicit call for action, or ongoing\nefforts to alleviate the problem are (1) explicitly described\nand (2) raise a sense of urgency\nRE5\n(0.55)6. Does the story suggest that\nsome entity could alleviate the\nproblem? If your answer is\n\"yes\", please select the most ap-\npropriate entity.Mark \u2018yes\u2019 if at least one entity in the story is described\nas actively alleviating, or planning to alleviate, the prob-\nlem. If multiple options: select the one that\u2019s most cen-\ntral/prevalent in the article (in terms of #mentions / men-\ntions in the central parts like title and opening.)\nRE6 7. Does the story suggest that\nsome entity is responsible for the\nissue/problem? If your answer\nis \"yes\", please select the most\nresponsible entity.Mark \u2018yes\u2019 if at least one entity in the story is described as\nactively causing, or having caused, the problem. If multiple\noptions: select the one that\u2019s most central/prevalent in the\narticle (in terms of the number of mentions / mentions in\nthe central parts like title and lead paragraphs).\n15https://en.wikipedia.org/wiki/Glossary_of_climate_change\nHI1\n(0.27)8. Does the story provide a\nhuman example or a \"human\nface\" on the problem/issue?Select \u2018yes\u2019 if the story uses \u201cdramatization\u201d i.e., explic-\nitly refers to how the issue impacts the personal life living\nentities (including animals).\nHI2\n(0.21)9.Does the story employ ad-\njectives or personal vignettes\nthat generate feelings of out-\nrage, empathy-caring, sympa-\nthy, or compassion?Mark \u2018yes\u2019 if the story uses emotional language (original Q\nis already very concrete).\nHI3 10. Does the story emphasize\nhow one or more entities are\nNEGATIVELY affected by is-\nsue/problem? If your answer is\n\"yes\", please select the most neg-\natively affected entity.Select \u2018yes\u2019 if the story explicitly refers to how one or more\nentity/ies suffer from the problem/issue.\nHI4 11. Does the story emphasize\nhow one or more entities are\nPOSITIVELY affected by the is-\nsue/problem? If your answer is\n\"yes\", please select the most pos-\nitively affected entity.Select \u2018yes\u2019 if the story explicitly refers to how one or more\nentity/ies benefit from the problem/issue.\nHI5\n(0.07)12. Does the story go into the\nprivate or personal lives of the\nentities involved?Mark \u2018yes\u2019 if the story explicitly refers to the personal life\nof at least one entity.\nCO1\n(0.73)13. Does the story reflect\ndisagreement between politi-\ncal parties/ individuals /groups/\ncountries?Select \u2018yes\u2019 even if the story describes a disagreement or a\nconflict in a passive/observational manner.\nCO2\n(0.40)14. Does one party/ individ-\nual/ group/ country reproach\nanother?Select \u2018yes\u2019 if the story explicitly refers to the active conflict\nbetween two or more entities \u2013 past or present.\nCO3\n(0.54)15. Does the story refer to two\nsides or more than two sides of\nthe problem or issue?Select \u2018yes\u2019 if the story explicitly mentions at least two\nviewpoints on the current issue (even if they\u2019re not presented\nin a balanced, objective manner).\nCO4 16. Does the story refer to win-\nners and losers? If your answer\nis \"yes\", please select the most\nappropriate winner/loser entity.Select \u2018yes\u2019 if the story explicitly refers to one or more\n\u2018winners\u2019 and/or \u2018losers\u2019 which emerged from an active\nconflict/argument/war. Note, in some stories an entity can\nbe both a winner and a loser.\nMO1\n(0.07)17. Does the story contain any\nmoral message?Select \u2018yes\u2019 if the story explicitly applies standards or judg-\nments of right or wrong to entities, actions or events.\nMO2\n(0.05)18. Does the story make ref-\nerence to morality, God, and\nother religious tenets?Select \u2018yes\u2019 if the story explicitly refers to religious tenets\nor moral obligations framed through the lens of obligations\nto a spiritual community. Select \u2018yes\u2019 also if the mention is\nindirect e.g., through a quote or a metaphor.\nMO3 19. Does the story offer specific\nsocial prescriptions about how to\nbehave?Select \u2018yes\u2019 if the story explicitly mentions expectations\naround norms of conduct, limitations or prohibitions on\nactions or events.\nEC1\n(0.28)20. Is there a mention of finan-\ncial losses or gains now or in\nthe future?Select \u2018yes\u2019 if the story explicitly refers to the financial\nimpacts of the issue.\nEC2\n(0.37)21. Is there a mention of the\ncosts/degree of the expense in-\nvolved?Select \u2018yes\u2019 if the story explicitly refers to the amount of\nloss or gain (e.g., \u201c$100,000\u201d, \u201cenormous cost\u201d).\nEC3\n(0.25)22. Is there a reference to the\neconomic consequences of pur-\nsuing or not pursuing a course\nof action?Select \u2018yes\u2019 if the story explicitly mentions the impacts of\naction or inaction on the economy.\nC Annotation Interface\nFigure 4 shows our annotation interface split into an answer form (left) and an article display with\n(optional) highlighting of prevalent entities (right, in color).\nFigure 4: Our annotation interface. Left: Excerpt of the annotation form which covers the 22 binary indicator\nquestions, and free-text fields to record role-specific entities. Right: the news article with prevalent entities\nhighlighted (based on automatic entity recognition and co-reference resolution.)\nD Media Outlets\nTable 5 lists all media outlets in the labeled data set, together with number of articles and MBFC political\nleaning.\nE Entity groups\nTable 6 lists our set of entity groups, together with some representative examples and the total number\n(tokens) of instances assigned to each group.\nF Label statistics\nFigure 5 shows label distributions in our data set. In terms of prevalence of our five frames individually,\nConflict is present in 63%; Resolution in 45%; Economic in 30%; Human Interest in 11%\nleft_bias: thehuffingtonpost (47), vox (22), cnn (18), politicususa (16), motherjones (10), shareblue\n(5), dailykos (4), talkingpointsmemo (3), slate (2), palmerreport (1)\nleft_center_bias: bbc (22), theguardian (20), npr (14), usatoday (10), cbsnews (9), yahoonews (9),\nthenewyorktimes (8), pbs (4), fusion (4), cnbc (3), thehill (3)\nright_bias: thedailycaller (39), drudgereport (27), foxnews (13), theblaze (10), nationalreview (9),\nredstate (6), newsbusters (4), thepoliticalinsider (2), therightscoop (1)\nquestionable_source: breitbart (38), rt (18), dailymail (12), bipartisanreport (2), theduran (1)\nTable 5: Media outlets in our data, grouped by their political leaning (based on the Media Bias Fact Check portal;\nrows) and with associated article count (in brackets).\nEntity Group Count Example entities\nGOVERNMENTS_POLITICIANS_POLIT.ORGS 828 democrats, trump, the EPA\nINDUSTRY_EMISSIONS 271 fossil fuels, carbon pollution,\nplastic, capitalism\nLEGISLATION_POLICIES_RESPONSES 251 US climate response, Green New\nDeal, paris agreement\nGENERAL PUBLIC 241 americans, indigenous people,\npublic health\nANIMALS_NATURE_ENVIRONMENT 213 air quality, the ocean, the earth\nENV .ORGS_ACTIVISTS 105 Greta Thunberg, youth activists,\nextinction rebellion\nSCIENCE_EXPERTS_SCI.REPORTS 59 the stupid bloody academics, pro-\nfessors, University of Auckland\nstudy\nCLIMATE CHANGE 52 climate change, global warming\nOTHER 49 meat consuption, resilience, god\nAMBIGUOUS 37 deniers, response\nGREEN TECHNOLOGY_INNOV ATION 31 wind energy, geoengineering, re-\nnewables\nMEDIA_JOURNALISTS 26 journalists, media outlets, CNN\nTable 6: Stakeholder groups with token count and examples of assigned entities.\nandMoral in 10% of all annotated articles.\n0.000.050.100.150.20% articles with frame(s)\n{CO}\n{RE, CO}\n{}\n{RE}\n{RE, CO, EC}\n{CO, EC}\n{RE, EC}\n{EC}\n{HI, CO}\n{MO}\n{HI, CO, MO}\n{RE, HI, CO, MO}\n{RE, CO, MO}\n{CO, MO}\n{RE, HI}\n{RE, MO}\n{RE, HI, CO}\n{RE, HI, EC}\n{HI, CO, EC}\n{HI, MO}\n{RE, HI, CO, EC}\n{RE, MO, EC}\n{HI}\n{HI, EC}\n{MO, EC}\n{RE, HI, CO, MO, EC}\n{CO, MO, EC}\n{HI, CO, MO, EC}\n{RE, CO, MO, EC}\nFigure 5: Distribution of the most frequent frame labels.\nG Hyperparameters, model sizes and compute costs\nTable 7 lists the hyperparameters for all neural models, and their total number of parameters. For KNN,\nItem RBF BERT Longformer Snippext\nrandom_seed 1042 1042 1042 \u2013\nlearning_rate 2e-6 2e-6 2e-6 2e-6\nmax_len 256 256 256 256\nbatch_size 8 16 16 8\nepochs 20 20 20 20\ntotal # parameters 149 M 109 M 149 M 149M\nTable 7: Hyper parameters and model size for all neural models.\nK was tuned on the dev set for each fold. L2 distance was used as a distance function and for all other\nparameters default values were used from this implementation: https://scikit-learn.org/\nstable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html .\nAll neural models were trained on a single Nvidia A100 GPU. The total compute budget cover-\ning all experiments were 26 hours.\nH Additional Frame Prediction Results\nFrame-wise analysis Table 8 shows frame-wise prediction performance averaged over five runs, for\nthe three best performing models in Section 5.3. We observe that Human Interest (HI) is the most\nchallenging frame for all models, while access to the unlabelled data appears to be effective to boost\nperformance for Snippext on this challenging class. The most prevalent Conflict (CO) frame is\npredicted most reliably.\nLongformer RBF Snippext\nPrecision Recall F1 Precision Recall F1 Precision Recall F1\nRE 0.52 0.80 0.63 0.52 0.83 0.64 0.54 0.71 0.61\nHI 0.22 0.28 0.24 0.20 0.59 0.30 0.48 0.47 0.48\nCO 0.70 0.92 0.80 0.70 0.89 0.78 0.76 0.83 0.80\nMO 0.50 0.46 0.48 0.51 0.69 0.59 0.51 0.55 0.53\nEC 0.46 0.70 0.55 0.63 0.80 0.70 0.51 0.68 0.58\nTable 8: Frame-level prediction results of the three best performing models in Section 5.3, averaged over five folds.\nLabel-wise performance We analyze for RBF, which multi-labels are predicted best (worst). Overall,\nRBF achieves 18% exact match accuracy. Table 9 lists the best (left) and worst (right) performing\nmulti-labels, with an occurrence (N) of at least three in the gold labeled data set. We can see, in line with\nTable 8 that the model struggles with multi-labels involving the Human Interest orMoral frame.\nWe also find that performance does not correlate with the number of frames: both the top and bottom\nperforming sets include single-labels and high multi-labels.\nH.1 Error analysis\nOverprediction of Human Interest We first analyze the false positive prediction of Human\nInterest (HI). We list sentences extracted by RBF most confidently extracted as evidence for an\nincorrect positive HI label, some examples include context for clarity, in gray:\nBest Worst\nLabel N % correct Label N % correct\nRE;CO;EC 40 0.4 HI;CO 12 0.0\nRE;CO 53 0.34 MO 7 0.0\nRE;HI;CO;EC 3 0.33 RE;CO;MO 6 0.0\nRE 43 0.21 RE;HI;CO;MO 6 0.0\nTable 9: The five best-predicted multi-labels by RBF (left) and worst-predicted (right) with >1occurrences in the\nlabeled data. For each label we show its prevalence in the data set (N) and % predicted exact match.\n(i) \u201cIn its research, SPARK Neuro measured physiological data such as brain activity and palm\nsweat to quantify people\u2019s emotional reactions to stimuli. \u201d (Breitbart, 2019-09-02)\n(ii) \u201c\u2018Something must have changed in the debate that so many young people are speaking up\nand so many young people are being targeted,\u2019 Thunberg told Yahoo News in response to the\nmockery her movement has received from leaders like Trump and Russian President Vladimir\nPutin. \u2018They can sense that we are making an impact\u2019 \u201d (Yahoo News, 2019-10-17)\n(iii) \u201c[...] it might be tempting to criticize or dismiss activists supporting it. But Amy Myers Jaffe\nhopes older, more experienced policymakers won\u2019t do that. \u2018We need not to discourage them,\u2019\nshe says. They have an energy and will to innovation that is not only infectious, but inspiring. \u201d\n(NPR, 2019-02-08)16\nSentence (i) refers to emotions, which are often linked to a human interest perspective, but not in this\nquote which refers to a scientific study. In case (ii) \u2018they\u2019 refers to members of the Russian government,\npointing to an error in contextualization. Resolving \u2018they\u2019 as a cataphora to \u2018so many young people\u2019 may\nbe plausible in a superficial, yet incorrect read, as evidence for a Human Interest frame. Sentence\n(iii) is about shaping a strategic response to activists, and does not imply any human impact or emotion.\nOverprediction of Resolution is often due to quotes, or criticisms, of previously proposed policies\nwithout framing them as actual solutions in the context of the article, for instance\n(iv) \u201cIn the 2016 presidential election, Sanders staked out the most ambitious climate platform of\nany candidate, vowing to slash carbon dioxide pollution 40 percent by 2030, end fossil fuel\nsubsidies and ban fracking. \u201d (Huffington Post, 2018-04-12)\nwhere Sanders\u2019 ambitions are discussed in the context election campaigns of different candidates.\nUnderprediction of Moral . Moral issues can take very different forms, for instance an article from\nThe Daily Caller (2018-12-12) refers to the importance of \u2018 tolerance of [a] diversity of viewpoints \u2019, and\nautomatic prediction of a link to moral questions is near impossible without a fundamental understanding\nof the concept of moralilty. Millenia of theoretical arguments on the conceptualization of moral, and a\nmuch shorter yet active stream of research in NLP/ML confirms the intrinsic challenge with this frame (Xie\net al., 2019; Ziems et al., 2022b). Our model to a large extent relies on explicit mentions of the keyword\n\u2018moral\u2019 or religious terms.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Conflicts, villains, resolutions: Towards models of narrative media framing", "author": ["L Frermann", "J Li", "S Khanehzar"], "pub_year": "2023", "venue": "arXiv preprint arXiv \u2026", "abstract": "Despite increasing interest in the automatic detection of media frames in NLP, the problem  is typically simplified as single-label classification and adopts a topic-like view on frames,"}, "filled": false, "gsrank": 341, "pub_url": "https://arxiv.org/abs/2306.02052", "author_id": ["y3l6y4IAAAAJ", "ml9hh18AAAAJ", ""], "url_scholarbib": "/scholar?hl=en&q=info:aZtG1wQWwrEJ:scholar.google.com/&output=cite&scirp=340&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D340%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=aZtG1wQWwrEJ&ei=QrWsaI2aB7_SieoPzJnloAQ&json=", "num_citations": 23, "citedby_url": "/scholar?cites=12808824500242520937&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:aZtG1wQWwrEJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2306.02052"}}, {"title": "Who blames or endorses whom? entity-to-entity directed sentiment extraction in news text", "year": "2021", "pdf_data": "Who Blames or Endorses Whom?\nEntity-to-Entity Directed Sentiment Extraction in News Text\nKunwoo Park\nSoongsil University\u0003\nkunwoo.park@ssu.ac.krZhufeng Pan\nUCLA\npanzhufeng@cs.ucla.eduJungseock Joo\nUCLA\njjoo@comm.ucla.edu\nAbstract\nUnderstanding who blames or supports whom\nin news text is a critical research question\nin computational social science. Traditional\nmethods and datasets for sentiment analysis\nare, however, not suitable for the domain of\npolitical text as they do not consider the direc-\ntion of sentiments expressed between entities.\nIn this paper, we propose a novel NLP task\nof identifying directed sentiment relationship\nbetween political entities from a given news\ndocument, which we call directed sentiment\nextraction . From a million-scale news cor-\npus, we construct a dataset of news sentences\nwhere sentiment relations of political entities\nare manually annotated. We present a simple\nbut effective approach for utilizing a pretrained\ntransformer, which infers the target class by\npredicting multiple question-answering tasks\nand combining the outcomes. We demonstrate\nthe utility of our proposed method for social\nscience research questions by analyzing pos-\nitive and negative opinions between political\nentities in two major events: 2016 U.S. pres-\nidential election and COVID-19. The newly\nproposed problem, data, and method will fa-\ncilitate future studies on interdisciplinary NLP\nmethods and applications.1\n1 Introduction\nSentiment analysis is a useful technique for opinion\nmining from text data. Most existing work either\nfocuses on sentence-level classi\ufb01cation (Van Hee\net al., 2018; Zampieri et al., 2019), or aims to detect\nthe sentiment polarity towards speci\ufb01c targets (Pon-\ntiki et al., 2016; Cortis et al., 2017). These ap-\nproaches typically do not distinguish sources and\ntargets of the sentiment. They mainly use user-\ngenerated content (UGC), such as tweets or restau-\nrant reviews from Yelp, which assumes each user\n\u0003This work was done while the \ufb01rst author was a postdoc-\ntoral researcher at UCLA.\n1https://github.com/bywords/directed_\nsentiment_analysis\nFigure 1: Overview of the directed sentiment extraction\n(account holder) is the source of the sentiment, and\nthat the target is also clearly de\ufb01ned or easily iden-\nti\ufb01able (e.g., the restaurant).\nThis assumption does not hold for political news\nanalysis where a large number of political actors\nblame or support each other in news articles. The\nkey interest for political sentiment analysis is to\nidentify \u201cwho\u201d blame or support \u201cwhom\u201d (Balahur\nand Steinberger, 2009) rather than simply assigning\na global sentiment polarity to a given document or\nsentence. For example, from a sentence like \u201cX\nsupported Y for criticizing Z,\u201d we can infer X is\npositive toward Y and both X and Y are negative\ntoward Z. However, existing sentiment analysis\nmethods are not suitable to detect such sentiment\nrelationships between entities.\nThis paper proposes a new NLP task of identi-\nfying directed sentiment relationships from a po-\nlitical entity to another in news articles: directed\nsentiment extraction . For this task, we introduce a\nnewly annotated corpus from a million-scale newsarXiv:2106.01033v2  [cs.CL]  22 Jun 2021\ndataset. As demonstrated in Figure 1, we transform\ndirected sentiment extraction to multiple question-\nanswering tasks ( DSE2QA ) and combine their pre-\ndictions for making a \ufb01nal prediction. Evaluation\nresults show it outperforms state-of-the-art classi\ufb01-\ncation approaches, such as a \ufb01ne-tuned RoBERT\nclassi\ufb01cation model. Going further, we demon-\nstrate the utility of our method through two case\nstudies on how news media in the U.S. portrayed\nrelationships between political entities differently\namid the US election and COVID-19 pandemic.\nThe analysis reveals that the left-leaning media\npresent Donald Trump more as the target of blame\nwhile the right-leaning media present news stories\nblaming other entities. This study not only makes\na contribution to the NLP community by de\ufb01ning\na new problem and approach but also adds the em-\npirical understanding of media bias to the social\nscience community.\n2 Related Work\n2.1 Sentiment Analysis in Media\nSentiment analysis or polarity detection aims at\ndeciding whether a given text contains positive or\nnegative sentiment (Liu, 2012) or quantifying the\ndegree of sentiments embedded in a text (Gilbert\nand Hutto, 2014). Previous studies have tackled the\nproblem as a classi\ufb01cation task (Maas et al., 2011)\nand applied the trained model to infer sentiments\nembedded in various web and social data (Park\net al., 2018). Recently, transformer-based models\nhave shown high performance in sentiment clas-\nsi\ufb01cation (Devlin et al., 2019) and aspect-based\nsentiment analysis (Sun et al., 2019).\nMeasuring sentiment or tone of political text in\nnews media is a widely used method in compu-\ntational social science (Young and Soroka, 2012).\nA stream of work has used social media posts to\nestimate public opinions about political actors and\npredict the outcomes of future events by large scale\nsentiment analysis (O\u2019Connor et al., 2010; Ceron\net al., 2014; Wang et al., 2012), while some studies\nfurther extend to nonverbal or multimodal dimen-\nsions (Joo et al., 2014; Won et al., 2017; Chen et al.,\n2020a).\n2.2 Stance Detection\nStance detection is a relevant NLP problem that\naims to predict a claim\u2019s stance on reference\ntext (Augenstein et al., 2016) or to infer social\nmedia users\u2019 view toward an issue (Darwish et al.,2020). Many studies tried to advance the deep\nlearning-based models (Mohtarami et al., 2018),\nfor example, by modeling text with a hierarchical\narchitecture (Sun et al., 2018; Yoon et al., 2019).\nUnlike stance detection, this study aims at under-\nstanding an entity\u2019s sentiment toward another entity,\nboth of which appear in the same sentence.\n2.3 Relation Extraction\nOur target problem is also relevant to relation ex-\ntraction, which is a task of extracting structured re-\nlationships between entities from unstructured text.\nWhile the early literature relied on feature-based\nmethods (Zelenko et al., 2003), recent methods\nactively utilize neural methods (Lin et al., 2016);\nfor example, a study proposed a neural model that\njointly learns to perform entity recognition and\nrelation extraction (Bekoulis et al., 2018). Most\nrecently, a study tested the use of the pretrained\ntransformer-based language model for relation ex-\ntraction (Zhang et al., 2020).\nDespite its similarity to directed sentiment ex-\ntraction, most of the existing datasets only consider\nexplicit entity relationships such as EMPLOYEE OF\nand CITY OFRESIDENCE (Zhang et al., 2017). Un-\nderstanding sentiment relationships between politi-\ncal entities is more challenging as their sentiment\nis usually hidden in text.\n3 Problem and Dataset\nIn this section, we introduce our problem formu-\nlation and explain the process of our dataset con-\nstruction and annotation.\n3.1 Target Problem\nGiven a sentence sthat contains two entities pand\nq, the directed sentiment extraction problem aims\nto detect the sentiment relation from ptoqamong\n\ufb01ve classes: neutral, pholds a positive or negative\nopinion towards q, and the reverse direction. For ex-\nample, in the given sentence in Figure 1, the model\nshould infer that Trump is the source of the nega-\ntive sentiment toward China, the target. Existing\napproaches for sentiment analysis cannot be eas-\nily adapted to the task, as existing methods aim to\ndetect polarity embedded in a text (sentiment clas-\nsi\ufb01cation), for a speci\ufb01c target (targeted), or with\nregard to an aspect (aspect-based). These problem\nsetups do not consider the source and target of the\nsentiment at a time, which cannot identify directed\nsentiment relationships between political entities.\nClass Count\nNeutral 10,604\nPositive ( p!q) 1,656\nPositive ( p q) 327\nNegative ( p!q) 3,163\nNegative ( p q) 478\nTotal 16,228\nTable 1: Dataset statistics\nIn the following, we introduce a new annotated\ncorpus for the problem.\n3.2 Data Collection\nTo construct our dataset, we used news articles\nfrom the Real News corpus (Zellers et al., 2019),\nwhich consists of 32,797,763 real news stories in\nEnglish published by various outlets over multi-\nple years. Among them, we used 7,127,692 news\narticles shared by news media that are veri\ufb01ed as\ntrustworthy by Media Bias/Fact Check (Media Bias\nFact Check, 2015). After splitting each article into\nmultiple sentences, we only took sentences with\ntwo or more entities using the named entity recog-\nnition tool in Spacy2. To focus on the relationships\nbetween political entities, we considered named\nentities identi\ufb01ed as people, countries/political\ngroups, organizations, or cities/states3.\nSince most entity relationships in regular sen-\ntences are presumably neutral, we took two ap-\nproaches for sampling sentences that cover diverse\nrelationships: (i) dictionary-based and (ii) random\nselection approaches. The dictionary-based ap-\nproach \ufb01lters in sentences containing positive or\nnegative keywords from a pre-de\ufb01ned dictionary.\nStarting from the blame-related keywords (Liang\net al., 2019), we extended the dictionary by adding\ntheir synonyms and antonyms. While this method\nis effective in sampling from an unbalanced dataset,\nit excludes sentences that do not explicitly men-\ntion a blame or support keyword. Thus, we also\nrandomly drew sentences to improve the dataset\ncoverage.\n3.3 Crowdsourced Annotation\nWe used Amazon Mechanical Turk (AMT) to an-\nnotate each sentence. The annotation task asked\nworkers to identify what sentiment does an entity\nholds toward another in a given sentence. We in-\n2https://spacy.io\n3https://spacy.io/api/annotation#named-entitiesstructed them to annotate a sentence based only\non the sentiment expressed within the sentence,\nwithout relying on prior knowledge. There are \ufb01ve\noptions to choose from, neutral, positive ( p!q),\npositive ( q!p), negative ( p!q), and negative\n(q!p).pis the preceding entity of q, and the ar-\nrow indicates sentiment direction between the two\nentities. The detailed instruction used for educating\nannotator is presented in Table A1 in Appendix.\nWe hired \ufb01ve workers to annotate each sentence.\nFor ensuring high-quality responses, we only al-\nlowed workers to participate in the task when they\nhad at least a 70% acceptance rate for more than\n1,000 previous annotations. After completing the\ninitial round of annotation, we \ufb01ltered out unreli-\nable responses completed within one second or re-\nsponses by workers who did not pass test questions.\nWe designated workers with at least one unreli-\nable response as untrustworthy and discarded all\nthe other responses submitted by the untrustworthy\nworkers. We repeated the annotation task for the\ndiscarded answers until we have \ufb01ve annotations\nfor every sentence. The \ufb01nal set of annotations\nindicates a Fleiss\u2019 kappa value of 0.26, indicating\nan acceptable level of agreement among annota-\ntors. The level of reliability is comparable to stud-\nies using subjective text annotations such as hate\nspeech annotation (Ross et al., 2017), subjectiv-\nity (Abdul-Mageed and Diab, 2011), and sentiment\nanalysis (Park et al., 2018). By aggregating \ufb01ve\nresponses for each sentence by a majority vote, we\nobtained the \ufb01nal dataset of 16,228 sentences of\nwhich sentiment direction is annotated, as shown\nin Table 1. While keeping the label distribution\nalmost identical, we split the dataset into 13144,\n1461, and 1623 instances for train, validation, and\ntest set, respectively.\n4 Methods\nThis section presents methods for addressing the\nproblem of directed sentiment extraction. We pro-\npose a novel approach for solving it by employing\naugmented inputs in BERT-like transformer models\nand compare it with classi\ufb01cation approaches.\n4.1 Classi\ufb01cation Approaches\nFollowing the standard in using classi\ufb01cation se-\ntups for (undirected) sentiment detection (Liu,\n2012; Devlin et al., 2019), we construct classi\ufb01-\ncation models that predict scores of each sentiment\nfor the directed sentiment extraction.\nFigure 2: Detailed illustration of the DSE2QA approach\n4.1.1 Existing Methods\nWe \ufb01rst construct previous approaches proposed\nfor blame relationship detection. Liang et al.\n(2019) proposed three neural models that predict\nthe classes of blame relationships in a given text:\np!q,p q, and no relationship. We extend their\napproaches to the \ufb01ve classes of directed sentiment\nin our dataset.\nEntity prior model exploits the prior knowledge\non political entities by using the representation of\ntwo entities using a pre-trained word embedding:\nepandeq. After concatenation, the two vectors are\nfed into a fully-connected network with a ReLU\nhidden layer to make a \ufb01nal prediction. Context\nmodel utilizes the context of the target sentence\nwhere two entities appear. After replacing pandq\nwith special tokens ( [ENT1]and[ENT2]) respec-\ntively, the model encodes the input text through\na bidirectional LSTM and extracts the representa-\ntion corresponding to the two entities: lstm pand\nlstm q. The representation gets fed into a fully-\nconnected network. Combined model utilizes the\nconcatenated representation of the outputs of the\nentity prior and context model: ep,eq,lstm p,\nandlstm q. Then, the vector is fed into a fully-\nconnected network. We train the existing models\nby minimizing the cross-entropy loss.\n4.1.2 Fine-Tuning a Pretrained Transformer\nFine-tuning a BERT-like pretrained transformer\nhas shown signi\ufb01cant performance in many down-\nstream tasks (Devlin et al., 2019). We also evaluate\nthe performance of a \ufb01ne-tuned transformer. In\nparticular, after replacing the tokens correspond-\ning to pandqwith [ENT1]and[ENT2], we train\na classi\ufb01cation model that predicts the \ufb01ve-class\noutput based on the representation of [CLS]4. We\nuse the RoBERTa base model (Liu et al., 2019) as\nbackbone, and we refer to the classi\ufb01cation model\n4<S>in RoBERTaasRoBERTa in evaluation experiments. The model\nis trained to minimize the cross-entropy loss.\n4.2 Proposed Approach: Directed Sentiment\nExtraction to Question-Answering\nBERT-like transformer models are pretrained using\ntwo inputs including a separator token5with vary-\ning training objectives. The input con\ufb01guration\nallows the model to be successfully transferred to\nthe tasks using an auxiliary input, such as sentence\npair classi\ufb01cation (sentence 1 and sentence 2) and\nquestion answering (reference and question). In-\nspired by the recent achievements using auxiliary\ninputs (Sun et al., 2019; Cohen et al., 2020), we pro-\npose a simple but effective approach of tackling the\ndirected sentiment extraction problem, which we\ncallDSE2QA ; we transform the sentiment extrac-\ntion task into the sub-tasks aiming for answering\nyes/no questions on whether a target sentiment is\nembedded in the text. The basic idea is we inquire\nan intelligent machine who can answer yes/no ques-\ntions on whether a target sentiment exists and then\ncombine the answers corresponding to the each\nsentiment class for making a \ufb01nal guess. Figure 2\npresents the overall framework, which we elaborate\non each step in the following. Technically, taking\nauxiliary input in BERT-like transformers enables\nimplementing the intelligent machine by making a\ndifferent prediction with the same sentence input,\naccording to the question fed as additional input.\nWe hypothesize that a large-scale pretrained trans-\nformer model on a massive corpus can understand\nthe meaning of the augmented question and thus\nsuccessfully answer whether a directed sentiment\nexists in a text.\nNote that our question-answering setup is dif-\nferent from standard question-answering tasks in\nNLP, as represented by well-known benchmark\ndata such as SQuAD (Rajpurkar et al., 2016) and\n5[CLS] in BERT, </S></S>in RoBERTa\nIndex Complete questions Pseudo questions\nq0 Do [Ent1] and [Ent2] have neutral sentiment toward each other? [Ent1] - [Ent2] - neutral\nq1 Does [Ent1] has positive sentiment toward [Ent2]? [Ent1] - [Ent2] - positive\nq2 Does [Ent2] has positive sentiment toward [Ent1]? [Ent2] - [Ent1] - positive\nq3 Does [Ent1] has negative sentiment toward [Ent2]? [Ent1] - [Ent2] - negative\nq4 Does [Ent2] has negative sentiment toward [Ent1]? [Ent2] - [Ent1] - negative\nTable 2: Auxiliary questions according to the target label\nWikiQA (Yang et al., 2015). Given a question and\nreference text, the standard task aims at generating\nanswers in a natural language form. In contrast, the\nquestion-answering process in DSE2QA requires a\nbinary answer, which can be seen as a special type\nof question-answering.\n4.2.1 Data Augmentation for DSE2QA\nFor each pair of label land sentence swhere the\ntwo target entities pandqare masked as [ENT1]\nand [E NT2] respectively, we augment the training\ndata by transforming the original input into the \ufb01ve\ntuples using the same sentence and different ques-\ntions: ti: (s,qi,li) where iis the index of the target\nrelation class: neutral (0), p!qwith positive\nsentiment (1), p qwith positive sentiment (2),\np!qwith negative sentiment (3), and p q\nwith negative sentiment (4). libecomes 1 if lisi;\notherwise liis 0.\nWe design the auxiliary question qiasking\nwhether the given sentence sis classi\ufb01ed as the\ntarget sentiment i. The list of questions are pre-\nsented in Table 2. For example, q1asks a model\nwhether a given sentence scontains positive sen-\ntiment from ptoq. Here, we de\ufb01ne two types of\nquestions: complete and pseudo. Complete ques-\ntions are written in a natural language, and pseudo\nquestions only contain keywords that is suf\ufb01cient\nto characterize a sentiment class iwhile ignoring\nthe syntactic structure.\n4.2.2 Model Prediction\nWe utilize the BERT-like transformer model (De-\nvlin et al., 2019), which can take sentence pairs as\ninput, for making a binary prediction on a given\nsentence sand question qi. In particular, the model\ntakes\n[CLS] s[SEP] qi[SEP]\nas input6and predicts a value yifrom 0 to 1 that\nindicates the con\ufb01dence on the target label i.\n6\u2018<S> s < /S> </S> q i</S> </S>\u2019 in RoBERTa4.2.3 Training and Inference\nFor the augmented input of ti, a pretrained BERT-\nlike transformer is trained to predict 1 for tland\n0 forti6=lthrough the [CLS] representation at the\nlast layer of the transformer model followed by\na classi\ufb01cation layer. For inference, we made a\nprediction corresponding to sbyargmaxiyiwhere\nyiis the prediction outcome of ti. The yiindicates\nthe con\ufb01dence on each sentiment i, and therefore\nwe take the class of which the value is maximum.\nIn the experiments, we utilize the RoBERTa base\nmodel for the backbone of DSE2QA and train the\nmodel to minimize the binary cross-entropy loss.\nThis approach is different from the RoBERTa clas-\nsi\ufb01cation model that only employs a single sen-\ntence input.\n5 Performance Evaluation\nWe evaluate the performance of the proposed\nDSE2QA approach using our annotated corpus.\nWe compare our method with the current state-\nof-the-art methods for directional blame detection\nproposed by Liang et al. (2019) (LNZ) as well as\na classi\ufb01cation model \ufb01ne-tuned on a pretrained\ntransformer (RoBERTa).\n5.1 Experiment Setups\nFor the LNZ models (Liang et al., 2019), we set the\nvocabulary size as 10000. We set the word embed-\nding size, LSTM hidden dimension, and the fully\nconnected layer dimension as 256, 512, and 1024.\nThe search space for the dropout rate is [0:1;0:5].\nWe train the LNZ models using Adam optimizer\nwith a learning rate of 1e-3 (Kingma and Ba, 2014).\nWe adopt an early stopping strategy with the pa-\ntience of 5. For training RoBERTa and DSE2QA,\nwe followed the procedure of Liu et al. (2019) us-\ning AdamW (Loshchilov and Hutter, 2017). We\noptimize hyperparameters by randomly choosing\nten sets for each model and selecting the model\nwith the best performance on the validation set.\nThe learning rate is set to 2e-5 with the epsilon as\nMethod Micro F1 Macro F1 mAP\nDSE2QA (Pseudo) 0.7973 0.6766 0.7488\nDSE2QA (Complete) 0.7726 0.6617 0.7387\nRoBERTa 0.7486 0.6409 0.7319\nLNZ (Combined) 0.7055 0.5358 0.5295\nLNZ (Context) 0.6371 0.4665 0.4921\nLNZ (EntityPrior) 0.5853 0.4063 0.414\nTable 3: Evaluated performance on the test set. Top performance for each metric is marked as bold.\nMethod 0 1 2 3 4\nDSE2QA (Pseudo) 0.855 0.6519 0.5672 0.7402 0.5686\nDSE2QA (Complete) 0.8293 0.6421 0.5672 0.7416 0.5283\nRoBERTa 0.8054 0.6373 0.5079 0.7184 0.5354\nLNZ (Combined) 0.7981 0.443 0.3333 0.5827 0.5217\nLNZ (Context) 0.7469 0.4069 0.2817 0.5007 0.3964\nLNZ (EntityPrior) 0.7133 0.2629 0.2353 0.4533 0.3667\nTable 4: F1-score per class measured on the test set. Top performance for each metric is marked as bold.\n1e-6. The weight decay is set to 0.1. We apply\nrandom oversampling to the training set to make\na balanced dataset against the label. We run the\nexperiment \ufb01ve times with different random seeds\nand report the average scores.\n5.2 Evaluation Results\nWe utilize three measures for evaluation: micro-\nf1, macro-f1, and mean average precision (mAP).\nMicro-f1 is calculated by (#correct)/(#total), which\ncorresponds to the multi-class classi\ufb01cation accu-\nracy. Macro-f1 measures an f1-score for each\nclass and averages them with equal importance;\ntherefore, macro-f1 is a more robust measure to a\nskewed class distribution, such as our annotation\ndata (see Table 1). Similarly, mAP measures the\nunweighted average of average precision (AP) on\neach class; AP summarizes a precision-recall curve\nvarying prediction threshold for a target class.\nIn Table 3, we make three observations. First,\namong classi\ufb01cation approaches (the bottom four\nrows), RoBERTa outperforms the other approaches\nacross the three measures (0.7486/0.6409/0.7319).\nThe LNZ combined model achieves a fair micro-f1\nscore of 0.7055 but low scores of macro-f1 (0.5358)\nand mAP(0.5295). This difference is because the\ncombined model (and other non-transformer mod-\nels) is poor at classifying non-neutral sentiment,\nwhich we will further investigate in Table 4. Sec-\nond, DSE2QA with complete questions outper-\nforms RoBERTa with a margin of 0.024 by micro\nF1. The proposed approach also achieves betterperformance in macro F1 and mAP. Third, the per-\nformance of DSE2QA gets further increased with\nthe usage of pseudo questions, up to the micro-f1\nscore of 0.7973. This observation implies that a\nBERT-like transformer model may not need a full\nsentence to utilize the auxiliary input because it\nalso performs well using fewer keywords for the\ndetection task with an augmented input.\nTable 4 presents the f1-score measured for each\nclass: neutral (0), positive from the left entity to\nthe right (1), positive from the right to the left (2),\nnegative from the left to the right (3), and negative\nfrom the right to the left (4). Here, we make three\nobservations. First, all models perform the best at\nidentifying neutral sentiment (0) compared to the\nother sentiment classes. Second, non-transformer\nmodels (the bottom three rows) are poor at extract-\ning non-neutral sentiment regardless of their direc-\ntion, which contributes to the decreased macro F1\nin Table 3. Third, among the sentiment classes\nfrom the left entity to the right entity (1, 3), trans-\nformer models better detect negative sentiment than\npositive sentiment. The \ufb01nding suggests that pos-\nitive entity relationships are more dif\ufb01cult to be\ncaptured in news articles, which calls for future\nstudies for a better understanding and model im-\nprovement. AP per each class also shows a similar\ntrend, as presented in Table A3.\nIn summary, the proposed approach of solving\nthe directed sentiment extraction task by multiple\nquestion-answering tasks outperforms the state-of-\nthe-art classi\ufb01cation approaches. The high perfor-\nmance suggests that the model can understand the\nmeaning of augmented questions to some extent,\nwhich may build on the language understanding\nability of the pretrained RoBERTa.\n6 Analyzing Entity Relationships in\nNews Articles\nTo demonstrate the utility of the proposed dataset\nand model, we conduct two case studies to analyze\nentity-to-entity sentiment relationships presented\nin recent news articles on political issues: the 2016\nU.S. presidential election and the COVID-19 pan-\ndemic. For the analyses, we utilize the DSE2QA\nmodel with pseudo questions trained on the anno-\ntated corpus, and we con\ufb01rm that the target news\narticles are not overlapped with the whole set.\n6.1 Case Study 1: 2016 U.S. election\nWe study how news media covered the entity re-\nlation during the 2016 United States presidential\nelection using a public dataset on news articles\nbetween Feb. 2016 to Feb. 20177. This dataset\nconsists of about 140K news articles in English\nfrom \ufb01fteen media companies, including CNN,\nNew York Times, and Guardian. We randomly\nselect 3K articles from each month, 39K articles\nin total. Then we apply the proposed model to all\nsentences that contain at least two entities from\nthe top-30 most frequent entities, including Donald\nTrump and Hillary Clinton.\nTed CruzBernie \nSanders\nHillary \nClinton Barack\nObamaMarco\nRubioDonald\nTrump3\n2\n1\n0\n-1\n-2\n-3\nFigure 3: Log ratios of positive (blue) and negative\n(red) sentiments in directed political relationships in the\nnews articles.\nFigure 3 presents the frequently mentioned pairs\nof politicians. The red color indicates an entity\npair tends to contain negative sentiment more than\npositive, and blue indicates the pairs with the neg-\native sentiment more. The opacity represents the\nstrength of the opinion measured by the log ra-\ntio of inferred pairs of positive and negative senti-\n7https://www.kaggle.com/snapcrack/all-the-newsLeft Center Right\nABC News Associated Press Breitbart News\nBuzzFeed News Forbes Daily Mail\nCBS News NPR Fox News\nCNN Reuter National Review\nDemocracy Now USA TODAY New York Post\nHuffPost Reason\nMSNBC The American Spectator\nNew York Times theblaze.com\nSlate The Daily Caller\nThe Atlantic The Daily Wire\nThe Guardian The Epoch Times\nThe New Yorker The Federalist\nTime Magazine Washington Times\nV ox Wall Street Journal\nWashington Post\nTable 5: The list target media outlets sorted by alpha-\nbetical order.\nment. For brevity, we present relations that appear\nat least 20 times in any sentiment. Overall, there\nare 4.68 times more negative sentiments found than\npositive ones, which may be explained due to the\nnegative nature of political media (Soroka, 2014).\nAn interesting observation is the asymmetric rela-\ntion between Hillary Clinton and Barack Obama.\nClinton holds a generally slightly negative opinion\ntowards Obama, while Obama holds a stronger pos-\nitive opinion towards Clinton. Note that our model\ndoes not just memorize the entity relationship in\nthe training dataset and apply it to the target dataset\nas we replace detected entities with tokens in input\nsentences.\n6.2 Case Study 2: the COVID-19 pandemic\nIn the second study, we investigate how news\nmedia portray political entities and their relation-\nships differently according to their political orien-\ntations. For example, a right-leaning news outlet\nmay show more negative opinions expressed to-\nward Democrats. To that end, we focused on the\nrecent issue of the COVID-19 pandemic to examine\nthe media bias. We expect the general sentiment\nabout COVID-19 is negative but would like to in-\nvestigate who blames whom because the messages\nwill have very different meanings according to the\nsources and targets, differentiated by our data and\nmethod.\nTo collect a recent news article set, we \ufb01rst com-\npiled a list of 35 popular news media outlets that\ncover American politics in English. We also ensure\nthe list of news outlets was balanced against po-\nlitical bias, according to the media bias ratings in\nallsides.com . For brevity, we consolidate \u2018Lean\nEntityRank\n(Left)Rank\n(Center)Rank\n(Right)\nDonald Trump 1 2 1\nRepublican 2 6 6\nU.S. 3 1 3\nDemocrat 4 5 4\nRussia 5 6 9\nAmerican 6 15 10\nChina 7 4 5\nObama 8 10 7\nChinese 9 3 2\nJoe Biden 9 8 7\nTable 6: Frequency rank of top-10 frequent entities tar-\ngeted with a negative sentiment through an entity-to-\nentity relationship in the COVID-19 news dataset. The\norder is sorted by the overall rank in the dataset.\nleft\u2019 and \u2018Left\u2019 into \u2018Left\u2019 and \u2018Lean right\u2019 and\n\u2018Right\u2019 into \u2018Right.\u2019 Table 5 presents the list of the\ntarget media.\nFor each of the target media outlets, we collected\nnews articles shared throughout 2020 until Septem-\nber from the Common Crawl corpus, which has\nbeen collecting web data since 20088. The total\nnumber of retrieved news pages are is 256,081; on\naverage, we have 7,113 published news articles for\neach outlet.\nNext, we selected documents containing at least\none of the keywords relevant to COVID-19 by\nfollowing similar practices used for collecting a\nTwitter dataset (Chen et al., 2020b): coronavirus ,\ncovid-19 ,COVID19 , and corona virus . We con-\nsider sentences containing two or more entities for\nthe target of inference, and every relationship pair\nis inferred when there are more than two entities in\na sentence. The \ufb01nal set consists of 6,180 articles\ninvolving 1,078,377 entity pairs for COVID-19.\nTable 6 presents the list of 10 frequent entities\nthat are manifested through entity-to-entity rela-\ntionships with a negative sentiment. While Don-\nald Trump was the most frequent target of blames\nin the total data, the results show that the right-\nleaning media tend to express a negative sentiment\ntoward China (#5) and Chinese people (#2) more\nfrequently. To examine the difference systemati-\ncally, we measure the spearman rank correlation co-\nef\ufb01cient for the whole list of entities that appeared\nin the dataset. The rank in the left-leaning media\nand that in right-leaning media exhibits a highly\nnegative correlation of -0.5722 ( p<0.001), which\n8https://commoncrawl.org/suggests that the list of political entities presented\nwith a negative sentiment signi\ufb01cantly varies across\nnews media according to their political orientation.\nSuch a high level of negative correlation is also\nobserved in the ranks for the source entity in neg-\native relationships ( \u00000.4129 with p<0.001) and\nthe source/target entities in positive relationships\n(\u00000.5605/\u00000.7929 with p<0.001).\nGoing further, we analyze the differences be-\ntween frequently presented entity pairs with nega-\ntive sentiment by the left and right-leaning media,\nrespectively. Table 7 presents the rank of each\nentity pair in the media groups according to their\npolitical orientation. In the left-leaning media of\nour dataset, Donald Trump appears as either source\nor target in the top-10 frequent negative pairs ex-\ncept for the pair of Republican !Democrat and\nvice versa. On the contrary, the top-10 pairs in\nthe right-leaning media include the international\nrelationships of Donald Trump to the other coun-\ntries. In other words, the left-leaning media may\ntry to frame COVID-19 as a domestic event fo-\ncusing on how the President handles it and how\npeople respond to his crisis management, and the\nright-leaning media focus more on foreign poli-\ncies and international relationship especially be-\ntween the U.S. and China. For the whole set of\nentity pairs, the rank correlation between the left\nand right media is \u00000.4847 ( p<0.001) for nega-\ntive sentiment and\u00000.7929 ( p<0.001) for positive\nsentiment. These negative correlations imply that\nthe news media has a bias in selecting issues to\ncover (selection bias) and presenting relationships\nof political entities (presentation bias).\n7 Conclusion\nDetecting who blames or endorses whom in news\narticles is a critical ability in understanding opin-\nions and relationship between political actors in\nnews media. This paper provides a computational\ntool based on natural language processing for facil-\nitating interdisciplinary studies using text in news\nand social media.\nWe introduced a new problem of identifying di-\nrected sentiment relationships between political\nentities, called directed sentiment extraction. We\nconstructed a training corpus of which entity rela-\ntionship is manually annotated for each sentence.\nThis dataset can serve as a benchmark for future\nstudies. A potential future direction is to build\nan improved version of the dataset where senti-\nFrequent pairs in the left-leaning media Frequent pairs in the right-leaning media\nEntity pairsRank\n(Left)Rank\n(Center)Rank\n(Right)Entity pairsRank\n(Left)Rank\n(Center)Rank\n(Right)\nDemocrat!Donald Trump 1 8 1 Democrat!Donald Trump 1 8 1\nRepublican!Donald Trump 2 66 4 Donald Trump!Democrat 4 3 2\nTwitter!Donald Trump 3 67 392 Donald Trump!Chinese 30 17 3\nDonald Trump!Democrat 4 3 2 Republican!Donald Trump 2 66 4\nBernie Sander!Donald Trump 5 67 153 Donald Trump!China 9 10 5\nDonald Trump!Ted Cruz 6 67 393 Donald Trump!Joe Biden 20 8 6\nRepublican!Democrat 7 66 47 Democrat!Republican 8 41 7\nDemocrat!Republican 8 41 7 Joe Biden!Donald Trump 38 5 8\nDonald Trump!China 9 10 5 Donald Trump!Russia 23 17 9\nDonald Trump!Bush 10 67 393 House!Donald Trump 12 67 10\nTable 7: Frequency rank of entity pairs presented with a negative sentiment in the COVID-19 news dataset\nment relationships between political entities appear\nacross multiple sentences in news articles. Our\nproblem setup is similar to the document-level sen-\ntiment inference task of Choi et al. (2016); they in-\nfer entity-to-entity sentiment in a sentence among\nthree classes (positive, unbiased, negative), and\nthe sentence-level outcomes are merged to infer\na 5-class sentiment for a document. Future stud-\nies could extend our sentence-level approach to\ndocument-level sentiment inference.\nTo tackle the problem, we proposed DSE2QA\n(Directed Sentiment Extraction to Question-\nAnswering), which is a simple yet effective method\nof utilizing BERT-like pretrained transformers by\npredicting answers for binary questions on whether\na sentiment relationship exists in a given text. An-\nswers for each sentiment class are aggregated to\nmake a \ufb01nal guess. Evaluation experiments show\nthe approach outperforms state-of-the-art classi\ufb01-\ncation models, such as the \ufb01ne-tuned RoBERTa\nclassi\ufb01cation model. We hypothesize the language\nunderstanding ability of the BERT-like pretrained\ntransformer may contribute to the high perfor-\nmance, combined with its facility of taking auxil-\niary input. Furthermore, the performance increase\nwith the pseudo questions implies that a few key-\nwords may suf\ufb01ce to make an inquiry. Future re-\nsearch could investigate which kind of pretrained\ntransformer is the most effective for understand-\ning the meaning of the augmented question, as\nDSE2QA\u2019s backbone can be replaced with any\nBERT-like transformer. Also, this study calls for\nfuture studies on advanced methods for directed\nsentiment extraction. A potential approach could\njointly learn entity recognition and directed senti-\nment extraction as similarly tackled by a study on\ninformation extraction (Bekoulis et al., 2018).\nAs the last step, we conducted case studies byanalyzing directed sentiments in news text for the\nUS election and COVID-19 pandemic. The ob-\nservations not only add empirical understandings\nto the social science research but also highlight\nthe utility of the proposed problem, dataset, and\nmodel for political news analysis. We believe the\nproposed method can therefore further the current\ninterdisciplinary efforts of the NLP, machine learn-\ning, and the social science communities (Grimmer\nand Stewart, 2013; Roberts et al., 2014; Joo and\nSteinert-Threlkeld, 2018).\nAcknowledgements\nWe thank anonymous reviewers for their valuable\ncomments. This work was supported by NSF\nSBE/SMA #1831848 \u201cRIDIR: Integrated Commu-\nnication Database and Computational Tools\u201d.\nEthics and Impact Statement\nIn online news and social media, people express\ndiverse sentiment toward a target through text, such\nas blame, support, endorsement, to list a few. Quan-\ntifying and understanding the patterns is of signif-\nicant interest in social science, but the lack of au-\ntomated methods makes it dif\ufb01cult to handle large-\nscale data, which can reveal patterns in a compre-\nhensive view. In this light, this study aims to de-\nvelop automated methods of identifying directed\nsentiment between entities by de\ufb01ning a new NLP\nproblem: directed sentiment extraction. The newly\nannotated dataset will facilitate future development\nof the NLP methods, and the DSE2QA approach\nwill serve as a strong baseline.\nThe development of an automated method will\nhave a broader impact by tackling real-world chal-\nlenges such as bias in news reporting against polit-\nical orientation, with potential collaboration with\nsocial science. Moreover, it will enable the discov-\nery of hidden biases with regard to sentiment in on-\nline text, which can be mistakenly learned through\ndata-driven methods. A \ufb01ne-grained understanding\nof sentiment relationships will broadly contribute\nto building a fair machine learning model, which is\nof signi\ufb01cant interest in AI ethics.\nReferences\nMuhammad Abdul-Mageed and Mona Diab. 2011.\nSubjectivity and sentiment annotation of modern\nstandard arabic newswire. In Proceedings of the 5th\nlinguistic annotation workshop , pages 110\u2013118.\nIsabelle Augenstein, Tim Rockt \u00a8aschel, Andreas Vla-\nchos, and Kalina Bontcheva. 2016. Stance detection\nwith bidirectional conditional encoding. In Proceed-\nings of the 2016 Conference on Empirical Methods\nin Natural Language Processing , pages 876\u2013885.\nAlexandra Balahur and Ralf Steinberger. 2009. Re-\nthinking sentiment analysis in the news: from theory\nto practice and back. Proceeding of WOMSA , 9.\nGiannis Bekoulis, Johannes Deleu, Thomas Demeester,\nand Chris Develder. 2018. Joint entity recogni-\ntion and relation extraction as a multi-head selection\nproblem. Expert Systems with Applications , 114:34\u2013\n45.\nAndrea Ceron, Luigi Curini, Stefano M Iacus, and\nGiuseppe Porro. 2014. Every tweet counts? how\nsentiment analysis of social media can improve our\nknowledge of citizens\u2019 political preferences with an\napplication to italy and france. New media & society ,\n16(2):340\u2013358.\nDanni Chen, Kunwoo Park, and Jungseock Joo. 2020a.\nUnderstanding gender stereotypes and electoral suc-\ncess from visual self-presentations of politicians in\nsocial media. In Joint Workshop on Aesthetic and\nTechnical Quality Assessment of Multimedia and Me-\ndia Analytics for Societal Trends , pages 21\u201325.\nEmily Chen, Kristina Lerman, and Emilio Ferrara.\n2020b. Covid-19: The \ufb01rst public coronavirus twit-\nter dataset. arXiv preprint arXiv:2003.07372 .\nEunsol Choi, Hannah Rashkin, Luke Zettlemoyer, and\nYejin Choi. 2016. Document-level sentiment infer-\nence with social, faction, and discourse context. In\nProceedings of the 54th Annual Meeting of the As-\nsociation for Computational Linguistics (Volume 1:\nLong Papers) , pages 333\u2013343, Berlin, Germany. As-\nsociation for Computational Linguistics.\nAmir DN Cohen, Shachar Rosenman, and Yoav Gold-\nberg. 2020. Relation extraction as two-way span-\nprediction. arXiv preprint arXiv:2010.04829 .\nKeith Cortis, Andr \u00b4e Freitas, Tobias Daudert, Manuela\nHuerlimann, Manel Zarrouk, Siegfried Handschuh,and Brian Davis. 2017. SemEval-2017 task 5: Fine-\ngrained sentiment analysis on \ufb01nancial microblogs\nand news. In Proceedings of the 11th International\nWorkshop on Semantic Evaluation (SemEval-2017) ,\npages 519\u2013535.\nKareem Darwish, Peter Stefanov, Micha \u00a8el Aupetit, and\nPreslav Nakov. 2020. Unsupervised user stance de-\ntection on twitter. In Proceedings of the Interna-\ntional AAAI Conference on Web and Social Media ,\nvolume 14, pages 141\u2013152.\nJacob Devlin, Ming-Wei Chang, Kenton Lee, and\nKristina Toutanova. 2019. BERT: Pre-training of\ndeep bidirectional transformers for language under-\nstanding. In Proceedings of the 2019 Conference of\nthe North American Chapter of the Association for\nComputational Linguistics: Human Language Tech-\nnologies, Volume 1 (Long and Short Papers) , pages\n4171\u20134186.\nCHE Gilbert and Erric Hutto. 2014. Vader: A parsimo-\nnious rule-based model for sentiment analysis of so-\ncial media text. In Proceedings of the International\nAAAI Conference on Weblogs and Social Media , vol-\nume 81, page 82.\nJustin Grimmer and Brandon M Stewart. 2013. Text as\ndata: The promise and pitfalls of automatic content\nanalysis methods for political texts. Political analy-\nsis, 21(3):267\u2013297.\nJungseock Joo, Weixin Li, Francis F Steen, and Song-\nChun Zhu. 2014. Visual persuasion: Inferring com-\nmunicative intents of images. In Proceedings of\nthe IEEE conference on computer vision and pattern\nrecognition , pages 216\u2013223.\nJungseock Joo and Zachary C Steinert-Threlkeld.\n2018. Image as data: Automated visual con-\ntent analysis for political science. arXiv preprint\narXiv:1810.01544 .\nDiederik P Kingma and Jimmy Ba. 2014. Adam: A\nmethod for stochastic optimization. arXiv preprint\narXiv:1412.6980 .\nShuailong Liang, Olivia Nicol, and Yue Zhang. 2019.\nWho blames whom in a crisis? detecting blame ties\nfrom news articles using neural networks. In Pro-\nceedings of the AAAI Conference on Arti\ufb01cial Intel-\nligence , volume 33, pages 655\u2013662.\nYankai Lin, Shiqi Shen, Zhiyuan Liu, Huanbo Luan,\nand Maosong Sun. 2016. Neural relation extraction\nwith selective attention over instances. In Proceed-\nings of the 54th Annual Meeting of the Association\nfor Computational Linguistics (Volume 1: Long Pa-\npers) , pages 2124\u20132133.\nBing Liu. 2012. Sentiment analysis and opinion min-\ning. Synthesis lectures on human language technolo-\ngies, 5(1):1\u2013167.\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\ndar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\nLuke Zettlemoyer, and Veselin Stoyanov. 2019.\nRoberta: A robustly optimized bert pretraining ap-\nproach. arXiv preprint arXiv:1907.11692 .\nIlya Loshchilov and Frank Hutter. 2017. Decou-\npled weight decay regularization. arXiv preprint\narXiv:1711.05101 .\nAndrew L. Maas, Raymond E. Daly, Peter T. Pham,\nDan Huang, Andrew Y . Ng, and Christopher Potts.\n2011. Learning word vectors for sentiment analysis.\nInProceedings of the 49th Annual Meeting of the\nAssociation for Computational Linguistics: Human\nLanguage Technologies , pages 142\u2013150.\nLLC Media Bias Fact Check. 2015. Media Bias/Fact\nCheck. https://mediabiasfactcheck.com .\n[Online; accessed 21-Sep-2020].\nMitra Mohtarami, Ramy Baly, James Glass, Preslav\nNakov, Llu \u00b4\u0131s M `arquez, and Alessandro Moschitti.\n2018. Automatic stance detection using end-to-end\nmemory networks. In Proceedings of the 2018 Con-\nference of the North American Chapter of the Asso-\nciation for Computational Linguistics: Human Lan-\nguage Technologies, Volume 1 (Long Papers) , pages\n767\u2013776.\nBrendan O\u2019Connor, Ramnath Balasubramanyan, Bryan\nRoutledge, and Noah Smith. 2010. From tweets to\npolls: Linking text sentiment to public opinion time\nseries. In Proceedings of the International AAAI\nConference on Web and Social Media , volume 4.\nKunwoo Park, Meeyoung Cha, and Eunhee Rhim.\n2018. Positivity bias in customer satisfaction ratings.\nInCompanion Proceedings of the The Web Confer-\nence 2018 , pages 631\u2013638.\nMaria Pontiki, Dimitrios Galanis, Haris Papageor-\ngiou, Ion Androutsopoulos, Suresh Manandhar, Mo-\nhammad Al-Smadi, Mahmoud Al-Ayyoub, Yanyan\nZhao, Bing Qin, Orph \u00b4ee De Clercq, et al. 2016.\nSemeval-2016 task 5: Aspect based sentiment anal-\nysis. In 10th International Workshop on Semantic\nEvaluation .\nPranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and\nPercy Liang. 2016. SQuAD: 100,000+ questions for\nmachine comprehension of text. In Proceedings of\nthe 2016 Conference on Empirical Methods in Natu-\nral Language Processing , pages 2383\u20132392.\nMargaret E Roberts, Brandon M Stewart, Dustin\nTingley, Christopher Lucas, Jetson Leder-Luis,\nShana Kushner Gadarian, Bethany Albertson, and\nDavid G Rand. 2014. Structural topic models for\nopen-ended survey responses. American Journal of\nPolitical Science , 58(4):1064\u20131082.\nBj\u00a8orn Ross, Michael Rist, Guillermo Carbonell, Ben-\njamin Cabrera, Nils Kurowsky, and Michael Wo-\njatzki. 2017. Measuring the reliability of hate\nspeech annotations: The case of the european\nrefugee crisis. arXiv preprint arXiv:1701.08118 .Stuart N Soroka. 2014. Negativity in democratic poli-\ntics: Causes and consequences . Cambridge Univer-\nsity Press.\nChi Sun, Luyao Huang, and Xipeng Qiu. 2019. Uti-\nlizing BERT for aspect-based sentiment analysis via\nconstructing auxiliary sentence. In Proceedings of\nthe 2019 Conference of the North American Chap-\nter of the Association for Computational Linguistics:\nHuman Language Technologies, Volume 1 (Long\nand Short Papers) , pages 380\u2013385.\nQingying Sun, Zhongqing Wang, Qiaoming Zhu, and\nGuodong Zhou. 2018. Stance detection with hierar-\nchical attention network. In Proceedings of the 27th\nInternational Conference on Computational Linguis-\ntics, pages 2399\u20132409.\nCynthia Van Hee, Els Lefever, and V \u00b4eronique Hoste.\n2018. Semeval-2018 task 3: Irony detection in en-\nglish tweets. In Proceedings of The 12th Interna-\ntional Workshop on Semantic Evaluation , pages 39\u2013\n50.\nHao Wang, Dogan Can, Abe Kazemzadeh, Franc \u00b8ois\nBar, and Shrikanth Narayanan. 2012. A system for\nreal-time Twitter sentiment analysis of 2012 U.S.\npresidential election cycle. In Proceedings of the\nACL 2012 System Demonstrations , pages 115\u2013120.\nDonghyeon Won, Zachary C Steinert-Threlkeld, and\nJungseock Joo. 2017. Protest activity detection and\nperceived violence estimation from social media im-\nages. In Proceedings of the 25th ACM international\nconference on Multimedia , pages 786\u2013794.\nYi Yang, Wen-tau Yih, and Christopher Meek. 2015.\nWikiQA: A challenge dataset for open-domain ques-\ntion answering. In Proceedings of the 2015 Con-\nference on Empirical Methods in Natural Language\nProcessing , pages 2013\u20132018.\nSeunghyun Yoon, Kunwoo Park, Joongbo Shin,\nHongjun Lim, Seungpil Won, Meeyoung Cha, and\nKyomin Jung. 2019. Detecting incongruity between\nnews headline and body text via a deep hierarchical\nencoder. In Proceedings of the AAAI Conference on\nArti\ufb01cial Intelligence , volume 33, pages 791\u2013800.\nLori Young and Stuart Soroka. 2012. Affective news:\nThe automated coding of sentiment in political texts.\nPolitical Communication , 29(2):205\u2013231.\nMarcos Zampieri, Shervin Malmasi, Preslav Nakov,\nSara Rosenthal, Noura Farra, and Ritesh Kumar.\n2019. Predicting the type and target of offensive\nposts in social media. In Proceedings of the 2019\nConference of the North American Chapter of the\nAssociation for Computational Linguistics: Human\nLanguage Technologies, Volume 1 (Long and Short\nPapers) , pages 1415\u20131420.\nDmitry Zelenko, Chinatsu Aone, and Anthony\nRichardella. 2003. Kernel methods for relation ex-\ntraction. Journal of machine learning research ,\n3(Feb):1083\u20131106.\nRowan Zellers, Ari Holtzman, Hannah Rashkin,\nYonatan Bisk, Ali Farhadi, Franziska Roesner, and\nYejin Choi. 2019. Defending against neural fake\nnews. In Advances in Neural Information Process-\ning Systems , pages 9051\u20139062.\nNingyu Zhang, Luoqiu Li, Shumin Deng, Haiyang Yu,\nXu Cheng, Wei Zhang, and Huajun Chen. 2020. Can\n\ufb01ne-tuning pre-trained models lead to perfect nlp?\na study of the generalizability of relation extraction.\narXiv preprint arXiv:2009.06206 .\nYuhao Zhang, Victor Zhong, Danqi Chen, Gabor An-\ngeli, and Christopher D. Manning. 2017. Position-\naware attention and supervised data improve slot\n\ufb01lling. In Proceedings of the 2017 Conference on\nEmpirical Methods in Natural Language Processing ,\npages 35\u201345.\nInstruction:\nBased the given sentence, please identify if one entity (person, organization, or country) holds a positive or\nnegative opinion towards another entity. There will be two entities in total. One is in red and the other is in blue.\nIt is also possible neither positive nor negative opinion exists in the sentence.\nPlease annotate such cases as neutral.\nPlease classify the sentence based on what people say instead of what they do.\nFor example, if a sentence only states the police arrest someone, this sentence should be classi\ufb01ed as neutral.\nInstead, if the police accuses someone of commiting a crime, this sentence should be classi\ufb01ed as police holds\na negative opinion towards the person.\nExamples:\n- Earlier on Tuesday, Mr. Trump criticized General Motors for making cars in Mexico.\n(Negative: Trump holds a negative opinion towards General Motors)\n- Hugo Ras has been accused of killing other people\u2019s rhino, and for that South Africans condemn him.\n(Negative: South Africans holds a negative opinion towards Hugo Ras)\n- DA VID Cameron\u2019s accused the Conservatives of failing to devolve essential welfare powers to, as agreed\nby the cross-party Smith Commission which considered further powers for the Scottish parliament last year.\n(Neutral: There is no direct opinions between these two entities.)\n- Prime Minister Stephen Harper shakes hands with Petty Harbour, N.L., during a campaign event in Toronto\non Sept. 18, 2015. (Neutral: They shake hands just for politeness. No opinions exist.)\n- Obama pulled Clinton into his administration after he defeated her in 2008 primary and has effusively praised\nher tenure as secretary of state. (Positive. Obama holds a positive opinion towards Clinton.)\n- Earlier on Tuesday, Mr. Trump has not comments on General Motors making cars in Mexico. (Neutral.)\nNote:\nThere are multiple annotators for each sentence. Your response will be judged as failed when it is different with\nother annotators. If the percentage of failed response from one annotator is above a threshold, the annotator\nwill NOT get paid for ALL responses. Thanks for your participation.\nTable A1: Instruction used for educating annotators in Amazon Mechanical Turk.\nMethodNum.\nparametersAvg. runtime\nper epochMicro F1 Macro F1 mAP\nDSE2QA (Pseudo) 125M + 1536 2154s 0.8072 0.6827 0.7528\nDSE2QA (Complete) 125M + 1536 2149s 0.7892 0.6751 0.7724\nRoBERTa 125M + 3840 437s 0.7618 0.6516 0.7493\nLNZ (Combined) 3.03M 12s 0.694 0.5189 0.4819\nLNZ (Context) 2.9M 12s 0.6331 0.4518 0.3908\nLNZ (EntityPrior) 2.65M 4.8s 0.5914 0.4427 0.31\nTable A2: Model details and evaluated performance on the validation set. Top performance for each metric is\nmarked as bold.\nMethod 0 1 2 3 4\nDSE2QA (Pseudo) 0.9316 0.7157 0.5952 0.8358 0.6658\nDSE2QA (Complete) 0.9341 0.7228 0.5747 0.8457 0.6161\nRoBERTa 0.929 0.7299 0.5236 0.8232 0.6536\nLNZ (Combined) 0.8452 0.4554 0.2887 0.6273 0.4311\nLNZ (Context) 0.8233 0.4261 0.2887 0.568 0.3545\nLNZ (EntityPrior) 0.7834 0.2181 0.2248 0.4405 0.4033\nTable A3: AP per class measured on the test set. Top performance for each metric is marked as bold.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Who blames or endorses whom? entity-to-entity directed sentiment extraction in news text", "author": ["K Park", "Z Pan", "J Joo"], "pub_year": "2021", "venue": "arXiv preprint arXiv:2106.01033", "abstract": "Understanding who blames or supports whom in news text is a critical research question in  computational social science. Traditional methods and datasets for sentiment analysis are,"}, "filled": false, "gsrank": 342, "pub_url": "https://arxiv.org/abs/2106.01033", "author_id": ["xiZ1ImoAAAAJ", "dJvzKAEAAAAJ", "ePNRe-EAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:jzBfF7bHEWAJ:scholar.google.com/&output=cite&scirp=341&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D340%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=jzBfF7bHEWAJ&ei=QrWsaI2aB7_SieoPzJnloAQ&json=", "num_citations": 10, "citedby_url": "/scholar?cites=6922533687135252623&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:jzBfF7bHEWAJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2106.01033"}}, {"title": "Automated Discovery of Self-Proclaimed News Providers on Facebook", "year": "NA", "pdf_data": "Automated Discovery of Self-Proclaimed News Providers on\nFacebook\nSalim Chouaki\nLIX, CNRS, Inria, Ecole Polytechnique,\nInstitut Polytechnique de Paris\nPalaiseau, FranceMinh-Kha Nguyen\nUniversit\u00e9 Grenoble Alpes\nGrenoble, FranceLaura Edelson\nNew York University\nNew York, NY, USA\nTobias Lauinger\nNew York University\nNew York, NY, USADamon McCoy\nNew York University\nNew York, NY, USAOana Goga\nLIX, CNRS, Inria, Ecole Polytechnique,\nInstitut Polytechnique de Paris\nPalaiseau, France\nABSTRACT\nThe credibility of news obtained from Facebook has become a con-\ncern due to the ease with which individuals or groups can claim to\nbe news publishers and share news-related content. Unfortunately,\nthe lack of transparency from Facebook regarding the list of pages\nclaiming to be news media hinders comprehensive research in this\narea. This paper takes a first step towards addressing this challenge\nby proposing an intuitive methodology that uses the GNews API\nand CrowdTangle to identify self-proclaimed news providers on\nFacebook. Through this approach, we collected data from two dif-\nferent periods, revealing over 26k self-proclaimed news pages in the\nUnited States, significantly more than the known 1,553 U.S.-based\nsources listed by Media Bias Fact Check and News Guard. Addi-\ntionally, we retrieve the posting history of discovered pages. Our\nanalysis reveals several interesting findings. The discovered pages\ncollectively exhibit higher visibility and engagement than those\nlisted by Media Bias Fact Check and News Guard, emphasizing the\nimportance of studying them. We also find that, on average, 300\nnew self-proclaimed news pages are created every four months,\nthat 15% of the identified news pages are news aggregators, and 57%\ndeclare to be local news. Overall, our paper shows the challenges of\nmanually compiling an extensive list of social media news providers\nand emphasizes the need for automated approaches like ours.\n1 INTRODUCTION\nSocial media platforms have changed how users consume news\nand stay updated on current events, with nearly half of U.S. adults\nnow turning to social media, especially Facebook, as their primary\nnews source [50]. This reliance on Facebook for news brings both\nadvantages and concerns. On the one hand, it enables effortless\nnews dissemination, democratizes access to information, and allows\nusers to exchange ideas and opinions with people. On the other\nhand, many organizations have raised concerns about the platform\nfacilitating exposure to misinformation [ 2,32]. One key enabling\nmechanism is the ease with which anyone can claim to be a news\nprovider and share news-related content without verification. For\ninstance, recent reports showed the emergence of organizations\naiming to influence voters during elections by claiming to be local\nnews providers [4].\nFostering a healthy news environment requires constant mon-\nitoring and auditing of content shared by both known and less-\nknown self-proclaimed news providers. Unfortunately, having acomprehensive view remains impossible, as Facebook does not dis-\nclose the list of self-proclaimed news providers on the platform . In an\nattempt to audit the (mostly U.S.) news media ecosystem, known\njournalistic agencies, Media Bias Fact Check and News Guard, have\naggregated a list of 4,323 news media Facebook pages [ 41,42].\nAs they are the only sources, many recent news-related studies\nhave only considered established news providers listed by journal-\nists [ 23,35,39,49,51]. However, we do not know to which extent\nthese lists are comprehensive and, hence, to which extent relying\nstudies provide an extensive view of the entire Facebook news\necosystem. Even worse, to our knowledge, there are no such lists\nin countries other than the U.S., which hampers both journalistic\nand academic auditing of the news ecosystem across countries.\nIn this work, we propose a simple yet effective methodology to\ndiscover self-proclaimed news providers on Facebook (Section 3.1). Our\napproach relies on the assumption that Facebook pages claiming\nto be (and wanting to look like) news sources typically post news-\nrelated content. Therefore, our key idea is to perform a daily crawl\nthat: (1) exploits the GNews API [ 31] to get a sample of news articles\npublished by established news media in the past 24 hours and\nextract a set of corresponding keywords ; (2) uses CrowdTangle [ 19],\nan API provided by Meta, to search for Facebook posts mentioning\nthese keywords in the past 24 hours; and (3) filters only Facebook\npages that self-identify as news media. We focus in this paper on\ndiscovering news provides primarily based in the U.S. to compare\nthe effectiveness of our method against known lists from Media\nBias Fact Check and News Guard; however, our method is adaptable\nto identifying pages based in any country.\nWe deployed our methodology to gather snapshots at two peri-\nods. First, we conducted a daily detection over June 2022, identifying\n19,590 Facebook news pages. Then, we conducted a retrospective\ndetection of news pages active in October 2020 (during the U.S. pres-\nidential election) that were not deleted since, discovering 23,992\npages, including pages that have since stopped posting. Overall,\nour data collection enabled the discovery of 26k+ self-proclaimed\nnews providers on Facebook based in the U.S. Note that we simply\nidentify pages that claim to be news providers without judging\nwhether they are legitimate according to journalistic standards.\nThis is unnecessary from an auditing perspective, as a page does\nnot need to be legitimate to influence public opinion.\nWe performed several tests to evaluate the effectiveness of our\nmethod (Section 4). In terms of coverage, we find that the results\n1\nConference\u201917, July 2017, Washington, DC, USA Salim Chouaki, Minh-Kha Nguyen, Laura Edelson, Tobias Lauinger, Damon McCoy, and Oana Goga\nof our two deployments cover over 95% of the pages listed by Media\nBias Fact Check and News Guard ; hence, our method can catch well-\nknown news providers. In addition, our method catches ten times\nmore U.S.-based news providers than Media Bias Fact Check and\nNews Guard together. If we look at the rate of new discoveries per\nday, our method catches 8k+ pages in the first day, 2k+ pages in\nthe second day, and further drops to only 250 new discoveries per\nday after the first two weeks of daily crawls; suggesting that a one\nmonth crawl is approaching a high coverage. Regarding timeliness,\nwe find that 90% of pages are detected in less than ten active days.\nThe detection speed is important to capture (malicious) actors that\nare only active on specific periods.\nFinally, we analyze several characteristics of the U.S. Facebook\nnews ecosystem we identified, including page dynamics, organi-\nzational affiliations, posting behavior, and engagement statistics\n(Section 5). To perform this analysis, for each Facebook page in\nour dataset, we collected information about allthe posts published\nfrom July 2017 to July 2022, including per-post engagement sta-\ntistics. In total, we collected information about 191,182,320 posts.\nOur analysis has two end-goals: (1) offer a first insight into the\nmuch larger than previously known Facebook news ecosystem,\nand (2) compare pages listed by Media Bias Fact Check and News\nGuard with non-listed pages to analyze the relevance and need for\nautomated discovery methods. Our results show:\n(1)Visibility and engagement : While listed pages generally have\nhigher individual visibility metrics like follower counts and engage-\nment scores (in median, 86k+ followers and 6k+ interactions per\nweek for listed pages vs. 7k+ followers and 351 interactions per\nweek for non-listed pages), the combined totals of these metrics\nfor non-listed pages are higher (2.65 billion followers and 113 mil-\nlion interactions for listed pages vs. 3.51 billion followers and 113.4\nmillion interactions per week for non-listed pages).\n(2)Organizational affiliation : Our analysis reveals that 44% of\nidentified pages mention a managing organization. We retrieved\n3,043 organizations, with 406 owning multiple Facebook pages. We\nobserve that, even for organizations audited by Media Bias Fact\nCheck and News Guard, they only review a subset of managed\nFacebook pages.\n(3)Posting behavior : We find that 15% of analyzed pages are news\naggregators , 97% of which are not listed by Media Bias Fact Check\nand News Guard. This category is crucial to scrutinize as such pages\ncan easily be automated to promote specific agendas by re-sharing\nonly information aligned with their motives. Furthermore, we find\nthat 56% of analyzed self-proclaimed news pages are focused on\nlocal news , with 92% of them not listed by Media Bias Fact Check\nand News Guard. Local news are less likely to reach the radar of\njournalistic auditors and are more likely to be trusted by users [ 38],\nmaking this an important aspect to consider.\n(4)Page dynamics : We find that, on average, 300 new self-proclaimed\nnews pages are created every four months in the past 15 years. More-\nover, we see two prominent peaks in page creations in 2016 and\n2019, potentially linked to the U.S. presidential elections. Indeed\nwe do find evidence of Facebook news pages that only operated in\nthe six months before/after the U.S. 2020 presidential election.1\n1For example, \u201cLouisiana Breaking News\u201d and \u201cAmerican Herald\u201d.Overall, our finding shows the challenges of manually compiling\na comprehensive list of news sources, emphasizing the need for an\nindependent system like ours to ensure rapid and broad coverage.\nGiven the ease of claiming to be a news provider, it is essential to\ngo beyond established media outlets and study all Facebook pages\nclaiming to be news providers, irrespective of their reputation,\npopularity, or whether they create original content or are simply\ncontent farms. We are working on building and publishing with\nthis paper the largest database of self-proclaimed news providers\non Facebook across the World. We hope this extended database will\nbe useful for both journalistic and academic research.\n2 BACKGROUND\nThis section provides an overview of various aspects related to\nFacebook news pages, including their creation, verification, and\nassociation to web domains. Additionally, it introduces the Face-\nbook News Page Index, an archive for pages predominantly sharing\nnews-related content on Facebook.\n2.1 Facebook Pages\nFacebook pages provide a platform for individuals, businesses, and\norganizations to build and manage their presence on the platform.\nCreation of Facebook pages. Creating a Facebook page is a simple\nprocess that only requires a personal Facebook account [ 14]. Users\ncan initiate page creation by visiting a designated URL [ 26]. They\nare required to provide a name , select a category aligning with the\npage\u2019s purpose, and can add additional information to enhance\nthe page\u2019s description, including contact details, website links, and\nprofile and cover photos. After completing these steps, the Facebook\npage becomes active and available for posting without verifying the\naccuracy of the provided information, enabling users to claim any\ncategory, including news media.\nBlue badge verification. Facebook pages can request a blue badge\nverification from Facebook to enhance their credibility. This badge\nis a visual indicator proving that Facebook has confirmed the page\nas the authentic presence of the individual, organization, or brand\nit represents [ 9]. The process involves submitting a verification\nrequest and supplying strong proof of identity such as driver\u2019s\nlicenses, passports, national id cards, tax filing, or utility bills [ 10].\nWhile the blue badge improves the credibility of a Facebook page\nby ensuring accountability, it is essential to note that it does not\nguarantee the accuracy or reliability of the page\u2019s content.\nDomain verification. Facebook pages can link to external domains\nto claim they represent the corresponding domain. Additionally,\nthey can provide strong proof for this claim by verifying the asso-\nciated domain. This verification process involves adding a meta tag\nor uploading an HTML file to the website\u2019s root directory [ 11,17].\nAlthough domain verification could be valuable for news media\npages to help distinguish them from fake pages pretending to rep-\nresent websites, Facebook does not mandate it. Even worse, there\nis no visible distinction between verified and unverified domains.\nPage Publishing Authorization. In response to the 2016 U.S.\npresidential election controversies, Facebook introduced the Page\n2\nAutomated Discovery of Self-Proclaimed News Providers on Facebook Conference\u201917, July 2017, Washington, DC, USA\nPublishing Authorization in August 2018 to enhance page account-\nability and prevent bad actors from hiding behind fake or com-\npromised accounts [ 24]. This authorization requires the concerned\npages\u2019 admins to secure their personal accounts with two-factor\nauthentication [ 8] and confirm their primary country location, with\nnon-compliance resulting in posting restrictions [ 6,7]. It is applied\nfor pages with a \u201chigh potential reach\u201d in the U.S., India, Indonesia,\nand the E.U. [28].\nUnlike verification badges, this authorization does not confirm\na page\u2019s authenticity but focuses on securing admin accounts and\nconfirming their location. Unfortunately, Facebook does not pub-\nlicly disclose which pages undergo this process, and there is no\npublic information on what qualifies as \u201chigh potential reach.\u201d\n2.2 Facebook News Page Index\nThe Facebook News Page Index is an initiative introduced by Face-\nbook to identify pages primarily publishing news-related content [ 13].\nPage admins can apply to register their pages in this index, requir-\ning a business and a domain verification [ 15]. The applications\nundergo an internal vetting process that considers various criteria,\nincluding sharing misinformation, violations of community stan-\ndards (e.g., hate speech), engaging in clickbait and engagement bait,\nand other factors not disclosed by Facebook [ 16,25]. Pages included\nin the News Page Index are exempted from the ads authorization\nand disclaimer processes when promoting social issues or political\nadvertisements [12, 13].\nParticipation in the Facebook News Page Index is voluntary.\nThus, not all self-proclaimed news pages are included in this index.\nRegrettably, Facebook has not made the list of pages within this\nindex publicly available and has declined our access request.\n3 METHOD AND DATA COLLECTION\nThis section first describes our methodology to identify self-proclaimed\nnews providers on Facebook. For simplicity, we sometimes call them\nFacebook news pages . We then describe our deployments and the\ndifferent data collections we performed for this study.\n3.1 Page Discovery Method\nOur key assumption is that news providers need to publish content\ndiscussing current events to inform their audiences and maintain\ninteractions. Although there can be specialized news websites fo-\ncusing on niche topics, news organizations that can potentially\ninfluence public opinion, and which we would like to monitor and\naudit, need (at least at some point) to discuss current affairs.\nOur approach involves three steps (Figure 1): (1) collect keywords\ncorresponding to current events, (2) search for Facebook posts that\nmention these keywords, and (3) filter the resulting Facebook posts\nto include only those from U.S.-based pages that share content in\nEnglish and claim to be news providers. Our method is designed to\nperform daily the following tasks:\n(1) Extracting keywords corresponding to daily news. We\ngather popular news headlines from Google News using the GNews\nAPI [ 31]. This API provides access to top-ranked and top-ranked-\nby-topic news articles across eight topics: World, Nation, Business,\nTechnology, Entertainment, Sports, Science, and Health. We extracttop-ranked and top-ranked-by-topic articles across the eight cate-\ngories and limit our search to articles published in English within\nthe past 24 hours. The median number of daily news headlines re-\ntrieved for each topic is as follows: General (37), World (67), Nation\n(61), Business (69), Technology (71), Entertainment (67), Sports (65),\nScience (30), and Health (40).\nNext, we employ Yake [ 52], a Python library for selecting the\nmost important keywords in a text. For every title of a news article\nwe instruct Yake to output the most relevant two tuples made of\ntwo or more keywords. For instance, Yake generates the tuples\n\u201cinvestigation into Trump\u201d and\u201csocial network deal\u201d for an article\nin June 2022.2This step yields a daily list of tuples made of two or\nmore keywords, with a median of 1,002 tuples generated each day.\n(2) Collecting Facebook posts covering daily news. We em-\nploy the CrowdTangle API, a tool provided by Meta for academics,\nto search for content on Facebook [ 18,19]. Precisely, we use the\nposts-search end-point that allows retrieving posts matching given\nparameters and search terms [ 21]. For each keyword tuple obtained\nin the previous step, we send a request to the API and limit the\nsearch window to 24 hours. We collect all the returned posts for each\nrequest, with a median of 343k posts per day. Note that CrowdTan-\ngle returns posts from tracked pages only. The API automatically\ntracks all pages with more than 25,000 followers and all verified\nprofiles, in addition to pages manually added by users [20].\nFor each post, the API returns various attributes such as the\npost\u2019s text, published time, language, and engagement level , along\nwith information about the publisher, such as the page\u2019s name, ID,\nverification status, category, andcountry of the page\u2019s admin .\n(3a) Category filtering. The prior step provides a list of Facebook\npages discussing current news. Many of these pages do not claim\nto be news providers. We consider a Facebook page to be a self-\nproclaimed news provider if, on its About page, it has put one of\nthe Facebook categories in Table 1. While some categories, like\n\u201cNewspaper\u201d or \u201cNews & media websites,\u201d are clear indicators that\na page claims to be a news provider, others, such as \u201cMedia\u201d or\n\u201cShow,\u201d are less specific. We opt for a broader net to ensure high\ncoverage and avoid missing relevant pages, particularly since many\nnews providers listed by Media Bias Fact Check or News Guard\nhave a general \u201cMedia\u201d category on Facebook.\n(3b) Location and language filtering. We filter U.S.-based pages\nthat share English content. Note that, this method can be adapted\nfor pages from different locations publishing in various languages.\nWe first enhance the attributes describing these pages by leverag-\ning the Facebook Ad Library, a publicly accessible platform listing\nFacebook ads [ 27]. This library provides details about advertiser\npages such as the the name and country of the organization that\nmanages the page and the main language used in its posts. Each page\nhas its dedicated web page within the Ad Library site, accessible\nvia a specific URL format.3Importantly, we discover that the Ad Li-\nbrary provides information for all pages, including those that have\nnever promoted ads on Facebook. We verified this with a test using\n2https://www.axios.com/2022/06/13/government-expands-investigation-trump-\nsocial-network-deal\n3https://www.facebook.com/ads/library/?active_status=all&ad_type=all&country=\nALL&view_all_page_id={page_id}\n3\nConference\u201917, July 2017, Washington, DC, USA Salim Chouaki, Minh-Kha Nguyen, Laura Edelson, Tobias Lauinger, Damon McCoy, and Oana Goga\nFigure 1: Diagram representing the full methodology for discovering self-proclaimed news providers\u2019 Facebook pages.\nFacebook Category News Guard & Media Bias Fact CheckSnapshot\nJune 2022Snapshot\nOctober 2020Overlap\nBroadcasting &\nmedia company283 2,864 3,480 2,561\nMedia 11 447 614 354\nMedia/news\ncompany421 6,363 7,588 5,346\nNewspaper 448 2,580 3,238 2,349\nNewsstand 0 8 12 6\nNews\npersonality10 2,747 3,699 2,265\nNews &\nmedia website379 4,412 5,124 3,788\nShow 0 129 168 89\nSocial Media\nAgency1 40 69 24\nAll pages with a\nnews category1,553 19,590 23,992 16,782\nOther categories 1059 0 0 0\nTable 1: Facebook categories related to news media and the corresponding number of pages in Media Bias Fact Check and News\nGuard listings, Snapshot_June_2022 ,Snapshot_October_2020 , and in the overlap between the two snapshots.\nTop other categories include: Nonprofit Organization, Website, Publisher, Community, Political Organization, Entertainment\nWebsite, Magazine, Interest, and Public Figure.\na newly created page, confirming its presence in the Ad Library\nfew days after its creation.\nWe use Selenium [ 47], a Python package for automating browser\ninteractions, to retrieve information from each page\u2019s About section\nin the Ad Library.4We have created a dedicated Facebook account\nfor this task and have implemented randomized delays of 1 to 4\nseconds between each iteration to avoid bot detection.\nThen, to identify U.S.-based news pages, we use two attributes:\n\u201ctopAdminCountry\u201d provided by CrowdTangle, indicating the page\u2019s\nadmin\u2019s country, and \u201corganizationCountry\u201d from the Facebook\nAd Library, indicating the page\u2019s organization\u2019s country. We select\n4For example, we access the following URL for CNN: https://www.facebook.com/\nads/library/?active_status=all&ad_type=all&country=ALL&view_all_page_id=\n5550296508pages where either of these attributes has \u201cU.S. \u201d as a value. Finally, to\nidentify pages primarily using English, we use the \u201cmainLanguage\u201d\nattribute from the Facebook Ad Library and select only pages with\nthe value \u201cen. \u201d\n3.2 Datasets\nWe performed our first data collection in June 2022, executing the\nwhole process once every day from June 1st to 30th, resulting in\nthe detection of 43,436 self-proclaimed news pages. Among these,\n19,590 pages are U.S.-based and primarily share content in English.\nWe refer to this list as Snapshot_June_2022 .\nWe conducted a second retrospective data collection to identify\nactive news pages from October 1st to 30th, 2020, a sensitive period\nencompassing the 2020 U.S. presidential elections. This is possible\n4\nAutomated Discovery of Self-Proclaimed News Providers on Facebook Conference\u201917, July 2017, Washington, DC, USA\nas both the GNews and the CrowdTangle API support historical\ndata searches within specific date ranges. We gathered data on\n46,758 active news pages, with 23,992 being U.S.-based and mainly\nusing English. We refer to this list as Snapshot_October_2020 .\nNote that CrowdTangle does not return results for pages or posts\nthat have been deleted. As a result, the dataset we obtained might\nrepresent a subset of the pages that were available in October 2020.\nAcross the two data collections, we compiled a total of 55,941\ndistinct self-proclaimed news pages, with 26,800 being U.S.-based\nand mainly publishing content in English.\n3.3 Collection of historical posts\nFor each identified page, we get its posting history between July\n2017 and July 2022 - i.e., all the content they have published within\nthis timeframe. This step is not essential for discovering Facebook\nnews pages but is important to analyze pages\u2019 posting behavior\nand users\u2019 engagement with their content. For this, we use the\nCrowdTangle dashboard\u2019s web interface to create lists of the pages\nfor which we want to download the posting histories. Since Crowd-\nTangle only allows downloading files with a maximum of 10,000\nposts, we have manipulated the browser to automate the process\nand select different pages and time ranges for each download, such\nthat we have complete post collections. Each post is characterized\nby the posting time, the editing time (if the post was edited), the\ntextual content, the type (link post, text post, image post, video post,\nor live video post), the post URL, the media URL, the landing URL,\nandthe engagement scores of the post . Moreover, we have additional\ninformation about the publisher with each post, such as the number\nof followers at posting time .\nWe collected historical data for all pages in both the Snap-\nshot_June_2022 andSnapshot_October_2020 datasets, cover-\ning the period from July 2017 to July 2022. In total we collected\n191,182,320 posts. Note that CrowdTangle does not provide posts\nthat have been deleted or made private. Therefore, we might have\ngaps in the complete posting history for certain pages.\nOur news discovery code and datasets are available at https:\n//anonymous.4open.science/r/News_discovery-3B08.\n4 VALIDATION\nOur method aims to capture self-proclaimed news provides address-\ning current events in their posts. For this, we rely on external APIs\nand several imperfect heuristics that can impact the effectiveness of\nthe method. Hence, this section investigates: (1) the extent to which\nthe method can capture a comprehensive list of news media pages;\n(2) the speed of capturing active Facebook news pages; and (3) the\nextent to which the captured news pages are indeed self-proclaimed\nnews media addressing current events.\n4.1 Coverage Analysis\nIdeally, we would want a method capable of identifying allactive\nself-proclaimed news providers on Facebook. However, there is no\nexisting ground truth to evaluate against. Therefore, we employ\ntwo proxies to measure the coverage of our method: (a) the extent\nto which it can capture well-known news media and (b) the rate\nat which it discovers new unseen pages. A high discovery rate\nindicates the difficulty in achieving comprehensive coverage since\n2020-10-01 2020-10-08 2020-10-15 2020-10-22 2020-10-29\nDays0500010000150002000025000Number of pagesNon-MBFC/NG pages\nMBFC/NG pagesFigure 2: Cumulative number of pages detected by our\nmethod each day in October 2020. In green are pages listed\nby Media Bias Fact Check or News Guard, and in blue are\npages not listed.\nthere will inevitably be more pages to discover, while a low rate\nsuggests we may be close to achieving high coverage.\nWe acquired a list of well-known news providers on Facebook\nfrom Edelson et al. [ 23], a study aggregating news domains listed\nby Media Bias Fact Check (MBFC) and News Guard (NG) and their\ncorresponding Facebook pages. This list was compiled in July 2020\nand contains 4,323 news media Facebook pages. Upon verifica-\ntion, many of these pages are not U.S.-based (e.g., 24ur.com). To\nensure a fair comparison, we excluded non-U.S.-based pages by\nusing the topAdminCountry and organisationCountry fields, pro-\nvided by CrowdTangle, to retain 2,624 U.S.-based Facebook pages.\nFurthermore, the MBFC/NG list includes pages that do not claim\nto be news providers (e.g., Public Interest Legal is categorized as\n\u201cLawyer & Law Firm,\u201d and Money and Markets as an \u201cInvesting\nService\u201d). Therefore, we further filter the MBFC/NG list to include\nonly 1,565 pages with one of the news media categories listed in\nTable 1. Finally, we discarded four pages for which we could not\nretrieve data from CrowdTangle (due to their deletion) and eight\nnon-English-sharing pages. As a result, we have a list of 1,553\nU.S.-based English-sharing Facebook news pages that we consider to\nevaluate the coverage of our method.5\nOur analysis reveals that Snapshot_June_2022 successfully cap-\ntures 89% of the U.S.-based English-sharing MBFC/NG pages, while\nSnapshot_October_2020 captures 94% of them. The combined\nscope of both snapshots includes 95%of the MBFC/NG pages, cor-\nresponding to 1,474 out of 1,553 pages. These results prove that our\nmethod can capture well-known news media and only misses 5%\nof them (which we further investigate in the next section).\nTo provide an alternative perspective, Figure 2 presents the cumu-\nlative number per day of Facebook pages detected during October\n2020. The figure shows a high discovery rate in the first seven days,\nwith 8,781 pages on the first day and 15,053 pages within the first\nfive days. However, the discovery rate significantly dropped after-\nward, with an average of 250 discovered pages per day in the last\ntwo weeks of data collection. A low rate in the second part of the\ncrawl suggests that our method may be approaching high coverage.\n5Note that the fact that MBFC/NG contains many non-U.S. based pages and pages not\nclaiming to be news providers does not reflect badly on our method (or theirs). First,\nour method can be used to extend the list to other countries, and second, we can easily\nextend the collection to other Facebook categories.\n5\nConference\u201917, July 2017, Washington, DC, USA Salim Chouaki, Minh-Kha Nguyen, Laura Edelson, Tobias Lauinger, Damon McCoy, and Oana Goga\n0 5 10 15 20 25 30\nNumber of active days0510152025303540Number of posts per active dayMBFC/NG covered\nMBFC/NG missed\nFigure 3: Number of active days and median number of posts\nper active day for MBFC/NG pages during October 2020.\n4.2 Missed Pages Analysis\nThe previous section shows that our method failed in detecting\n79 (5%) MBFC/NG news pages. Among these, 37 pages remained\ninactive (i.e., did not post any content) during our two data col-\nlection periods. Hence, we are left with 42 active Facebook news\npages we failed to detect. Our analysis of their posting activity\nduring October 2020 reveals these pages displayed significantly\nlower posting frequency than the pages we successfully identified.\nPrecisely, half of these undetected pages only published a median\nof one post per active day compared to 13 posts per active day for\ndetected pages (as illustrated in Figure 3). Understandably, pages\nthat produce limited content are less likely to meet our search filters.\nThus, our ability to detect such pages is lowered.\nFurthermore, we manually inspected posts from the ten most\nactive non-detected pages (at least six posts in median per active\nday) to understand why they were not identified. Our findings re-\nveal that five of these pages treat specific niche topics and did not\npublish content relevant to current news during our data collection.\nThese pages include BleepingComputer, The Scientist, Community\nImpact, Face2Face Africa, and The Vintage News, and their respec-\ntive topics, as described in their about sections, are technology,\nscience, hyperlocal news, black history, and vintage news. Given\nthe thematic nature of their posts, they are less likely to align with\nthe news headline-based filtering we employ.\nThe remaining five pages actively posted worldwide and U.S.-\nrelated news content. However, our method did not detect them;\nnone of their posts matched our keyword searches in CrowdTangle.\n4.3 Timeliness Analysis\nThe dynamic nature of the Facebook news ecosystem enables mali-\ncious third parties to create several pages, share false or misleading\ncontent, and rapidly delete them. It is crucial for a method that aims\nto identify active news sources to detect such pages before they get\ndeleted. Therefore, we evaluate the timeliness of our method.\nTo measure the time our method took to detect each page in our\ndataset, we count the number of active days from a page\u2019s first post\nin our crawling window to its detection time. We only consider\ndays during our data collection period when pages were active, as\n0 5 10 15 20 25 30\nNumber of days0.00.20.40.60.81.0Cumulative distribution functionSnapshot_October_2020\nSnapshot_June_2022Figure 4: Cumulative distribution of the number of (active)\ndays our method required to detect each Facebook news page\ninSnapshot_June_2022 andSnapshot_October_2020 .\nour method cannot detect pages that do not publish anything (e.g.,\nif a page was active only on \u201c2020-10-01\u201d and \u201c2020-10-10\u201d, and\nwe detected it on \u201c2020-10-10\u201d, we consider that the duration for\ndetecting this page is 2 days). Figure 4 presents the distribution of\nthe number of (active) days our method required to detect each page\nwithin both Snapshot_June_2022 andSnapshot_October_2020 .\nThe figure demonstrates the rapid detection of most Facebook news\npages, with a median detection time of two active days and more\nthan 90% detected in less than ten active days.\n4.4 Relevancy Analysis\nOur method aims to identify self-proclaimed news pages sharing\nposts related to current events. However, it employs a few imperfect\nheuristics that can affect the relevancy of the pages returned:\n(1) To search pages discussing current events, we rely on a list of\nkeyword tuples. Some keyword tuples may be very general and not\nnecessarily represent current events. For example, some extracted\nkeywords include: arab country6and home sales.7\n(2) To select self-proclaimed news providers, we refer to the cate-\ngories listed in Table 1. Some of these categories are broad and can\ninclude pages not presenting themselves as news media.\nTo understand the relevancy of pages discovered by our method,\nwe randomly sampled 50 pages from Snapshot_June_2022 and\nSnapshot_October_2020 that were not covered by MBFC/NG. We\nmanually scrutinized the posts shared by each page in the sample\nto assess whether the page consistently posted content related\nto current news and events. We reviewed 20 random posts from\neach page during October 2020 or June 2022 and classified posts\nas news-related if they discussed current events, irrespective of\nthe specific subject. A Facebook page was deemed a relevant news\nsource if at least 50% of the inspected posts were news-related.\nTwo co-authors of the paper conducted separate evaluations and\nthe results were consistent, with 74% of the examined pages being\nclassified as relevant news sources . For verification, we list here the\nrandom sample of 50 pages and our relevancy classification.\nOne way to reduce the number of irrelevant pages is to apply\nstricter filters. For instance, we could consider including a Facebook\npage only if our method detected it on multiple distinct days, hinting\n6Extracted from https://www.cnbc.com/2022/05/31/israel-signs-trade-deal-with-uae-\nits-biggest-with-any-arab-country.html\n7Extracted from https://edition.cnn.com/2022/06/12/business/luxury-home-sales-fall-\nredfin/index.html\n6\nAutomated Discovery of Self-Proclaimed News Providers on Facebook Conference\u201917, July 2017, Washington, DC, USA\n0 5 10 15 20 25 30\nNumber of times0.00.20.40.60.81.0Cumulative distribution functionSnapshot_October_2020\nSnapshot_June_2022\nFigure 5: Cumulative distribution of the number of distinct\ndays on which each page was detected by our method in\nSnapshot_June_2022 andSnapshot_October_2020 .\nthat this page shares posts about current events in a regular rather\nthan occasional manner. Figure 5 presents the distribution of the\nnumber of distinct days on which each page was detected by our\nmethod. We can see that 19% of Snapshot_June_2022 pages and\n14% of Snapshot_October_2020 pages were detected only once,\nand the median number of distinct days on which pages were\ndetected is five days for Snapshot_June_2022 and seven days\nforSnapshot_October_2020 . We performed a second manual\ninvestigation of 20 random non-listed pages selected from three\ndistinct categories: pages detected on one or two different days,\npages detected on at least five days, and pages detected on at least\nseven days. Our results show that 50%, 80%, and 85% pages were\ndeemed relevant in each category. Hence, pages detected more\nfrequently are more likely to be pertinent news sources.\nStricter filters might come at the cost of lower coverage. The list\nof pages detected on five or more days covers 90% of pages listed\nby Media Bias Fact Check and News Guard (compared to 95% when\nconsidering all pages). Our method can be adapted depending on\nthe goal of the study.\n5 NEWS ECOSYSTEM ANALYSIS\nThis section analyzes the characteristics of self-proclaimed news\nproviders our method identified. We focus on non-listed pages\ndetected in at least five daily crawls to reduce noise. For comparison,\nwe consider the discovered listed pages without applying the same\nfilter, as Media Bias Fact Check and News Guard have already\nclassified them as relevant news sources. Our analysis includes\n16,559 pages; 1,474 listed pages and 15,085 non-listed pages.\n5.1 Dynamics\nGiven the risk of creating news pages to disseminate false or biased\ninformation, the first question we go after is how dynamic is the\nnews ecosystem: (1) how many new news pages are created each\nyear; and (2) whether they have a stable activity over time or their\nactivity only revolves around important events such as elections.\nCreation. Figure 6 presents the timeline of the creation of news\npages in our dataset. The figure shows that 297 new news pages\nin the median were created on Facebook every four months in the\npast 15 years. Notably, non-listed pages tend to be more recent,\nwith over 50% emerging after 2012, in contrast to the listed pages,\nwhere only 18% were created post-2012. We particularly see two\n2007-01 2008-01 2009-01 2010-01 2011-01 2012-01 2013-01 2014-01 2015-01 2016-01 2017-01 2018-01 2019-01 2020-01 2021-01 2022-01\nYear02004006008001000Number of pagesMBFC/NG pages\nNon-MBFC/NG pagesFigure 6: Creation time of Facebook pages: MBFC/NG pages\nvs. non-listed pages. Each point represents the number of\npages created in a four-months period.\n2018-07 2018-11 2019-03 2019-07 2019-11 2020-03 2020-07 2020-11 2021-03 2021-07 2021-11 2022-030123Number of posts (x 106)\nFigure 7: Combined total number of posts over all discovered\npages for each month between July 2018 and July 2022\nprominent peaks in the creation time in 2016 and 2019 that might\nbe linked to the U.S. 2016 and 2020 presidential elections.\nActivity. We explore whether identified self-proclaimed news pages\nexhibit consistent or intermittent posting activity. Figure 7 presents\na timeline of the combined number of posts across all pages per\nmonth. The figure shows that the total number of posts does not\nconsistently increase despite the continuous creation of pages, sug-\ngesting that certain pages stop being active or are only active for\nspecific periods. For instance, we identified 53 news pages that\noperated only from January 2020 to June 2021 (6 months before\nand after the U.S. presidential election).\nThese findings show the ever-changing nature of the Facebook\nnews ecosystem, with new pages regularly emerging. Our method\neffectively detects these pages, particularly if used continuously.\n5.2 Affiliations\nTo promote content associated with political and social issues on\nFacebook, pages are required to disclose and verify their managing\norganization [ 3]. We retrieved this information from the Facebook\nAd Library for 7,277 (44%) self-proclaimed news providers pages.\nWe have identified 3,043 distinct organizations, of which 406 own\nat least two pages. Table 2 presents organizations with the largest\nnumber of Facebook pages. This table uncovers several insights.\n7\nConference\u201917, July 2017, Washington, DC, USA Salim Chouaki, Minh-Kha Nguyen, Laura Edelson, Tobias Lauinger, Damon McCoy, and Oana Goga\nOrganization name # Listed # Nonlisted\nParticle Media, Inc. 0 928\nPlanck, LLC 1 552\nGannett Satellite\nInformation Network, LLC88 106\nGatehouse Media LLC 72 56\nTownsquare Media, INC. 3 113\nLee Enterprises Incorporated 57 50\nEntercom Communications\nCORP.2 81\nGray Television, INC. 54 27\nBuzzFeed 2 50\nSinclair Broadcast Group Inc. 37 14\nTAP Into Local LLC 1 49\nAdvance Local Media LLC 12 36\nCollege Spun Media INC. 0 44\nOn3 Media, LLP 0 44\nInsider, INC. 2 39\nAlpha Media LLC 0 37\nHeavy, INC. 1 35\nCANTATA MEDIA LLC 1 32\nHearst 18 14\nIHEARTMEDIA, INC. 0 32\nTable 2: Top organizations and the number of Pages they\nmanage that are listed by Media Bias Fact Check and News\nGuard, and the number of Pages not listed.\nFirst, some news organizations possess multiple Facebook news\npages, none of which are present on Media Bias Fact Check or\nNews Guard lists. Examples include \u201cParticle Media, Inc.\u201d and \u201cOn3\nMedia, LLP.\u201d Second, even organizations audited by News Guard\nand Media Bias Fact Check, such as \u201cGatehouse Media LLC\u201d and\n\u201cSinclair Broadcast Group Inc.,\u201d have numerous Facebook pages\nthat are not listed. For instance, while \u201cThe National Desk - TND\u201d\nis included in the MBFC/NG list, \u201cKlew News\u201d, managed by the\nsame organization (Sinclair Broadcast Group Inc.), is not listed.\nThese findings underscore the relevance of the self-proclaimed\nnews sources identified by our method.\n5.3 Types\nThe section explores various categories of self-proclaimed news\nproviders, including news aggregators and local news sources.\nNews Aggregators. Recent reports have raised concerns about the\nrise of news aggregators, pages that republish news from various\nsources without creating original content, potentially driven by\nspecific agendas and selectively sharing information aligning with\ntheir motives [ 5]. This section investigates the prevalence of news\naggregators among self-proclaimed news providers.\nWe analyze landing URLs in pages\u2019 posts from July 2017 to July\n2022. We first unshorten links to various URL shortening servicesto obtain the actual landing URL.8Then, we extract the distinct do-\nmains and compute the proportion of posts leading to each domain.\nWe use the \u201ctldextract\u201d Python package [ 48] and the \u201cPublic Suffix\nList\u201d [ 45] for this purpose. Note that we only consider the registered\ndomain, discarding the complete domain name. For instance, if a\npage shares posts leading to edition.cnn.com and us.cnn.com, we\nconsider only the unique registered domain cnn.com.\nWe assume that news creators predominantly share posts lead-\ning to a single domain, while news aggregators share posts with\nURLs spanning multiple websites, lacking a predominant domain.\nTherefore, we classify a page as a news aggregator if it does not\nhave a predominant landing domain, meaning no domain accounts\nfor 50% of the page\u2019s posts.\nWe find that 15% of the identified pages (2,508 pages) are news\naggregators. The vast majority of these aggregators (97%) were not\nlisted in the MBFC/NG list, like \u201cEverything Inspirational.\u201d Addi-\ntionally, we find that a median news aggregator has posted URLs\nfrom 123 distinct domains, and 1% of aggregators have shared over\n1,000 domains, such as \u201cTully News.Info.\u201d\nThese results underscore another dimension of the relevance\nof the self-proclaimed news pages identified by our method. The\nmethod allows discovering news aggregators, most of which are\nnot listed by Media Bias Fact Check and News Guard.\nLocal news We explore the geographical coverage of self-proclaimed\nnews providers. We assume that pages primarily focused on local\nnews at a city or state level will explicitly mention the correspond-\ning locations in their About sections. Therefore, we analyze all\npages\u2019 names and About section descriptions and classify them as\nlocal if they mention a city or a state.\nFor this purpose, we utilize the locationtagger Python library [ 46],\nwhich employs Named Entity Recognition techniques to extract\nlocation information, such as countries, regions/states, and cities,\nfrom input text or URLs. This library provides geographical infor-\nmation in three categories: cities, states, and countries. If a city or\nstate is mentioned in the page\u2019s name or about section, we classify\nthe page as a local news source. Similarly, if a country is mentioned,\nwe identify the page as a source of national news content.\nWe extracted geographical data from 57% (9,452) of the self-\nproclaimed news pages. Pages lacking geographical information\nin their names or About sections are more likely to be national or\nglobal news sources. We find that 56% of analyzed pages (9,367) are\ndedicated to local news, with 52% focusing on city-level news and\n4% on state-level news. Noteworthy, 92% of these local news pages\nare not listed by Media Bias Fact Check and News Guard.\n5.4 Engagement\nThis section analyzes the extent to which users follow and interact\nwith content from self-proclaimed news providers, which are valu-\nable indicators of pages\u2019 visibility and potential impact on users.\nFigure 8 presents the cumulative distribution of follower counts,\nand Figure 9 the cumulative distribution of average weekly interac-\ntions for discovered pages. The figures show that non-listed pages\ngenerally have significantly fewer followers (7,576 in median) and\nengagement scores (351 interactions per week in median) than listed\n8The list of URL shorteners we consider: bitly.com, cutt.ly, ow.ly, rebrandly.com, short-\nurl.at, tiny.cc, tinyurl.com, t.ly, trib.al, and usehyperlink.com.\n8\nAutomated Discovery of Self-Proclaimed News Providers on Facebook Conference\u201917, July 2017, Washington, DC, USA\n0100101102103104105106107108\nnumber of followers0.00.20.40.60.81.0cumulative distribution functionMBFC/NG pages\nNon-MBFC/NG pages\nFigure 8: CDF of the number of followers for Facebook\npages listed by MBFC/NG and Facebook pages not listed by\nMBFC/NG but discovered by our method.\n101\n101103105107\nAverage number of interactions0.00.20.40.60.81.0Cumulative distribution functionMBFC/NG pages\nNON-MBFC/NG pages\nFigure 9: Cumulative distribution of the average number of\ninteractions per active week for each Facebook news page.\npages (86,817 followers and 6,868 interactions per week). However,\nwe find that the total followers and interaction scores across non-\nlisted pages (3,512,253,595 followers and 113,401,864 interactions\nper week) are higher than those of listed pages (2,651,529,840 fol-\nlowers and 112,974,157 interactions per week). Hence, non-listed\npages have slightly greater overall visibility (as measured by fol-\nlowers and engagement) than listed pages, making them important\nto scrutinize and consider for news and misinformation studies.\n6 LIMITATIONS\nOur methodology has some limitations caused by the API it relies on.\nFirst, we depend on GNews for sourcing daily news headlines and\nextracting search keywords. Consequently, the range of news items\nwe can cover is tied to the news items returned by GNews. Second,\nto retrieve Facebook posts and pages, we rely on CrowdTangle,\nwhich exclusively returns posts from actively tracked pages. The\nAPI automatically tracks all pages with over 25,000, verified pages,\nand pages manually added by users. As a result, our methodology\nfails to identify news-related, non-verified pages with fewer than\n25,000 followers that were not added by users. Finally, CrowdTangle\ndoes not provide access to posts that have been deleted or set to\nprivate. This implies that (a) we may have missed some deleted\nnews pages in our retrospective detection, and (b) we may not have\nconsidered the complete posting history of certain pages in our\nanalysis. Nevertheless, despite these limitations, our approach has\nproven to be effective in uncovering a much larger dataset of news\nsources on Facebook than was previously known.7 RELATED WORK\nThere is a vast literature exploring online news exposure and con-\nsumption characteristics which is complementary to our work. One\nclass of studies focused on news shared on social media [22,23,30,\n33,43]. For instance, Edelson et al. [ 23] employed CrowdTangle\nto examine the posting history of pages sourced from NewsGuard\nand Media Bias Fact Check and evaluate the scale and engagement\nscores of posts containing misinformation. On a different direction,\nGuess et al. [ 33] examined the individual-level characteristics of\nusers associated with sharing false articles on Facebook.\nA second class of studies has mainly focused on news consump-\ntion on news media websites [ 1,29,34\u201337,40,44,49]. For instance,\nHorne et al. [ 37] present a dataset of news articles from 313 U.S.\nnews outlets, Agarwal et al. [ 1] consider 103 sources to analyze the\nIndian news media landscape, and Scharkow et al. [ 49] consider 319\nnews domains to study the impact of news aggregators on news\nexposure political diversity. All these studies analyzed only a small\nset of news sources listed by journalists. We believe such studies\ncould benefit from methodologies and datasets like ours, allowing\nfor a more comprehensive news media analysis.\n8 CONCLUDING DISCUSSION\nOur method offers a solid starting point for future research. It\nprovides a first step towards addressing a foundational problem\nfor the community posed by the lack of transparency from online\nplatforms. Facebook and similar social media do not make the index\nof all self-proclaimed news providers public. We did attempt to ask\nFacebook for such information, but our request has been denied.\nWe hope this paper brings awareness that many news providers fly\nunder the radar and are not covered by known lists such as Media\nBias Fact Check and News Guard and pushes platforms to provide\nmore transparency in the social media news ecosystem. Moreover,\nour work opens the more general question of how to define and\nidentify news providers. For instance, pages predominately sharing\nnews content but not self-declaring a news-related category are not\nconsidered by our method and might not be identified by journalists.\nWe hope our extensive list will assist journalists in establishing\nprecise criteria for what constitutes a news provider, as our dataset\ncontains several illustrative examples.\nThe European Union has recently passed a legal framework, the\nDigital Services Act, that requires online platforms to share data\nwith researchers and regulators for assessing systemic risks. As the\nEuropean Commission is still defining the data access procedures,\nwe believe that having an index of self-proclaimed news providers\nis essential to understanding and mitigating misinformation and\nmanipulation risks and should be a high priority. Alternatively,\nCrowdTangle could allow searching pages based on their category.\nThe lack of this functionality makes it challenging to identify news\npages and almost impossible to have complete coverage. Moreover,\nwe argue that all self-proclaimed news providers\u2019 pages should\nundergo the same verification processes as pages wanting to place\npolitical ads, providing verifiable information on the user or or-\nganization behind the page. In addition, to reduce impersonation,\nFacebook should require domain verification for all self-proclaimed\nnews pages that want to list a website link in their About page.\n9\nConference\u201917, July 2017, Washington, DC, USA Salim Chouaki, Minh-Kha Nguyen, Laura Edelson, Tobias Lauinger, Damon McCoy, and Oana Goga\nFinally, providing aggregated audience statistics would serve as a\nvaluable proxy for determining a page\u2019s location focus.\nOverall, this paper proposes a method employing available tools\nfor researchers, such as the GNews API and the CrowdTanble API,\nto identify self-proclaimed news providers on Facebook. We im-\nplement this method to discover over 26k U.S.-based news pages,\nsignificantly more than the 1,553 listed by Media Bias Fact Check\nand News Guard. Consequently, previous studies relying solely on\nthese two agencies provide a restricted perspective of exposure\nto news, especially since we show the relevance of the additional\npages we discover.\nREFERENCES\n[1]Vibhor Agarwal, Yash Vekaria, Pushkal Agarwal, Sangeeta Mahapatra, Shounak\nSet, Sakthi Balan Muthiah, Nishanth Sastry, and Nicolas Kourtellis. 2021. Under\nthe Spotlight: Web Tracking in Indian Partisan News Websites. Proceedings of\nthe International AAAI Conference on Web and Social Media .\n[2]Michael Barthel, Amy Mitchell, and Jesse Holcomb. 2016. Many Americans believe\nfake news is sowing confusion. https://www.journalism.org/2016/12/15/many-\namericans-believe-fake-news-is-sowing-confusion/\n[3]Ben Matthews. 2022. How to get authorisation to run political and so-\ncial issue ads on Facebook and Instagram. Retrieved 5 November 2023\nfrom https://empower.agency/how-to-get-authorisation-to-run-political-and-\nsocial-issue-ads-on-facebook-and-instagram/\n[4]Priyanjana Bengani. 2019. Hundreds of \u2018pink slime\u2019 local news outlets are\ndistributing algorithmic stories and conservative talking points. Columbia\nJournalism Review (2019). https://www.cjr.org/tow_center_reports/hundreds-\nof-pink-slime-local-news-outlets-are-distributing-algorithmic-stories-\nconservative-talking-points.php\n[5]Priyanjana Bengani. 2021. Advocacy groups and Metric Media collaborate on local\n\u2018community news\u2019. Columbia Journalism Review (2021). https://www.cjr.org/\ntow_center_reports/community-newsmaker-metric-media-local-news.php\n[6]Facebook Business. 2023. Get authorized to manage Pages with large audiences.\nRetrieved 5 November 2023 from https://www.facebook.com/business/m/one-\nsheeters/page-publishing-authorization\n[7]Facebook Help Center. 2023. Get authorized to post or interact as your\nPage. Retrieved 5 November 2023 from https://www.facebook.com/help/\n1939753742723975\n[8]Facebook Help Center. 2023. How wo-factor authentication works on Face-\nbook. Retrieved 5 November 2023 from https://www.facebook.com/help/\n148233965247823\n[9]Facebook Help Center. 2023. Request a verified badge on Facebook. Retrieved 5\nNovember 2023 from https://www.facebook.com/help/1288173394636262\n[10] Facebook Help Center. 2023. Verify Your Page or Profile. Retrieved 5 November\n2023 from https://www.facebook.com/help/contact/295038365360854\n[11] Meta Business Help Center. 2023. About domain verification in Meta Business\nManager. Retrieved 5 November 2023 from https://www.facebook.com/business/\nhelp/286768115176155\n[12] Meta Business Help Center. 2023. About News Page index. Retrieved 5 November\n2023 from https://www.facebook.com/business/help/377680816096171\n[13] Meta Business Help Center. 2023. About News Pages Index. Retrieved 5\nNovember 2023 from https://www.facebook.com/business/help/377680816096171\n[14] Meta Business Help Center. 2023. How to create a new Page on Facebook.\nRetrieved 5 November 2023 from https://www.facebook.com/business/help/\n1199464373557428?id=418112142508425\n[15] Meta Business Help Center. 2023. Register your News Page. Retrieved 5\nNovember 2023 from https://www.facebook.com/business/help/316333835842972\n[16] Meta Business Help Center. 2023. Registration guidelines for the news Page\nindex. Retrieved 5 November 2023 from https://www.facebook.com/business/\nhelp/270254993785210\n[17] Meta Business Help Center. 2023. When to use domain verification to verify\nyour business. Retrieved 5 November 2023 from https://www.facebook.com/\nbusiness/help/245311299870862\n[18] CrowdTangle. 2021. CrowdTangle access criteria. Retrieved 5 November 2023\nfrom https://www.crowdtangle.com/request\n[19] CrowdTangle. 2023. A tool from Meta to help follow, analyze, and report on\nwhat\u2019s happening across social media. Retrieved 5 November 2023 from https:\n//www.crowdtangle.com/\n[20] CrowdTangle. 2023. What data is CrowdTangle tracking? Retrieved 5 Novem-\nber 2023 from https://help.crowdtangle.com/en/articles/1140930-what-data-is-\ncrowdtangle-tracking\n[21] CrowdTangle API. 2021. post-search end-point. Retrieved 5 November 2023\nfrom https://github.com/CrowdTangle/API/wiki/Search[22] DA Parry, BI Davidson, C Sewall JR, JT Fisher, H Mieczkowski, DS Quintana.\n2021. A systematic review and meta-analysis of discrepancies between logged and\nself-reported digital media use. Nature Human Behaviour 5, 11 (2021), 1535\u20131547.\n[23] Laura Edelson, Minh-Kha Nguyen, Ian Goldstein, Oana Goga, Damon McCoy, and\nTobias Lauinger. 2021. Understanding Engagement with U.S. (Mis)Information\nNews Sources on Facebook. Proceedings of the 21st ACM Internet Measurement\nConference . https://doi.org/10.1145/3487552.3487859\n[24] Facebook. 2018. Making Ads and Pages More Transparent. Retrieved 5 November\n2023 from https://about.fb.com/news/2018/04/transparent-ads-and-pages/\n[25] Facebook. 2019. Introducing Facebook News. Retrieved 5 November 2023 from\nhttps://about.fb.com/news/2019/10/introducing-facebook-news/\n[26] Facebook. 2023. Create a Facebook page. Retrieved 5 November 2023 from\nhttps://www.facebook.com/pages/creation/\n[27] Facebook. 2023. Facebook Ad Library. Retrieved 5 November 2023 from\nhttps://www.facebook.com/ads/library/\n[28] Facebook Business. 2018. New Authorization for Pages. Retrieved 5 Novem-\nber 2023 from https://www.facebook.com/business/news/new-authorization-for-\npages\n[29] Seth Flaxman, Sharad Goel, and Justin M. Rao. 2016. Filter Bubbles, Echo\nChambers, and Online News Consumption. Public Opinion Quarterly (2016).\nhttps://doi.org/10.1093/poq/nfw006\n[30] Richard Fletcher and Rasmus Kleis Nielsen. 2018. Are people incidentally exposed\nto news on social media? A comparative analysis. New Media & Society (2018).\nhttps://doi.org/10.1177/1461444817724170\n[31] GNews. 2023. A Python Package that searches Google News RSS Feed and returns\na usable JSON response. Retrieved 5 November 2023 from https://github.com/\nranahaani/GNews\n[32] Ted Van Green. 2020. Few Americans are confident in tech companies to prevent\nmisuse of their platforms in the 2020 election. https://www.pewresearch.org/fact-\ntank/2020/09/09/few-americans-are-confident-in-tech-companies-to-prevent-\nmisuse-of-their-platforms-in-the-2020-election/\n[33] Andrew Guess, Jonathan Nagler, and Joshua Tucker. 2019. Less than you think:\nPrevalence and predictors of fake news dissemination on Facebook. Science\nAdvances (2019). https://www.science.org/doi/abs/10.1126/sciadv.aau4586\n[34] Andrew M. Guess, Pablo Barber\u00e1, Simon Munzert, and JungHwan Yang. 2021.\nThe consequences of online partisan media. Proceedings of the National Academy\nof Sciences (2021). https://www.pnas.org/doi/abs/10.1073/pnas.2013464118\n[35] Andrew M Guess, Brendan Nyhan, and Jason Reifler. 2020. Exposure to untrust-\nworthy websites in the 2016 US election. Nature human behaviour (2020).\n[36] Homa Hosseinmardi and Amir Ghasemian and Aaron Clauset and Markus Mobius\nand David M. Rothschild and Duncan J. Watts. 2021. Examining the consumption\nof radical content on YouTube. Proceedings of the National Academy of Sciences\n(2021). https://www.pnas.org/doi/abs/10.1073/pnas.2101967118\n[37] Benjamin D. Horne, Maur\u00edcio Gruppi, Kenneth Joseph, Jon Green, John P. Wihbey,\nand Sibel Adal\u0131. 2022. NELA-Local: A Dataset of U.S. Local News Articles for\nthe Study of County-Level News Ecosystems. Proceedings of the International\nAAAI Conference on Web and Social Media (2022). https://ojs.aaai.org/index.php/\nICWSM/article/view/19379\n[38] JOHN SANDS. 2019. Local news is more trusted than national\nnews \u2014 but that could change. Retrieved 5 November 2023 from\nhttps://knightfoundation.org/articles/local-news-is-more-trusted-than-\nnational-news-but-that-could-change/\n[39] Ro\u2019ee Levy. 2021. Social Media, News Consumption, and Polarization: Evidence\nfrom a Field Experiment. American Economic Review (2021). https://www.aeaweb.\norg/articles?id=10.1257/aer.20191777\n[40] Benjamin A. Lyons, Jacob M. Montgomery, Andrew M. Guess, Brendan Nyhan,\nand Jason Reifler. 2021. Overconfidence in news judgments is associated with\nfalse news susceptibility. Proceedings of the National Academy of Sciences (2021).\nhttps://www.pnas.org/doi/abs/10.1073/pnas.2019527118\n[41] Media Bias Fact Check. 2023. Retrieved 5 November 2023 from https:\n//mediabiasfactcheck.com/\n[42] News Guard. 2023. Retrieved 5 November 2023 from https://www.newsguardtech.\ncom/\n[43] Anne Oeldorf-Hirsch. 2018. The Role of Engagement in Learning From Active\nand Incidental News Exposure on Social Media. Mass Communication and Society\n(2018). https://doi.org/10.1080/15205436.2017.1384022\n[44] Katherine Ognyanova, David Lazer, Ronald E. Robertson, and Christo Wilson.\n2020. Misinformation in action: Fake news exposure is linked to lower trust in\nmedia, higher trust in government when your side is in power. Harvard Kennedy\nSchool Misinformation Review (2020). https://doi.org/10.37016/mr-2020-024\n[45] The public suffix list. 2022. Retrieved 5 November 2023 from https://publicsuffix.\norg/\n[46] Pypi. 2020. locationtagger. Retrieved 5 November 2023 from https://pypi.org/\nproject/locationtagger/\n[47] Pypi. 2023. Selenium 4.9.1. Retrieved 5 November 2023 from https://pypi.org/\nproject/selenium/\n[48] Pypi. 2023. The tldextract python package. Retrieved 5 November 2023 from\nhttps://pypi.org/project/tldextract/\n10\nAutomated Discovery of Self-Proclaimed News Providers on Facebook Conference\u201917, July 2017, Washington, DC, USA\n[49] Michael Scharkow, Frank Mangold, Sebastian Stier, and Johannes Breuer. 2020.\nHow social network sites and other online intermediaries increase exposure to\nnews. Proceedings of the National Academy of Sciences (2020). https://www.pnas.\norg/doi/abs/10.1073/pnas.1918279117\n[50] Mason Walker and Katerina Eva Matsa. 2022. News Consumption Across Social\nMedia in 2021. https://www.pewresearch.org/journalism/2021/09/20/news-consumption-across-social-media-in-2021/\n[51] Galen Weld, Maria Glenski, and Tim Althoff. 2021. Political bias and factualness\nin news sharing across more than 100,000 online communities. Proceedings of\nthe International AAAI Conference on Web and Social Media .\n[52] YAKE. 2023. Yet Another Keyword Extractor. Retrieved 5 November 2023 from\nhttps://github.com/LIAAD/yake\n11", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Automated Discovery of Self-Proclaimed News Providers on Facebook", "author": ["S Chouaki", "MK Nguyen", "L Edelson", "T Lauinger"], "venue": "NA", "pub_year": "NA", "abstract": "The credibility of news obtained from Facebook has become a concern due to the ease with  which individuals or groups can claim to be news publishers and share news-related content"}, "filled": false, "gsrank": 343, "pub_url": "https://www.lix.polytechnique.fr/~goga/assets/PDFs/nd.pdf", "author_id": ["", "w4cKb8EAAAAJ", "5-5-AqcAAAAJ", ""], "url_scholarbib": "/scholar?hl=en&q=info:6f5NnDze9tEJ:scholar.google.com/&output=cite&scirp=342&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D340%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=6f5NnDze9tEJ&ei=QrWsaI2aB7_SieoPzJnloAQ&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:6f5NnDze9tEJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://www.lix.polytechnique.fr/~goga/assets/PDFs/nd.pdf"}}, {"title": "Analysing state-backed propaganda websites: a new dataset and linguistic study", "year": "2023", "pdf_data": "Analysing State-Backed Propaganda Websites:\na New Dataset and Linguistic Study\nFreddy Heppell, Kalina Bontcheva andCarolina Scarton\nDepartment of Computer Science, University of Sheffield, Sheffield, UK\n{frheppell1, k.bontcheva, c.scarton}@sheffield.ac.uk\nAbstract\nThis paper analyses two hitherto unstudied sites\nsharing state-backed disinformation, Reliable\nRecent News ( rrn.world ) and WarOnFakes\n(waronfakes.com ), which publish content in\nArabic, Chinese, English, French, German, and\nSpanish. We describe our content acquisition\nmethodology and perform cross-site unsuper-\nvised topic clustering on the resulting multilin-\ngual dataset. We also perform linguistic and\ntemporal analysis of the web page translations\nand topics over time, and investigate articles\nwith false publication dates. We make publicly\navailable this new dataset of 14,053 articles, an-\nnotated with each language version, and addi-\ntional metadata such as links and images. The\nmain contribution of this paper for the NLP\ncommunity is in the novel dataset which en-\nables studies of disinformation networks, and\nthe training of NLP tools for disinformation\ndetection.\n1 Introduction\nCoordinated, state-backed disinformation opera-\ntions have become an increasing problem in recent\nyears, particularly surrounding the war in Ukraine\n(Mork \u00afunas, 2022). In September 2022, a sophisti-\ncated network of doppelganger websites (imperson-\nating genuine news sites from across Europe) was\ndiscovered by EUDisinfoLab (Alaphilippe et al.,\n2022) and later expanded on in a report from Meta\n(Nimmo and Torrey, 2022). Among these was also\na small number of conventional false news sites.\nThe focus of this study is on two related dis-\ninformation sites in particular: Reliable Recent\nNews1(RRN) and War On Fakes2(WoF). Both\nsites are multilingual, publishing in Arabic, Chi-\nnese, English, French, German, and Spanish, and\nRRN additionally in Italian3. They have been\npromoted by Russian government sources, includ-\ning being shared by Russian embassies (Maitland,\n1https://rrn.world , formerly called Reliable Russia\nNews using rrussianews.com .\n2https://waronfakes.com\n3WoF also has a separate Russian-language site2022; Roache, 2022), and publicised by the Min-\nistry of Foreign Affairs of Russia\u2019s official Twitter\naccount4. We focus on these two \u201cnews\u201d sources\ndue to their links to the Doppelganger network,\ntheir potential to deceive unsuspecting citizens\n(compared to better known propaganda sources\nsuch as Russia Today), and their prior exposure\nas disinformation spreaders (see Appendix A).\nBackovic and Walter (2023) investigated the\nownership of WarOnFakes, and stated it was op-\nerated by Russian journalist Timofey Vasiliev, a\nknown affiliate of Russian propaganda groups, due\nto the presence of his name, email and phone num-\nber on the website. However, they do not state\nprecisely how they found this information, and do\nnot attempt to establish a link between Vasiliev and\nRRN or the Doppelganger operation.\nHanley et al. (2022) included selected articles\nfrom WarOnFakes and nine other disinformation\nwebsites in an analysis of narratives spread on Red-\ndit. In contrast, our dataset includes all WarOn-\nFakes posts and extracts the full article content.\nPropaganda is defined as content that intention-\nally influences opinion to advance its creators\u2019\ngoals (Bolsover and Howard, 2017). Numerous\npropaganda datasets have previously been cre-\nated, with both document-level (Rashkin et al.,\n2017; Barr\u00f3n-Cede\u00f1o et al., 2019) and span-level\n(Da San Martino et al., 2019b) technique annota-\ntions, using articles collected from multiple dis-\ninformation sites. At article-level, classifiers us-\ning combinations of multiple linguistic representa-\ntions based on style and readability outperform con-\ntent representation (Barr\u00f3n-Cede\u00f1o et al., 2019),\nwhereas content-based transformer models such as\nBERT have seen use at span-level (Da San Martino\net al., 2019a). Detectors are often evaluated on sin-\ngle datasets, prompting concerns on generalisation\n(Martino et al., 2020).\nWe are not aware of any prior work including\nRRN, nor of any work which has released a com-\n4https://twitter.com/mfa_russia/status/150022\n3302941487107arXiv:2310.14032v1  [cs.CL]  21 Oct 2023\nplete dataset of a disinformation operation, includ-\ning a detailed linguistic analysis.\nThus the contributions of this paper are: i) a\nnew publicly available5dataset of content from two\nstate-backed disinformation websites; ii) a linguis-\ntic, topic, and temporal analysis of their articles;\nand iii) our open-source toolkit for processing site\ndata and extraction of translations6.\n2 Methodology\n2.1 Data Collection\nIn March 2023 we used the WordPress REST API7\nto obtain all posts from WoF and RRN. Each post\nwas parsed to extract its text, removing non-article\ncontent (such as figure captions). The webpage\nof each post was then analysed to extract the dif-\nferent translations from the language picker. Our\nextraction tool supports the specific markup used\nby these two sites, but can be easily extended to\nsupport others. An example of an extracted article\nis shown in Appendix B.\nPublication and modification times, which are\nprovided in GMT by the API, were also converted\nto Moscow local time for analysis, since it is be-\nlieved that at least one of the sites is based in Russia\n(Backovic and Walter, 2023).\n2.2 Topic Analysis\nThe articles were clustered using BERTopic (Groo-\ntendorst, 2022). We assume that whilst each ar-\nticle may discuss many topics, each sentence of\nan article is likely to discuss a single topic. Ar-\nticles were split using spaCy\u2019s dependency-parse-\nbased sentenceizer, and sentences with less than\n5 tokens were removed. The remaining sentences\nwere embedded with Sentence Transformers MP-\nNET8(Reimers and Gurevych, 2019; Song et al.,\n2020). The dimensionality of each embedding was\nreduced using UMAP (McInnes et al., 2020) from\n768 to 5, whilst keeping the structure of the higher-\ndimensional space. This is necessary to avoid the\n\u2018curse of dimensionality\u20199.\nThe 5d embeddings were clustered with HDB-\nSCAN (Campello et al., 2013), which notably al-\n5https://zenodo.org/records/10007383\n6https://github.com/GateNLP/wordpress-site-e\nxtractor\n7https://developer.wordpress.org/rest-api/\n8https://huggingface.co/sentence-transformers/\nall-mpnet-base-v2 @bd44305\n9Clustering is difficult in higher dimensional spaces as\ndistance is less meaningful (Aggarwal et al., 2001)lows for embeddings to not be included in a cluster,\npreventing overly broad clusters by forcing nearby\nbut unrelated sentences in. It is expected that this\nproduces a large number of outliers, since it is nat-\nural that many of the sentences in the articles will\nhave meanings unrelated to any other. A minimum\ncluster size of 25 is set to prevent too many small\nclusters from being generated.\nKeyword representations are generated by creat-\ning a bag-of-words vector of the unigrams and bi-\ngrams of each topic (excluding English stopwords)\nwhich is L1-normalized to account for cluster size.\nAn adapted class-based TF-IDF is used to calculate\nthe most significant words in each cluster. This\nrepresentation is then fine-tuned by selecting key-\nwords with a high Maximal Marginal Relevance, in\norder to maximise their diversity. The diversity\nparameter was set to 0.5. The top 3 most significant\nkeywords are used to name the cluster.\nEach article is then labelled with the unique set\nof clusters assigned to its sentences.\n2.3 Article Backdating\nIn WordPress, article publication dates can be set\nto any given date, however this does not affect the\nauto-incrementing IDs which are generated in the\norder of article creation. Thus backdated articles\ncan be detected based on their IDs being higher\nthan that of their following articles, when they are\nordered by supposed publication date.\n2.4 n-gram Frequency\nFrequent 2-4-grams were extracted using NLTK,\nafter tokenisation, lowercasing, and stopword and\npunctuation removal. N-gram frequency was cal-\nculated monthly, and the most frequent 10 n-grams\nper month were selected, excluding the phrase\n\u201carmed forces\u201d10, and n-grams which are part of\nanother, longer n-gram of equal frequency (e.g. re-\nmoving \u201cukrainian armed\u201d in favour of \u201cukrainian\narmed forces\u201d). We include ties for 10th place.\n3 Analysis\n3.1 Dataset Size and Coverage\nOur dataset contains 14,053 translations of 3,447\narticles posted between 4 Mar 2022 and 6 Mar\n2023. Table 1 shows the number of articles per\n10This term is highly frequent, but is ambiguous as includes\nboth Russian and Ukrainian armed forces, which appear as\nseparate highly frequent trigrams.\nMay Jul Sep Nov 2023 Mar\nDate050100150200CountRRN\nMay Jul Sep Nov 2023 Mar\nDateWoF\nLanguage\nar\nde\nen\nes\nfr\nit\nzhFigure 1: Monthly post counts across both sites, by reported article date. Partial data for March 2023 excluded.\nLanguageArticle Count Mean #/article\nRRN WoF Total Toks. Sents.\nArabic (ar) 509 324 833 201.89 10.44\nGerman (de) 2032 473 2505 339.90 15.91\nEnglish (en) 2265 864 3129 341.31 15.84\nSpanish (es) 1229 468 1697 345.22 14.99\nFrench (fr) 1968 683 2651 386.91 15.42\nItalian (it) 1288 - 1288 429.89 19.03\nChinese (zh) 1220 730 1950 261.47 13.41\nAll 10511 3542 14053 338.89 15.37\nTable 1: Number of articles per site, per language\nsite and language, and mean token and sentence\ncounts11.\n3.2 Article Frequency\nFigure 1 shows the proportion of each language\nover time for each site. The first WoF article is pub-\nlished on the 4th March 2022, and the first RRN\narticle on the 11th. WarOnFakes has an unusual\npattern of publication in its first few days, publish-\ning sixty articles on the first day, and an average of\n34 articles/day over the first 7 days, whereas RRN\npublished only 7 articles on day one and an average\nof 21 articles/day over the first week.\nGenerally, posts are published on weekdays,\nwith only 9.5% of posts having publication dates\nand 7.0% having modification dates on a Saturday\nor Sunday. The week beginning 2nd January 2023,\nmuch of which is public holidays in Russia12, has\n11Calculated using the spaCy tokeniser and rule-based sen-\ntenciser, with \\nadded to delimiters. Chinese segmented with\nPKUSEG webmodel (Luo et al., 2022). Arabic support is\nlimited.\n12https://www.cbr.ru/eng/other/holidays/the lowest activity in the sites\u2019 history, with only\n60 articles published on RRN and 19 on WoF. For\ncomparison, the mean in other weeks is 200 (RRN)\nand 66 (WoF).\n25 identical articles were published on both sites\npredominantly in March 2022, and in all but one\ncase they were a WoF-style debunk. They were not\npublished simultaneously on the two sites, nor is it\nconsistent which site published first.\n3.3 Language Coverage\nOnly a small minority of posts ( \u223c9.1%) are not\navailable in English, and the majority of these do\nnot have any translations at all, suggesting they are\nlikely \u2018orphaned\u2019 translations. The mean number\nof available languages for a post is 4.1\u00b11.5(1 std)\nAll site-language pairs continued to be published\nuntil the end of the collection period, except Ara-\nbic and Spanish on WoF and Chinese on RRN,\nwhich stopped in July and October 2022 respec-\ntively. Spanish posts resumed in December 2022.\n3.4 Topics\nAmongst the 45,991 English sentences in the En-\nglish articles, 24,800 were considered outliers and\n21,191 were assigned one of 144 topics. These top-\nics ranged from broad, recurrent themes (e.g. #0,\nthe donation of arms and aid to Ukraine) to more\nspecific, time-limited ones (e.g. #139, the burning\nof the Quran by far-right activist Rasmus Paludan).\nThe mean number of topics assigned per arti-\ncle is 4.33\u00b12.66(1 std). In the first week of the\nwar in Ukraine (beginning 28th Feb 2022), the vast\nmajority of articles are categorised as #2 ( russian\nmilitary, ukranian telegram, telegram channels, ac-\ncording [to] ukranian ). These articles are all from\nWarOnFakes (since RRN did not start publishing\nuntil the following week) and are claiming that\nvarious evidence from the war in Ukraine is fake.\nOf the 144 topics we identified, 126 were as-\nsigned to articles from both RRN and WoF, and\nonly 18 were assigned to posts from just one of the\ntwo sites. This demonstrates the significant topi-\ncal overlap between the sites. Further details and\nfigures are provided in Appendix C.\n3.5 LIWC Analysis\nWe use LIWC2015 (Pennebaker et al., 2015) to\ncompare the linguistic properties of English RRN\nand WoF posts against the metrics for genuine New\nYork Times (NYT) articles provided by Pennebaker\net al. (see Table 2 and Appendix C.1).\nEmotional tone, which is on a scale of 0-100\n(negative to positive), shows that RRN and WoF are\nwritten more negatively than real news, with WoF\nbeing even more negative than RRN. This is con-\nfirmed by the values for Affective Processes , which\nshow that both sites use more emotion-laden words\nthan NYT. The sub-metrics show this is skewed\ntowards negativity , particularly anger (where both\nsites have over double the proportion of anger-\nindicating words than NYT).\nAll three sources focus most commonly on the\npresent (e.g. words like \u201ctoday\u201d, \u201cis\u201d, \u201cnow\u201d), how-\never RRN and WoF do so at a higher rate than the\nNYT. RRN and WoF also use more future focus\nterms (e.g. \u201cmay\u201d, \u201cwill\u201d, \u201csoon\u201d) compared to\nthe NYT , and past focus terms (e.g. \u201cago\u201d, \u201cdid\u201d,\n\u201ctalked\u201d) less frequently. This suggests that the\ncontent of RRN and WoF comments is more spec-\nulative as compared to reputable journalism and is\nmore focused on covering current events than past\nones.\nTable 3 shows the top 5 LIWC categories with\nthe strongest correlation for each of the two sites.\nThe strong correlation of colons and interrogatives\nfor WoF is unsurprising, given its repeated use of\nthe phrase \u201c What \u2019s really going on :\u201d. RRN\u2019s cor-\nrelation with conjunctions suggests it tends to use\nmore complex sentences. The remaining attributes\nare below the 0.3 threshold of strong correlation.\nHowever RRN is weakly correlated to personal\npronouns which is due to its tendency to cover in-\ndividual politicians (see Table 6 in Appendix C),\nwhile WoF is weakly correlated to impersonal pro-Metric RRN WoF NYT\nTone 27.71 \u219315.06\u219343.61\nAffective Processes 4.67 \u2191 3.97\u2191 3.82\nPositive Emotion 2.12 \u2193 1.23\u2193 2.32\nNegative Emotion 2.49 \u2191 2.72\u2191 1.45\nAnger 1.01 \u2191 0.98\u2191 0.47\nPast Focus 3.67 \u2193 3.77\u2193 4.09\nPresent Focus 6.42 \u2191 6.40\u2191 5.14\nFuture Focus 1.12 \u2191 1.00\u2191 0.8\nTable 2: Comparison of selected LIWC2015 attributes,\ncompared to the New York Times\nRRN WoF\nMetric rMetric r\nConjunctions 0.311 Colons 0.487\nPos. Emotions 0.310 Interrogatives 0.373\nPers. Pronouns 0.277 Impers. Pronouns 0.293\nDiscrepancies 0.271 See 0.263\nTime 0.270 Leisure 0.189\nTable 3: Top 5 correlated LIWC values. Bold values\nabove strength threshold.\nnouns (i.e. one, you, they) as it tends to discuss\ngroups, such as the Russian and Ukrainian armed\nforces (see Table 7 in Appendix C).\n3.6 Article Backdating\nBoth sites tend to backdate non-English posts (by\nas much as 136 days in two cases, see Appendix C,\nTable 5), in order to make translations appear pub-\nlished at a similar time. The two most backdated\narticles are Spanish and Chinese translations of an\nEnglish article, which were actually published 136\ndays later.\nOur hypothesis for the backdating is due to lim-\nited resources articles were only translated into a\ngiven language when that became necessary for\na particular disinformation campaign. In order to\nconvey timeliness, the translations were then back-\ndated to the date of the original.\n3.7 n-gram Analysis\nTables 6 and 7 in Appendix C show the top occuring\nn-grams per month for the respective websites. The\nmost frequent \u201creally going\u201d n-gram on WoF is\npart of the phrase \u201cWhat\u2019s really going on\u201d, which\nappears in all of its fact-check-style articles. The\nn-gram also appears frequently in the first month\nof RRN data, due to the articles copied from WoF.\nCategory RRN WoF\nAccidental Cyrillic 58 34\nForgotten Cyrillic 15 25\nIntentional 36 10\nUnclear 0 2\nTable 4: Frequency of Cyrillic usage reasons\nOn WoF, the most frequent n-grams typically\nrelate directly to the war in Ukraine itself (\u201crus-\nsian troops\u201d, \u201cukranian armed forces\u201d), whereas on\nRRN they relate to the consequences of the conflict\nfor the rest of the world (\u201cunited states\u201d, \u201crussian\ngas\u201d). Consequently, the most frequent n-grams\non WoF are relatively constant across the differ-\nent months, whereas RRN\u2019s n-grams change from\none month to the next as they tend to be connected\nto current affairs. For example, the bigram \u201canti-\nrussian sanctions\u201d enters the top 10 in June 2022,\nand remains the second most used bigram from July\nto September, and refers to the damage allegedly\ncaused to Western economies. Other terms demon-\nstrate that RRN also covers some genuine news,\ne.g. \u201celizabeth ii\u201d in September 2022 and \u201cworld\ncup\u201d in November and December 2022.\nEven though to a much lesser degree, WoF still\nresponds to specific highly controversial events\nfrom the conflict. For example in August 2022,\nin response to Ukraine and Russia blaming each\nother for the shelling of the Zaporizhzhia nuclear\npower station13, the n-grams \u201cnuclear power\u201d and\n\u201cnuclear power plant\u201d both appear with high fre-\nquency in WoF articles that promote the Russian\nperspective on these events.\n3.8 Presence of Cyrillic Characters\n178 of the articles were found to contain characters\nin the Cyrillic codepoint range (Table 4), which\nwere manually examined to determine the reason.\nAccidental Cyrillic : Incorrect usage of Cyrillic\ncharacters instead of the intended character in the\nLatin alphabet. For example, 11 times the \u201cc\u201d in\nRobert Habeck, a German politician, is actually the\nidentical-looking lowercase Cyrillic Es14.\nForgotten Cyrillic : Issues with translation where\na Russian sentence was left in the article, with or\nwithout the target language translation.\nIntentional : Expected usage of Cyrillic characters\n13https://reut.rs/46KWvTS\n14https://en.wikipedia.org/wiki/Es_(Cyrillic)e.g. the name of a Russian organisation.\nUnclear : We were unable to determine why the\ncharacters were used.\nGiven that both RRN and WoF had forgotten\nRussian text in all languages, we hypothesise that\nall articles were originally written in Russian. Two\nArabic articles on RRN contain the phrases \u201cthe\ntranslation is too long\u201d and\u201csave translation\u201d in\nRussian, likely copied from a machine translation\ntool\u2019s UI, although we were not able to determine\nthe specific tool used. Although this was only\nfound in one language on one of the sites, it sug-\ngests it is more likely the articles are machine than\nhuman translated.\n4 Future Work\nThere is much additional work which could be per-\nformed on this dataset. Although we identify the\nsubject of articles via topic clustering and n-grams,\nwe do not attempt to identify stance towards it.\nMore complex topic analysis, such as identifying\ncommonly co-occuring topics, would also be pos-\nsible. Given the mixture of true and false posts\non the sites, this dataset may be a useful resource\nfor automated fact-checking, although this would\nrequire human annotation and ground-truth may\nbe difficult to establish in the complex information\nenvironment of the war in Ukraine.\n5 Conclusion\nThis paper presented an analysis of the Russian\ndisinformation sites Recent Reliable News and\nWarOnFakes, including an analysis of the articles\u2019\ntopics, publication times, and linguistic properties.\nWe show that the sites cover a diverse range of\ntopics, and that their linguistic properties differ\nfrom those of reputable media. We analysed the\npresence of Cyrillic characters due to site opera-\ntor errors, and their practice of backdating articles,\nshowing that a significant proportion of translations\nare falsely dated. This new multilingual dataset will\nfacilitate further research in disinformation analy-\nsis and promote repeatability.\nLimitations\nAlthough our work provides a complete collection\nof WoF and RRN, since these two websites seem to\nbe highly related, it is unsurprising that they tend\nto publish similar types of content. Therefore this\ndataset cannot be considered fully representative\nof all kinds of Russian disinformation. Neverthe-\nless, it is complementary to overtly Russian state\nmedia, such as Sputnik and Russia Today. Unfor-\ntunately, due to the ban on accessing their content\nfrom the EU, we could not supplement the dataset\nfrom those sources or compare against them.\nOur topic analysis model has not been formally\nvalidated, for example by comparing topics to those\nassigned by human or expert annotators. Some\nsmall scale manual validation was performed in\norder to find good hyperparameters, however this\nconsisted of inspecting a small random sample of\nsome of the categories. A particular area warrant-\ning validation in future work is examining the texts\nnot assigned categories. These are only a very\nsmall number, however as we aggregate sentence\nclassifications at article level, which means that an\narticle can be assigned the correct topics even if\nsome of its sentences may not be.\nIn our LIWC analysis, we compare to the New\nYork Times data provided by Pennebaker et al.\n(2015). Although this is the closest source out\nof the provided LIWC baselines, the New York\nTimes represents a more formal style of journalism\nthan many online media. In future work we plan\nto compare these two disinformation sites against\nofficial state-affiliated news sources such as Russia\nToday.\nFinally, we did not analyse the separate Russian-\nlanguage edition of WarOnFakes. As it is a separate\nsite in Russian only, there is no reliable way to con-\nnect its articles to their similar English-language\nversions (if such are published). Analysing the Rus-\nsian WoF website is planned for future work, as it\nrequires adaptation of the analysis to be bilingual,\nwhich is out of scope for this paper.\nEthics\nThe data collection was carried out in accordance\nwith our institutional ethics policy.\nCollection was via the Wordpress API, followed\nby automated processing and a limited amount of\nmanual analysis by the authors. No external vol-\nunteers or crowd-workers were recruited. Due to\nthe disinformation nature of these two websites,\nthe data may contain content which is disturbing\nor distressing. Therefore we limited the possibil-\nity of harm during analysis by: i) minimising the\nnumber of individual articles studied by the authors\nas much as possible; ii) where necessary, viewing\nonly the text of articles, to avoid the possibility ofviewing distressing media; iii) ensuring familiarity\nwith supporting resources for researchers working\nwith potentially disturbing content.\nAs the websites in question are not legitimate\nnews websites, they do not have a terms of use to\nallow or prohibit the acquisition of their content.\nWe consider the collection and distribution of their\narticles in the public interest, due to the prominence\nof their disinformation and the harm that results\nfrom it. It is not feasible to contact them to obtain\npermission, as they have previously been unrespon-\nsive to enquiries15. The dataset does not include\nimages, as in many cases they appear to have been\ntaken from stock agencies. This is a commonly\nused tactic by disinformation websites.\nWe have checked that the dataset does not con-\ntain personally identifiable information in the user\ndata files, as all users have either generic (e.g. \u201cAd-\nmin\u201d) or random (e.g. \u201cUiXnZyvH\u201d) names. No\nuser comments were available to collect.\nIt is possible that the process of creating a disin-\nformation dataset increases the spread and promi-\nnence of the disinformation. We would argue that\nis not the case with this dataset as we: i) are\nonly focusing on content from disinformation web-\nsites, the low credibility of which has already been\nwidely publicised (see Appendix A); iii) are not in-\ncreasing the longevity of disinformation narratives\nby preserving them after they have being taken\ndown, since the two independent websites that are\npublishing them are still publicly accessible via all\ncommon search engines.\nSome articles make reference to individuals, al-\nbeit only public figures to our knowledge, and many\ncontain narratives which are hateful towards indi-\nviduals and groups. We encourage researchers who\nuse this dataset to do so responsibly, and in par-\nticular to avoid highlighting specific individuals\nand to ensure that the disinformation narratives\nare presented alongside authoritative evidence of\ntheir untrue nature. We would like to specifically\ndiscourage the use of this dataset for training gen-\nerative models that are capable of creating new\ndisinformation. The dataset is released under a\nlicense which prohibits commercial activity.\nAcknowledgments\nThis work is partially supported by the UK\u2019s\ninnovation agency (InnovateUK) grant number\n15NewsGuard attempted to contact them as part of their\nreview process (Maitland, 2022; Roache, 2022)\n10039039 (approved under the Horizon Europe Pro-\ngramme as VIGILANT, EU grant agreement num-\nber 101073921).16Freddy Heppell is supported by\na University of Sheffield Faculty of Engineering\nPGR Prize Scholarship.\nReferences\nCharu C. Aggarwal, Alexander Hinneburg, and\nDaniel A. Keim. 2001. On the surprising behavior\nof distance metrics in high dimensional spaces. In\nInternational Conference on Database Theory .\nAlexandre Alaphilippe, Gary Machado, Raquel Miguel,\nand Francesco Poldi. 2022. Doppelganger - media\nclones serving russian propaganda. Technical report,\nEU DisinfoLab.\nNick Backovic and Kyle Walter. 2023. Logically in-\nvestigations: Russian propaganda disguised as fact\nchecking. Technical report, Logically.\nAlberto Barr\u00f3n-Cede\u00f1o, Israa Jaradat, Giovanni Da San\nMartino, and Preslav Nakov. 2019. Proppy: Organiz-\ning the news based on their propagandistic content.\nInformation Processing & Management , 56(5):1849\u2013\n1864.\nGillian Bolsover and Philip Howard. 2017. Compu-\ntational propaganda and political big data: Moving\ntoward a more critical research agenda. Big Data ,\n5(4):273\u2013276.\nRicardo J. G. B. Campello, Davoud Moulavi, and Jo-\nerg Sander. 2013. Density-based clustering based\non hierarchical density estimates. In Advances in\nKnowledge Discovery and Data Mining , pages 160\u2013\n172, Berlin, Heidelberg. Springer Berlin Heidelberg.\nGiovanni Da San Martino, Alberto Barr\u00f3n-Cede\u00f1o, and\nPreslav Nakov. 2019a. Findings of the NLP4IF-2019\nshared task on fine-grained propaganda detection. In\nProceedings of the Second Workshop on Natural Lan-\nguage Processing for Internet Freedom: Censorship,\nDisinformation, and Propaganda , pages 162\u2013170,\nHong Kong, China. Association for Computational\nLinguistics.\nGiovanni Da San Martino, Seunghak Yu, Alberto\nBarr\u00f3n-Cede\u00f1o, Rostislav Petrov, and Preslav Nakov.\n2019b. Fine-grained analysis of propaganda in news\narticle. In Proceedings of the 2019 Conference on\nEmpirical Methods in Natural Language Processing\nand the 9th International Joint Conference on Natu-\nral Language Processing (EMNLP-IJCNLP) , pages\n5636\u20135646, Hong Kong, China. Association for Com-\nputational Linguistics.\nMaarten Grootendorst. 2022. BERTopic: Neural topic\nmodeling with a class-based TF-IDF procedure.\nComputing Research Repository , arXiv:2203.05794.\nVersion 1.\n16https://www.vigilantproject.euHans W. A. Hanley, Deepak Kumar, and Zakir Du-\nrumeric. 2022. Happenstance: Utilizing semantic\nsearch to track russian state media narratives about\nthe russo-ukrainian war on reddit. Computing Re-\nsearch Repository , arXiv:2205.14484v2. Version 2.\nRuixuan Luo, Jingjing Xu, Yi Zhang, Zhiyuan Zhang,\nXuancheng Ren, and Xu Sun. 2022. Pkuseg: A\ntoolkit for multi-domain chinese word segmentation.\nComputing Research Repository , arXiv:1906.11455.\nVersion 3.\nEva Maitland. 2022. RRN.world nutrition label. Tech-\nnical report, NewsGuard.\nGiovanni Da San Martino, Stefano Cresci, Alberto\nBarron-Cedeno, Seunghak Yu, Roberto Di Pietro,\nand Preslav Nakov. 2020. A survey on computa-\ntional propaganda detection. Computing Research\nRepository , arXiv:2007.08024.\nLeland McInnes, John Healy, and James Melville. 2020.\nUMAP: Uniform manifold approximation and projec-\ntion for dimension reduction. Computing Research\nRepository , arXiv:1802.03426.\nMangirdas Mork \u00afunas. 2022. Russian disinformation in\nthe baltics: Does it really work? Public Integrity ,\npages 1\u201315.\nBen Nimmo and Mike Torrey. 2022. Taking down coor-\ndinated inauthentic behavior from russia and china.\nTechnical report, Meta.\nJames W Pennebaker, Ryan L Boyd, Kayla Jordan, and\nKate Blackburn. 2015. The development and psycho-\nmetric properties of LIWC2015.\nHannah Rashkin, Eunsol Choi, Jin Yea Jang, Svitlana\nV olkova, and Yejin Choi. 2017. Truth of varying\nshades: Analyzing language in fake news and po-\nlitical fact-checking. In Proceedings of the 2017\nConference on Empirical Methods in Natural Lan-\nguage Processing , pages 2931\u20132937, Copenhagen,\nDenmark. Association for Computational Linguis-\ntics.\nNils Reimers and Iryna Gurevych. 2019. Sentence-\nBERT: Sentence embeddings using Siamese BERT-\nnetworks. In Proceedings of the 2019 Conference on\nEmpirical Methods in Natural Language Processing\nand the 9th International Joint Conference on Natu-\nral Language Processing (EMNLP-IJCNLP) , pages\n3982\u20133992, Hong Kong, China. Association for Com-\nputational Linguistics.\nMadeline Roache. 2022. WarOnFakes.com nutrition\nlabel. Technical report, NewsGuard.\nKaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, and Tie-\nYan Liu. 2020. MPNet: Masked and permuted pre-\ntraining for language understanding. Computing Re-\nsearch Repository , arXiv:2004.09297. Version 2.\n0 5 10 15 20\nNumber of topics0200400600Number of articles\nFigure 2: Number of unique topics assigned per article\nLanguage Backdated Mean Max\nar 39.4% -8d -34d\nes 11.5% -9d -136d\nde 11.1% -7d -104d\nfr 10.2% -9d -109d\nzh 8.4% -15d -136d\nit 6.9% -4d -26d\nen 0.2% -1d -2d\nTable 5: Backdating per language for both sites.\nA Evidence of Disinformation\nFor WarOnFakes, there is a substantial number of\narticles and fact-checks establishing it as a disin-\nformation source. PolitiFact undertook a review\nof over 380 of their fact-checks and found a sig-\nnificant number of falsehoods17. In an article by\nAFP via France24, Roman Osadchuk, from the\nAtlantic Council\u2019s Digital Forensic Research Lab\n(DFRLab), is quoted as saying \u201cSince Russia\u2019s in-\nvasion, the \u2018War On Fakes\u2019 initiative has become a\npowerhouse of spreading false debunks\u201d and \u201cIt is\nan effective tool of state propaganda and disinfor-\nmation\u201d18. The Institute of Network Cultures de-\nscribes it as \u201cKremlin-Sponsored Particpatory Pro-\npaganda\u201d19, and highlights connections between\nthe Russian state and the website, including promo-\ntion from organisations under the Russian Ministry\nof Foreign Affairs, and on the Russian Ministry of\n17https://www.politifact.com/article/2022/aug/\n08/how-war-fakes-uses-fact-checking-spread-pro\n-russia/\n18https://www.france24.com/en/live-news/202302\n16-fake-fact-checks-seek-to-obscure-russian-rol\ne-in-war\n19https://networkcultures.org/tactical-media-r\noom/2022/07/22/weaponized-osint-the-new-kremlin\n-sponsored-participatory-propaganda/Defence\u2019s Telegram channel. BBC Monitoring, the\nspecialist media source analysis division of BBC\nNews, states \u201cSome of its fact-checks are genuine\nbut most content is Russian talking points on the\ninvasion which do not stand up to scrutiny\u201d20.\nThe site has also been covered by EUvsDis-\ninfo21, DFRLab22, the European Digital Media Ob-\nservatory23, and Media Bias/Fact Check24.\nRRN has received comparatively less attention\nfrom fact checkers, however was described as disin-\nformation by NewsGuard (Maitland, 2022), which\nadditionally claims that they reuse content from\nWarOnFakes, and EU Disinfo Lab have noted a\nconnection in the hosting infrastructure of the two\nsites (Alaphilippe et al., 2022). It is therefore prob-\nable that the apparent state-backing of WarOnFakes\nalso applies to RRN.\nB Data Example\nFigure 3 shows an example of an article published\non WoF25in English, French, Spanish, Chinese and\nArabic. Full texts are omitted for languages other\nthan English. This story was judged to be fake by\nfact-checkers26. Usage of guillemets (\u00ab \u00bb) as quote\nmarks is reproduced as returned by the WordPress\nAPI, but this appears to be normalised when the\npage is rendered.\nC Detailed Dataset Statistics\nFigure 4 shows a weekly chart of the 10 most com-\nmon topics on the site. In general, there is no clear\nvariation between these topics, with the exception\nof the initial popularity of the topic #2 due to the\nmajority of posts that week being from WarOn-\nFakes. The significant dip in January 2023 is due\nto the Russian public holidays discussed in section\n3.2.\nFigure 2 shows the distribution of sentence-level\ntopic counts aggregated for each article. 78 posts\nwere not assigned any topic, the majority of articles\n20https://monitoring.bbc.co.uk/product/c203aqg1\n21https://euvsdisinfo.eu/riding-the-bomb/\n22https://medium.com/dfrlab/russian-telegram-c\nhannel-embraces-fact-checking-tropes-to-sprea\nd-disinformation-c6a54393c635\n23https://edmo.eu/2022/03/17/russian-propaga\nnda-disguising-as-fact-checking-a-statement-fro\nm-the-edmo-taskforce/\n24https://mediabiasfactcheck.com/war-on-fakes\n-bias/\n25https://waronfakes.com/civil/fake-russian-a\nviation-struck-a-maternity-hospital-with-mothers\n-and-children/\n26https://reut.rs/3tEvFfk\nhave 1-3 topics, however in the extreme some have\nas many as 21 - this is an article from WarOnFakes\n\u201cWhat happened in Bucha? A full analysis of the\nUkrainian provocation\u201d , a long article supposedly\nexplaining the truth about many elements of the\nBucha massacre.\nTable 5 shows the proportion of backdated ar-\nticles per language, and the mean and maximum\nbackdating period for each. For English, a small\nnumber of posts are backdated after a short period\nof time. It is likely this is caused by posts that have\nbeen forward-dated (i.e. set to be published in the\nfuture) by one or two days, resulting in subsequent\nposts appearing to be backdated until the publica-\ntion date catches up. However, for other languages,\nbackdates are for a much longer period.\nC.1 Complete LIWC2015 Data\nThe complete listing of LIWC2015 is included in\nTable 8, in the hope it can be used for comparison\nin future work.\nENGLISH\nFake: Russian aircraft attacked a maternity hospital with mothers and children inside\nWhat is fake about:\nInformation that Russia launched an airstrike on a maternity hospital in Mariupol is being spread online.\nUkrainian President V olodymyr Zelensky called it \u00aban atrocity\u00bb and said that women and children\nremained under the rubble.\nThe fact\nDespite the fact that information about the strike appeared in the middle of the day of March 8, no single\npatient was visible on numerous videos and photos. The footage of pregnant women appeared on the\nInternet much later \u2013 in the evening of March 9. However, it immediately was circulated by all news\nagencies, social media, popular communities and bloggers, which may be the result of a preplanned\ncampaign. Moreover, it was happening despite the fact that the locals themselves claimed that there were\nno patients or members of the staff in the maternity hospital.\nThis story is rather dubious. It is logical to assume that if there really had been patients then the rescue\nservice officers and eyewitnesses who arrived at the scene would immediately have taken photos of\nthe accident scene with their phones, without waiting for a well-known photographer. However, it so\nhappened that the well-known Ukrainian propaganda activist Evgeniy Maloletka was the first to prepare\nand publish the photographs.\nToday we received indisputable confirmation that the \u00abphotos of pregnant women\u201d were staged. The\nUkrainians used a model called Marianna who comes from Mariupol for the most striking photos (there\nare three in total). It is notable that she played roles of two different pregnant women at the same time: she\neven had to change clothes and the color of her hair, which, however, is not surprising: in fact, Marianna\nis a well-known beauty blogger in the region. It\u2019s worth noting that the girl is indeed pregnant, but she\njust could not have been in the maternity hospital: the Azov militants had used the medical facility for\nseveral days as a fortified stronghold that does not function as a maternity hospital any longer. The main\nheroine of this hoax has already been caught in the spotlight. In the comment section of her Instagram\naccount there are already more than 500 comments under her last post written by real users condemning\nthe girl for participating in information manipulations.\nFRENCH\nL\u2019infox: les forces a\u00e9riennes russes ont bombard\u00e9 la maternit\u00e9. Les femmes et les enfants\nont \u00e9t\u00e9 cibl\u00e9s\nSPANISH\nFake: La aviaci\u00f3n rusa atac\u00f3 al hospital materno-infantil con madres y beb\u00e9s\nCHINESE\n\u5047\u65b0\u95fb\uff1a\u4fc4\u7f57\u65af\u7a7a\u519b\u88ad\u51fb\u4e86\u4ea7\u79d1\u533b\u9662\nARABIC\n\\lamisolated\\aleffinal\\fehmedial\\tahinitial\\lamwithalefhamzaaboveisolatedd\\alefisolated\\wawisolated \\tehisolated\\aleffinal\\hehmedial\\meeminitial\\lamwithalefhamzaaboveisolatedd\\alefisolated \\aleffinal\\hehmedial\\behinitial \\tehmarbutaisolated\u062f\\lamwithalefisolated\\wawfinal\\laminitial\\alefisolated \\alefmaksurafinal\\fehmedial\\sheenmedial\\tehmedial\\seenmedial\\meeminitial \\meemfinal\\jeeminitial\\aleffinal\\hehinitial \\yehfinal\\seeninitial\\wawisolated\\rehfinal\\laminitial\\alefisolated \\noonisolated\\alefisolated\\rehfinal\\yehmedial\\tahmedial\\laminitial\\alefisolated :\\fehfinal\\yehinitial\\zainfinal\\meeminitial \\rehfinal\\behmedial\\khahinitial\nFigure 3: An example of an article from WoF. Article text is omitted for non-EN languages for space.\nMar 2022 May 2022 Jul 2022 Sep 2022 Nov 2022 Jan 2023020406080100120000_military aid_vehicles_bundeswehr_tanks ukraine 001_truth_think_tell situation_conclusions drawn\n002_russian military_ukrainian telegram_telegram channels_according ukrainian\n003_vladimir_president zelensky_volodymyr_ukrainian president 004_brussels_european union_european leaders_commission\n005_german government_berlin_german foreign_republic germany 006_russian gas_price ceiling_russian ener gy_rubles\n007_winter_lighting_firewood_19 degrees 008_joe_son_fbi_white house\n009_ukrainian telegram_reported ukrainian_reported_ukrainian media 010_china_jinping_prc_pelosi\nWeekNumber of articlesFigure 4: Weekly frequency of top 10 clusters. Partial data for March 2023 excluded.\nMar 22 Apr May Jun Jul Aug\nunited states united states united states united states prime minister prime minister\nrussian gas russian federation special operation european union anti-russian sanctions anti-russian sanctions\nrussian federation russian military prime minister anti-russian sanctions european union nord stream\nreally going special operation russian military prime minister nord stream energy crisis\nrussian military ukrainian armed ukrainian armed sanctions russia ukrainian refugees russian gas\neuropean countries ukrainian armed forces ukrainian military white house ukrainian army united states\nprime minister le pen western countries joe biden von der leyen per cent\nministry defense russian troops ukrainian armed forces ukrainian refugees european commission nuclear power\npeople republic russian gas ukrainian soldiers european commission german government energy prices\nukrainian nationalists joe biden olaf scholz united states nord stream 2\nrussian oil ukranian crisis\nSep Oct Nov Dec Jan 23 Feb\nprime minister prime minister united states united states united states united states\nanti-russian sanctions united states joe biden world cup prime minister white house\nnord stream liz truss prime minister white house ukrainian army joe biden\nenergy crisis nuclear power white house joe biden ukrainian armed prime minister\nunited states vladimir putin world cup prime minister ukrainian armed forces vladimir zelensky\neuropean commission nord stream foreign minister ukrainian army white house military aid\nvladimir putin anti-russian sanctions elon musk vladimir putin foreign minister nord stream\nelizabeth ii crimean bridge vladimir putin emmanuel macron joe biden ukrainian armed forces\nnuclear power energy crisis rishi sunak price cap foreign policy last year\nliz truss white house anti-russian sanctions elon musk olaf scholz ukrainian army\nrussian gas new year world war world war\nordinary people\nTable 6: Top n-grams for RRN\nMar 22 Apr May Jun Jul Aug\nreally going russian troops really going really going really going really going\nfake message telegram channels telegram channels telegram channels telegram channels ukrainian armed forces\ntelegram channels forces ukraine russian military ukrainian telegram channels ukrainian armed forces telegram channels\nrussian military fake news ukrainian telegram shopping center saudi arabia power plant\nforces ukraine armed forces ukraine ukrainian telegram channels ukrainian armed forces fake russian fake russian\narmed forces ukraine fake message russian troops fake russian ukrainian telegram channels ukrainian telegram\nministry defense russian soldiers special operation russian military russian armed forces nuclear power\nrussian federation really going ukrainian armed forces according ukrainian russian military ukrainian telegram channels\nukrainian telegram channels russian military fake ukrainian fake according western media nuclear power plant\nrussian armed ukrainian telegram channels russian armed forces fake ukrainian ukrainian side russian armed\nrussian armed forces ukrainian sources russian troops russian armed forces\nukrainian media ukrainian side\nSep Oct Nov Dec Jan 23 Feb\nreally going really going really going really going really going really going\ntelegram channels ukrainian armed forces telegram channels ukrainian armed forces united states telegram channels\nukrainian armed forces telegram channels ukrainian armed forces ukrainian army telegram channels military operation\nukrainian telegram russian armed forces ukrainian telegram russian armed forces ukrainian telegram special military operation\nukrainian telegram channels russian federation ukrainian telegram channels telegram channels ukrainian army russian federation\nfake russian air defence channels really going vladimir zelensky ukrainian telegram channels ukrainian telegram channels\nchannels really going ukrainian telegram channels russian armed forces russian federation air defence telegram channels really going\nrussian armed forces vladimir putin ukrainian media telegram channel russian armed forces united states\ntelegram channels really fake russian air defence president vladimir ukrainian armed forces nord stream\ntelegram channels really going ukrainian army telegram channels really going war fakes ukrainian propaganda fake russian\nvladimir putin\nTable 7: Top n-grams for WoF\nCategory RRN WoF All\nWord count (mean) 313.80 249.24 295.74\nSummary Variables\nAnalytic 94.37 95.12 94.58\nClout 63.62 56.75 61.70\nAuthentic 23.13 22.95 23.08\nEmotional Tone 27.71 15.06 24.17\nLanguage Metrics\nWords/sentence 19.92 20.15 19.98\nWords > 6 letters 27.97 29.12 28.30\nDictionary words 76.81 75.33 76.40\nFunction Words 45.94 46.86 46.20\nTotal pronouns 6.30 6.20 6.27\nPersonal pronouns 2.70 1.54 2.38\n1st pers singular 0.16 0.06 0.14\n1st pers plural 0.50 0.38 0.46\n2nd person 0.16 0.09 0.14\n3rd pers singular 0.95 0.41 0.80\n3rd pers plural 0.94 0.60 0.84\nImpersonal pronouns 3.59 4.66 3.89\nArticles 10.30 11.06 10.51\nPrepositions 15.81 16.09 15.89\nAuxiliary verbs 6.53 7.21 6.72\nAdverbs 3.23 3.83 3.40\nConjunctions 4.44 3.37 4.14\nNegations 1.17 1.16 1.17\nOther Grammar\nCommon verbs 11.01 11.03 11.02\nCommon adiectives 3.97 3.62 3.87\nComparisons 2.02 1.46 1.86\nInterrogatives 0.92 1.66 1.13\nNumber 2.13 1.75 2.02\nQuantifiers 1.62 1.24 1.51\nPsychological Processes\nAffective processes 4.67 3.97 4.47\nPositive emotion 2.12 1.23 1.87\nNegative emotion 2.49 2.72 2.55\nAnxiety 0.38 0.22 0.34\nAnger 1.01 0.98 1.00\nSadness 0.37 0.21 0.33\nSocial processes 6.82 4.84 6.26\nFamily 0.15 0.09 0.13\nFriends 0.16 0.09 0.14\nFemale references 0.34 0.19 0.30\nMale references 0.85 0.41 0.72\nCognitive processes 8.26 7.69 8.10\nInsight 1.52 1.36 1.48\nCausation 1.72 1.91 1.77\nDiscrepancy 0.96 0.47 0.82\nTentative 1.36 1.13 1.30\nCertainty 1.11 1.02 1.09\nDifferentiation 2.34 2.26 2.32\ncontinued...Category RRN WoF All\nPerceptual processes 1.72 2.03 1.81\nSee 0.65 1.32 0.84\nHear 0.63 0.42 0.57\nFeel 0.34 0.22 0.30\nBiological processes 1.24 1.06 1.19\nBody 0.40 0.36 0.39\nHealth 0.56 0.57 0.57\nSexual 0.04 0.03 0.04\nIngestion 0.27 0.14 0.24\nDrives 8.41 6.95 8.00\nAffiliation 1.57 1.25 1.48\nAchievement 1.54 1.06 1.40\nPower 4.60 4.05 4.44\nReward 0.77 0.51 0.70\nRisk 0.97 0.64 0.88\nTime orientations\nPast focus 3.67 3.77 3.70\nPresent focus 6.42 6.40 6.42\nFuture focus 1.12 1.00 1.09\nRelativity 13.77 13.05 13.57\nMotion 1.70 1.78 1.72\nSpace 7.73 8.02 7.81\nTime 4.39 3.21 4.06\nPersonal Cocnerns\nWork 3.77 3.32 3.64\nLeisure 0.76 1.29 0.91\nHome 0.34 0.31 0.33\nMoney 1.48 0.67 1.25\nReligion 0.38 0.35 0.37\nDeath 0.38 0.43 0.39\nInformal Language 0.23 0.19 0.22\nSwear words 0.01 0.01 0.01\nNetspeak 0.06 0.09 0.07\nAssent 0.04 0.04 0.04\nNonfluencies 0.08 0.06 0.07\nFillers 0.02 0.00 0.02\nPunctuation\nTotal Punctuation 15.09 13.87 14.75\nPeriods 5.26 5.31 5.28\nCommas 4.91 4.14 4.70\nColons 0.36 1.08 0.56\nSemicolons 0.05 0.03 0.04\nQuestion marks 0.13 0.03 0.11\nExclamation marks 0.09 0.01 0.07\nDashes 0.69 0.70 0.69\nQuotation marks 2.09 1.52 1.93\nApostrophes 0.97 0.57 0.86\nParentheses 0.25 0.37 0.28\nOther punctuation 0.28 0.12 0.23\nTable 8: Complete LIWC2015 listings", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Analysing state-backed propaganda websites: a new dataset and linguistic study", "author": ["F Heppell", "K Bontcheva", "C Scarton"], "pub_year": "2023", "venue": "arXiv preprint arXiv:2310.14032", "abstract": "This paper analyses two hitherto unstudied sites sharing state-backed disinformation, Reliable  Recent News (rrn.world) and WarOnFakes (waronfakes.com), which publish content in"}, "filled": false, "gsrank": 344, "pub_url": "https://arxiv.org/abs/2310.14032", "author_id": ["dpnpV8AAAAAJ", "kUbDCnMAAAAJ", "e6YOuiQAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:ZT-U3meFfA0J:scholar.google.com/&output=cite&scirp=343&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D340%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=ZT-U3meFfA0J&ei=QrWsaI2aB7_SieoPzJnloAQ&json=", "num_citations": 7, "citedby_url": "/scholar?cites=971798300767567717&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:ZT-U3meFfA0J:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2310.14032"}}, {"title": "Tracking the Takes and Trajectories of English-Language News Narratives across Trustworthy and Worrisome Websites", "year": "2025", "pdf_data": "Tracking the Takes and Trajectories of English-Language News Narratives across\nTrustworthy and Worrisome Websites\nHans W. A. Hanley\nStanford UniversityEmily Okabe\nStanford UniversityZakir Durumeric\nStanford University\nAbstract\nUnderstanding how misleading and outright false informa-\ntion enters and spreads within news ecosystems remains a\ndifficult challenge that requires tracking how stories spread\nacross thousands of fringe and mainstream news websites.\nTo take this challenge, we introduce a novel system that\nutilizes encoder-based large language models and zero-shot\nstance detection to scalably identify and track news stories and\ntheir attitudes to different topics across thousands of factually\nunreliable, mixed-reliability, and factually reliable English-\nlanguage news websites. Deploying our system over an 18-\nmonth period, we track the spread of 146K news stories across\nover 4,000 websites. Using network-based interference via\nthe NETINF algorithm, we show that the paths of news sto-\nries and the stances of websites toward particular entities can\nbe used to uncover slanted propaganda networks ( e.g., anti-\nvaccine and anti-Ukraine) and to identify the most influential\nwebsites in spreading these attitudes in the broader news\necosystem. We hope that the increased visibility into news\necosystems that our system provides assists with the reporting\nand fact-checking of propaganda and disinformation.\n1 Introduction\nMisinformation has promoted dangerous fake health\ncures [16], promoted jingoism and propaganda during\nwars [84, 109, 121], and incited violence [6, 17]. While there\nhas been significant investigation into how misleading in-\nformation spreads across social media platforms and fringe\nwebsites [80, 81, 127], recent work has emphasized the de-\ngree to which the vast majority of people do not visit fringe\nwebsites or regularly encounter misinformation on social me-\ndia [10,101]; rather, most people consume news through more\nmainstream platforms like television news [10]. However, sys-\ntematically tracking how misleading, propagandistic, and out-\nright false information spreads from untrustworthy websites\ninto mainstream media and how fringe websites influence\nthe broader news ecosystem remains a significant technicalchallenge due to the magnitude and distributed nature of the\nnews ecosystem [9, 19, 61, 127].\nIn this work, we introduce and validate a system for\nscalably identifying and tracking potentially unreliable news\nstories across different English-language media ecosystems.\nBuilding on past work [3,62,92,145], our proposed approach:\n(1) collects articles by continually crawling news websites\nfrom across media ecosystems; (2) extracts semantic stories\nand articles\u2019 stances towards different topics using a fine-\ntuned version of the e5-base-v2 large language model [138],\nDP-Means clustering [38], and zero-shot stance detection [8];\nand (3) identifies the relationships between news websites\nand broader ecosystems using the NETINF algorithm [49].\nWe note that our approach does not make factual assessments\nof individual stories, which is a deeply nuanced task. Rather,\nour system allows us to shed light on how stories travel\nacross the distributed news ecosystem.\nWe analyze the results from our deployed system across an\n18-month period during which we collected articles from pre-\ncurated lists of 1,003 factually unreliable news websites ( e.g.,\ntwisted.news), 1,012 mixed factuality reliability websites ( e.g.,\nfoxnews.com), and 2,061 factually reliable news websites\n(e.g., washingtonpost.com) maintained by Media-Bias/Fact-\nCheck [33] and Hanley et al., [60]. Analyzing 146K stories\nthat our system extracted from 29M articles on these news\nwebsites, we observe significant crossover in the stories cov-\nered by different news ecosystems [136]. We show that reli-\nable and mixed-reliability news websites play the largest role\nin setting the stories and stories addressed by other websites.\nHowever, despite covering similar topics, our stance analysis\nreveals that each type of website adopts distinctive stances\ntowards shared topics, with factually reliable news websites,\nfor example, generally being left-leaning and pro-Ukraine and\nunreliable websites being the right-leaning and anti-Ukraine.\nFraming our story clusters as cascades, our system uses\nthe NETINF [49] algorithm to uncover relationships between\nnews websites and to detect potential networks of coordinat-\ning websites that spread particular slanted content and sto-\nries. For example, using this approach, we identify a network\nof right-leaning news websites that ostensibly act as local-\nnews websites, all operated by Metric Media, LLC. Using\nthis algorithm, we further identify the websites most influ-\nential in spreading stories amongst unreliable websites ( e.g.,\nthegatewaypundit.com) and the websites from which both re-\nliable and unreliable news websites most commonly adopt sto-\nries ( e.g., dailymail.co.uk and ussanews.com). Additionally,\nwe identify the websites that most effectively promote spe-\ncific types of information across ecosystems like anti-vaccine\nmisinformation (naturalnews.com, theepochtimes.com, and\nvaccines.news) and anti-Ukrainian propaganda (rt.com, sput-\nniknews.com, and news-front.info).\nUltimately, our work introduces an end-to-end system for\nbuilding a wide perspective of the English-language news\necosystem and explores how tracking how stories travel within\nit can help us understand how misleading information en-\nters mainstream news and uncover previously unknown re-\nlationships between news websites. We hope that our ap-\nproach can serve as the foundation for further studies of\nhow information spreads online. Our code and URL data\nare available at https://github .com/hanshanley/tracking-takes\nand https://zenodo .org/records/14656479.\n2 Related Work\nSignificant prior work has studied news ecosystems and an-\nalyzed how information and misinformation spread online.\nHere, we summarize the prior work that our study builds on:\nTracking Narratives on News Websites. Several studies\nhave utilized online document clustering [22,142] for tracking\nnews stories. For example, Zhang et al. [146] identify poten-\ntial events by monitoring the appearance of specific phrases or\nkeywords, clustering identified phrases that may indicate news\nevents, and training a series of classifiers to assign news arti-\ncles to identified clusters. Similarly, by clustering a collection\nof short phrases or \u201cmemes\u201d across news websites and blogs,\nLeskovec et al. find that smaller blogs often play a definitive\nrole in encouraging the adoption of particular language onto\nmainstream websites [85]. Rodriguez et al. [49,50] further ex-\namine the changing relationships between websites during the\ndiscussion of news events, finding that connections between\nwebsites increase during periods of high activity.\nIn a similar vein, while many studies have analyzed topics\nand their spread using statistical word-association approaches\nlike Latent Dirichlet Allocation (LDA) and Dynamic Topic\nModels [5, 100, 147], recent works such as those by Meng\net al. [96], Hanley et al. [56, 61], and Grootendorst [52] have\nused large language models (LLMs) for more granular topic\nmodeling. In line with our work, Nakshatri et al. [104] utilize\npeak detection and HDBSCAN [93] on news article embed-\ndings to identify the most prominent news events in a stream\nof news articles. Saravanakumar et al. [119] similarly uti-\nlize an external named entity recognition system to embedentity knowledge into a BERT language model to differen-\ntiate between news articles about different events. Beyond\nthese quantitative approaches, many prior works have qual-\nitatively investigated the spread of individual news stories\n(e.g., [112, 120, 127]).\nMost similar to our work, Hanley et al. [62], using MP-\nNet and DP-Means clustering, track news narratives across a\nsmaller number of fringe websites to determine the role that\nindividual unreliable news websites play in originating and\namplifying news narratives. Their work finds that less-popular\nwebsites oftentimes play an outsized role in promoting narra-\ntives that reverberate across the unreliable news ecosystem.\nIn contrast to these prior works, our study accounts for\nthestance towards each topic in order to better differentiate\nbetween articles that cover the same topic. Tracking stance\nenables our work to understand the widespread understanding\nof individual websites\u2019 ideological skew, changes in cover-\nage of individual topics, and the detection of websites that\ncoordinate in spreading particular types of propaganda.\nAnalyzing the Spread of Misinformation. While our\napproach is one of the first to track both topics and va-\nlence/stance towards those topics programmatically in service\nof understanding misinformation and propaganda, several\nprior works have focused on the peculiarities, detection, and\nspread of misinformation. For example, Ma et al. [88] and\nJin et al. [71] utilize recurrent neural networks to analyze\nand detect the spread of unreliable rumors on social media.\nAbdali [1] et al., taking a domain-based approach, use website\nscreenshots to assess the credibility of news websites. In addi-\ntion to analyzing the spread of general misinformation on par-\nticular social platforms, other works have further investigated\nthe spread of specific narratives, including those concerning\nthe Syrian White Helmets [127], QAnon [11, 58, 107], the\nRusso-Ukrainian War [59,61,109], and COVID-19 [4,31,89].\nWe note that because work utilizes topic analysis followed by\nstance detection, our system can be used to quickly identify\nwebsites and topics that deserve in-depth investigation, further\nenabling studies of these kinds.\nBuilding off these studies, several works have analyzed the\ncharacteristics of misinformation. Juul and Ugander find that\noften false information on Twitter spreads faster and wider\nthan factual information [73]. Indeed, Kwon et al. [81], utiliz-\ning the distinct temporal differences between reliable informa-\ntion and unreliable rumors, are able to classify these rumors\nwith an F1-score as high as 0.878. In a different work [80],\nKwon et al. analyze the semantic and structural characteristics\nof rumors on Twitter. In a similar vein, using a learning-to-\nrank-based approach and ClaimBuster API, Paudel et al. [108]\nidentify potential claims that should be fact-checked on Twit-\nter [64].\nBeyond studying the dynamics of misinformation, Bak\net al. [15] have proposed concrete steps to ameliorate the\nspread of misinformation, including removal and nudges. Fi-\nnally, Kaiser et al. [74] have studied how borrowing tech-\nNews Article Daily Document StreamArticle T ext and Date Extraction \nCalculate Passage\nEmbeddingsWebsite\nScrapes,\nRSS feeds\nSeparate Document into Passages\nNarrative 1\nNarrative 3Narrative 2\nUpdate Cluster Centers or Create New\nCluster based on Semantic Similarity to\nCurrent ClustersNarrative 402-24-22Russia\ninvaded...\nUkraine\nresponded ...\nRussia\ninvaded...Narrative 2\n Stance\n Detect \nDetermine Stance of T exts within\nNarrative Clusters with Respect \nto Extracted KeywordsPro Neutral AgainstUpdate Cluster Keywords\nwith Pointwise Mutual\nInformation and Extract\nSummaryNews Article\nWebsites\nBias EstimationFigure 1: Our pipeline for identifying, labeling, and extracting the stance of story clusters from the daily publications of news websites.\nniques from the security warning landscape might help inform\nusers of potential misinformation.\nUnlike the past approaches outlined above, by utilizing\nfine-tuned encoder-based large language models, our work\nscalably tracks and identifies unique news stories across thou-\nsands of news websites without depending on particular key-\nwords or by limiting analysis to a subset of unreliable websites\npreviously fact-checked or curated by experts [62, 127]. By\nutilizing network analysis combined with stance detection,\nour work further provides a highly interpretable means of\nunderstanding the spread and dynamics of propagandistic,\nbiased, or factually unreliable stories across multiple media\necosystems.\n3 Methodology\nIn this section, we provide an overview of our data collec-\ntion methodology as well as our approach for extracting and\ntracking stories across different types of news websites.\n3.1 News Websites\nOur study analyzes articles collected from three sets of\nEnglish-language news websites of varying factual reliability.\nWe specifically track stories on websites rated by Media-\nBias/Fact-Check [33], a media monitoring website founded\nby Dave M. Van Zandt to assess the factual reliability of in-\ndividual websites. We use Media-Bias/Fact-Check given its\nwidespread use in prior work [14,62,103,139] and its ratings\u2019\nhigh agreement with other organizations like NewsGuard.\nUnreliable News Websites. We collect news articles from\n1,003 websites labeled as having \u201clow\u201d or \u201cvery low\u201d fac-\ntual reporting by Media-Bias/Fact-Check [33]. We extend\nthis list with conspiracy theory-promoting websites identified\nby Hanley et al. [60]. Our list of unreliable news websites\nincludes pseudo-science websites like vaccine.news, state-\npropaganda outlets such as rt.com, and partisan websiteswith low-factuality ratings like the liberal-leaning occupy-\ndemocrats.com.\nMixed-Reliability News Websites. We collect articles from\n1,012 mixed-reliability news websites labeled as having\n\u201cmixed\u201d factual reporting by Media-Bias/Fact-Check [33].\nThis list includes websites across the political spectrum, such\nas foxnews.com, nypost.com, and theguardian.com.\nReliable News Websites. We collect articles from 2,061 re-\nliable news websites labeled as having \u201chigh\u201d, \u201cvery high\u201d,\nor \u201cmostly factual\u201d reporting by Media-Bias/Fact-Check [33].\nThe category \u201cmostly factual\u201d is included to capture sources\nwith strong reputations like The Washington Post. This list\nalso features websites such as reuters.com and apnews.com.\nWe lastly note that we utilize the full set of English-language\nnews websites from the lists of Media-Bias/Fact-Check [33]\nand Hanley et al. [60] that were accessible to us from the\nbeginning of our study.\n3.2 Definition of a News Story\nOur approach tracks specific news stories and their propaga-\ntion across websites rather than analyzing broader themes as\ncaptured by methods like LDA [7,36,70]. Following previous\nresearch [61, 62], we adopt Event Registry\u2019s definition of a\nnews story as \u201ccollections of documents that seek to address\nthe same event orissue \u201d [83, 98]. It is important to note that\neven if two ideas are related, they may not constitute the same\nnews story. For example, while \u201cFlorida Governor Ron De-\nSantis declares for President\u201d and \u201cNikki Haley surpasses\nRon DeSantis in the polls\u201d are related, they are considered\nseparate news stories in our work.\n3.3 System Architecture\nOur approach for capturing and tracking news stories builds\non the LLM-based story tracking methodology introduced\nby Hanley et al. [62]. However, while Hanley et al.\u2019s method\nall-mpnet all-mpnet e5-base-v2\nBERT USE specious peft+lora peft+lora\n0.464 0.749 0.856 0.860 0.866\nTable 1: Model Performance on SemEval STS Benchmark. Our\nPEFT+LoRA models fine-tuned using unsupervised contrastive loss\nperform better than prior work [26, 27, 37, 62, 114].\nscalably tracks individual topics, their work does not incor-\nporate articles\u2019 attitudes towards a topic. While this was not\nproblematic for their work, which focused on the spread of\nstories amongst unreliable news websites, their approach can-\nnot track news stories across a broader set of news websites\nthat present stories in dramatically different ways. We expand\ntheir method to additionally account for the stance /valence\nof news articles towards a topic ( i.e., we distinguish between\narticles that cover vaccines positively vs. negatively).\nAs shown in Figure 1, our system identifies stories by:\n(1) scraping articles from news websites, (2) splitting arti-\ncles into passages of 100 words [62, 110], (3) embedding\npassages with a fine-tuned LLM [138], and (4) clustering\nnews articles using an optimized version of the DP-Means\nalgorithm [38, 72]. To describe clusters that each represent a\nstory, we extract keywords from the resulting cluster using\npointwise mutual information (PMI) and performing multi-\ndocument summarization with an open-source LLM. Build-\ning on the clusters, we utilize network inference techniques\nto identify website relationships and zero-shot stance detec-\ntion [8, 55] to determine the stance/position of individual\npassages within each cluster. Finally, based on individual\nwebsites\u2019 stances toward their given topics, we perform bias\nestimation to quantify websites\u2019 biases along various political\nand non-political axes. We detail each stage below:\nCollecting and Preparing News Articles. We crawl our\nset of 4,076 websites daily using the Go Colly library [125]\nfrom January 1, 2022 to July 1, 2023. Each day, we collect\nevery website\u2019s homepage, RSS feeds, and linked articles. We\ncollected a total 29.0M articles: 17.9M articles from reliable\nnews websites (median 2,467 articles/site), 8.7M articles from\nmixed-reliability news websites (median 964 articles/site),\nand 2.5M articles from unreliable news websites (median\n219 articles/site). We provide to URLs researchers on request.\nTo prepare our news article data for embedding, we first\nremove any URLs, emojis, and HTML tags from the text.\nThen, in line with prior work, after first separating articles into\nparagraphs by splitting text on ( \\n) or tab ( \\t) characters [57],\nwe subsequently divide paragraph into constituent passages\nwith at most 100 words [57, 61, 110]. This enables us to fit\npassages into the context window of our LLM embedding\nmodel. Further, given that articles often address multiple ideas,\nembedding passages allows us to track the often single idea\npresent within the passage [57, 110]. Our dataset consists of\n428M passages. For additional details, see Appendix A.Embedding Passages. Before embedding our articles\u2019 pas-\nsages, to ensure that our embedding model is attuned to the\nlanguage of news articles, we tailor our model to our do-\nmain of our collected articles using Parameter Efficient Fine-\nTuning /PEFT [86] through Low-Rank Adaption /LoRA [69]\nwith an unsupervised contrastive learning loss based on\nSimCSE [47]. Rather than directly fine-tuning the original\nmodel\u2019s weights as in Hanley et al. [62], this approach freezes\nthe originally trained large language model and introduces an\nadditional set of parameters of reduced dimensionality that are\nthen fine-tuned, allowing for better generalizability [69]. We\nutilize default LoRA hyperparameters of rank=8 and \u03b1=16.1\nSee Appendix B and C for additional details. We utilize cosine\nsimilarity of embeddings to determine passages\u2019 estimated\nsemantic similarity [28, 47, 52, 110].\nWe specifically fine-tune and evaluate two public open-\nsource large language models, e5-base-v2 [138] and\nMPNet [126] using this approach. We benchmark these two\nfine-tuned models on the SemEval STS-benchmark (Table 1)\nand find that our models outperform prior work as gen-\neral models for semantic similarity. We use the fine-tuned\ne5-base-v2 model in this work given its top performance.\nStory Identification. We base our story-identification algo-\nrithm on Dinari et al.\u2019s optimized and parallelizable version\nof the DP-Means algorithm, a non-parametric version of K-\nmeans [38] (see Appendix E). We utilize this approach as\nit is highly scalable (able to cluster our 428M embeddings)\nunlike other LLM-based approaches [52] while also allow-\ning us to identify stories without a priori knowledge. To\nfurther scale the approach, we re-implement DP-Means [38]\nto use the GPU-enhanced FAISS library [72] to perform the\nembedding-to-cluster assignments and similarity calculations\nrequired by DP-Means. To determine a suitable threshold\nfor clustering two news passages together, after fine-tuning\ne5-base-v2 , we benchmark our model on the English portion\nof the SemEval 2022 Task 8 dataset [29] (see Appendix F).\nThe SemEval 2022 Task 8 dataset consists of two parallel\nlists of news articles where each pair is graded on whether\nthey are about the same news story. Our model achieves a\nmax F1-score of 0.793 on this dataset near a cosine similarity\nthreshold of 0.50, which we use in this work. We provide\nexamples of passage pairs in the Supplementary Material.2\nFrom January 1, 2022 to July 1, 2023, clustering all our em-\nbeddings required the equivalent of 12 days using an NVIDIA\nA100 GPU. After clustering, like in other works [62, 85], we\nfilter out clusters where 50% or more of the passages are from\nonly one website ( e.g., website-specific headers or author\nbios). After this pruning, we identified 146,212 story clusters.\nWe provide 30 cluster examples in Appendix G and evaluate\nthese 30 clusters to ensure that they contain coherent stories\nusing the method outlined by Hanley et al. [62]. We achieve\n1https://huggingface .co/docs/peft/task_guides/semantic-similarity-lora\n2https://www .hanshanley .com/files/tracking_supp_material .pdf\nan estimated precision of 99.3% of assigning passages to\nappropriate story clusters where each passage matches the\nsummary, keywords, and other passages in the cluster.\nStory Summarization and Labeling. To build human-\nunderstandable representations of our clusters, we extract\nkeywords using pointwise mutual information (PMI), an\ninformation-theoretic for uncovering associations [23], to un-\ncover the words most associated with each story cluster [59].\nTo make these words more uniform, we lemmatize each word\nin each cluster. For additional details, see Appendix D. In\naddition to keyword extraction, we perform multi-document\nsummarization utilizing an instruction fine-tuned version of\nLlama 3 [39].3This enables us to summarize the different\nperspectives of the passages within a given cluster, while also\nallowing humans to easily understand a story cluster\u2019s con-\ntents. We utilize the following prompt to summarize the con-\ntents of each of our clusters: You work for a news researcher\nand your job is to summarize articles. Write a single concise\ncollective abstractive summary of the texts, where individual\ntexts are separated by |||||, and return your response as a\nsingle summary that covers the key points of the text.\nWebsite Relationship Inference. To further understand the\nrelationships between news websites, we analyze how sto-\nries spread across websites over time. We consider the set\nof articles in a cluster as a time cascade based on the date\nthat each article was published, and we use an open-source\nversion of NETINF [49] to infer the underlying structure and\nrelationship amongst our set of news websites.4Given a set\nof time cascades ( e.g., the time steps for when a particular\nwebsite posts an article within a given story cluster), while\nassuming that each node in a particular cascade is influenced\nby exactly one other node, the NETINF algorithm attempts to\ninfer the optimal network to explain the observed posting be-\nhavior [49]. Based on each website\u2019s posting behavior across\nthe different cascades, NETINF estimates the number of times\nthat each website copied information from another as well as\nthe time delay between copies. We provide additional details\nabout the NETINF algorithm in the Supplementary Material.5\nStance Detection. While passages may cover the same\nstory, they often adopt different stances [61,78,99] in address-\ning the same event. After identifying the stories on our set\nof news websites, we employ stance detection to understand\nhow different websites address each story. More concretely,\nstance detection methods determine the attitude of an author\ntoward a specific topic or target [20]. Typically, stance de-\ntection involves taking a passage piand a topic or target ti,\nand outputting the stance si\u2208 {Pro,Against ,Neutral }of the\npassage pitowards the target ti, where the target is a noun or a\nnoun phrase . Given that most stance detection methods heav-\nily rely on the topic or target, with many models struggling to\n3https://huggingface .co/meta-llama/Meta-Llama-3 .1-8B-Instruct\n4https://snap .stanford .edu/netinf/\n5https://www .hanshanley .com/files/tracking_supp_material .pdfgeneralize to topics or targets outside their domain, various\nmodels have been developed to perform stance detection in\nzero-shot (where the tested topics or targets are not in the\ntraining data) and few-shot (where very few examples of the\ntested topics or targets are in the training data) settings [8,87].\nTo perform this stance detection, we utilize the current state-\nof-the-art zero-shot TATA model [55], which was trained on\nthe V AST dataset [8]. We note that the size of our dataset of\nstance pairs precluded us from using popular large language\nmodel services like GPT-4 or Claude Sonnet. To enhance this\nmodel, we retrained it on both the V AST dataset and news-\nspecific stance detection NewsMTSC dataset [53]. By training\nthe TATA model using this extended dataset, we achieved\nstate-of-the-art F1scores of 0.781in the zero-shot setting and\n0.741in the few-shot setting on the V AST test dataset, and a\nmacro F1score of 0 .849 on the NewsMTSC test dataset.\nRather than performing stance detection on a pre-\ndetermined set of topics [51,78,82], we leverage our topic and\nstory modeling to conduct stance detection across each story\ncluster. This is such that, after we extract story keywords us-\ning PMI, we utilize the Python NLTK library\u2019s Part-of-Speech\n(POS) tagging function to identify the most distinctive noun\nkeywords [21], capturing the topic addressed in each pas-\nsage. We further use the NLTK library to filter out common\nfirst names ( e.g., Michael, Jessica) from our stance detection\nalgorithm and employ the Python spaCy library [135] to ex-\nclude nouns that fall into the following categories: FAC, LOC,\nWORK_OF_ART, DATE, TIME, PERCENT, MONEY, QUAN-\nTITY, ORDINAL, CARDINAL . This approach ensures that\npassages are not erroneously categorized as ProorAgainst\nparticular dates or monetary amounts. To ensure robust mea-\nsurements of ecosystems\u2019 and websites\u2019 stances toward spe-\ncific entities, we gather the top 5,000 noun entities ( i.e. popu-\nlar topics ) from our data and perform stance detection on each\npassage within each cluster where it appears among the top\n10 PMI keywords. Altogether, this process involves running\nstance detection on 96.3M passage and keyword pairs.\nInterpretable Mapping of Websites\u2019 Biases. A simplistic\napproach to understanding a website\u2019s overall bias ( i.e., how\nanti or pro) toward an entity such as \u201cUkraine\u201d would in-\nvolve aggregating the percentage of their articles that had pro-\n\u201cUkraine\u201d and anti-\u201cUkraine\u201d stances ( i.e., % pro-Ukraine\narticles \u2212%anti-Ukraine articles). However, this approach\ncould potentially fail given that some websites may not have\nan abundance of articles focused on Ukraine or may only\ndiscuss Ukraine-related entities to obfuscate their bias. As\nsuch, taking inspiration from Waller et al. [137] who train\nWord2Vec models to predict subreddit\u2019s biases, we instead\ntake a holistic approach by aggregating each website\u2019s respec-\ntive stances to all their written-about entities and predicting\nbias via Bayesian regression models.\nTo estimate websites\u2019 bias toward a given subject along an\naxis, we first gather a seed set of websites with at least 250 ar-\n3\n2\n1\n0\n1\n2\n3\nEstimated Bias (Pro-Democrat -> Pro-Republican)wethepeopledaily.comgopdailybrief.comfreespeech.orgblackpressusa.comReliable (\u00b5=-0.21)\nMixed (\u00b5=0.24)\nUnreliable (\u00b5=0.58)Figure 2: Partisanship of our websites based on their stances to their\narticles\u2019 topics; estimated by Bayesian regression.\nticles6discussing the entity and compute their simplistic bias\nscore ( i.e., % pro-entity articles \u2212% anti-entity articles). To\nmake these values more interpretable, we normalize these\nscores as z-scores ( i.e., mean 0 and variance 1), such that\na score of 1.0 can be interpreted as bias in favor of entity\none standard deviation above the mean [137]. Following this\ncalculation, we subsequently train a linear Bayesian regres-\nsion model with L2regularization to predict this bias score\nby utilizing our seed set of websites\u2019 stances to other entities\n(besides the one in question). Finally, once trained, using the\nmodel, we estimate the rest of our websites\u2019 bias scores to the\ngiven entity. We adopt a Bayesian approach as this directly\nenables us to quantify how individual stances contribute to\nour prediction of a website\u2019s bias to a particular entity.\nTo validate this approach, we mapped our websites to par-\ntisanship scores along the U.S. left\u2013right political spectrum\n(Figure 2) using the keywords \u201cdemocrat\u201d and \u201crepublican,\u201d\nand a seed set of 105 websites. The partisanship scores from\nthe resulting model had a \u03c1=0.51Spearman correlation with\nthe partisanship labels (Far-Right, Right, Right-Center, Cen-\nter, Left-Center, etc.) provided by Media-Bias/Fact-Check.\nAs seen in Table 2, some of the most right-leaning partisan\nstances included positive stances towards Dinesh D\u2019Souza, a\nright-leaning commentator [140] and America, while having\na negative stance toward communism. On the Democratic\nside, the associated stances include being against Texas, con-\nservatives, and the former Republican congressman George\nSantos. Similarly, as seen in Figure 2, matching the partisan\nlabels from Media-Bias/Fact-Check, we broadly observe that\nour set of reliable websites is left-leaning and the unreliable\nwebsites are right-leaning.\n4 Characterizing News Ecosystems\nHaving detailed our methodology, we now characterize the\necosystems of reliable, mixed reliability, and unreliable news\n6This ensures that the margin of error for probabilities is below 0.10 with\na 95% confidence interval based on the normal distribution.Republican Stances Coeff. Std.\nPro Souza 0.311 0.083\nPro America 0.245 0.122\nAgainst Communist 0.215 0.102\nDemocratic Stances Coeff. Std.\nAgainst Santos -0.323 0.105\nAgainst Texas -0.315 0.075\nAgainst Conservative -0.282 0.098\nTable 2: The stances most associated with U.S. partisan factions;\nestimated by Bayesian regression.\nReliable News Mixed News Unreliable News\nPro CDC Against Kardashian Against Pfizer\nPro Quantum Pro Gunnar Against Vaccine\nPro Senate Pro Alnassar Against Wuhan\nTable 3: Keywords most associated with each news ecosystem;\nestimated using PMI.\nwebsites. Visualized in Figure 3, the most heavily discussed\nstories among our set of reliable news websites included\nthe U.S. Republican primary (62,911 articles), business\nnews quarterly revenue (57,453 articles), the U.S. Supreme\nCourt\u2019s decision to overturn federal abortion rights (Roe v.\nWade) (38,358 articles), and the Russian invasion of Ukraine\n(35,135 articles). Looking at the top stories spread by un-\nreliable news websites, we observe many of the same sto-\nries, most notably one concerning the U.S. Republican pri-\nmary (13,393 articles). Indeed, across all shared story clusters\n(91,390 stories, 62.5%), we observe an average Pearson cor-\nrelation of 0.501 between the volume of articles from our\nunreliable and reliable news websites. Beyond these shared\nstories, we observe on unreliable websites a focus on corrup-\ntion and government failures (9,094 articles), the U.S. Federal\nBureau of Investigation\u2019s (FBI) search of President Donald\nTrump\u2019s Mar-a-Lago estate (7,678 articles), and the investi-\ngation into Hunter Biden\u2019s (U.S. President Joe Biden\u2019s son)\nlaptop (7,509 articles) [105]. For our set of mixed-reliability\nnews websites, we observe a heavy focus on sports and pop\nculture; two of the top five stories focus on the celebrity Kar-\ndashian family and one on the footballer Cristiano Ronaldo.\nMixed-reliability news volume is also highly correlated with\nthe volume of stories on reliable (127,106/86.9% shared sto-\nries with a \u03c1=0.689Pearson correlation for the story vol-\numes) and unreliable news websites (91,205/62.4% shared\nstories with a \u03c1=0.646). We detail each ecosystem\u2019s stories\n(i.e., the number of articles about each story as well as their\nsummaries) in the Supplementary Material.7\nUsing the stance of each website toward the top 5,000 enti-\nties in our dataset, as output by our augmented TATA model,\nwe further characterize the attitudes of our reliable, mixed-\n7https://www .hanshanley .com/files/tracking_supp_material .pdf\nThe indictment of Donald Trump comes as his Super PAC spends $1.3 million to attack potential 2024 Republican primary challenger Ron DeSantis. Meanwhile, DeSantis has been focusing on his own presidential campaign, taking a confrontational stance against Trump\nKey companies in the financial sector reported significant year-over-year growth in 2022, with some suffering a significant COVID-19 hitThe international community, particularly the U.S. and Europe, has pledged unwavering support to Ukraine in upholding its sovereignty and territorial integrity, and in defending itself against Russian aggression.Symptoms of respiratory illnesses such as COVID-19, the flu, and common colds often overlap, including fever, cough, sore throat, runny or stuffy nose, and fatigue, making it difficult to determine the specific infection. Tests are necessary to confirm the diagnosis, as symptoms can be similar to other common illnesses like allergies or respiratory conditions. The US Supreme Court's overturning of the landmark 1973 Roe v. Wade decision has given individual states the authority to decide whether abortion should be legal within their borders\nUkrainian President Volodymyr Zelenskyy is facing pressure to protect his troops and maintain public support as Russia gains ground in the Donbas region. Artificial Intelligence (AI) is a complex topic that refers to the simulation of human intelligence in machines, enabling them to think, act, and learn like humans. Small businesses are facing significant challenges due to rising inflation, supply chain issues, and labor shortages, making it harder for them to succeed. The match was characterized by a mix of dominant and even halves, with both teams creating chances but struggling to convert them into goals.Elon Musk's acquisition of Twitter for $44 billion has been tumultuous, with the company's stock value plummeting 65% in 2022 and a 44% drop in December.Figure 3: The most commonly discussed stories on reliable news websites labeled with their LLM-generated summaries.\nreliability, and unreliable news websites. To do this, we utilize\nPMI to determine the non-neutral stances most associated\nwith each ecosystem (we limit this analysis to stances rep-\nresented in at least 500 total articles within each ecosystem\nto avoid spurious values). As seen in Table 3, reliable news\nwebsites are more pro-CDC (Centers for Disease Control),\npro-Quantum, and pro-Senate (than mixed-reliability and un-\nreliable websites). The most distinctive stances of mixed-\nreliability websites concern pop culture and football (Gunnar\nis a Norwegian football manager and Al Nassr Football Club\nis a Saudi-Arabian football team). In contrast, the most dis-\ntinctive stances among the unreliable news websites primarily\nconcern the COVID-19 pandemic, with these websites dis-\ntinctly opposing vaccines, Pfizer (one of the leading compa-\nnies that developed a COVID-19 vaccine), and Wuhan, China\n(the origin of COVID-19) [102].\nThe stances between different news ecosystems are fairly\ndistinctive. Indeed, by fitting a random forest classifier to 80%\n(3,260 websites) of the websites\u2019 stance data based on their\npercentage for and against different entities (using 10% of\nthe websites as validation (408 websites) and 10% as test\ndata), we achieve an accuracy of 85.9% and an AUC of 0.889\nin differentiating unreliable news websites from reliable and\nmixed-reliability websites. This illustrates the ease of differ-\nentiating between types of websites by their stances and the\nability to predict a potentially unlabeled website\u2019s reliability\nbased on its stance towards popular news stories.\nBias Case Study: Ukraine and Vaccines. Beyond the most\ndistinctive stances that each website has, to further understandthe underlying attitudes within each ecosystem, we perform\na case study on each website ecosystem\u2019s attitudes towards\nUkraine andVaccines \u2014two of the most commonly covered\ntopics in our dataset\u2014using the methodology outlined in\nSection 3.3. While this analysis specifically addresses Ukraine\nand vaccines, similar to how we analyzed U.S.-based political\npartisanship in Section 3.3, this approach can be applied to\nany popular entity within our dataset. We additionally present\nanalyses for America, China, and Iran in the Supplementary\nMaterial.8\nPro-Ukraine Stances Coeff. Std.\nPro Zelenskyy 0.378 0.114\nPro Zelensky 0.368 0.110\nAgainst Syria 0.225 0.114\nAnti-Ukraine Stances\nAgainst Zelenskiy -0.500 0.111\nAgainst Biden -0.370 0.103\nAgainst DHS -0.345 0.119\nTable 4: Stances associated with Ukraine; estimated by Bayesian\nregression.\nFitting our Bayesian regression models for both Ukraine\nand vaccines, we map all of our news articles to a bias latent\nfor both entities in Figure 4. We observe that reliable news\nwebsites express higher support for Ukraine and vaccines\n(\u00b5vaccine =0.32, \u00b5ukraine =0.36), while unreliable news web-\nsites oppose both ( \u00b5vaccine =-0.82, \u00b5ukraine =-0.87), and mixed-\n8https://www .hanshanley .com/files/tracking_supp_material .pdf\n3\n2\n1\n0\n1\n2\n3\nEstimated Bias (Anti-Ukraine -> Pro-Ukraine)europereloaded.comzerohedge.com\nbipartisanpolicy.org\nconservativefighters.coReliable (\u00b5=0.36)\nMixed (\u00b5=0.04)\nUnreliable (\u00b5=-0.87)\n3\n2\n1\n0\n1\n2\n3\nEstimated Bias (Anti-Vaccines -> Pro-Vaccines)vaccines.newspatrioticviralnews.com\nwho.int\nhopkinsmedicine.orgReliable (\u00b5=0.32)\nMixed (\u00b5=-0.11)\nUnreliable (\u00b5=-0.82)Figure 4: Distribution of Ukraine and vaccine bias across unreliable, mixed-reliability, and reliable news websites; estimated by Bayesian\nregression.\nPro-Vaccine Stances Coeff. Std.\nPro Ukraine 0.343 0.111\nPro Trans 0.259 0.110\nPro Healthcare 0.233 0.093\nAnti-Vaccine Stances\nAgainst COVID -0.360 0.144\nAgainst FDA -0.334 0.122\nAgainst Pfizer-BioNTech -0.333 0.143\nTable 5: Stances associated with vaccines; estimated by Bayesian\nregression.\nreliability websites in the middle ( \u00b5vaccine =\u22120.11,\u00b5ukraine =\n0.04). This largely matches the original article stance distri-\nbution where we found that 31.9% of unreliable news articles\nwere anti-Ukraine and 23.8% were anti-vaccine; for mixed-\nreliability websites, 17.8% were anti-Ukraine and 8.5% were\nanti-vaccine; and for reliable news websites 12.9% of articles\nwere anti-Ukraine and 7.1% were anti-vaccine.\nAmong our dataset, the news websites most anti-Ukraine\ninclude rt.com ( zukraine = -2.36), strategic-culture.org ( zukraine\n= -2.54), and southfront.org ( zukraine = -2.41) \u2014 three web-\nsites known for spreading Russian propaganda [106]. Some of\nthe most pro-Ukraine websites include nationaljournal.com\n(zukraine = +2.53), a U.S. political policy-oriented website,\nkyivpost.com ( zukraine = +0.80), a Ukrainian website, as well\nas a selection of NBC and ABC affiliate websites including\nwbaltv.com ( zukraine = +2.04), wvtm13.com ( zukraine = +2.14),\nand ketv.com ( zukraine = +2.55) [33]. The most anti-vaccine\nwebsites include vaccineimpact.com ( zvaccine = -3.41) and\npantsonfirenews.com ( zvaccine = -2.56), both known for spread-\ning misinformation [33]. Conversely, the most pro-vaccine\nwebsites include Johns Hopkins ( zvaccine = +1.28) and the\nWorld Health Organization ( zvaccine = +0.94).\nExamining the stances most associated with each topic\nlatent (Tables 4 and 5), we observe that for Ukraine, this in-\ncludes stances concerning the current president of Ukraine,V olodymyr Zelensky [131]. Beyond this entity, we further\nobserve the entities associated with attitudes towards toward\nUkraine include other Ukrainian allies ( e.g., Biden and DHS)\nand countries in the Global South that have battled for atten-\ntion and aid following the Russian invasion of Ukraine [25].\nFor the vaccine latent, we observe that the stances most associ-\nated with being pro vaccines have to do with being pro-health\ninterventions like healthcare, as well as left-leaning causes\nlike transgender rights and Ukraine [75, 77]. In contrast, we\nobserve that being against vaccines is associated with being\nagainst COVID (the cause of the polarization of vaccina-\ntion [75]), the U.S. Food and Drug Administration (FDA),\nand Pfizer, one of the companies that developed COVID-19\nvaccines [75, 122].\n5 Underlying Website Relationships\nAs observed in Section 4, unreliable, mixed-reliability, and\nreliable news websites often cover the same stories simultane-\nously, suggesting an interdependence [127]. To further under-\nstand these relationships, we utilize an open source version\nof the NETINF [49] algorithm to infer the underlying struc-\nture and relationships amongst our sets of news websites [85].\nSpecifically, we first run NETINF using all of the extracted\nstories within our dataset as time cascades. To determine the\nappropriate number of iterations to run NETINF algorithm, as\nin Gomez et al. [49], we utilize the point at which the marginal\ngain within the algorithm of adding new edges plateaus (90%\nof the total marginal gain; see Supplemental Material9for\nadditional details).\nEcosystem Relationships Across All News Stories. Using\nthe estimated number of copies between websites and the\ntime delay between copies as found by NETINF, we first\nexamine the overall relationships between ecosystems. We\nfind that reliable and mixed-reliability news websites have\na large role in introducing stories adopted by the rest of the\n9https://www .hanshanley .com/files/tracking_supp_material .pdf\nReliable Mixed Unreliable\nCopied FromReliable Mixed UnreliableCopied To0.6 0.29 0.1\n0.43 0.44 0.13\n0.32 0.41 0.27\n0.20.30.40.50.6(a) Copies for All Stories\nReliable Mixed Unreliable\nCopied fromReliable Mixed UnreliableCopied to-1.07 days -0.44 days 7.81 days\n-1.87 days -1.51 days 4.64 days\n2.41 days 0.71 days 2.08 days\n0246 (b)\u2206-Copy Times for All Stories\nReliable Mixed Unreliable\nCopied FromReliable Mixed UnreliableCopied To0.22 0.34 0.44\n0.12 0.35 0.53\n0.041 0.21 0.75\n0.10.20.30.40.50.60.7 (c) Copies for Unrel. Stories\nReliable Mixed Unreliable\nCopied fromReliable Mixed UnreliableCopied to1.67 days 2.96 days 8.40 days\n0.17 days -3.47 days 2.16 days\n-3.40 days -5.35 days -2.09 days\n4\n2\n02468 (d)\u2206-Copy Times for Unrel. Stories\nFigure 5: The percentage of each ecosystem\u2019s copied stories that came from each different ecosystem as well as the change in the average time\ndelay between website copy/reposting of stories depending on the combination of news ecosystems.\nnews ecosystem. As seen in Figure 5a, 60% of the news\narticles on reliable news websites that were copied/influenced\nfrom elsewhere came from other reliable news websites, 43%\non mixed-reliability websites came from reliable websites,\nand 32% on unreliable websites came from reliable websites.\nUnreliable news websites had significantly less influence;\nonly 10% of the copied stories on reliable news websites\noriginated from unreliable news websites (13% for mixed-\nreliability, 27% for unreliable).\nLooking at the set of reliable websites that are the most\ncommon sources of copied stories throughout the entire news\necosystem, we see several popular websites including ya-\nhoo.com (1.19%), apnews.com (0.73%), abcnews.go.com\n(0.60%), and cnn.com (0.60%). Despite popular reliable news\nwebsites being common sources, website popularity had only\na slight Pearson correlation with their percentage of copies.\nUsing data from the Google Chrome User Report (CrUX)\nfrom October 2022 (which Ruth et al. [116,117] showed to be\nthe most reliable website popularity metric), we find that for\nunreliable news websites copying from reliable websites, the\ncorresponding reliable websites\u2019 popularity had a correlation\nof\u03c1=0.225 ( \u03c1=0.189 for reliable websites copying from reli-\nable websites, \u03c1=0.311 for mixed-reliability news websites\ncopying from reliable websites).\nAs seen in Figure 5b, reliable news websites adopt the\nstories of other reliable news websites more quickly (-1.07\ndays) compared to the average copy delay (38.4 days). Mann-\nWhitney U-tests indicate that these differences are all signif-\nicant. This compares to a nearly +7.81 day additional delay\nof reliable news websites picking up the stories from unre-\nliable news websites and -0.44 days from mixed-reliability\nwebsites. We find a similar pattern amongst mixed-reliability\nwebsites, which adopt stories from reliable news websites\n(-1.87 days) more quickly than from unreliable news websites\n(+4.64 days).\nInfluence on the Full News Ecosystem. Having examined\nthe website copies and rates of adoption between the different\necosystems, we next consider which websites are the most\ninfluential using the graph of the edge connections between\nindividual news websites. Eigenvector centralities are oftenutilized to determine the relative influence of nodes within\ngraphs [115] and, as such, we utilize this metric to understand\nwebsites\u2019 influence. We further compute hub centralities as a\nmetric for websites\u2019 influence in originating stories that spread\nto other websites (given the directionality of the arrows in\nour graph, this metric determines the most important websites\nfor supplying content [76]). We show the most influential\nwebsites in Table 6 and Figure 6.\nAll stories Hub Eign.\nyahoo.com 0.149 0.111\napnews.com 0.101 0.092\ndailymail.co.uk 0.097 0.099\nnypost.com 0.052 0.076\nindependent.co.uk 0.049 0.097\nTable 6: Websites with the largest influence in the underlying influ-\nence graph determined by NETINF with all stories considered.\nWe find that website popularity is moderately correlated\nwith the relative influence of websites within the news ecosys-\ntems (when looking at all news websites compared to only\nreliable websites in the last section). Again using website pop-\nularity data from the Google Chrome User Report (CrUX),\nwe find that a website\u2019s eigenvector centrality/influence has a\nSpearman correlation of \u03c1=0.571 (0.396 for hub centrality)\nwith that website\u2019s popularity rank.\nDespite making up 24.6% of the news websites in our\ndataset, unreliable news websites do not make up a propor-\ntional percentage amongst the most influential news websites.\nDirectly comparing the eigenvector centralities of the reli-\nable news websites to those of the unreliable news websites,\nwe find that reliable news websites are significantly more\ninfluential in this ecosystem than unreliable news websites\n(Cohen\u2019s D = 0.64, p-value \u22480),10with mixed reliability\nwebsites having comparable influence to reliable ones (no sig-\nnificant difference through Mann Whitney U-test). In terms of\norigination (hub centralities), we observe a slightly different\ntrend with mixed-reliability websites having slightly more\n10The p-value is computed using the Mann-Whitney U-test.\ndailymail.co.ukdailymail.co.ukyahoo.comyahoo.com\nindependent.co.ukindependent.co.uktheguardian.comtheguardian.com\nthe-sun.comthe-sun.com\nthesun.co.ukthesun.co.ukmetro.co.ukmetro.co.uk\ndailystar.co.ukdailystar.co.uknypost.comnypost.comcnn.comcnn.com\napnews.comapnews.com\ntheepochtimes.comtheepochtimes.combusinessinsider.combusinessinsider.com\ncbsnews.comcbsnews.comabcnews.go.comabcnews.go.com\nbreitbart.combreitbart.com\nnewsweek.comnewsweek.comwashingtonpost.comwashingtonpost.com\nforbes.comforbes.comheadtopics.comheadtopics.comupi.comupi.com\nusatoday.comusatoday.comreuters.comreuters.comwn.comwn.comnewsbreak.comnewsbreak.com latimes.comlatimes.com\nthehill.comthehill.comindianexpress.comindianexpress.com\nfoxnews.comfoxnews.com\nnecn.comnecn.comthenationalnews.comthenationalnews.commercurynews.commercurynews.com\nsandiegouniontribune.comsandiegouniontribune.comkhon2.comkhon2.com\nabovetopsecret.comabovetopsecret.comibtimes.comibtimes.combostonglobe.combostonglobe.comwavy.comwavy.comFigure 6: The most influential websites and their interactions. The\nsizes of nodes are proportional to their hub centrality. Reliable news\nwebsites are colored blue, mixed-reliability websites are colored\ngrey, and unreliable news websites are colored red.\ninfluence in originating stories compared to reliable news\nwebsites (Cohen\u2019s D = 0.04, p-value \u22480) and unreliable\nnews websites (Cohen\u2019s D = 0.05, p-value \u22480).\nSpread by Unreliable News Stories. To understand the\ndynamics of the spread of potentially factually unreliable sto-\nries, we run the NETINF algorithm on the set of 6,762 news\nstories where unreliable news websites posted a plurality\nof articles about those stories. The most popular story\namongst these clusters was about government censorship and\ncontrol (9,094 articles) summarized as: There is censorship,\npropaganda, and government control in the U.S. Cancel\nculture is a form of censorship, and that government-funded\nmedia outlets can exercise control over editorial content.\nThe text also warns about the influence of the \u201cDeep State\u201d\nand far-left communists in U.S. institutions, including the\ngovernment, media, education, and Big Business.\nAs expected, given how we narrow our set of stories, as\nseen in Figure 5c, relative to all news stories, unreliable news\nwebsites had significantly more influence in originating po-\ntentially unreliable content. For example, while for all sto-\nries, reliable news websites sourced less than 10% of all of\ntheir copied stories from unreliable news websites, within\nthis specific set of news stories, the figure was 44%. Simi-\nlarly, for mixed-reliability websites, this percentage increased\nfrom 13% to 53%. Furthermore, we find that unreliable web-\nsites source the majority of their influenced or copied stories\nfrom other unreliable news websites, at a rate of 75%. Look-\ning at the set of websites that are the common source for\nother websites to copy from (Table 7), we find a heavy re-\nliance on dailymail.co.uk, a United Kingdom-based tabloidReliable Propor.\ndailymail.co.uk 0.140\nabovetopsecret.com 0.039\nussanews.com 0.035\nMixed\ndailymail.co.uk 0.062\nthegatewaypundit.com 0.030\nussanews.com 0.027\nUnreliable\nnaturalnews.com 0.025\nussanews.com 0.021\ntheburningplatform.com 0.020\nTable 7: Websites that are the most common source of unreliable\nnews stories for each news ecosystem.\nthat Media-Bias/Fact-Check describes as having \u201clow\u201d fac-\ntual reporting due to \u201cnumerous failed fact checks and poor\ninformation sourcing.\u201d We also find that ussanews.com, de-\nscribed by Media-Bias/Fact-Check as promoting \u201centirely\nfalse, so-called facts,\u201d was a common source of potentially\nunreliable news stories.\nFor this selection of news stories predominately published\nby unreliable news websites, comparing the copy times of\nthese stories in Figure 5d to those in Figure 5b, we find that\nreliable news websites are slower to adopt the stories, regard-\nless of from which news ecosystem the story originated. We\nthus observe a reticence amongst our reliable news websites\nto report on the news stories primarily spread by unreliable\nnews outlets. However, we find that for mixed-reliability web-\nsites, if the news story began amongst other mixed-reliability\nnews outlets, these news outlets are faster to adopt the story\n(-3.47 days). We further observe that unreliable news websites\nare the fastest at picking up these news stories comparatively,\npicking them up quicker if they initially came from a mixed-\nreliability (-5.35 days) or a reliable news website (-3.40 days).\nPredom. Unreliable News Stories Hub Eign.\nthegatewaypundit.com 0.129 0.109\ndailymail.co.uk 0.075 0.125\ntheburningplatform.com 0.060 0.103\nTable 8: Websites with the largest influence in the underlying influ-\nence graph for stories predominately spread by unreliable websites.\nInfluence in the Unreliable News Ecosystem. To under-\nstand which websites are the most influential in the unreli-\nable news ecosystem, we utilize the eigenvector centrality\nof each website in the resultant graph created by running\nNETINF on our set of predominantly unreliable news sto-\nries (Table 8). For this ecosystem, we find the popularity\nof websites is only slightly correlated with eigenvector cen-\ntrality/influence ( \u03c1= 0.158) and hub centrality ( \u03c1= 0.175).\nnaturalnews.comnaturalnews.comnoqreport.comnoqreport.com\nsurvivethenews.comsurvivethenews.combeforeitsnews.combeforeitsnews.comsgtreport.comsgtreport.comlewrockwell.comlewrockwell.com\nussanews.comussanews.comthelibertybeacon.comthelibertybeacon.comlifesitenews.comlifesitenews.com\ntheepochtimes.comtheepochtimes.comtheburningplatform.comtheburningplatform.comchildrenshealthdefense.orgchildrenshealthdefense.org\nwelovetrump.comwelovetrump.comfreerepublic.comfreerepublic.com\nfoxnews.comfoxnews.comthegatewaypundit.comthegatewaypundit.com\nyahoo.comyahoo.com\ndailymail.co.ukdailymail.co.ukdailycaller.comdailycaller.com\nwesternjournal.comwesternjournal.comzerohedge.comzerohedge.com\nnewswars.comnewswars.comabovetopsecret.comabovetopsecret.com\nindependent.co.ukindependent.co.uk\nthesun.co.ukthesun.co.ukbreitbart.combreitbart.comnypost.comnypost.comredstate.comredstate.comwnd.comwnd.comFigure 7: Most influential websites and their interaction for stories\nthat are predominantly spread by unreliable news websites. Nodes\u2019\nsizes are proportional to their hub centralities.\nExamining the set of websites that are most prominent within\nthe unreliable news ecosystem (Table 8 and Figure 7), we\nfind that many well-documented websites known for spread-\ning unreliable information are among the most prominent,\nincluding theepochtimes.com, dailymail.co.uk, and thegate-\nwaypundit.com [127].\nComparing the eigenvector centralities of the unreliable\nnews websites to those of the reliable news websites, we\nfind that unreliable news websites are more influential within\nthis ecosystem (Cohen\u2019s D = 0.219, p-value <0.001), but\nthat unreliable and mixed-reliability websites had comparable\ninfluence (no significant difference via the Mann-Whitney\nU-test). However, most notably, we observe that among the\ntop influencers within this ecosystem are the reliable news\nwebsite, Yahoo News, and the mixed-reliability Fox News (not\nshown in the table). Yahoo News primarily serves as a news\naggregator, gathering reports from various sources including\nFox News, the BBC, and Reuters [143]. Given its role as an\naggregator, Yahoo News appears to have a prominent role\nin disseminating current events that are reported by other\noutlets. Classified as mixed-reliability, Fox News similarly\nhas been widely commented upon for its role in disseminating\nhyperpartisan news and misinformation [18, 34, 67].\nCase Study: News Website Coordination. To identify po-\ntential coordination among our websites in spreading unre-\nliable news, we finally utilize NETINF to discern the rela-\ntionships between websites involved in stories predominantly\npublished articles spread by unreliable and mixed-reliability\nnews websites (encompassing 40,325 news stories). After\nrunning the NETINF algorithm, we clustered the resulting\ngraph using the Louvain clustering algorithm [35]. Qualita-\ntively, the largest of these clusters was comprised of 885 rel-\natively mainstream and tabloid websites that report on gen-\neral news ( e.g., wpxi.com, nbc29.com, wvva.com), with the\ntop stories concerning the Kardashians ( Keywords: Kourt-ney, Kardashian, Travis, Khloe, Barker ). The second largest\ncluster consisted of 492 locally-oriented news websites ( e.g.,\ncbs4local.com, idahostatejournal.com), where the top stories\nfocused on immigration ( Migrant, Border, Patrol, Customs,\nSmuggling ) and the U.S. Constitution ( Constitution, Oath,\nAmendment, Constitutional ). The fourth largest cluster ( Crore,\nYoy, Profit, FY23, Quarter ) included 334 international web-\nsites ( e.g., sputniknews.com, alarabiya.net), where the top\nstory involved international companies\u2019 profits.\nMost notably, however, among our clusters was a set of\n338 websites, all with seemingly innocuous names such\nas southindynews.com and northalaskanews.com, which ap-\npeared to be dedicated to local news. Upon further investiga-\ntion through querying WHOIS, we discovered that each of\nthese websites was registered by the domain registrar Epik,\nInc., a popular provider for misinformation and online hate\nwebsites [54]. We find that this set of 338 ostensibly local\nwebsites is owned and operated by the same entity, Metric\nMedia LLC, which produces algorithmically generated con-\ntent and promotes right-wing views [144]. Indeed, using our\nmapping of websites to their respective political partisanship,\nwe found that despite these websites rarely writing articles\nabout Republicans or Democrats, they have an average parti-\nsanship \u00b5politics =0.22, indicating a slight right-leaning bias,\nwith 88.2% of these websites being classified as right-leaning.\nThese websites largely repeat the same text including arti-\ncles promoting herd immunity from COVID-19 in the United\nStates: More than 50 percent of U.S. citizens are considered\nfully vaccinated against COVID-19, nearing the target for\n\u201cherd immunity\u201d Herd immunity happens when enough of the\npopulation has become immune to the virus from the previous\ninfection that it effectively protects those who are not immune.\n6Propaganda and Slanted Influence Networks\nAs seen in the last sections, news websites, regardless of\ntheir factual reliability, often report on the same stories, with\nunreliable news websites, in select cases, influencing both\nreliable and mixed-reliability news platforms. Furthermore,\nwhile reliable and mixed-reliability news websites predomi-\nnantly adopt stories from other reliable and mixed-reliability\nsources (Figure 5a), for topics primarily spread by unreliable\nnews websites, these specious sources often act as the origina-\ntors of the content (Figure 5c). Within this vein, tracking the\nspread of unreliable news and propaganda and determining\nwhich sources are most effective at seeding these stories into\nthe mainstream media is critical for fact-checkers, journalists,\nand researchers [62, 127]. To this effect, in this section, we\nutilize our system to understand the websites originating and\nspreading specific propaganda and influence campaigns.\nTo map the influence networks targeting specific entities (ei-\nther positively or negatively), we gather news articles and the\nassociated websites that exhibit a particular valence towards\na given entity ( e.g., anti-vaccine articles). Upon gathering this\nReliable Mixed Unreliable\nCopied FromReliable Mixed UnreliableCopied To0.23 0.24 0.53\n0.17 0.22 0.61\n0.12 0.18 0.7\n0.20.30.40.50.60.7Figure 8: Anti-Ukraine Copy Matrix.\nsubset of news articles, we run the NETINF algorithm over\nthese cascades of news article clusters with specific stances.\nWe subsequently perform network analysis using eigenvec-\ntor centrality and hub centrality, as discussed in the previous\nsection, to identify the most prominent and influential web-\nsites promoting a given stance towards a particular subject.\nBy further examining day-to-day increases in news stories\nwith specific stances and comparing their spread in reliable\nand unreliable news ecosystems, we further document new\nindividual stories meant to spread particular views or stances.\nThis programmatic approach can help identify stories that\nare receiving renewed focus from unreliable news websites\nand which websites are influential in propagating stances to-\nwards entities of interest in a particularly damaging manner,\nthereby facilitating the identification and mitigation of misin-\nformation [62, 113, 118, 141]. To illustrate, we perform this\nanalysis for anti-vaccine and anti-Ukraine news stories.\nAnti-Ukraine Hub Eign.\nrt.com 0.155 0.210\nsputniknews.com 0.073 0.129\nnews-front.info 0.054 0.163\nAnti-Vaccine\nnaturalnews.com 0.141 0.179\ntheepochtimes.com 0.086 0.196\nvaccines.news 0.049 0.170\nTable 9: Websites with the largest influence in the underlying influ-\nence graph of anti-vaccine and anti-Ukraine news.\nAnti-Ukraine Messaging. As seen in Figure 9 and Table 9,\nthe most prominent anti-Ukrainian news websites during\nour study included well-known Russian propaganda web-\nsites such as Russia Today (RT), Sputnik News, and News-\nFront [106]. Beyond known Russian propaganda websites,\nwe also find that antiwar.com, described as a \u201clibertarian non-\ninterventionist website\u201d [33], was one of the most prominent\nwebsites in spreading anti-Ukrainian content. Altogether, as\nseen in Figure 8, unreliable news websites largely supply the\nrt.comrt.comtheautomaticearth.comtheautomaticearth.com\nbeforeitsnews.combeforeitsnews.comnews-front.infonews-front.info\ntheburningplatform.comtheburningplatform.comsott.netsott.netzerohedge.comzerohedge.com\nstrategic-culture.orgstrategic-culture.org\nantiwar.comantiwar.com\nussanews.comussanews.commoonofalabama.orgmoonofalabama.orgveteranstoday.comveteranstoday.com\nsputniknews.comsputniknews.comdefenddemocracy.pressdefenddemocracy.press\nbiggovernment.newsbiggovernment.newsasiatimes.comasiatimes.comconservapedia.comconservapedia.com\ntass.comtass.comindependentsentinel.comindependentsentinel.com\nthegatewaypundit.comthegatewaypundit.comthemoscowtimes.comthemoscowtimes.com\ninvestmentwatchblog.cominvestmentwatchblog.com\nfreerepublic.comfreerepublic.comtheduran.comtheduran.com\nabovetopsecret.comabovetopsecret.comnaturalnews.comnaturalnews.com\nsouthfront.orgsouthfront.org\nlewrockwell.comlewrockwell.comnationandstate.comnationandstate.com\nhotair.comhotair.comtelesurenglish.nettelesurenglish.net\ntheconservativetreehouse.comtheconservativetreehouse.comFigure 9: Anti-Ukraine Influence Network determined by the NET-\nINF algorithm. The nodes\u2019 sizes are proportional to their hub cen-\ntralities.\nmajority of the stories used across the entire news ecosys-\ntem, with reliable websites copying 53% of their copied anti-\nUkrainian stories from unreliable outlets, mixed-reliability\nwebsites copying 61%, and unreliable websites 70%.\nThe most common story pushed in this ecosystem of web-\nsites concerned justifications for Russia\u2019s invasion of Ukraine,\nwith one Russia Today article writing [132]: Moscow attacked\nthe neighboring state in late February, following Ukraine\u2019s\nfailure to implement the terms of the Minsk agreements signed\nin 2014, and Russia\u2019s eventual recognition of the Donbass\nrepublics of Donetsk and Lugansk . Further, the anti-Ukrainian\nnews story that received the largest increase in relative popu-\nlarity among our unreliable news websites in the last week of\nour study (June 25 to July 1, 2023) featured a series of articles\nwith the keywords Ukraine, MacGregor, Douglas, Colonel,\nZelensky , showing a ratio of 9 articles in the unreliable news\necosystem for every 1 article in the reliable news ecosystem.\nThis story, which predominantly spread within the unreli-\nable news ecosystem, concerned an interview with retired\nU.S. Colonel Douglas MacGregor suggesting that the war be-\ntween Ukraine and Russia was unwinnable and that Ukrainian\nPresident Zelensky was a puppet of Western powers: \u201cThe\nwar is really over for the Ukrainians. I don\u2019t see anything\nheroic about the man. And I think the most heroic thing he\ncan do right now is to come to terms with reality,\" retired\nArmy Colonel Douglas MacGregor told Fox Business News.\n\"I think Zelensky is a puppet, and he is putting huge numbers\nof his own population in unnecessary risk,\" he said. The web-\nsite that spread this story the most was paulcraigroberts.org\n(zukraine =-3.59, 3 articles).\nBeyond the set of unreliable news websites spreading anti-\nUkrainian messaging, we further observe several international\nnews websites including asiatimes.com ( zukraine =-1.13), the-\nmoscowtimes.com ( zukraine =-0.67), and the right-leaning web-\nsite hotair.com ( zukraine =-1.21) as purveyors of influential\nnaturalnews.comnaturalnews.com\ntheepochtimes.comtheepochtimes.combeforeitsnews.combeforeitsnews.com\nvaccines.newsvaccines.news\npandemic.newspandemic.newstheautomaticearth.comtheautomaticearth.com\nvaccineimpact.comvaccineimpact.com\ntheburningplatform.comtheburningplatform.com\nhealth.newshealth.newsexpose-news.comexpose-news.comlewrockwell.comlewrockwell.comthelibertybeacon.comthelibertybeacon.com\nsurvivethenews.comsurvivethenews.comabovetopsecret.comabovetopsecret.com\naustraliannationalreview.comaustraliannationalreview.comsgtreport.comsgtreport.comnewswars.comnewswars.com\nlifesitenews.comlifesitenews.comchildrenshealthdefense.orgchildrenshealthdefense.orgFigure 10: Anti-Vaccine Influence Network determined by NETINF.\nThe nodes\u2019 sizes are proportional to their hub centralities.\nanti-Ukrainian content in this ecosystem. Based on the inward-\nweighted edges, the most influenced mainstream news website\nin this ecosystem was haaretz.com, an Israeli outlet ( zukraine\n=+0.002 for Ukraine bias), and the most influenced mixed-\nreliability news website was salon.com ( zukraine = -0.056),\na US-based left-leaning news outlet. We thus observe that\neven relatively neutral and pro-Ukrainian websites can be\npotentially influenced by anti-Ukrainian news articles.\nAnti-Vaccine Messaging. As seen in Figure 10 and Ta-\nble 9, the largest source of anti-vaccine stories was natural-\nnews.com, while the most influential anti-vaccine website was\ntheepochtimes.com, both known for spreading anti-vaccine\nmisinformation [33, 111]. As with anti-Ukraine stories, we\nobserve that each website category predominantly sourced\ntheir content from unreliable news websites: 51% for reliable\nnews websites, 66% for mixed-reliability news websites, and\n81% for unreliable news websites (Figure 11). In addition\nto the theepochtimes.com and naturalnews.com, we find that\nchildrenshealthdefense.org, a website associated with former\npresidential candidate Robert F. Kennedy Jr., had a major\ninfluence on spreading anti-vaccine content, including one\narticle suggesting that a vaccine was not as safe as the U.S.\nFood and Drug Administration claimed [30].\nThe most prominent-anti-vaccine story in terms of article\nvolume raised concerns about children receiving COVID-19\nvaccines, as highlighted by childrenshealthdefense.org [97]:\nPfizer, at the urging of federal health officials, is hustling to\nget infants and toddlers injected with experimental COVID\nvaccines . The story that saw the largest relative increase in\nnews articles in the last week of our study (14 articles in\nthe unreliable news ecosystem for every 1 in the reliable\nnews ecosystem) was one with the keywords Pfizer, Batch,\nDanish, Bnt162b2, Adverse . This story concerned Danish\nscientists ostensibly discovering that batches of Pfizer vac-\nReliable Mixed Unreliable\nCopied FromReliable Mixed UnreliableCopied To0.27 0.22 0.51\n0.11 0.23 0.66\n0.031 0.16 0.81\n0.10.20.30.40.50.60.70.8Figure 11: Anti-Vaccine Copy Matrix.\ncines were actually placebos: The Danish scientists uncov-\nered \u201ccompelling evidence\u201d that a significant percentage of\nthe batches distributed in the EU likely consisted of \u201cplace-\nbos and non-placebos, \u201d prompting the researchers to call for\nfurther investigation. . The top websites that spread this story\nwere sgtreport.com ( zvaccine =-1.31 for vaccine-bias), theauto-\nmaticearth.com ( zvaccine =-1.08), and theburningplatform.com\n(zvaccine =-1.86) with two articles each.\nWe find that the reliable news website most influenced (by\nthe weighted in-degree within the resulting NETINF graph)\nwas sciencebasedmedicine.org ( zvaccine = +0.06), which fre-\nquently reports on and quotes anti-vaccine information [94],\ndetected by our system. Additionally, the most influenced\nmixed-reliability website (besides theepochtimes.com) was\nthelibertyloft.com ( zvaccine =-0.81), a right-leaning website\nthat Media-Bias/Fact-Check has identified as spreading\nCOVID-19 related misinformation [33].\n7 Limitations and Future Work\nOur work shows the promise of mapping the trajectories of\nnews stories and the takes of news websites towards specific\nentities. However, we emphasize the complexity of the news\necosystem and the considerable future work that remains to\nunderstand how information travels online. Below, we discuss\nthe limitations of our work and potential future research.\nEnglish-Language Websites. Our work is limited to\nEnglish-language news articles and focuses predominantly\non US, UK, and Australian websites. As a result, our analy-\nsis of the spread of particular stories is limited largely to the\nEnglish-speaking world and could miss other sources of news\n(i.e., a Russian-language website for example may be more\ninfluential in spreading pro-Russian propaganda than the web-\nsites in our dataset). This restriction is largely due to our use\nof PMI for identifying keywords for stance detection amongst\nour story clusters, which does not directly work in a multi-\nlingual setting. Similarly, we currently lack highly accurate\nmultilingual topic-agnostic stance-detection models [55, 63].\nWe leave to future work to consider how to semantically map\nboth news topics and stances towards them in multilingual\nsettings, as well as to consider how to source news content\nfrom websites in additional languages.\nAutomated Fact-Checking of Narratives. As previously\nnoted, we do not fact-check individual news stories, which we\nargue is a journalistic task beyond the scope of our automated\napproach. While our system can be utilized to uncover net-\nworks of websites pushing potentially unreliable news narra-\ntives allowing journalists to prioritize which stories need to be\nfact-checked by their relative spread, these stories still require\nhuman investigation to determine their veracity. However, we\nnote that for stories that have already been fact-checked on\nreputable websites, it may be possible to incorporate the ap-\nproaches of Hanley et al. [62], Zhou et al. [148], and others to\nautomatically label particular stories. Hanley et al.\u2019s approach\ninvolves gathering fact-checks from reputable sources and\nusing a DeBERTa-based model [65] to identify unreliable\nnews stories that directly contradict these fact-checks [62]. In\na similar fashion, Zhou et al.\u2019s [148] approach involves using\nan LLM agent and Google Search to identify which unreliable\nnews stories contradict fact-checks.\nEphemeral Unreliable News Websites. Factually unreli-\nable news websites tend to be ephemeral [32, 58, 68, 101],\noften only being active long enough to spread misinformation\nto other platforms before shutting down themselves. As such,\nfinding news websites as soon as they come online is criti-\ncal long term. We note that while our current system relies\non previously curated lists of websites, it can easily incor-\nporate new websites as they appear ( e.g., using the methods\noutlined by Hounsel et al. [68] for identifying new unreli-\nable news websites based on their domain registration and\nnetwork infrastructure characteristics). This inclusion would\nenable our system to surface potentially unreliable news sto-\nries that have not spread onto more popular websites. Similar\nto past work that has detected phishing and malware domains,\nit would also potentially enable uncovering malicious Doppel-\ng\u00e4nger websites that masquerade as ordinary local websites\nbut that actually spread propaganda as soon as they come\nonline [12, 13, 46, 90, 134].\n8 Discussion and Conclusion\nIn this work, we investigated the spread and stance of news\nstories across 4,076 news websites from January 1, 2022, to\nJuly 1, 2023. Our approach, which advances previous method-\nologies for understanding news flows by incorporating stance\ninto how we understand stories, allows us to track stories\nacross a mix of reliable, mixed-reliability, and unreliable news\nwebsites. (Neglecting stance in understanding the spread of\nnarratives, while helpful for examining a singular ecosystem\n[62, 127], would likely lead to misrepresentations of the inter-\nactions between websites for particular stories.)\nOur work demonstrates the key role that reliable newsplatforms play in dictating the stories covered by the entire\nnews ecosystem. These popular and largely factual websites\nmaintain the largest degree of influence on the broader news\necosystem (Figure 6) and are the source of much content\non mixed-reliability and unreliable websites (Figure 5). To\nunderstand which stories unreliable websites will spin or con-\ntort, researchers should consider reliable outlets as agenda-\nsetters [24, 45, 91]. However, we simultaneously highlight\nthat while a minimum of 62.4% of stories are shared between\ndifferent types of news websites (Section 4), different ecosys-\ntems often have distinctive attitudes towards stories. For ex-\nample, using our analysis, inline with prior work [44, 48], we\nshow that current lists of unreliable websites, in contrast to\nreliable news websites, among other biases, tend to be more\nconservative and have distinctive biases against COVID-19\nvaccines and Pfizer (Table 3).\nFinally, our work demonstrates how, by analyzing the\nstance of articles towards specific topics, we can uncover and\nunderstand influence networks directed at specific entities,\nfacilitating the tracking of propaganda ( e.g., anti-Ukraine) or\nmisinformation ( e.g., anti-vaccine) within the news ecosys-\ntem. This method also aids in identifying which otherwise\nreliable news sources may be influenced by disinformation\nand propaganda campaigns. Our approach, which considers\nthe context of authentic and mainstream websites, provides\na valuable tool for identifying dubious networks of websites\nspreading particular types of slanted information, which we\nargue can assist fact-checkers, journalists, and researchers in\nbetter understanding potential online misinformation.\nWe hope that our work encourages further quantitative anal-\nysis of the distributed news ecosystem, particularly as social\nmedia platforms become more opaque to researchers. Prior se-\ncurity research has uncovered weaknesses and attacks through\nlarge-scale analysis ( e.g., [2, 40, 42, 66, 95, 128 \u2013130]), and we\nargue that there is significant potential for future work within\nthe security community on understanding attacks against and\nstrengthening the resilience of news ecosystems.\nAcknowledgments\nThis work was supported in part by the NSF Graduate Fellow-\nship DGE-1656518, a Meta Ph.D. Fellowship, and a Sloan\nResearch Fellowship. Any opinions, findings, conclusions, or\nrecommendations expressed in this paper are those of the au-\nthors and do not necessarily reflect the views of the National\nScience Foundation or other funding agencies.\nEthical Considerations\nTrustworthy news media is fundamental to a democratic so-\nciety. Previously, false information has incited real-world\nviolence and had major consequences on public health and\nelections. Disinformation and propaganda are attacks , and it\nbehooves the security community to understand how these at-\ntacks are conducted and how to build better defenses against\nthem. Advances in this space help both citizens and news\noutlets themselves, who regularly fact-check articles. At the\nsame time, like all active measurements, web crawling and\nprogrammatic analysis of online content have potential ethical\nramifications that we must carefully consider.\nOur work collects only publicly available news content\nin line with prior work ( e.g., [60, 123, 124]). We follow best\npractices when scraping websites by slowly collecting content\nover time to reduce load. Our scraping also includes built-in\nsafety mechanisms to prevent making requests more often\nthan once every 10 seconds. We never attempt to access any\nprivileged or private data but rather focus on public stories\nthat are linked from news platforms\u2019 public homepages.\nWe also adhere to the best practices set forth for conducting\nactive Internet measurements [2, 41, 43]. The servers we use\nfor collecting content are identified as part of a research study\nthrough WHOIS, reverse DNS, and informational websites\nthat indicate how to reach us researchers. Our IT and security\nteams are also informed about how to route any questions,\nrequests, or complaints to our team. We received no requests\nto opt out of our data collection during our study.\nOur study does not generate any new content or redistribute\nexisting content. Instead, we analyze how context spreads.\nWe emphasize that while we utilize labels of individual web-\nsites as unreliable ormixed-reliability from Media-Bias/Fact-\nCheck [33] and on existing previously-curated lists, this does\nnot necessarily mean that every news story spread by these\nwebsites is misinformation. Many unreliable news websites\nreport factual information [127], and at times, otherwise re-\nliable websites may mistakenly report incorrect information.\nWe only label stories that have been previously and individu-\nally expertly labeled as misinformation .\nOpen Science\nWe are committed to sharing our data with other researchers at\nacademic or non-profit institutions seeking to conduct future\nwork or re-implement our approach. We will publicly release\nthe weights and the code for the models used in this study.\nAdditionally, we will supply the URLs of crawled news stories\nused in this study upon request.\nReferences\n[1]S. Abdali, R. Gurav, S. Menon, D. Fonseca, N. Entezari, N. Shah,\nand E. E. Papalexakis. Identifying misinformation from website\nscreenshots. In Proceedings of the International AAAI Conference on\nWeb and Social Media , volume 15, pages 2\u201313, 2021.\n[2]G. Acar, C. Eubank, S. Englehardt, M. Juarez, A. Narayanan, and\nC. Diaz. The web never forgets: Persistent tracking mechanisms in the\nwild. In ACM SIGSAC Conference on Computer and Communications\nSecurity , 2014.[3]S. Afroz, A. C. Islam, A. Stolerman, R. Greenstadt, and D. McCoy.\nDoppelg\u00e4nger finder: Taking stylometry to the underground. In IEEE\nSymposium on Security and Privacy , 2014.\n[4]H. Aghababaeian, L. Hamdanieh, and A. Ostadtaghizadeh. Alcohol\nintake in an attempt to fight covid-19: A medical myth in iran. Alcohol ,\n88:29\u201332, 2020.\n[5]R. Albalawi, T. H. Yeap, and M. Benyoucef. Using topic modeling\nmethods for short-text data: A comparative analysis. Frontiers in\nartificial intelligence , 3:42, 2020.\n[6]M. Aliapoulios, A. Papasavva, C. Ballard, E. De Cristofaro, G. Stringh-\nini, S. Zannettou, and J. Blackburn. The gospel according to q: Un-\nderstanding the qanon conspiracy from the perspective of canonical\ninformation. In The 16th International AAAI Conference on Web and\nSocial Media (ICWSM 2022) , 2022.\n[7]J. Allan. Detection as multi-topic tracking. Information Retrieval ,\n5(2-3):139\u2013157, 2002.\n[8]E. Allaway and K. McKeown. Zero-Shot Stance Detection: A Dataset\nand Model using Generalized Topic Representations. In Empirical\nMethods in Natural Language Processing , 2020.\n[9]H. Allcott and M. Gentzkow. Social media and fake news in the 2016\nelection. Journal of economic perspectives , 31(2), 2017.\n[10] J. Allen, B. Howland, M. Mobius, D. Rothschild, and D. J. Watts.\nEvaluating the fake news problem at the scale of the information\necosystem. Science advances , 6(14), 2020.\n[11] A. Amarasingam and M.-A. Argentino. The qanon conspiracy theory:\nA security threat in the making. CTC Sentinel , 13(7):37\u201344, 2020.\n[12] M. Antonakakis, R. Perdisci, D. Dagon, W. Lee, and N. Feamster.\nBuilding a dynamic reputation system for {DNS}. In19th USENIX\nSecurity Symposium (USENIX Security 10) , 2010.\n[13] M. Antonakakis, R. Perdisci, W. Lee, N. Vasiloglou II, and D. Dagon.\nDetecting malware domains at the upper {DNS}hierarchy. In 20th\nUSENIX Security Symposium (USENIX Security 11) , 2011.\n[14] M. Babaei, J. Kulshrestha, A. Chakraborty, E. M. Redmiles, M. Cha,\nand K. P. Gummadi. Analyzing biases in perception of truth in news\nstories and their implications for fact checking. IEEE Transactions\non Computational Social Systems , 9(3):839\u2013850, 2021.\n[15] J. B. Bak-Coleman, I. Kennedy, M. Wack, A. Beers, J. S. Schafer,\nE. S. Spiro, K. Starbird, and J. D. West. Combining interventions to\nreduce the spread of viral misinformation. Nature Human Behaviour ,\n6(10):1372\u20131380, 2022.\n[16] P. Ball and A. Maxmen. The epic battle against coronavirus mis-\ninformation and conspiracy theories. Nature , 581(7809):371\u2013375,\n2020.\n[17] S. Banaji, R. Bhat, A. Agarwal, N. Passanha, and M. Sadhana Pravin.\nWhatsapp vigilantes: An exploration of citizen reception and circu-\nlation of whatsapp misinformation linked to mob violence in India.\n2019.\n[18] A. Bauer, A. Nadler, and J. L. Nelson. What is fox news? partisan jour-\nnalism, misinformation, and the problem of classification. Electronic\nNews , 16(1):18\u201329, 2022.\n[19] P. Biancovilli, L. Makszin, and C. Jurberg. Misinformation on social\nnetworks during the novel coronavirus pandemic: a quali-quantitative\ncase study of Brazil. BMC Public Health , 21(1):1\u201310, 2021.\n[20] D. Biber and E. Finegan. Adverbial stance types in english. Discourse\nprocesses , 11(1), 1988.\n[21] S. Bird, E. Klein, and E. Loper. Natural language processing with\nPython: analyzing text with the natural language toolkit . 2009.\n[22] D. M. Blei, T. L. Griffiths, and M. I. Jordan. The nested chinese\nrestaurant process and bayesian nonparametric inference of topic\nhierarchies. Journal of the ACM (JACM) , 57(2):1\u201330, 2010.\n[23] G. Bouma. Normalized (pointwise) mutual information in collocation\nextraction. Proceedings of GSCL , 30:31\u201340, 2009.\n[24] G. R. Boynton and G. W. Richardson Jr. Agenda setting in the twenty-\nfirst century. New Media & Society , 18(9):1916\u20131934, 2016.\n[25] M. Brosig and R. Verma. The war in ukraine, the global south and\nthe evolving global order. Global Policy , 2024.\n[26] D. Cer, M. Diab, E. Agirre, I. Lopez-Gazpio, and L. Specia. Semeval-\n2017 task 1: Semantic textual similarity multilingual and crosslingual\nfocused evaluation. In Proceedings of the 11th International Workshop\non Semantic Evaluation (SemEval-2017) , pages 1\u201314, 2017.\n[27] D. Cer, Y . Yang, S.-y. Kong, N. Hua, N. Limtiaco, R. S. John, N. Con-\nstant, M. Guajardo-Cespedes, S. Yuan, C. Tar, et al. Universal sentence\nencoder for English. In Conference on Empirical Methods in Natural\nLanguage Processing: System Demonstrations , 2018.\n[28] D. Chandrasekaran and V . Mago. Evolution of semantic similarity\u2014a\nsurvey. ACM Computing Surveys (CSUR) , 54(2):1\u201337, 2021.\n[29] X. Chen, A. Zeynali, C. Camargo, F. Fl\u00f6ck, D. Gaffney, P. Grabowicz,\nS. Hale, D. Jurgens, and M. Samory. Semeval-2022 task 8: Multilin-\ngual news article similarity. In Proceedings of the 16th International\nWorkshop on Semantic Evaluation (SemEval-2022) , pages 1094\u20131106,\n2022.\n[30] J. Comber. Fda authorizes \u00b4traditional \u00b4novavax covid vaccine,\nbut critics question safety claims. https://web .archive .org/web/\n20220713202551/https://childrenshealthdefense .org/defender/fda-\nauthorize-traditional-novavax-covid-vaccine-safety-claims/, 7 2022.\n[31] J. Y . Cuan-Baltazar, M. J. Mu\u00f1oz-Perez, C. Robledo-Vega, M. F.\nP\u00e9rez-Zepeda, and E. Soto-Vega. Misinformation of covid-19 on the\ninternet: infodemiology study. JMIR public health and surveillance ,\n6(2):e18444, 2020.\n[32] R. Dahlke, D. Kumar, Z. Durumeric, and J. T. Hancock. Quantifying\nthe systematic bias in the accessibility and inaccessibility of web\nscraping content from url-logged web-browsing digital trace data.\nSocial Science Computer Review , page 08944393231218214, 2023.\n[33] Dave Van Zandt. Media bias/fact check. https:\n//mediabiasfactcheck .com/, 2023.\n[34] R. C. David Bauder and G. Mulvihill. Fox, dominion reach 787m\nsettlement over election claims. https://web .archive .org/web/\n20230418103714/https://apnews .com/article/fox-news-dominion-\nlawsuit-trial-trump-2020-0ac71f75acfacc52ea80b3e747fb0afe, 4\n2023.\n[35] P. De Meo, E. Ferrara, G. Fiumara, and A. Provetti. Generalized\nlouvain method for community detection in large networks. In 2011\n11th international conference on intelligent systems design and appli-\ncations , pages 88\u201393. IEEE, 2011.\n[36] P. Devine and K. Blincoe. Unsupervised extreme multi label classifi-\ncation of stack overflow posts. In Proceedings of the 1st International\nWorkshop on Natural Language-based Software Engineering , pages\n1\u20138, 2022.\n[37] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova. Bert: Pre-training\nof deep bidirectional transformers for language understanding. In\nNorth American Chapter of the Association for Computational Lin-\nguistics: Human Language Technologies, Volume 1 , 2019.\n[38] O. Dinari and O. Freifeld. Revisiting dp-means: fast scalable algo-\nrithms via parallelism and delayed cluster creation. In Uncertainty in\nArtificial Intelligence , pages 579\u2013588. PMLR, 2022.\n[39] A. Dubey, A. Jauhri, A. Pandey, A. Kadian, A. Al-Dahle, A. Letman,\nA. Mathur, A. Schelten, A. Yang, A. Fan, et al. The llama 3 herd of\nmodels. arXiv preprint arXiv:2407.21783 , 2024.\n[40] Z. Durumeric, D. Adrian, A. Mirian, J. Kasten, E. Bursztein,\nN. Lidzborski, K. Thomas, V . Eranti, M. Bailey, and J. A. Halder-\nman. Neither snow nor rain nor mitm... an empirical analysis of email\ndelivery security. In Proceedings of the 2015 Internet Measurement\nConference , pages 27\u201339, 2015.[41] Z. Durumeric, D. Adrian, P. Stephens, E. Wustrow, and J. A. Halder-\nman. Ten years of zmap. In Proceedings of the 2024 ACM on Internet\nMeasurement Conference , pages 139\u2013148, 2024.\n[42] Z. Durumeric, J. Kasten, M. Bailey, and J. A. Halderman. Analysis of\nthe https certificate ecosystem. In Proceedings of the 2013 conference\non Internet measurement conference , pages 291\u2013304, 2013.\n[43] Z. Durumeric, E. Wustrow, and J. A. Halderman. {ZMap}: Fast\ninternet-wide scanning and its security applications. In 22nd USENIX\nSecurity Symposium (USENIX Security 13) , pages 605\u2013620, 2013.\n[44] U. K. Ecker and L. C. Ang. Political attitudes and the processing\nof misinformation corrections. Political Psychology , 40(2):241\u2013260,\n2019.\n[45] L. Erbring, E. N. Goldenberg, and A. H. Miller. Front-page news and\nreal-world cues: A new look at agenda-setting by the media. American\njournal of political science , pages 16\u201349, 1980.\n[46] EU Disinfo Lab. What is the doppelganger operation? https:\n//www .disinfo .eu/doppelganger-operation/.\n[47] T. Gao, X. Yao, and D. Chen. Simcse: Simple contrastive learning\nof sentence embeddings. In Proceedings of the 2021 Conference\non Empirical Methods in Natural Language Processing , pages 6894\u2013\n6910, 2021.\n[48] R. K. Garrett and R. M. Bond. Conservatives\u2019 susceptibility to politi-\ncal misperceptions. Science Advances , 7(23):eabf1234, 2021.\n[49] M. Gomez-Rodriguez, J. Leskovec, and A. Krause. Inferring net-\nworks of diffusion and influence. ACM Transactions on Knowledge\nDiscovery from Data (TKDD) , 5(4):1\u201337, 2012.\n[50] M. Gomez Rodriguez, J. Leskovec, and B. Sch\u00f6lkopf. Structure and\ndynamics of information pathways in online media. In Proceedings\nof the sixth ACM international conference on Web search and data\nmining , pages 23\u201332, 2013.\n[51] L. Grimminger and R. Klinger. Hate towards the political opponent: A\ntwitter corpus study of the 2020 us elections on the basis of offensive\nspeech and stance detection. In Proceedings of the Eleventh Workshop\non Computational Approaches to Subjectivity, Sentiment and Social\nMedia Analysis , pages 171\u2013180, 2021.\n[52] M. Grootendorst. Bertopic: Neural topic modeling with a class-based\ntf-idf procedure. arXiv preprint arXiv:2203.05794 , 2022.\n[53] F. Hamborg and K. Donnay. Newsmtsc: A dataset for (multi-) target-\ndependent sentiment classification in political news articles. In Pro-\nceedings of the 16th Conference of the European Chapter of the Associ-\nation for Computational Linguistics: Main Volume , pages 1663\u20131675,\n2021.\n[54] C. Han, D. Kumar, and Z. Durumeric. On the infrastructure providers\nthat support misinformation websites. In Proceedings of the interna-\ntional aaai conference on web and social media , volume 16, pages\n287\u2013298, 2022.\n[55] H. Hanley and Z. Durumeric. Tata: Stance detection via topic-agnostic\nand topic-aware embeddings. In Proceedings of the 2023 Conference\non Empirical Methods in Natural Language Processing , pages 11280\u2013\n11294, 2023.\n[56] H. W. Hanley and Z. Durumeric. Machine-made media: Monitoring\nthe mobilization of machine-generated articles on misinformation and\nmainstream news websites. In Proceedings of the International AAAI\nConference on Web and Social Media , volume 18, pages 542\u2013556,\n2024.\n[57] H. W. Hanley and Z. Durumeric. Partial mobilization: Tracking\nmultilingual information flows amongst russian media outlets and\ntelegram. In Proceedings of the International AAAI Conference on\nWeb and Social Media , volume 18, pages 528\u2013541, 2024.\n[58] H. W. Hanley, D. Kumar, and Z. Durumeric. No calm in the storm:\ninvestigating qanon website relationships. In Proceedings of the\ninternational AAAI conference on Web and social media , volume 16,\npages 299\u2013310, 2022.\n[59] H. W. Hanley, D. Kumar, and Z. Durumeric. \"A special operation\":\nA quantitative approach to dissecting and comparing different media\necosystems\u2019 coverage of the russo-ukrainian war. In Proceedings\nof the International AAAI Conference on Web and social media , vol-\nume 17, pages 339\u2013350, 2023.\n[60] H. W. Hanley, D. Kumar, and Z. Durumeric. A golden age: Conspiracy\ntheories\u2019 relationship with misinformation outlets, news media, and\nthe wider internet. Proceedings of the ACM on Human-Computer\nInteraction , 7(CSCW2):1\u201333, 2023.\n[61] H. W. Hanley, D. Kumar, and Z. Durumeric. Happenstance: utilizing\nsemantic search to track russian state media narratives about the russo-\nukrainian war on reddit. In Proceedings of the international AAAI\nconference on web and social media , volume 17, pages 327\u2013338,\n2023.\n[62] H. W. Hanley, D. Kumar, and Z. Durumeric. Specious sites: Tracking\nthe spread and sway of spurious news stories at scale. In 2024 IEEE\nSymposium on Security and Privacy (SP) , pages 1609\u20131627. IEEE,\n2024.\n[63] M. Hardalov, A. Arora, P. Nakov, and I. Augenstein. Few-shot cross-\nlingual stance detection with sentiment-based pre-training. In Pro-\nceedings of the AAAI Conference on Artificial Intelligence , volume 36,\npages 10729\u201310737, 2022.\n[64] N. Hassan, G. Zhang, F. Arslan, J. Caraballo, D. Jimenez, S. Gawsane,\nS. Hasan, M. Joseph, A. Kulkarni, A. K. Nayak, et al. Claimbuster:\nThe first-ever end-to-end fact-checking system. Proceedings of the\nVLDB Endowment , 10(12):1945\u20131948, 2017.\n[65] P. He, J. Gao, and W. Chen. Debertav3: Improving deberta using\nelectra-style pre-training with gradient-disentangled embedding shar-\ning. In 11th Intl. Conf. on Learning Representations , 2022.\n[66] N. Heninger, Z. Durumeric, E. Wustrow, and J. A. Halderman. Mining\nyour ps and qs: Detection of widespread weak keys in network devices.\nIn21st USENIX Security Symposium (USENIX Security 12) , pages\n205\u2013220, 2012.\n[67] J. Hoewe, K. C. Brownell, and E. C. Wiemer. The role and impact\nof fox news. In The forum , volume 18, pages 367\u2013388. De Gruyter,\n2020.\n[68] A. Hounsel, J. Holland, B. Kaiser, K. Borgolte, N. Feamster, and\nJ. Mayer. Identifying disinformation websites using infrastructure\nfeatures. In USENIX Workshop on Free and Open Communications\non the Internet , 2020.\n[69] E. J. Hu, P. Wallis, Z. Allen-Zhu, Y . Li, S. Wang, L. Wang, W. Chen,\net al. Lora: Low-rank adaptation of large language models. In Inter-\nnational Conference on Learning Representations , 2021.\n[70] H. Jelodar, Y . Wang, C. Yuan, X. Feng, X. Jiang, Y . Li, and L. Zhao.\nLatent dirichlet allocation (lda) and topic modeling: models, applica-\ntions, a survey. Multimedia Tools and Applications , 2019.\n[71] Z. Jin, J. Cao, H. Guo, Y . Zhang, and J. Luo. Multimodal fusion\nwith recurrent neural networks for rumor detection on microblogs. In\nProceedings of the 25th ACM international conference on Multimedia ,\npages 795\u2013816, 2017.\n[72] J. Johnson, M. Douze, and H. J\u00e9gou. Billion-scale similarity search\nwith GPUs. IEEE Transactions on Big Data , 7(3), 2019.\n[73] J. L. Juul and J. Ugander. Comparing information diffusion mech-\nanisms by matching on cascade size. Proceedings of the National\nAcademy of Sciences , 118(46), 2021.\n[74] B. Kaiser, J. Wei, E. Lucherini, K. Lee, J. N. Matias, and J. Mayer.\nAdapting security warnings to counter online disinformation. In 30th\nUSENIX Security Symposium (USENIX Security 21) , pages 1163\u2013\n1180, 2021.\n[75] J. Kerr, C. Panagopoulos, and S. Van Der Linden. Political polarization\non covid-19 pandemic response in the united states. Personality and\nindividual differences , 179:110892, 2021.[76] J. M. Kleinberg, R. Kumar, P. Raghavan, S. Rajagopalan, and A. S.\nTomkins. The web as a graph: Measurements, models, and methods. In\nComputing and Combinatorics: 5th Annual International Conference,\nCOCOON\u201999 Tokyo, Japan, July 26\u201328, 1999 Proceedings 5 , pages\n1\u201317. Springer, 1999.\n[77] P. Kreko. Political tribalism, polarization, and the motivated rejection\nof science. In The Tribal Mind and the Psychology of Collectivism ,\npages 169\u2013185. Routledge, 2024.\n[78] D. K\u00fc\u00e7\u00fck and F. Can. Stance detection: A survey. ACM Computing\nSurveys (CSUR) , 53(1):1\u201337, 2020.\n[79] B. Kulis and M. I. Jordan. Revisiting k-means: new algorithms via\nbayesian nonparametrics. In International Conference on Machine\nLearning , 2012.\n[80] S. Kwon, M. Cha, K. Jung, W. Chen, and Y . Wang. Aspects of rumor\nspreading on a microblog network. In Social Informatics: 5th Inter-\nnational Conference, SocInfo 2013, Kyoto, Japan, November 25-27,\n2013, Proceedings 5 , pages 299\u2013308. Springer, 2013.\n[81] S. Kwon, M. Cha, K. Jung, W. Chen, and Y . Wang. Prominent features\nof rumor propagation in online social media. In 2013 IEEE 13th\ninternational conference on data mining , pages 1103\u20131108. IEEE,\n2013.\n[82] M. Lai, V . Patti, G. Ruffo, and P. Rosso. Stance evolution and twit-\nter interactions in an italian political debate. In Natural Language\nProcessing and Information Systems: 23rd International Conference\non Applications of Natural Language to Information Systems, NLDB\n2018, Paris, France, June 13-15, 2018, Proceedings 23 , pages 15\u201327.\nSpringer, 2018.\n[83] G. Leban, B. Fortuna, J. Brank, and M. Grobelnik. Event registry:\nlearning about world events from news. In Proceedings of the 23rd\nInternational Conference on World Wide Web , pages 107\u2013110, 2014.\n[84] D. Leonhardt. Revisiting the gaza hospital explosion.\nhttps://www .nytimes .com/2023/11/03/briefing/gaza-hospital-\nexplosion .html, 11 2023.\n[85] J. Leskovec, L. Backstrom, and J. Kleinberg. Meme-tracking and\nthe dynamics of the news cycle. In Proceedings of the 15th ACM\nSIGKDD international conference on Knowledge discovery and data\nmining , pages 497\u2013506, 2009.\n[86] B. Lester, R. Al-Rfou, and N. Constant. The power of scale for\nparameter-efficient prompt tuning. In Proceedings of the 2021 Confer-\nence on Empirical Methods in Natural Language Processing , pages\n3045\u20133059, 2021.\n[87] B. Liang, Q. Zhu, X. Li, M. Yang, L. Gui, Y . He, and R. Xu. Jointcl:\nA joint contrastive learning framework for zero-shot stance detection.\nInProceedings of the 60th Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long Papers) , volume 1, pages\n81\u201391. Association for Computational Linguistics, 2022.\n[88] J. Ma, W. Gao, P. Mitra, S. Kwon, B. J. Jansen, K.-F. Wong, and\nM. Cha. Detecting rumors from microblogs with recurrent neural\nnetworks. 2016.\n[89] G. Madraki, I. Grasso, J. M. Otala, Y . Liu, and J. Matthews. Charac-\nterizing and comparing covid-19 misinformation across languages,\ncountries and platforms. In Companion proceedings of the web con-\nference 2021 , pages 213\u2013223, 2021.\n[90] A. Martin. Russians impersonate washington post and fox news with\nanti-ukraine stories. https://therecord .media/russians-fake-news-anti-\nukraine.\n[91] M. McCombs and D. Shaw. The agenda-setting function of the press.\nThe Press. Oxford, England: Oxford University Press Inc , pages 156\u2013\n168, 2005.\n[92] D. McCoy, A. Pitsillidis, J. Grant, N. Weaver, C. Kreibich, B. Krebs,\nG. V oelker, S. Savage, and K. Levchenko. {PharmaLeaks }: Under-\nstanding the business of online pharmaceutical affiliate programs. In\n21st USENIX Security Symposium (USENIX Security 12) , pages 1\u201316,\n2012.\n[93] L. McInnes, J. Healy, S. Astels, et al. hdbscan: Hierarchical density\nbased clustering. J. Open Source Softw. , 2(11):205, 2017.\n[94] S. B. Medicine. Vaccines. https://sciencebasedmedicine .org/category/\nvaccines/, 2024.\n[95] S. Meiklejohn, M. Pomarole, G. Jordan, K. Levchenko, D. McCoy,\nG. M. V oelker, and S. Savage. A fistful of bitcoins: characterizing\npayments among men with no names. In Proceedings of the 2013 con-\nference on Internet measurement conference , pages 127\u2013140, 2013.\n[96] Y . Meng, Y . Zhang, J. Huang, Y . Zhang, and J. Han. Topic discovery\nvia latent space clustering of pretrained language model represen-\ntations. In Proceedings of the ACM web conference 2022 , pages\n3143\u20133152, 2022.\n[97] J. Mercola. Fda anxious for pfizer to rush covid shots for babies and\ntoddlers. but why? https://web .archive .org/web/20220208225347/\nhttps://childrenshealthdefense .org/defender/fda-pfizer-rush-covid-\nshots-babies-toddlers/, 2 2022.\n[98] S. Miranda, A. Znotins, S. B. Cohen, and G. Barzdins. Multilingual\nclustering of streaming news. In Proceedings of the 2018 Conference\non Empirical Methods in Natural Language Processing , pages 4535\u2013\n4544, 2018.\n[99] S. Mohammad, S. Kiritchenko, P. Sobhani, X. Zhu, and C. Cherry.\nSemeval-2016 task 6: Detecting stance in tweets. In Proceedings of\nthe 10th international workshop on semantic evaluation (SemEval-\n2016) , pages 31\u201341, 2016.\n[100] E. Momeni, S. Karunasekera, P. Goyal, and K. Lerman. Modeling\nevolution of topics in large-scale temporal text corpora. In Proceed-\nings of the International AAAI Conference on Web and Social Media ,\nvolume 12, 2018.\n[101] R. C. Moore, R. Dahlke, and J. T. Hancock. Exposure to untrustworthy\nwebsites in the 2020 us election. Nature Human Behaviour , 7(7):1096\u2013\n1105, 2023.\n[102] B. Mueller and S. G. Stolberg. Fauci grilled by law-\nmakers on masks, vaccine mandates and lab leak theory.\nhttps://web .archive .org/save/https://www .nytimes .com/2024/\n06/03/science/fauci-hearing-covid-origins .html, 6 2024.\n[103] P. Nakov and G. Da San Martino. Fake news, disinformation, propa-\nganda, and media bias. In Proceedings of the 30th ACM International\nConference on Information & Knowledge Management , pages 4862\u2013\n4865, 2021.\n[104] N. Nakshatri, S. Liu, S. Chen, D. Roth, D. Goldwasser, and D. Hopkins.\nUsing llm for improving key event discovery: Temporal-guided news\nstream clustering with event summaries. In Findings of the Associa-\ntion for Computational Linguistics: EMNLP 2023 , pages 4162\u20134173,\n2023.\n[105] D. Ng. Left-wing guardian triggered by my son hunter:\nStop trying to make hunter biden conspiracy theories hap-\npen. https://web .archive .org/web/20220903140730/https:\n//www .breitbart .com/entertainment/2022/09/03/leftwing-guardian-\ntriggered-by-my-son-hunter-stop-trying-to-make-hunter-biden-\nconspiracy-theories-happen/, 9 2022.\n[106] U. D. of State Global Engagement Center. Gec special report: Russia\u2019s\npillars of disinformation and propaganda - united states department\nof state. https://www .state .gov/russias-pillars-of-disinformation-and-\npropaganda-report/, 8 2020.\n[107] A. Papasavva, J. Blackburn, G. Stringhini, S. Zannettou, and E. D.\nCristofaro. \u201cis it a qoincidence?\u201d: An exploratory study of qanon on\nvoat. In Proceedings of the Web Conference 2021 , pages 460\u2013471,\n2021.\n[108] P. Paudel, J. Blackburn, E. De Cristofaro, S. Zannettou, and G. Stringh-\nini. Lambretta: learning to rank for twitter soft moderation. In 2023\nIEEE Symposium on Security and Privacy (SP) , pages 311\u2013326. IEEE,\n2023.[109] F. Pierri, L. Luceri, N. Jindal, and E. Ferrara. Propaganda and mis-\ninformation on facebook and twitter during the russian invasion of\nukraine. In Proceedings of the 15th ACM web science conference\n2023 , pages 65\u201374, 2023.\n[110] A. Piktus, F. Petroni, V . Karpukhin, D. Okhonko, S. Broscheit, G. Izac-\nard, P. Lewis, B. O \u02d8guz, E. Grave, W.-t. Yih, et al. The web is your\noyster\u2013knowledge-intensive nlp against a very large web corpus. arXiv\npreprint arXiv:2112.09924 , 2021.\n[111] T. A. Press. Not real news: A look at what didn\u2019t happen\nthis week. https://web .archive .org/web/20231124154018/\nhttps://apnews .com/article/fact-check-misinformation-\nf3c1d54f2d059de0532360d638335e99, 11 2023.\n[112] S. Prochaska, K. Duskin, Z. Kharazian, C. Minow, S. Blucker,\nS. Venuto, J. D. West, and K. Starbird. Mobilizing manufactured\nreality: How participatory disinformation shaped deep stories to cat-\nalyze action during the 2020 us presidential election. Proceedings of\nthe ACM on Human-Computer Interaction , 7(CSCW1):1\u201339, 2023.\n[113] M. Rajdev and K. Lee. Fake and spam messages: Detecting mis-\ninformation during natural disasters on social media. In 2015\nIEEE/WIC/ACM International Conference on Web Intelligence and\nIntelligent Agent Technology (WI-IAT) , volume 1, pages 17\u201320. IEEE,\n2015.\n[114] N. Reimers and I. Gurevych. Sentence-BERT: Sentence embeddings\nusing Siamese BERT-networks. In K. Inui, J. Jiang, V . Ng, and\nX. Wan, editors, Proceedings of the 2019 Conference on Empirical\nMethods in Natural Language Processing and the 9th International\nJoint Conference on Natural Language Processing (EMNLP-IJCNLP) ,\npages 3982\u20133992, Hong Kong, China, Nov. 2019. Association for\nComputational Linguistics.\n[115] B. Ruhnau. Eigenvector-centrality\u2014a node-centrality? Social net-\nworks , 22(4):357\u2013365, 2000.\n[116] K. Ruth, A. Fass, J. Azose, M. Pearson, E. Thomas, C. Sadowski, and\nZ. Durumeric. A world wide view of browsing the world wide web.\nInProceedings of the 22nd ACM Internet Measurement Conference ,\npages 317\u2013336, 2022.\n[117] K. Ruth, D. Kumar, B. Wang, L. Valenta, and Z. Durumeric. Toppling\ntop lists: Evaluating the accuracy of popular website lists. In Pro-\nceedings of the 22nd ACM Internet Measurement Conference , pages\n374\u2013387, 2022.\n[118] M. H. Saeed, S. Ali, J. Blackburn, E. De Cristofaro, S. Zannettou,\nand G. Stringhini. Trollmagnifier: Detecting state-sponsored troll\naccounts on reddit. In 2022 IEEE symposium on security and privacy\n(SP), pages 2161\u20132175. IEEE, 2022.\n[119] K. K. Saravanakumar, M. Ballesteros, M. K. Chandrasekaran, and\nK. Mckeown. Event-driven news stream clustering using entity-aware\ncontextual embeddings. In Proceedings of the 16th Conference of the\nEuropean Chapter of the Association for Computational Linguistics:\nMain Volume , pages 2330\u20132340, 2021.\n[120] M. S. Sch\u00e4fer and J. Painter. Climate journalism in a changing media\necosystem: Assessing the production of climate change-related news\naround the world. Wiley Interdisciplinary Reviews: Climate Change ,\n12(1):e675, 2021.\n[121] G. K. Shahi. Warclaim: A dataset for fake news on 2023 Israel\u2013Hamas\nwar. In ACM Web Science Conference , 2024.\n[122] L. Silver and A. Connaughton. Partisanship colors\nviews of covid-19 handling across advanced economies.\nhttps://www .pewresearch .org/global/2022/08/11/partisanship-\ncolors-views-of-covid-19-handling-across-advanced-economies/, 8\n2022.\n[123] V . Singrodia, A. Mitra, and S. Paul. A review on web scrapping\nand its applications. In 2019 international conference on computer\ncommunication and informatics (ICCCI) , pages 1\u20136. IEEE, 2019.\n[124] J. R. Smith, H. Saint-Amand, M. Plamada, P. Koehn, C. Callison-\nBurch, and A. Lopez. Dirt cheap web-scale parallel text from the\ncommon crawl. Association for Computational Linguistics, 2013.\n[125] V . Smith. Go Web Scraping Quick Start Guide: Implement the power\nof Go to scrape and crawl data from the web . 2019.\n[126] K. Song, X. Tan, T. Qin, J. Lu, and T.-Y . Liu. Mpnet: Masked and\npermuted pre-training for language understanding. Adv. in Neural\nInformation Processing Systems , 2020.\n[127] K. Starbird, A. Arif, T. Wilson, K. Van Koevering, K. Yefimova, and\nD. Scarnecchia. Ecosystem or echo-system? exploring content sharing\nacross alternative media domains. In Proceedings of the International\nAAAI Conference on Web and Social Media , volume 12, 2018.\n[128] R. Sundara Raman, L.-H. Merino, K. Bock, M. Fayed, D. Levin,\nN. Sullivan, and L. Valenta. Global, passive detection of connection\ntampering. In Proceedings of the ACM SIGCOMM 2023 Conference ,\npages 622\u2013636, 2023.\n[129] R. Sundara Raman, P. Shenoy, K. Kohls, and R. Ensafi. Censored\nplanet: An internet-wide, longitudinal censorship observatory. In\nproceedings of the 2020 ACM SIGSAC conference on computer and\ncommunications security , pages 49\u201366, 2020.\n[130] K. Thomas, E. Bursztein, C. Grier, G. Ho, N. Jagpal, A. Kapravelos,\nD. McCoy, A. Nappa, V . Paxson, P. Pearce, et al. Ad injection at\nscale: Assessing deceptive advertisement modifications. In 2015\nIEEE Symposium on Security and Privacy , pages 151\u2013167. IEEE,\n2015.\n[131] F. Timotija. Ukraine defense minister presses us to allow use\nof long-range weapons on russia. https://web .archive .org/web/\n20240831192927/https://thehill .com/policy/international/4857208-\nukraine-defense-minister-rustem-umerov-long-range-missiles-\nrestriction/, 8 2024.\n[132] R. Today. Finland rules on fate of seized russian art-\nwork. https://web .archive .org/web/20220524233445/https:\n//www .rt.com/russia/553529-finland-russia-art-decision/, 4 2022.\n[133] P. D. Turney. Mining the web for synonyms: Pmi-ir versus lsa on\ntoefl. In European conference on machine learning , pages 491\u2013502.\nSpringer, 2001.\n[134] U.S. Department of Justice. Justice department disrupts\ncovert russian government-sponsored foreign malign influence\noperation targeting audiences in the united states and else-\nwhere. https://www .justice .gov/opa/pr/justice-department-disrupts-\ncovert-russian-government-sponsored-foreign-malign-influence.\n[135] Y . Vasiliev. Natural language processing with Python and spaCy: A\npractical introduction . No Starch Press, 2020.\n[136] S. V osoughi, D. Roy, and S. Aral. The spread of true and false news\nonline. science , 359(6380):1146\u20131151, 2018.\n[137] I. Waller and A. Anderson. Quantifying social organization and\npolitical polarization in online platforms. Nature , 600(7888):264\u2013268,\n2021.\n[138] L. Wang, N. Yang, X. Huang, B. Jiao, L. Yang, D. Jiang, R. Majumder,\nand F. Wei. Text embeddings by weakly-supervised contrastive pre-\ntraining. arXiv preprint arXiv:2212.03533 , 2022.\n[139] G. Weld, M. Glenski, and T. Althoff. Political bias and factualness\nin news sharing across more than 100,000 online communities. In\nProceedings of the International AAAI Conference on Web and Social\nMedia , volume 15, pages 796\u2013807, 2021.\n[140] C. Wilkie. Dinesh d \u00b4souza election fraud film, book \u00b42000 mules pulled\nafter defamation suit. https://web .archive .org/web/20240601000808/\nhttps://www .cnbc .com/2024/05/31/dinesh-dsouza-election-film-\n2000-mules-pulled .html, 5 2024.\n[141] L. Wu, F. Morstatter, K. M. Carley, and H. Liu. Misinformation in\nsocial media: definition, manipulation, and detection. ACM SIGKDD\nExplorations Newsletter , 21(2):80\u201390, 2019.[142] J. Yin, D. Chao, Z. Liu, W. Zhang, X. Yu, and J. Wang. Model-based\nclustering of short text streams. In Proceedings of the 24th ACM\nSIGKDD international conference on knowledge discovery & data\nmining , pages 2634\u20132642, 2018.\n[143] D. V . Zandt. Media-Bias/Fact-Check. https://\nmediabiasfactcheck .com/yahoo-news/, 2022.\n[144] D. V . Zandt. Media-Bias/Fact-Check. https://\nmediabiasfactcheck .com/north-alaska-news/, 2022.\n[145] E. Zeng, T. Kohno, and F. Roesner. Bad news: Clickbait and deceptive\nads on news and misinformation websites. In Workshop on Technology\nand Consumer Protection , pages 1\u201311, 2020.\n[146] Y . Zhang, F. Guo, J. Shen, and J. Han. Unsupervised key event de-\ntection from massive text corpora. In Proceedings of the 28th ACM\nSIGKDD conference on knowledge discovery and data mining , pages\n2535\u20132544, 2022.\n[147] D. Zhou, H. Xu, and Y . He. An unsupervised Bayesian modelling\napproach for storyline detection on news articles. In Conference on\nEmpirical Methods in Natural Language Processing , 2015.\n[148] X. Zhou, A. Sharma, A. X. Zhang, and T. Althoff. Correcting misinfor-\nmation on social media with a large language model. arXiv preprint\narXiv:2403.11169 , 2024.\nA Article Preprocessing\nAfter collecting each page\u2019s HMTL, we then parse the con-\ntent to extract the news article text and publication date using\nthe Python libraries newspaper3k andhtmldate . We subse-\nquently remove any leftover boilerplate language ( i.e., nav-\nigation links, headers, and footers) from the text using the\njustext Python library and remove any non-English articles\nbased on labels provided by the Python langdetect library.\nWe embed the constituent passages , rather than full articles\ngiven the context window size limitations of the large lan-\nguage that we use in this work. Furthermore, as argued by\nHanley et al. [62] and shown by Pikbus et al. [110], given that\narticles often address multiple ideas, embedding passages\nallows us to track the often single idea present within the\npassage. Our dataset consists of 428,051,085 passages.\nB PEFT through LoRA\nWe utilize Parameter Efficient Fine-Tuning /PEFT [86]\nthrough Low-Rank Adaption /LoRA [69] to fine-tune and\nadapt pre-trained models to our datasets and to better their\nperformance. LoRA, specifically, after freezing the weights\nof the original pre-trained model learns pairs of low-rank-\ndecomposition matrices, reducing the amount of parameters\nthat need to be learned. LoRA has been shown to often out-\nperform other types of adaptions including full-tuning [69].\nOnce learned, these matrices are merged with the original\nfrozen weights. LoRA requires the specification of the rank\nof the matrices learned and an \u03b1value that scales the learned\nparameters. Within this work, we learn LoRA matrices for\nthe attention and the dense/linear layers of our models and\nutilize the commonly used defaults of rank=8 and \u03b1=16 [69].\nCTraining with Unsupervised Contrastive Loss\nTo adapt our embedding models to our news dataset, we uti-\nlize unsupervised contrastive learning [47]. For training, this\nis such that we embed each example xi= (passage i)\u2208DNews\n(where passage iis the passage text) twice (with dropout both\ntimes) with a given model by inputting [CLS]text i[SEP]and\naveraging the contextual word vectors of the resulting outputs\nas hidden vectors hiand\u02dchiforpassage ias its representations.\nThen, given a set of hidden vectors {hi}Nb\ni=0and{\u02dchj}Nb\nj=0(dif-\nferent dropout), where Nbis the size of the batch, we perform\na contrastive learning step for each batch. This is such that\nfor each Batch B, for an anchor hidden embedding hiwithin\nthe batch, the set of hidden vectors hi,\u02dchj\u2208B, vectors where\ni=jare positive pairs. Other pairs where i\u0338=jare considered\nnegative pairs. Within each batch B, the contrastive loss is\ncomputed across all positive pairs in the batch:\nLsim=\u22121\nNb\u2211\nhi\u2208Blc(hi)\nlc(hi) =log\u2211j\u2208B 1[i=j]exp(h\u22a4\ni\u02dchj\n\u03c4||hi||||\u02dchj||)\n\u2211j\u2208Bexp(h\u22a4\ni\u02dchj\n\u03c4||hi||||\u02dchj||)\nwhere, as in prior work [62, 87], we utilize a temperature\n\u03c4=0.07. When performing fine-tuning, we utilize default\nhyperparameters (learning rate 3\u00d710\u22125, batch size=128, and\n1M examples) specified in Gao et al. [47].\nD Pointwise Mutual Information\nThe PMI of a word word iin a cluster Cjis calculated:\nPMI(word i,Cj) =log2P(word i,Cj)\nP(word i)P(Cj)\nwhere Pis the probability of occurrence and a scaling parame-\nter\u03b1=1is added to the counts of each word per cluster. This\nscaling parameter \u03b1prevents low-frequency words in each\ncluster from having the highest PMI value [133].\nE Optimized DP-Means\nDP-Means [79] is a non-parametric extension of the K-means\nalgorithm that does not require the specification of the number\nof clusters a priori . Within DP-Means, when a given datapoint\nis a chosen parameter \u03bbaway from the closest cluster, a new\ncluster is formed. Dinari et al. [38] parallelize this algorithm\nbydelaying cluster creation until the end of the assignment\nstep. Namely, instead of creating a new cluster each time a\nnew datapoint is discovered, the algorithm determines which\ndatapoint is furthest from the current set of clusters and thencreates a new cluster with that datapoint. By delaying cluster\ncreation, the DP-means algorithm can be trivially parallelized.\nFurthermore, by delaying cluster creation, this version of DP-\nMeans avoids over-clustering the data ( i.e.,only the most\ndisparate datapoints create new clusters) [38].\nF Evaluation on SemEval22 Task 8\n0.00 0.10 0.20 0.30 0.40 0.50 0.60 0.70 0.80\nCosine Similarity Threshold0.00.10.20.30.40.50.60.70.80.91.0Metric on STS22-ENPrecision\nRecall\nF1-Score\nFigure 12: Evaluation of our model\u2019s precision, recall, and F1scores\non the English portion of the SemEval22 test dataset [29] (using 3.0\nas the cut-off for the two articles being about the same event [57]).\nG Evaluation of Clusters\nPassages\nKeywords Checked Prec.\nlaissez-faire, progressivism, liberalism, laissez, corpus 193 96.89%\nquake, earthquake, aftershock, turkey, rubble 500 100.00%\nsinema, manchin, filibuster, kyrsten, senate 500 100.00%\nwilliamson, marianne, self-help, williamsons, sander 500 97.40%\ndysphoria, puberty, blocker, crosssex, hormone 500 100.00%\nsudan, anand, evacuation, sudanese, khartoum 500 100.00%\nrioter, slogan, bearing, capitol, drum 500 99.20%\nteixeira, dighton, guardsman, teixeiras, massachusetts 500 99.40%\nfdny, firefighter, firehouse, klein, kavanagh 500 97.00%\nbragg, alvin, rouser, nypd, rabble 500 95.60%\ntaliban, afghan, afghanistan, hunger, malnutritio 500 100.00%\neyesight, blindness, blind, eye, sight 500 99.40%\nmaralago, classified, ballroom, fundraiser, document 500 100.0%\ncarolina, vetoproof, map, raleigh, cooper 500 99.80%\ntarantino, quentin, pulp, cinema, filmmaker 500 99.20%\nseoul,korea, posco, compensate, keb 500 100.00%\nmiscarriage, pregnant, pregnancy, csection, motherhood 500 100.00%\nfaucis, niaid, anthony, gain-of-function, allergy 500 100.00%\ncrump, arbery, breonna, ahmaud, trayvon 500 99.08%\nportuguese, slave, plantation, colony, dutch 500 100.00%\ncadet, guard, harassment, assault, adjutant 500 100.00%\nspam, bot, musk, twitter, elon 500 98.80%\nufo, roswell, sighting, saucer, alien 500 100.00%\ncpu, intel, x86, processor, amd 500 96.40%\nchappelle, comedian, isaiah, onstage, attacker 500 100.00%\nburisma, pozharskyi, vadym, hunter, zlochevsky 500 100.00%\nbridgerton, penelope, featherington, daphne, coughland 500 100.00%\nnaloxone, narcan, over-the-counter, emergent, nasal 500 100.00%\nschmitt, greitens, hartzler, missouri, trudy 100 99.20%\ncurrency, dollar, yuan, reserve, de-dollarization 500 99.80%\nPrec. 99.26%", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Tracking the Takes and Trajectories of English-Language News Narratives across Trustworthy and Worrisome Websites", "author": ["HWA Hanley", "E Okabe", "Z Durumeric"], "pub_year": "2025", "venue": "34th USENIX Security Symposium \u2026", "abstract": "Understanding how misleading and outright false information enters and spreads within news  ecosystems remains a difficult challenge that requires tracking how stories spread across"}, "filled": false, "gsrank": 345, "pub_url": "https://www.usenix.org/system/files/conference/usenixsecurity25/sec25cycle1-prepub-487-hanley.pdf", "author_id": ["ewdWfOoAAAAJ", "", "TxPSRHIAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:oOyDranV6BgJ:scholar.google.com/&output=cite&scirp=344&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D340%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=oOyDranV6BgJ&ei=QrWsaI2aB7_SieoPzJnloAQ&json=", "num_citations": 2, "citedby_url": "/scholar?cites=1794919376244436128&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:oOyDranV6BgJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://www.usenix.org/system/files/conference/usenixsecurity25/sec25cycle1-prepub-487-hanley.pdf"}}, {"title": "Multilingual coarse political stance classification of media. the editorial line of a ChatGPT and bard newspaper", "year": "2023", "pdf_data": "Multilingual Coarse Political Stance Classification of Media.\nThe Editorial Line of a ChatGPT and Bard Newspaper\nCristina Espa\u00f1a-Bonet\nDFKI GmbH, Saarland Informatics Campus\nSaarbr\u00fcken, Germany\ncristinae@dfki.de\nAbstract\nNeutrality is difficult to achieve and, in politics,\nsubjective. Traditional media typically adopt\nan editorial line that can be used by their po-\ntential readers as an indicator of the media bias.\nSeveral platforms currently rate news outlets\naccording to their political bias. The editorial\nline and the ratings help readers in gathering\na balanced view of news. But in the advent of\ninstruction-following language models, tasks\nsuch as writing a newspaper article can be dele-\ngated to computers. Without imposing a biased\npersona, where would an AI-based news outlet\nlie within the bias ratings? In this work, we\nuse the ratings of authentic news outlets to cre-\nate a multilingual corpus of news with coarse\nstance annotations (Left and Right) along with\nautomatically extracted topic annotations. We\nshow that classifiers trained on this data are\nable to identify the editorial line of most un-\nseen newspapers in English, German, Spanish\nand Catalan. We then apply the classifiers to\n101 newspaper-like articles written by Chat-\nGPT and Bard in the 4 languages at different\ntime periods. We observe that, similarly to\ntraditional newspapers, ChatGPT editorial line\nevolves with time and, being a data-driven sys-\ntem, the stance of the generated articles differs\namong languages.\n1 Introduction\nInstruction-following language models (ILMs) are\nomnipresent. Their use is not so extended as that\nof search engines yet, but due to the availability\nand high quality of systems and models such as\nAlpaca (Taori et al., 2023), Bard (Google, 2023),\nBLOOMZ and mT0 (Muennighoff et al., 2023),\nChatGPT (OpenAI, 2023), Llama 2-chat (Touvron\net al., 2023), or Koala (Geng et al., 2023), their use\nis expected to be more common in the near future.\nThese models face several problems being the\nmost relevant the lack of trustworthiness (van Dis\net al., 2023; Huang et al., 2023; Wang et al., 2023a).\nThey are not ready to be used as a source of reliableinformation if their outputs are not fact checked. A\nsecond big issue with systems based on language\nmodels (LM) is the fact that they might repro-\nduce the biases present in the training data (Nav-\nigli et al., 2023). Biases range from cultural miss-\nrepresentation due to data imbalance to offensive\nbehaviour reproduced from written texts. LMs are\nfinetuned into ILMs either in a supervised way us-\ning input-output pairs and an instruction (Wei et al.,\n2022; Wang et al., 2022, 2023b) or with reinforce-\nment learning from human feedback (Ouyang et al.,\n2022; Nakano et al., 2021). In both cases, the fine-\ntuning should help removing bias. But neutrality\nis something very difficult to achieve, also for the\nhumans that generate the supervisory data. The\nfinetuning phase might therefore over correct the\noriginal biases or introduce new ones. For meth-\nods that generate the supervision data with the LM\nitself, the original biases might be inherited.\nWe focus on a specific use of ILMs: the writing\nof newspaper articles. Journals and newspapers\nfollow an editorial line which is in general know\nto the reader. Besides, sites such AllSides,1Media\nBias Fact Check2(MB/FC), or Ad Fontes Media3\nprovide ratings about the political bias of (mostly\nUSA) media sources and their quality with respect\nto factual information. With these ratings, consci-\nentious readers can make informed decisions about\nwhich media outlets to choose in order to get a\nbalanced perspective. But what happens when jour-\nnalists use systems such as ChatGPT or Bard to aid\nin their writing? As said above, humans also have\nbiases, the danger lies in being unaware of them,\nas they might affect the user\u2019s/reader\u2019s perspective\n(Jakesch et al., 2023; Carroll et al., 2023). Chat-\nGPT already warns its users about misinformation.\nHowever, the political bias, if any, is not known\napart from the subjective perception that a user has.\n1https://www.allsides.com/\n2https://mediabiasfactcheck.com/\n3https://adfontesmedia.com/arXiv:2310.16269v1  [cs.CL]  25 Oct 2023\nWe address the question above for articles gen-\nerated by ChatGPT and Bard in four languages:\nEnglish, German, Spanish and Catalan. We do this\nin an automatic and systematic way with almost no\nhuman intervention so that the method can be eas-\nily extended to new languages and other ILMs with\nfew effort. We do not aim at classifying individ-\nual articles with their specific bias, but to classify\nthe media source (an ILM in this case) as Left or\nRight-oriented in a similar way as the media bias\nsites do for newspapers and other media outlets.\n2 Corpora Compilation\nWe approach our task as a classification problem\nwith two classes: Left ( L) and Right ( R) political\norientations. This is a simplification of the real\nproblem, where articles can also be neutral and\nthere might be different degrees of biases. Previ-\nous work relied on 3 or 5 classes, always includ-\ning the neutral option (Baly et al., 2020; Aksenov\net al., 2021). In these works, data was manually\nannotated creating high quality training data but\nalso limiting a lot the scope of the work in terms\nof languages and countries covered. When using\nthe fine-grained classification scale, the authors ac-\nknowledge a bad generalisation of the classifiers\nto new sources. On the other hand, Garc\u00eda-D\u00edaz\net al. (2022) and Russo et al. (2023) exclude the\nneutral class and work with a binary or multiclass\nLeft\u2013Right classifications of tweets from Spanish\nand Italian politicians respectively, but their work\ndoes not include longer texts. The binary classifica-\ntion might be justified as they worked with tweets,\na genre where people tend to be more visceral and\ntherefore probably more polarised. In our case, we\nneed to be sure that the classifier generalises well\nto unseen sources and we stick to the 2-class task\nwhile minimising the number of neutral articles in\ntraining (see below).\nDistant Supervision. As far as we know, only\na manually annotated newspaper corpus in En-\nglish (Baly et al., 2020) and another one in Ger-\nman (Aksenov et al., 2021) are available. We fol-\nlow a different approach in the spirit of Kulkarni\net al. (2018) and Kiesel et al. (2019). We do not\nmanually annotate any article, but we trust All-\nSides, MB/FC, Political Watch and Wikipedia (the\nlatter only in cases where the information is not\navailable in the previous sites) with their classi-\nfication of a newspaper bias. We extract this in-\nformation for newspapers from USA, Germany,Spain and Catalonia. With the list of newspapers,\ntheir URL,4and their stance, we use OSCAR, a\nmultilingual corpus obtained by filtering the Com-\nmon Crawl (Ortiz Su\u00e1rez et al., 2019; Abadji et al.,\n2021), to retrieve the articles. Appendix A lists\nthe sources used in this work: 47 USA newspapers\nwith 742,691 articles, 12 German with 143,200, 38\nSpanish with 301,825 and 19 Catalan with 70,496.\nTopic Modelling. Not all articles have a bias,\nsome topics are more prone than others. While\nthe Sports section of a newspaper is usually less\nprone to reflect political biases, the opposite hap-\npens with the International section. We therefore\nuse topics to select a subset of relevant training\ndata for our binary classification. We do topic mod-\nelling on the articles extracted from OSCAR using\nMallet (McCallum, 2002) which applies LDA with\nGibbs sampling. We cluster the data in both 10\nand 15 groups per language, roughly correspond-\ning to the number of sections a newspaper has.\nThe keywords extracted for each topic are listed\nin Appendix B. We choose articles that fall under\nthe topics we label as International, Government,\nLaw & Justice, Economy, Live Science/Ecology,\nand specific language-dependent topics such as Im-\nmigration and Violence for English, Nazism for\nGerman, and Social for Spanish. The selection is\ndone after the inspection of the keywords. For the\nfinal dataset, we do the union of the selected ar-\nticles clustered to 10 and 15 topics. The process\nfilters out 49% of the Spanish articles, 39% of the\nGerman and 31% of the English ones.\nPreprocessing and Cleaning. We discard ar-\nticles with more than 2000 or less than 20 words\nbefore cleaning. Afterwards, we remove headers,\nfooters and any boilerplate text detected. This text\nhas the potential to mislead a neural classifier, as\nit might encourage the classifier to learn to distin-\nguish among newspapers rather than focusing on\ntheir political stance. We select a newspaper per\nlanguage and stance for testing and clean manually\ntheir articles. To create a balanced training corpus\nfor each language, we randomly select a similar\nnumber of Left and Right-oriented articles from\nthe remaining collection. This balanced dataset is\ndivided into training and validation as shown in\nTable 1 (top rows).\nChatGPT/Bard Corpus. We create a multilin-\ngual dataset with 101 articles. For this, we define\n4This implies selecting all the articles that are under a\ndomain name of a news outlet, whether they are news or not.\nEnglish (USA) German (Germany) Spanish (Spain) Catalan (Catalonia)\nL R L R L R L R\nTraining 182,056 (756) 178,463 (768) 31,445 (550) 30,745 (384) 70,384 (874) 67,888 (806) \u2013 \u2013\nValidation 1,503 (723) 1,497 (678) 1,528 (570) 1,472 (374) 1,539 (878) 1,461 (842) \u2013 \u2013\nNewspaper 298 (731) 413 (487) 623 (278) 276 (734) 350 (844s) 518 (731) 2,105 (1,152) 800 (538)\nChatGPTv02 101 (337) \u2013 101 (346) \u2013\nChatGPTv03 \u2013 101 (299) \u2013 \u2013\nChatGPTv05 101 (585) 101 (436) 101 (553) 101 (496)\nChatGPTv08 101 (v08a:470/v08b:467) 101 (v08a:321/v08b:324) 101 (v08a:454/v08b:464) 101 (v08a:378/v08b:365)\nBardv08 101 (v08a:437/v08b:407) 101 (v08a:268/v08b:269) 101 (v08a:338/v08b:325) 101 (v08a:331/v08b:345)\nTable 1: Number of articles (average word count in parentheses) divided as articles belonging to a newspaper with a\nLeft (L) and Right orientation ( R). For testing, we use newspapers not seen in training or validation: Slate (L) and\nThe National Pulse (R) for USA, My Heimat (L) and die Preu\u00dfische Allgemeine Zeitung (R) for Germany, Mundo\nObrero (L) and El Diestro (R) for Spain and Vilaweb (L) and Diari de Tarragona (R) for Catalonia.\n101 subjects including housing prices ,abortion ,to-\nbacco ,Barak Obama , etc. and translate them man-\nually into the 4 languages (see Appendix D). The\nsubjects consider topics prone to have a political\nstance such as those related to feminism, capital-\nism, ecologism, technology, etc. We also include\nproper names of people in the 4 countries being\nconsidered, whose biography may differ depending\non the political stance of the writer. These subjects\nare inserted into the template prompt (and its trans-\nlations into German, Spanish and Catalan):5Write\na newspaper article on [SUBJECT] en\nWe prompt ChatGPT (GPT-3.5-Turbo) five times\nusing the same subjects across four time periods.\nWe generate the dataset with ChatGPT versions of\nFeb 13 (v02), Mar 23 (v03), May 24 (v05) and Aug\n3 (v08); we cover the 4 languages simultaneously\nonly with the last two. ChatGPTv05 generates sig-\nnificantly longer texts than the other ones with an\narticle-oriented structure with slots to be filled with\nthe name of the author, date and/or city. Multi-\nlingual Bard was available later, and we prompt\nit twice during the same period as ChatGPTv8.6\nTable 1 shows the statistics for this corpus.\n3 Political Stance Classification\nThe Network. We finetune XLM-RoBERTa\nlarge (Conneau et al., 2020), a multilingual\ntransformer-based masked LM trained on 100 lan-\nguages including the 4 we consider. The details\n5More specific prompts did not lead to different styles for\nthe first versions of ChatGPT, for the last one we added more\ninformation such as ...without subheaders. to avoid excesive\nsubsectioning and/or bullet points. Neither ChatGPT nor Bard\ndid always follow properly the instruction. The dataset we\nprovide includes the prompts we used.\n6Prompted 14\u201321 August 2023 from Berlin for English\nand German and from Barcelona for Spanish and Catalan as,\ncontrary to ChatGPT, the generation depends on the location.of the network and the hyperparameter exploration\nper model are reported in Appendix F.\nThe Models. We train 4 models: 3 monolingual\nfinetunings with the English, German and Spanish\ndata, plus a multilingual one with the shuffled con-\ncatenation of the data. All models are based on mul-\ntilingual embeddings (RoBERTa) finetuned either\nmonolingually or multilingually. Notice that we do\nnot train any model for Catalan. With this, we want\nto compare the performance of mono- and multi-\nlingual finetunings and explore the possibility of\nusing multilingual models for zero-shot language\ntransfer.\nCoarse Classification with Newspaper Arti-\ncles. Table 2 summarises the results. All the mod-\nels achieve more than 95% accuracy on the valida-\ntion set which is extracted from the same distribu-\ntion as the training data. In order to see how the\nmodels behave with unseen data, we calculate the\npercentage of articles that are classified as Left ( L)\nand Right ( R) in the test newspapers of Table 1.\nWe perform bootstrap resampling of the test sets\nwith 1000 bootstraps to obtain confidence intervals\nat 95% level. We do not expect all the articles of a\nnewspaper leaning towards the Left to show clear\ncharacteristics of the Left, but given that there is no\nneutral class, we expect the majority of them to be\nclassified as Left. A good result is not necessarily\n100%\u20130%, as this would not be realistic either. We\nconsider that a newspaper has been classified as\nhaving a Left/Right political stance if more than\n50% of its articles have been classified as such.\nThese cases are boldfaced in Table 2.\nThis is the behaviour we obtain for all the test\nnewspapers but for the German Right-oriented\nnewspaper: die Preu\u00dfische Allgemeine Zeitung\n(PAZ). The German model is trained only on 12\nEnglish German Spanish Catalan\nMonolingual Multilingual Monolingual Multilingual Monolingual Multilingual Multilingual\nL R L R L R L R L R L R L R\nVal. Acc (%) 97.9 96.9 99.2 96.9 95.9 96.9 \u2014\nClassification (% of articles per stance)\nNewspaper L 82\u00b15 18\u00b1481\u00b1519\u00b1487\u00b1313\u00b1265\u00b1435\u00b1455\u00b15 45\u00b15 61\u00b15 39\u00b15 65\u00b12 35\u00b12\nNewspaper R 11\u00b13 89\u00b13 7\u00b1293\u00b13 71\u00b1629\u00b1665\u00b1635\u00b15 12\u00b13 88\u00b13 19\u00b13 81\u00b14 13\u00b12 87\u00b12\nChatGPTv02 75\u00b19 25\u00b1893\u00b15 7\u00b15 \u2013 \u2013 \u2013 \u2013 65\u00b110 35\u00b110 53\u00b110 47\u00b110 \u2013 \u2013\nChatGPTv03 \u2013 \u2013 \u2013 \u2013 97\u00b14 3\u00b13 69\u00b1931\u00b19 \u2013 \u2013 \u2013 \u2013 \u2013 \u2013\nChatGPTv05 26 \u00b19 74\u00b1940\u00b1960\u00b19 96\u00b15 4\u00b13 65\u00b1935\u00b19 25\u00b19 75\u00b19 26\u00b19 74\u00b18 71 \u00b19 29\u00b19\nChatGPTv08a 54\u00b110 46\u00b110 85\u00b1815\u00b1699\u00b13 1\u00b11100\u00b120\u00b10 50\u00b110 50 \u00b110 40 \u00b110 60\u00b110 50\u00b110 50 \u00b19\nChatGPTv08b 52\u00b110 48\u00b110 85\u00b1815\u00b16100\u00b120\u00b10100\u00b120\u00b1051\u00b110 49\u00b110 36 \u00b110 64\u00b1947\u00b110 53\u00b110\nBardv08a 57\u00b111 43\u00b110 75\u00b1925\u00b1882\u00b1818\u00b1782\u00b1818\u00b1774\u00b19 26\u00b18 35 \u00b19 65\u00b19 66 \u00b19 34\u00b19\nBardv08b 61\u00b110 39\u00b110 82\u00b1818\u00b1781\u00b1819\u00b1790\u00b1710\u00b1574\u00b19 26\u00b18 44\u00b110 56\u00b110 68 \u00b19 32\u00b19\nTable 2: (top) Accuracy of the 4 finetuned models on the corresponding validation sets. (bottom) Percentage\nof articles classified as having a Left ( L) and a Right ( R) orientation (columns) for the test newspapers and the\nBard/ChatGPT generated articles at four different time periods (rows). The majority stance is boldfaced.\nnewspapers to be compared to the 47 in English and\n38 in Spanish. The incorrect classification might be\nan indication that diversity is a key aspect for the\nfinal model performance. Multilinguality does not\nhelp and 65% of the PAZ articles are still classified\nas Left oriented. We also assess the effectiveness of\nthe English model on the German data, two close\nlanguages. We acknowledge that the topics of the\nUSA and German newspapers might differ a lot,\nbut the high diversity of the English training data\ncould potentially compensate for this. The English\nmodel is able to correctly classify the German My\nHeimat as a Left-oriented newspaper ( L: 67\u00b13%)\nand PAZ as a Right-oriented one ( R: 58\u00b15%). We\nagain attribute the difference to the German model\nbeing trained on a corpus lacking diversity. When\nwe use the multilingual system, the dominant fac-\ntor distinguishing the outputs is the language itself\nrather than the stance. The addition of English data\nis insufficient to alter the classification significantly.\nWhen we use the English system, the language does\nnot play a role any more and only the stance fea-\ntures are considered. When we apply the English\nmodel to the Catalan newspapers we do not obtain\nsatisfactory results though (95 \u00b11% for the Left but\n16\u00b13% for the Right newspaper) showing that the\nrelatedness across languages is important. The mul-\ntilingual model however properly detects the stance\nof the Catalan newspapers probably because it has\nbeen trained with an heterogeneous corpus that in-\ncludes a related language (Spanish). We are able to\nperform zero-shot language transfer classification\nwhen we deal with close related languages.\nCoarse Classification with ILM-generated Ar-\nticles. The bottom part of Table 2 details the results.We first focus on the English and Spanish models\nas the German one did not properly classify our\ntest newspapers. The most relevant aspect to no-\ntice in ChatGPT is the strong change in political\nstance between February (v02) and May (v05) fol-\nlowed by a movement towards neutrality in August\n(v08). We checked that this polarity change is not\nan effect of the length of the outputs \u2014the major\nshallow change in the generated articles. The train-\ning data in English has 5,730 L\u20136,988Rarticles\nwith 584 <length (words )<624 (similar to ChatG-\nPTv05 length) and 4,563 L\u20137,127Rarticles with\n331<length< 371 (similar to ChatGPTv02). In\nboth cases the number of articles is larger for the\nRight stance, but the prediction for ChatGPTv02\nclearly points towards the Left, rejecting the hy-\npothesis that length plays a role in the classifica-\ntion. A similar thing happens for Spanish. Ac-\ncording to our models, the May 24th version of\nChatGPT in English and Spanish would have an\neditorial line close to the Right ideology, which\ndiffers from the ideology of the previous versions.\nNotably, this period corresponds to the time when\nChatGPT experienced a performance drop in sev-\neral tasks according to Chen et al. (2023). The\nGerman and Catalan outputs would still show an\nimprint from the Left ideology also in v05 but more\ndiverse training data would be needed to confirm\nthis with our monolingual models. It is interesting\nto notice that if we use the English monolingual\nmodel for German and Catalan, we still get the\nLeft imprint (60 \u00b110% for German and 87 \u00b17% for\nCatalan). So we have indications that the political\nstance of ChatGPT depends on the language, which\nis not surprising in a data-driven system. The last\nversion, ChatGPTv08, produces the most neutral\ntexts, with only German clearly leaning towards the\nLeft. The two generations, v08a and v08b, show\nthat results are robust and are not tied to a particular\ngeneration.\nThere is only a version available for multilingual\nBard that covers our time frame.7The variation\nbetween generations is larger for Bard than for\nChatGPT but, comparing v08 versions, Bard points\ntowards the Left in a more consistent way across\nlanguages. Bard\u2019s political orientation can also\nbe determined by its answers to political test or\nquiz questions. The Political Compass (PC) site8\ndefines 62 propositions to identify the political ide-\nology \u2014with an European/Western view\u2014 in two\naxes: economic policy (Left\u2013Right) and social pol-\nicy (Authoritarian\u2013Libertarian), both in the range\n[-10,10]. Each proposition is followed by 4 alterna-\ntives: strongly agree, agree, disagree and strongly\ndisagree. When prompted with the questionnaire,9\nBard\u2019s scores are (-6.50, -4.77) for English, (-8.00,\n-7.13) for German, (-5.75, -4.15) for Spanish and\n(-6.75, -4.56) for Catalan, where the first number\ncorresponds to the economic policy and the second\nto the social policy. The results are in concordance\nwith Table 2 and give an indirect validation of our\nmethod which does not rely on direct questions.10\nThis kind of analysis is not possible with Chat-\nGPT any more as it refrains from expressing opin-\nions and preferences, demonstrating the relevance\nof an approach that detects the leaning in a more\nindirect way. Also notice that these questionnaires\nare well-known and public, so it would be easy\nto instruct a LM to avoid the questions or react\nto its propositions in a neutral manner. Previous\nwork used only political tests and questionnaires\nto estimate ChatGPT\u2019s orientation. Hartmann et al.\n(2023) used PC, 38 political statements from the\nvoting advice application Wahl-O-Mat (Germany)\nand 30 from StemWijzer (the Netherlands) to con-\nclude that ChatGPT\u2019s ideology in its version of Dec\n15 2022 was pro-environmental and left-libertarian.\nA study conducted by the Manhattan Institute for\n7Notice that the version we use does not officially support\nCatalan, but native speakers confirmed that generations are\nmostly correct and fluent with few grammatical mistakes.\n8https://www.politicalcompass.org/test (accessed\nbetween 13th and 20th August 2023)\n9The Spanish questionnaire was translated into Catalan, as\nthe questionnaire was not available.\n10Even though, similarly to people, it is possible for an ILM\ntosayone thing (chose an option for a proposition) and act\n(write a text) in an inconsistent way.Policy Research11reported that ChatGPT tended\nto give responses typical of Left-of-center politi-\ncal viewpoints for English (Rozado, 2023). The\nauthors administered 15 political orientation tests\nto the ChatGPT version of Jan 9. Their results are\nconsistent with our evaluation of the Feb 13 model.\nFinally, Motoki et al. (2023) performed a battery of\ntests based on PC to show that ChatGPT is strongly\nbiased towards the Left. The authors do not state\nthe version they use, but the work was submitted on\nMarch 2023. All these results are therefore before\nthe move to the Right we detected in May.\n4 Summary and Conclusions\nMedia sources have an editorial line and an associ-\nated bias. Getting rid of political biases is difficult\nfor humans, but being aware of them helps us get-\nting a global view of news. Biases are sometimes\nclear and/or appear in form of harmful text, but\nsometimes are subtle and difficult to detect. These\nsubtle hidden biases are potentially dangerous and\nlead to manipulation whenever we are not aware of\nthem. In this work, we systematically studied the\nsubtle political biases behind ChatGPT and Bard,\nthose that appear without assigning any persona\nrole (Deshpande et al., 2023). We showed that\nChatGPT\u2019s orientation changes with time and it\nis different across languages. Between Feb and\nAug 2023, ChatGPT transitioned from a Left to\nNeutral political orientation, with a Right-leaning\nperiod in the middle for English and Spanish. The\nevolution for Bard cannot be studied yet. Its cur-\nrent version as of Aug 2023 consistently shows\nLeft-leaning for the 4 languages under study. This\nbias is independent on the factual mistakes that the\nmodel generates, and should also be considered by\nits users. We provide models to regularly check\nthe bias in text generations for USA, Germany and\nSpain, as well as in closely related political con-\ntexts and languages using a zero-shot approach.\nAs a by-product of our analysis, we created a\nmultilingual corpus of 1.2M newspaper articles\nwith coarse annotations of political stance and topic.\nWe show that distant supervision allows us to build\nmeaningful models for coarse political stance clas-\nsification as long as the corpus is diverse. We make\navailable this data together with the LMs genera-\ntions and our code through Zenodo (Espa\u00f1a-Bonet,\n2023) and Github.12\n11A conservative think tank according to Wikipedia.\n12https://github.com/cristinae/docTransformer\nLimitations\nWe are assuming that All media sources have an ed-\nitorial line and an associated bias , and we treat the\nILM as any other media source. We do not consider\nthe possibility of a ChatGPT or Bard article being\nunbiased. This is related to the distant supervision\nmethod used to gather the data that currently al-\nlows for a binary political stance annotation. Since\nmanually annotating hundreds of thousands of ar-\nticles with political biases in a truly multilingual\nsetting seems not possible in the foreseeable future,\nwe decided to implement a completely data-based\nmethod and study its language and culture transfer\ncapabilities.\nUsing distant supervision for detecting the po-\nlitical stance at article level is a delicate topic\nthough. First, because the same newspaper can\nchange ideology over time. Second, and this is\nmore related to the content of an individual article,\nnon-controversial subjects might not have a bias.\nEven in cases where bias exists, there is a spec-\ntrum ranging from the extreme Left to the extreme\nRight, rather than a clear-cut division between the\ntwo ideologies.\nIn order to quantify and if possible mitigate the\ncurrent limitations, we plan to conduct a stylis-\ntic analysis of the human-annotated corpora (Baly\net al., 2020; Aksenov et al., 2021) and compare it\nto our semi-automatically annotated corpus. As a\nfollow-up of this work, we will perform a stylistic\nanalysis of the ILM-generated texts too as a similar\nstyle between the training data and these texts is\nneeded to ensure good generalisation and transfer\ncapabilities.\nEthics Statement\nWe use generative language models, ChatGPT and\nBard, to create our test data. Since we deal with\nseveral controversial subjects (death penalty, sexual\nharassment, drugs, etc.) the automatic generation\nmight produce harmful text. The data presented\nhere has not undergone any human revision. We\nanalyse and provide the corpus as it was generated,\nalong with the indication of the systems version\nused.\nAcknowledgements\nThe author thanks the anonymous reviewers for\ninsightful comments and discussion. Eran dos ifs.References\nJulien Abadji, Pedro Javier Ortiz Su\u00e1rez, Laurent Ro-\nmary, and Beno\u00eet Sagot. 2021. Ungoliant: An op-\ntimized pipeline for the generation of a very large-\nscale multilingual web corpus. Proceedings of the\nWorkshop on Challenges in the Management of\nLarge Corpora (CMLC-9) 2021. Limerick, 12 July\n2021 (Online-Event), pages 1\u20139, Mannheim. Leibniz-\nInstitut f\u00fcr Deutsche Sprache.\nDmitrii Aksenov, Peter Bourgonje, Karolina Zaczyn-\nska, Malte Ostendorff, Julian Moreno-Schneider, and\nGeorg Rehm. 2021. Fine-grained classification of\npolitical bias in German news: A data set and initial\nexperiments. In Proceedings of the 5th Workshop\non Online Abuse and Harms (WOAH 2021) , pages\n121\u2013131, Online. Association for Computational Lin-\nguistics.\nRamy Baly, Giovanni Da San Martino, James Glass,\nand Preslav Nakov. 2020. We can detect your bias:\nPredicting the political ideology of news articles. In\nProceedings of the 2020 Conference on Empirical\nMethods in Natural Language Processing (EMNLP) ,\npages 4982\u20134991, Online. Association for Computa-\ntional Linguistics.\nMicah Carroll, Alan Chan, Henry Ashton, and David\nKrueger. 2023. Characterizing Manipulation from\nAI Systems. arXiv preprint arXiv:2303.09387 .\nLingjiao Chen, Matei Zaharia, and James Zou. 2023.\nHow is ChatGPT\u2019s behavior changing over time?\narXiv preprint arXiv:2307.09009 .\nAlexis Conneau, Kartikay Khandelwal, Naman Goyal,\nVishrav Chaudhary, Guillaume Wenzek, Francisco\nGuzm\u00e1n, Edouard Grave, Myle Ott, Luke Zettle-\nmoyer, and Veselin Stoyanov. 2020. Unsupervised\ncross-lingual representation learning at scale. In Pro-\nceedings of the 58th Annual Meeting of the Asso-\nciation for Computational Linguistics , pages 8440\u2013\n8451, Online. Association for Computational Lin-\nguistics.\nAmeet Deshpande, Vishvak Murahari, Tanmay Rajpuro-\nhit, Ashwin Kalyan, and Karthik Narasimhan. 2023.\nToxicity in ChatGPT: Analyzing Persona-assigned\nLanguage Models. arXiv preprint arXiv:2304.05335 .\nCristina Espa\u00f1a-Bonet. 2023. Multilingual Coarse Po-\nlitical Stance Classification of Media. The Editorial\nLine of a ChatGPT and Bard Newspaper. Dataset on\nZenodo, v1.0.\nJos\u00e9 Antonio Garc\u00eda-D\u00edaz, Ricardo Colomo-Palacios,\nand Rafael Valencia-Garc\u00eda. 2022. Psychographic\nTraits Identification Based on Political Ideology:\nAn Author Analysis Study on Spanish Politicians\u2019\nTweets Posted in 2020. Future Gener. Comput. Syst. ,\n130(C):59\u201374.\nXinyang Geng, Arnav Gudibande, Hao Liu, Eric Wal-\nlace, Pieter Abbeel, Sergey Levine, and Dawn Song.\n2023. Koala: A Dialogue Model for Academic Re-\nsearch. Blog post.\nGoogle. 2023. Bard [Instruction-following large lan-\nguage model].\nJochen Hartmann, Jasper Schwenzow, and Maximil-\nian Witte. 2023. The political ideology of conversa-\ntional AI: Converging evidence on ChatGPT\u2019s pro-\nenvironmental, left-libertarian orientation. arXiv\npreprint arXiv:2301.01768 .\nXiaowei Huang, Wenjie Ruan, Wei Huang, Gaojie\nJin, Yi Dong, Changshun Wu, Saddek Bensalem,\nRonghui Mu, Yi Qi, Xingyu Zhao, et al. 2023. A\nSurvey of Safety and Trustworthiness of Large Lan-\nguage Models through the Lens of Verification and\nValidation. arXiv preprint arXiv:2305.11391 .\nMaurice Jakesch, Advait Bhat, Daniel Buschek, Lior\nZalmanson, and Mor Naaman. 2023. Co-writing with\nopinionated language models affects users\u2019 views.\nInProceedings of the 2023 CHI Conference on Hu-\nman Factors in Computing Systems , pages 1\u201315, New\nYork, NY , USA. Association for Computing Machin-\nery.\nJohannes Kiesel, Maria Mestre, Rishabh Shukla, Em-\nmanuel Vincent, Payam Adineh, David Corney,\nBenno Stein, and Martin Potthast. 2019. SemEval-\n2019 task 4: Hyperpartisan news detection. In\nProceedings of the 13th International Workshop on\nSemantic Evaluation , pages 829\u2013839, Minneapolis,\nMinnesota, USA. Association for Computational Lin-\nguistics.\nVivek Kulkarni, Junting Ye, Steve Skiena, and\nWilliam Yang Wang. 2018. Multi-view models for\npolitical ideology detection of news articles. In Pro-\nceedings of the 2018 Conference on Empirical Meth-\nods in Natural Language Processing , pages 3518\u2013\n3527, Brussels, Belgium. Association for Computa-\ntional Linguistics.\nAndrew Kachites McCallum. 2002. MALLET:\nA Machine Learning for Language Toolkit.\nhttp://mallet.cs.umass.edu.\nFabio Motoki, Valdemar Pinho Neto, and Victor Ro-\ndrigues. 2023. More human than human: Measuring\nChatGPT political bias. Public Choice .\nNiklas Muennighoff, Thomas Wang, Lintang Sutawika,\nAdam Roberts, Stella Biderman, Teven Le Scao,\nM Saiful Bari, Sheng Shen, Zheng Xin Yong, Hai-\nley Schoelkopf, Xiangru Tang, Dragomir Radev,\nAlham Fikri Aji, Khalid Almubarak, Samuel Al-\nbanie, Zaid Alyafeai, Albert Webson, Edward Raff,\nand Colin Raffel. 2023. Crosslingual generaliza-\ntion through multitask finetuning. In Proceedings\nof the 61st Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long Papers) ,\npages 15991\u201316111, Toronto, Canada. Association\nfor Computational Linguistics.\nReiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu,\nLong Ouyang, Christina Kim, Christopher Hesse,\nShantanu Jain, Vineet Kosaraju, William Saunders,et al. 2021. WebGPT: Browser-assisted question-\nanswering with human feedback. arXiv preprint\narXiv:2112.09332 .\nRoberto Navigli, Simone Conia, and Bj\u00f6rn Ross. 2023.\nBiases in Large Language Models: Origins, Inven-\ntory, and Discussion. J. Data and Information Qual-\nity, 15(2).\nOpenAI. 2023. ChatGPT [Instruction-following large\nlanguage model].\nPedro Javier Ortiz Su\u00e1rez, Beno\u00eet Sagot, and Lau-\nrent Romary. 2019. Asynchronous pipelines for\nprocessing huge corpora on medium to low re-\nsource infrastructures. Proceedings of the Work-\nshop on Challenges in the Management of Large\nCorpora (CMLC-7) 2019. Cardiff, 22nd July 2019,\npages 9\u201316, Mannheim. Leibniz-Institut f\u00fcr Deutsche\nSprache.\nLong Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida,\nCarroll Wainwright, Pamela Mishkin, Chong Zhang,\nSandhini Agarwal, Katarina Slama, Alex Ray, John\nSchulman, Jacob Hilton, Fraser Kelton, Luke Miller,\nMaddie Simens, Amanda Askell, Peter Welinder,\nPaul F Christiano, Jan Leike, and Ryan Lowe. 2022.\nTraining language models to follow instructions with\nhuman feedback. In Advances in Neural Information\nProcessing Systems , volume 35, pages 27730\u201327744.\nCurran Associates, Inc.\nDavid Rozado. 2023. Danger in the Machine: The Per-\nils of Political and Demographic Biases Embedded\nin AI System. Manhatan Institue, Issue Brief , pages\n1\u201316.\nDaniel Russo, Salud Mar\u00eda Jim\u00e9nez-Zafra, Jos\u00e9 Antonio\nGarc\u00eda-D\u00edaz, Tommaso Caselli, L. Alfonso Ure\u00f1a-\nL\u00f3pez, and Rafael Valencia-Garc\u00eda. 2023. PoliticIT\nat EV ALITA 2023: Overview of the Political Ideol-\nogy Detection in Italian Texts Task. In Eighth Eval-\nuation Campaign of Natural Language Processing\nand Speech Tools for Italian 2023 , number 3473 in\nCEUR Workshop Proceedings, Aachen.\nRohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann\nDubois, Xuechen Li, Carlos Guestrin, Percy Liang,\nand Tatsunori B. Hashimoto. 2023. Stanford Alpaca:\nAn Instruction-following LLaMA model. https:\n//github.com/tatsu-lab/stanford_alpaca .\nHugo Touvron, Louis Martin, Kevin Stone, Peter Al-\nbert, Amjad Almahairi, Yasmine Babaei, Nikolay\nBashlykov, Soumya Batra, Prajjwal Bhargava, Shruti\nBhosale, Dan Bikel, Lukas Blecher, Cristian Canton\nFerrer, Moya Chen, Guillem Cucurull, David Esiobu,\nJude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller,\nCynthia Gao, Vedanuj Goswami, Naman Goyal, An-\nthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan\nInan, Marcin Kardas, Viktor Kerkez, Madian Khabsa,\nIsabel Kloumann, Artem Korenev, Punit Singh Koura,\nMarie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Di-\nana Liskovich, Yinghai Lu, Yuning Mao, Xavier Mar-\ntinet, Todor Mihaylov, Pushkar Mishra, Igor Moly-\nbog, Yixin Nie, Andrew Poulton, Jeremy Reizen-\nstein, Rashi Rungta, Kalyan Saladi, Alan Schelten,\nRuan Silva, Eric Michael Smith, Ranjan Subrama-\nnian, Xiaoqing Ellen Tan, Binh Tang, Ross Tay-\nlor, Adina Williams, Jian Xiang Kuan, Puxin Xu,\nZheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan,\nMelanie Kambadur, Sharan Narang, Aurelien Ro-\ndriguez, Robert Stojnic, Sergey Edunov, and Thomas\nScialom. 2023. Llama 2: Open foundation and fine-\ntuned chat models. arXiv preprint arXiv:2307.09288 .\nEva A. M. van Dis, Johan Bollen, Willem Zuidema,\nRobert van Rooij, and Claudi L. Bockting. 2023.\nChatGPT: five priorities for research. Nature ,\n614(7947):224\u2013226.\nBoxin Wang, Weixin Chen, Hengzhi Pei, Chulin Xie,\nMintong Kang, Chenhui Zhang, Chejian Xu, Zidi\nXiong, Ritik Dutta, Rylan Schaeffer, et al. 2023a.\nDecodingTrust: A Comprehensive Assessment of\nTrustworthiness in GPT Models. arXiv preprint\narXiv:2306.11698 .\nYizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa\nLiu, Noah A. Smith, Daniel Khashabi, and Hannaneh\nHajishirzi. 2023b. Self-instruct: Aligning language\nmodels with self-generated instructions. In Proceed-\nings of the 61st Annual Meeting of the Association for\nComputational Linguistics (Volume 1: Long Papers) ,\npages 13484\u201313508, Toronto, Canada. Association\nfor Computational Linguistics.\nYizhong Wang, Swaroop Mishra, Pegah Alipoormo-\nlabashi, Yeganeh Kordi, Amirreza Mirzaei, Atharva\nNaik, Arjun Ashok, Arut Selvan Dhanasekaran,\nAnjana Arunkumar, David Stap, Eshaan Pathak,\nGiannis Karamanolakis, Haizhi Lai, Ishan Puro-\nhit, Ishani Mondal, Jacob Anderson, Kirby Kuznia,\nKrima Doshi, Kuntal Kumar Pal, Maitreya Patel,\nMehrad Moradshahi, Mihir Parmar, Mirali Purohit,\nNeeraj Varshney, Phani Rohitha Kaza, Pulkit Verma,\nRavsehaj Singh Puri, Rushang Karia, Savan Doshi,\nShailaja Keyur Sampat, Siddhartha Mishra, Sujan\nReddy A, Sumanta Patro, Tanay Dixit, and Xudong\nShen. 2022. Super-NaturalInstructions: Generaliza-\ntion via declarative instructions on 1600+ NLP tasks.\nInProceedings of the 2022 Conference on Empiri-\ncal Methods in Natural Language Processing , pages\n5085\u20135109, Abu Dhabi, United Arab Emirates. As-\nsociation for Computational Linguistics.\nJason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu,\nAdams Wei Yu, Brian Lester, Nan Du, Andrew M.\nDai, and Quoc V Le. 2022. Finetuned language mod-\nels are zero-shot learners. In International Confer-\nence on Learning Representations .\nA Newspapers in OSCAR 22.01\nLanguage Leaning Newspaper URL #Articles Word average\nen L ABC News abcnews.go.com 28101 659\nen L AlterNet www.alternet.org 1228 1680\nen L Associated Press News apnews.com 47090 679\nen L Axios www.axios.com 2119 733\nen L Buzzfeed News www.buzzfeednews.com 11025 885\nen L CBS News www.cbsnews.com 19761 534\nen L CNN www.cnn.com 15273 712\nen L edition.cnn.com 19204 772\nen L Democracy Now! www.democracynow.org 1481 1213\nen L HuffPost www.huffpost.com 45721 961\nen L preview.www.huffpost.com 181 1097\nen L staging.www.huffpost.com 266 1142\nen L Insider www.insider.com 3705 1047\nen L Mother Jones www.motherjones.com 12332 688\nen L MSNBC News www.msnbc.com 20682 250\nen L NBC News www.nbcnews.com 38620 518\nen L NPR www.npr.org 45517 793\nen L archive.nytimes.com 524 913\nen L Politico www.politico.com 30842 804\nen L Slate www.slate.com 674 761\nen L The Atlantic www.theatlantic.com 41816 750\nen L The Daily Beast www.thedailybeast.com 27771 806\nen L The Economist www.economist.com 38672 822\nen L The Intercept theintercept.com 17766 1328\nen L The New Yorker www.newyorker.com 18698 688\nen L The New York Times www.nytimes.com 2382 446\nen L The Washington Post www.washingtonpost.com 11944 1009\nen L USA Today www.usatoday.com 4526 1308\nen L V ox www.vox.com 6746 934\nen R American Greatness amgreatness.com 2405 849\nen R American Thinker www.americanthinker.com 9891 805\nen R Breitbart News Network www.breitbart.com 18762 651\nen R ConservativeHQ www.conservativehq.com 1685 455\nen R Fox News www.foxnews.com 25074 770\nen R InfoWars www.infowars.com 127 574\nen R Life Action www.liveaction.org 3095 740\nen R National Review www.nationalreview.com 7251 946\nen R Reason reason.com 23553 489\nen R The American Conservative www.theamericanconservative 1228 935\nen R The Blaze www.theblaze.com 34 1291\nen R The Daily Caller dailycaller.com 26125 449\nen R amp.dailycaller.com 61 540\nen R The Daily Wire www.dailywire.com 7143 603\nen R The Epoch Times www.theepochtimes.com 27553 695\nen R The Federalist thefederalist.com 7759 835\nen R The Gateway Pundit www.thegatewaypundit.com 5232 431\nen R The National Pulse thenationalpulse.com 481 593\nen R The Washington Free Beacon freebeacon.com 7310 593\nen R The Washington Times www.washingtontimes.com 19486 710\nen R The Spectator spectator.org 14903 762\nen R Washington Examiner m.washingtonexaminer.com 30 647\nen R WND www.wnd.com 21099 664\nde L Die Zeit www.zeit.de 12 4211\nde L Die Tageszeitung taz.de 40253 694\nde L blogs.taz.de 1336 723\nde L genossenschaft.taz.de 16 482\nde L DW News www.dw.com 2290 1075\nde L Junge Welt www.jungewelt.de 7386 279\nde L My Heimat www.staz.de 2499 329\nde L Neues Deutschland www.nd-aktuell.de 6608 785\nde L S\u00fcddeutsche Zeitung www.sueddeutsche.de 31578 583\nde R Bild www.bild.de 24459 279\nde R Frankfurter Allgemeine Zeitung www.faz.net 12340 478\nContinued on next page\nLanguage Leaning Newspaper URL #Articles Word average\nde R Die Welt www.welt.de 9546 553\nde R Junge Freiheit jungefreiheit.de 8379 496\nde R Preu\u00dfische Allgemeine Zeitung paz.de 385 945\nes L Cuarto poder www.cuartopoder.es 3105 1353\nes L De Verdad digital deverdaddigital.com 3422 1071\nes L Diario progresista www.diarioprogresista.es 217 599\nes L Digital Sevilla digitalsevilla.com 751 494\nes L elcomunista.net elcomunista.net 736 1974\nes L elDiario.es www.eldiario.es 17846 1887\nes L El Obrero elobrero.es 2856 1094\nes L El pa\u00eds elpais.com 49923 903\nes L El peri\u00f3dico www.elperiodico.com 26940 647\nes L El plural www.elplural.com 570 759\nes L El siglo de Europa elsiglodeuropa.es 207 1596\nes L HuffPost www.huffingtonpost.es 9967 1097\nes L La Rep\u00fablica larepublica.es 125 842\nes L Los Replicantes www.losreplicantes.com 5398 735\nes L Mundiario www.mundiario.com 16299 461\nes L Mundo Obrero www.mundoobrero.es 527 764\nes L Postdigital postdigital.es 209 824\nes L P\u00fablico www.publico.es 9126 1097\nes R Adelante Espa\u00f1a adelanteespana.com 178 731\nes R Altavoz de sucesos altavozdesucesos.es 136 257\nes R Disidentia disidentia.com 167 967\nes R El Confidencial www.elconfidencial.com 23560 1037\nes R El correo de Andaluc\u00eda elcorreoweb.es 4940 539\nes R El correo de Espa\u00f1a elcorreodeespana.com 1896 1343\nes R El diestro www.eldiestro.es 3046 1321\nes R El Imparcial www.elimparcial.es 4777 518\nes R El independiente www.elindependiente.com 7061 806\nes R El Mundo www.elmundo.es 24828 901\nes R Hispanidad www.hispanidad.com 2021 1414\nes R Informaci\u00f3n www.informacion.es 1432 768\nes R La Gaceta gaceta.es 326 986\nes R La Raz\u00f3n www.larazon.es 22283 619\nes R La Vanguardia www.lavanguardia.com 26533 777\nes R La voz de Galicia www.lavozdegalicia.es 6709 935\nes R Libertad digital www.libertaddigital.com 12591 561\nes R OK Diario okdiario.com 1636 780\nes R Periodista digital www.periodistadigital.com 9386 1690\nes R V oz libre vozlibre.com 329 1441\nca Ara www.ara.cat 14317 664\nca Ara Balears www.arabalears.cat 3743 626\nca CatalunyaPress www.catalunyapress.cat 2669 411\nca Cr\u00edtic www.elcritic.cat 447 1516\nca Diari d\u2019Andorra www.diariandorra.ad 5036 444\nca Diari de Girona www.diaridegirona.cat 4706 456\nca Diari Segre www.segre.com 1196 945\nca El 9 Nou el9nou.cat 287 684\nca 9club.el9nou.cat 11 334\nca El Nacional www.elnacional.cat 1400 575\nca El Punt Avui www.elpuntavui.cat 11571 666\nca e-Not\u00edcies www.e-noticies.cat 20 240\nca La Rep\u00fablica www.larepublica.cat 1137 662\nca La Naci\u00f3 digital www.naciodigital.cat 14183 602\nca Regi\u00f3 7 www.regio7.cat 2728 476\nca L El Periodico www.elperiodico.cat 3095 792\nca L jornal.cat www.jornal.cat 106 648\nca L P\u00fablico www.publico.es 85 1745\nca L VilaWeb www.vilaweb.cat 2955 2247\nca R Diari de Tarragona www.diaridetarragona.com 800 540\nTable 3: List of newspapers available in the OSCAR corpus (version 22.01) for the four languages used in this work.\nB Topics\nID % Label Keywords\n10:0 0.12 economy percent year government tax money billion economic economy years pay financial federal workers u.s\njobs people companies market business spending energy plan climate prices work policy trade bank time\nbudget\n10:1 0.16 culture time people life years work book story love family good day film music man feel women great told\nyoung year lot movie kind long art friends woman times thought york\n10:2 0.10 international u.s military government war president united security china people minister country foreign israel iran\niraq international american countries russia chinese officials forces nuclear political attack news north\nparty intercept group\n10:3 0.15 government trump president house democrats campaign republican obama election senate democratic republicans\nparty white vote clinton political biden voters presidential donald news people time congress conservative\nsen gop washington support national\n10:4 0.08 technology company companies business facebook data technology online market news media internet work google\nsocial people users time digital twitter service tech site products including content industry ceo free\ncustomers apple\n10:5 0.13 law & justice court law federal case department u.s justice investigation government attorney told report legal news\nofficials public judge office fbi security administration general supreme trump border president statement\nhouse criminal evidence\n10:6 0.13 education people school students women black american education rights children university america schools\npublic white years political work religious social community americans college time life men country\nchurch history parents free\n10:7 0.08 covid health people covid coronavirus care medical vaccine pandemic share cases children patients news\nabortion virus disease study drug public hospital time percent risk email women doctors university\ncancer deaths treatment\n10:8 0.10 hotchpotch I police game city team time gun told shooting season people year-old year man officers games shot night\nplayers killed news sports day left officer football sunday death week county play\n10:9 0.09 hotchpotch II water food people city years space year air time area day climate local national miles travel flight land\nsmall island oil south park coast scientists north long sea california change\n15:0 0.09 education school people students women children health university work study time education parents schools life\nkids percent college years care medical child high family student young cancer good feel day patients\n15:1 0.04 immigration immigration border u.s people immigrants mexico government illegal country united president american\nmarijuana drug migrants children year years security work democracy administration america news\nmexican texas refugees legal today enforcement\n15:2 0.07 government I trump news president u.s intelligence media report house investigation security fbi department govern-\nment white intercept campaign officials committee clinton told story national trump\u2019s justice washington\nrussian administration member documents donald\n15:3 0.14 hotchpotch time people life years love film book story work music family day good year movie man art great women\ntold young kind feel lot york series long woman books night\n15:4 0.06 covid covid health people coronavirus pandemic vaccine share cases virus york news public medical care\nofficials u.s week vaccinated disease workers deaths vaccines reported hospital city twitter email patients\ntold facebook\n15:5 0.11 violence police people told city news death man officers gun county shooting family year-old black killed violence\nofficer case video school reported charges prison department crime years shot arrested time authorities\n15:6 0.07 international I china chinese government countries minister north european united u.s south party country international\npresident russia korea foreign europe prime russian british political trade germany year years french\nleader global britain\n15:7 0.13 government II trump president house democrats republican campaign obama senate election democratic republicans\nparty vote biden voters white presidential political clinton sen gop percent congress support donald\ncandidate people time washington national\n15:8 0.13 hotchpotch people american political america president black time years white war conservative media fact americans\nleft history conservatives movement good country church power speech book social public free life\nreligious man\n15:9 0.10 economy percent tax year money government billion economic economy pay financial years federal jobs workers\npeople spending market companies business prices bank u.s budget insurance rate plan debt health\ngrowth costs\n15:10 0.08 ecologism water climate food years energy space people city year oil change time environmental air gas area power\nnational natural miles day land scientists small science local emissions carbon earth weather\n15:11 0.05 international II u.s military war israel iran iraq government security forces afghanistan united syria attack people\npresident israeli islamic attacks killed american troops nuclear army obama country muslim group\nterrorist officials weapons\n15:12 0.03 sports game team season games players sports football play time win coach league year nfl points player won\nteams left field week good fans yards sunday night final big college played\n15:13 0.09 law & justice court law federal rights case supreme legal abortion justice public government judge decision laws action\nu.s amendment department order attorney lawsuit news ban cases ruling issue general filed texas policy\n15:14 0.07 technology company companies business facebook technology market data online internet google media users\nproducts digital work tech people service industry news site time social content customers ceo free apple\nfirm year\nTable 4: Topics (with 10 and 15 clusters) obtained with Mallet on OSCAR\u2019s English newspaper documents. Clusters\nboldfaced and colored in blue are used to build the training data.\nID % Label Keywords\n10:0 0.14 culture film leben frau bild welt musik sehen erz\u00e4hlt frauen mutter kunst geschichte berlin paar vater wei\u00df\nfamilie liebe steht k\u00fcnstler zeigt b\u00fchne kinder leute spielt bilder eher publikum m\u00e4nner band\n10:1 0.15 hotchpotch welt deutschen deutschland gesellschaft buch leben geschichte deutsche beitrag frage frauen politik\njunge politischen politische berlin medien kirche juden thema wissen krieg freiheit steht eher leute kultur\nstaat arbeit sprache\n10:2 0.11 law & justice polizei gericht fall polizisten laut staatsanwaltschaft opfer deutschland bild berlin gewalt frau t\u00e4ter j\u00e4hrige\nrichter ermittlungen urteil verletzt prozess beh\u00f6rden foto personen dpa verfahren angaben verurteilt\noffenbar beamten berliner m\u00e4nner\n10:3 0.11 government spd partei cdu gr\u00fcnen merkel afd berlin deutschland fdp union politik bundestag linke csu parteien wahl\ngr\u00fcne koalition regierung angela frage linken bundesregierung stimmen kanzlerin berliner mehrheit\nm\u00fcsse kritik steht\n10:4 0.10 economy euro millionen unternehmen deutschland milliarden geld deutschen wirtschaft deutsche zahlen berlin\nkosten dollar bank banken welt kunden europa folgen zukunft europ\u00e4ischen arbeit laut usa china land\nfirmen bild konzern markt\n10:5 0.05 sport bayern spiel trainer spieler fu\u00dfball spielen saison bild deutschen mannschaft fans platz spiele team sieg\nsport tor m\u00fcnchen league liga deutsche minuten letzten dortmund steht bundesliga verein ball teilen\ndatensicherheit\n10:6 0.07 technology daten inhalte finden informationen internet facebook vergleich inhalt google twitter zustimmung person-\nenbezogene artikel nutzer angezeigt \u00fcbermittelt einverstanden brauchen laden ger\u00e4t anzeige forscher\nnetz sozialen bild unternehmen euro kunden produkte app\n10:7 0.09 covid kinder deutschland frauen eltern zahl schulen schule leben pandemie sch\u00fcler patienten laut kindern\narbeit woche liegt bayern berlin zahlen kind corona arbeiten bekommen deutschen fl\u00fcchtlinge studie gilt\npersonen wochen millionen\n10:8 0.10 international regierung usa land trump pr\u00e4sident t\u00fcrkei russland europa staaten deutschland soldaten china israel\npr\u00e4sidenten syrien afghanistan landes welt krieg iran fl\u00fcchtlinge frankreich grenze ausland donald\nmillionen russischen hauptstadt armee obama\n10:9 0.10 local stadt euro wasser m\u00fcnchen meter stra\u00dfe steht ort kilometer stehen haus leben liegt quelle auto platz\nfahren berlin augsburg geb\u00e4ude m\u00fcnchner bild stra\u00dfen tiere besucher paar unterwegs projekt millionen\nsieht\n15:0 0.05 covid bayern pandemie corona m\u00fcnchen landkreis deutschland augsburg oktober zahl junge freitag woche virus\nmontag welt covid coronavirus mittwoch stadt patienten november dienstag donnerstag liegt ma\u00dfnahmen\nsonntag bayerischen geimpft feiern wochen\n15:1 0.06 local stadt euro vergleich berlin auto wohnungen stra\u00dfe autos bahn m\u00fcnchen fahren meter geb\u00e4ude hamburg\nquelle bau platz kilometer berliner projekt haus finden kosten stra\u00dfen steht stehen gebaut millionen\nwohnen bauen\n15:2 0.08 social frauen kinder deutschland eltern schule arbeit berlin schulen sch\u00fcler leben m\u00e4nner kindern arbeiten kind\nfrau fl\u00fcchtlinge studie deutschen bekommen universit\u00e4t lehrer zahl thema familien familie jungen laut\nberliner euro stellen\n15:3 0.11 government spd cdu gr\u00fcnen partei merkel afd berlin fdp deutschland union bundestag csu gr\u00fcne linke koalition\nparteien politik wahl angela bild kanzlerin regierung bundesregierung geben berliner linken kritik m\u00fcsse\nseehofer dpa\n15:4 0.06 live science wasser tiere deutschland forscher natur erde wissenschaftler millionen grad meter welt leben klimawandel\nstudie pflanzen wald liegt landwirtschaft umwelt essen weltweit fleisch tonnen bauern tier kilometer\nk\u00f6rper bild gesundheit laut\n15:5 0.06 Nazism deutschen berlin geschichte kirche juden buch ddr deutsche berliner seite deutschland leben krieg b\u00fccher\nj\u00fcdischen museum stadt tod ausstellung papst weltkrieg kultur hitler nazis j\u00fcdische literatur polen verlag\nschriftsteller welt\n15:6 0.18 family leben frau paar leute bild wei\u00df familie steht kinder erz\u00e4hlt mutter welt vater frauen sehen m\u00e4nner junge\neltern geld wissen sieht stehen bisschen liebe haus kind kopf hause schnell j\u00e4hrige\n15:7 0.19 hotchpotch welt deutschland frage gesellschaft politik beitrag deutschen politischen politische leben eher wissen\nbuch fragen deutsche freiheit art europa staat medien steht leute thema problem geschichte sehen rolle\ndemokratie all klar\n15:8 0.05 sport bayern trainer spiel spieler fu\u00dfball spielen saison mannschaft deutschen fans platz team sieg sport bild\nspiele tor liga league deutsche minuten m\u00fcnchen dortmund letzten bundesliga verein ball stadion steht\nminute\n15:9 0.12 law & justice polizei gericht fall polizisten staatsanwaltschaft laut opfer t\u00e4ter richter j\u00e4hrige ermittlungen urteil gewalt\nbild verletzt berlin prozess deutschland beh\u00f6rden verfahren dpa personen angaben foto frau verurteilt\nbeamten offenbar hamburg montag\n15:10 0.07 culture film musik kunst k\u00fcnstler welt berlin band b\u00fchne sehen geschichte bild filme publikum zeigt spielt\nausstellung theater bilder album regisseur leben roman art schauspieler kino musiker berliner york werk\nerz\u00e4hlt\n15:11 0.06 technology daten inhalte artikel facebook internet inhalt informationen finden twitter google medien netz bild zus-\ntimmung personenbezogene laden nutzer angezeigt einverstanden \u00fcbermittelt sozialen zeitung wahrheit\ndigitalen journalismus brauchen soziale ger\u00e4t app unternehmen\n15:12 0.07 international I trump usa regierung pr\u00e4sident land china donald partei pr\u00e4sidenten obama frankreich staaten wahl europa\nwashington parlament gro\u00dfbritannien us-pr\u00e4sident europ\u00e4ischen br\u00fcssel trumps stimmen welt landes\nitalien york biden macron london mehrheit\n15:13 0.10 economy euro millionen unternehmen deutschland milliarden geld deutschen wirtschaft deutsche zahlen dollar\nkosten bank banken kunden berlin europ\u00e4ischen europa l\u00e4nder bundesregierung griechenland firmen\nkonzern folgen laut krise mitarbeiter insgesamt land markt\n15:14 0.07 international II t\u00fcrkei russland regierung deutschland land israel fl\u00fcchtlinge syrien soldaten afghanistan iran usa pr\u00e4sident\nkrieg grenze europa bundeswehr russischen putin ukraine armee t\u00fcrkischen deutsche irak t\u00fcrkische\nstaaten taliban moskau russische stadt\nTable 5: Topics (with 10 and 15 clusters) obtained with Mallet on OSCAR\u2019s German newspaper documents. Clusters\ncolored in blue are used to build the training data.\nID % Label Keywords\n10:0 0.14 hotchpotch mensaje espa\u00f1a sociedad a\u00f1os opini\u00f3n vida mundo denunciar pol\u00edtica mujeres gente personas historia\nprivado educaci\u00f3n social art\u00edculo iglesia redactar realidad pa\u00eds citar pol\u00edticos forma enviar libertad derecho\nespa\u00f1oles leer papa\n10:1 0.16 economy millones euros espa\u00f1a a\u00f1o econom\u00eda empresas a\u00f1os gobierno crisis mercado sector empresa pa\u00eds banco\nsocial pa\u00edses econ\u00f3mica informaci\u00f3n compa\u00f1\u00eda dinero pol\u00edtica europea precio trabajadores sistema caso\ndeuda servicios mes meses\n10:2 0.16 culture a\u00f1os vida mundo historia casa a\u00f1o pel\u00edcula cine libro obra mujer familia m\u00fasica serie madre gente padre\nthe arte programa espa\u00f1a premio televisi\u00f3n director hijo novela amor hombre joven noche\n10:3 0.12 government gobierno s\u00e1nchez psoe partido presidente elecciones congreso pol\u00edtica pedro iglesias ciudadanos espa\u00f1a\nrajoy madrid pablo catalu\u00f1a vox partidos electoral l\u00edder ley socialista moncloa d\u00edaz izquierda pol\u00edtico\nvotos diputados constituci\u00f3n euros\n10:4 0.15 local barcelona madrid ciudad a\u00f1os centro ayuntamiento covid catalunya personas espa\u00f1a zona visto comunidad\nperi\u00f3dico a\u00f1o calle metros relacionadas noticias local proyecto palma galicia vecinos hora plaza euros\ncomentado nacional semana\n10:5 0.11 science a\u00f1os forma personas salud mundo tipo estudio tecnolog\u00eda vida productos datos sistema informaci\u00f3n agua\nexplica internet caso usuarios a\u00f1o investigaci\u00f3n importante calidad universidad mejores permite cambio\nconsumo espa\u00f1a problema enfermedad\n10:6 0.06 covid espa\u00f1a coronavirus casos sociedad covid mapas evoluci\u00f3n gobierno datos vacunaci\u00f3n gr\u00e1ficos pol\u00edtica\nmundo personas socios canarias madrid le\u00eddo a\u00f1os pandemia contagios sanidad variante \u00f3micron salud\navanza hazte enlace copiar vacuna\n10:7 0.11 law & justice a\u00f1os caso madrid polic\u00eda comentarios juez tribunal vox p\u00fablico espa\u00f1a d\u00edaz hombre sociedad ayuso\njusticia ley fiscal\u00eda investigaci\u00f3n comunidad casado nacional judicial yolanda sentencia delito publicidad\nprisi\u00f3n audiencia civil noticias\n10:8 0.07 sport madrid real partido equipo f\u00fatbol a\u00f1os espa\u00f1a club liga temporada barcelona jugador jugadores bar\u00e7a\nbal\u00f3n a\u00f1o juego carrera mundial puntos partidos minutos jornada messi espa\u00f1ol gol jugar historia campo\nentrenador\n10:9 0.10 international pa\u00eds presidente gobierno a\u00f1os pa\u00edses unidos internacional guerra trump china eeuu personas ministro\neuropa rusia informaci\u00f3n mundo diciembre seguridad m\u00e9xico pol\u00edtica militar nacional noviembre francia\neuropea elecciones actualidad millones frente\n15:0 0.07 live science salud a\u00f1os estudio personas agua vida enfermedad forma investigaci\u00f3n pacientes c\u00e1ncer virus hospital\ntipo riesgo alimentos explica productos tratamiento enfermedades cient\u00edficos mundo caso animales a\u00f1o\nm\u00e9dicos consumo m\u00e9dico investigadores ni\u00f1os\n15:1 0.05 Catalonia barcelona catalunya generalitat catal\u00e1n covid peri\u00f3dico catalu\u00f1a puigdemont catalana relacionadas noticias\nvisto comentado temas mossos pasaporte lee sant govern minutos erc a\u00f1os confiar jordi pandemia centro\nling\u00fc\u00edstica parlament coronavirus directo\n15:2 0.14 government I gobierno partido psoe presidente s\u00e1nchez elecciones pol\u00edtica espa\u00f1a congreso ciudadanos madrid rajoy\nley partidos electoral pedro l\u00edder izquierda votos vox pol\u00edtico socialista pablo pa\u00eds diputados ejecutivo\ndebate iglesias portavoz comunidad\n15:3 0.11 law & justice a\u00f1os caso polic\u00eda juez comentarios madrid tribunal p\u00fablico sociedad justicia investigaci\u00f3n fiscal\u00eda nacional\nespa\u00f1a comunidad euros judicial ley civil sentencia delito prisi\u00f3n audiencia ayuso mujer fiscal recuerda\njuicio guardia juzgado\n15:4 0.05 covid espa\u00f1a coronavirus casos sociedad covid mapas evoluci\u00f3n gobierno datos vacunaci\u00f3n gr\u00e1ficos mundo\npol\u00edtica socios canarias personas le\u00eddo madrid contagios pandemia a\u00f1os variante \u00f3micron avanza hazte\nsanidad salud enlace copiar econom\u00eda\n15:5 0.04 hotchpotch I espa\u00f1a comentar accede archivado le\u00eddas galicia portada sociedad madrid diciembre f\u00fatbol gobierno alerta\na\u00f1os leer navidad econom\u00eda ma\u00f1ana grados famosos historia gallego voz antonio juan marruecos covid\njos\u00e9 m\u00e1xima carlos\n15:6 0.12 local madrid ciudad zona a\u00f1os ayuntamiento centro personas metros a\u00f1o proyecto palma san comunidad vecinos\ncalle mar agua informaci\u00f3n kil\u00f3metros obras capital zonas plaza isla volc\u00e1n sevilla local edificio municipal\nbarrio\n15:7 0.10 international pa\u00eds presidente gobierno a\u00f1os unidos pa\u00edses internacional guerra trump china eeuu rusia ministro personas\ndiciembre europa m\u00e9xico seguridad informaci\u00f3n mundo militar noviembre francia venezuela nacional\nmillones actualidad europea reino pol\u00edtica\n15:8 0.18 social mujeres a\u00f1os mundo vida espa\u00f1a personas sociedad pol\u00edtica gente opini\u00f3n social educaci\u00f3n realidad pa\u00eds\nforma historia sociales universidad caso ni\u00f1os libertad violencia hombres problema mujer derecho autor\ng\u00e9nero sentido padres\n15:9 0.14 economy millones euros espa\u00f1a a\u00f1o econom\u00eda a\u00f1os empresas gobierno crisis sector mercado banco pa\u00eds pa\u00edses\nempresa econ\u00f3mica social europea trabajadores deuda dinero precio crecimiento meses medidas mes plan\ninversi\u00f3n europa informaci\u00f3n\n15:10 0.05 sport madrid equipo real partido f\u00fatbol club a\u00f1os liga barcelona temporada jugador espa\u00f1a jugadores bar\u00e7a\npapa a\u00f1o bal\u00f3n mundial carrera partidos espa\u00f1ol puntos minutos juego selecci\u00f3n gol entrenador mundo\njornada messi\n15:11 0.02 government II s\u00e1nchez iglesias gobierno pedro euros millones moncloa psoe juez periodista denuncia rey ayuso palo pablo\nrobles margarita olona dinero calle le\u00eddo ocultan v\u00eddeo vox comunicaci\u00f3n congreso art\u00edculo venezuela\na\u00f1o telecinco\n15:12 0.03 hotchpotch II mensaje denunciar privado redactar publicidad citar espa\u00f1a opini\u00f3n enviar a\u00f1os art\u00edculos vida sociedad\neconom\u00eda correo d\u00edaz vox yolanda favor hombre art\u00edculo virales quieres deja gracias coche casado\nanteriores problema pol\u00e9mica\n15:13 0.09 technology compa\u00f1\u00eda tecnolog\u00eda usuarios internet datos privacidad editorial empresa forma informaci\u00f3n s.l espa\u00f1a\ntitania euros cookies reservados pol\u00edtica mundo red comscore auditado digital transparencia web google\ncondiciones loter\u00eda recomienda tipo m\u00f3vil\n15:14 0.16 culture a\u00f1os vida mundo historia casa cine pel\u00edcula a\u00f1o familia libro obra mujer m\u00fasica madre serie padre the\npremio gente programa director hombre hijo espa\u00f1a televisi\u00f3n novela amor joven arte noche\nTable 6: Topics (with 10 and 15 clusters) obtained with Mallet on OSCAR\u2019s Spanish newspaper documents. Clusters\ncolored in blue are used to build the training data.\nC Distribution of Topics per Newspaper\nNewspaper 10:0 10:1 10:2 10:3 10:4 10:5 10:6 10:7 10:8 10:9 15:0 15:1 15:2 15:3 15:4 15:5 15:6 15:7 15:8 15:9 15:10 15:11 15:12 15:13 15:14\nLDie Zeit 0 7 0 2 1 0 0 0 1 0 0 0 0 1 0 0 0 9 0 0 0 0 0 1 0\nLDie Tageszeitung 319 5750 3942 4207 4516 41 815 254 5070 1099 44 469 541 3138 2158 1365 514 3787 31 3921 190 1269 2491 2923 3172\nLDW News 17 246 103 121 274 0 77 24 713 101 5 13 34 86 219 142 19 97 2 84 3 27 253 212 480\nLJunge Welt 69 1035 945 632 1205 20 51 88 2035 91 377 37 60 531 160 357 26 299 10 921 27 68 888 1171 1239\nLMy Heimat 2 39 299 73 39 2 12 11 3 169 25 11 5 46 71 65 5 14 0 374 1 0 1 28 3\nLNeues Deutschland 37 969 728 1041 961 3 49 63 972 168 6 135 121 766 252 426 45 697 5 757 12 34 508 688 539\nLS\u00fcddeutsche Zeitung 264 1927 2578 2977 3358 38 817 304 2701 1377 108 377 185 2345 2101 925 221 1191 22 2653 57 187 1466 2885 1618\nRBild 168 3491 2843 1335 1592 86 395 189 1229 682 34 138 56 1169 866 307 142 3210 19 3086 7 82 396 1522 976\nRFrankfurter Allgemeine Zeitung 1313 1292 584 972 1896 17 262 106 1406 331 14 82 57 1910 593 465 74 906 12 582 36 108 747 1776 817\nRDie Welt 110 741 550 883 1272 12 488 107 1024 552 17 122 52 712 1046 407 66 440 3 567 13 60 521 1121 592\nRJunge Freiheit 16 2100 1652 2071 504 5 12 91 880 42 12 19 180 1677 41 382 43 1752 5 1634 14 42 372 523 677\nRPreu\u00dfische Allgemeine Zeitung 9 38 5 26 13 0 3 8 259 14 0 0 1 10 3 328 0 11 0 5 0 0 2 10 5\nTable 7: Number of articles per newspaper (row) and topic (column) for the German subset of OSCAR. See Table 5 for the definition of the topics. Topics boldfaced and in blue\nare used for training the classifier after balancing LvsR.\nNewspaper 10:0 10:1 10:2 10:3 10:4 10:5 10:6 10:7 10:8 10:9 15:0 15:1 15:2 15:3 15:4 15:5 15:6 15:7 15:8 15:9 15:10 15:11 15:12 15:13 15:14\nLABC News 1666 516 2480 3345 119 2680 661 238 3121 2603 49 518 976 68 166 5063 998 3091 381 1380 2494 1391 20 767 67\nLAlterNet 133 22 90 169 5 91 327 15 6 83 4 25 37 2 3 49 19 96 366 103 111 60 0 64 2\nLAssociated Press News 2676 180 4642 3365 243 4296 721 362 2900 3933 58 1224 1006 61 296 5007 2632 3021 333 1866 3759 1923 43 1840 249\nLAxios 347 9 41 262 23 82 33 66 75 325 9 23 36 6 14 140 32 236 6 322 353 7 1 52 26\nLBuzzfeed News 268 224 729 1561 175 2600 434 88 1098 344 31 447 1128 46 44 2385 264 1201 232 245 311 320 2 815 50\nLCBS News 1402 263 1741 2371 133 2136 434 270 2315 2028 66 503 863 70 166 3742 531 2018 266 1218 1965 1025 11 562 87\nLCNN 1067 416 6031 2235 333 2267 933 242 1911 6177 65 665 678 82 164 3743 2312 2005 665 988 5865 3592 25 709 54\nLDemocracy Now! 7 2 181 16 2 15 1244 4 5 1 0 1448 1 0 0 9 0 4 2 1 1 10 0 1 0\nLHuffPost 4601 640 2260 3740 183 2343 4406 379 842 3489 363 616 830 43 73 2035 1548 3277 3544 3391 3924 1389 4 1733 113\nLInsider 90 26 59 34 49 178 54 17 332 405 2 23 28 5 3 542 34 22 23 70 405 26 0 41 20\nLMother Jones 2233 224 819 2912 81 1656 750 199 242 1214 42 279 860 28 31 565 204 2390 1003 1759 1522 617 5 993 32\nLMSNBC News 1085 314 1156 9739 84 2253 2057 143 1179 382 58 1637 2044 176 162 1941 294 8390 713 955 400 719 25 848 30\nLNBC News 2887 583 4327 4244 243 3376 1336 349 4388 5929 103 901 1235 125 218 6737 1859 3817 502 2511 5708 2648 24 1103 171\nLNPR 2982 587 4816 4374 188 3438 1550 456 1822 5357 129 1335 1410 123 170 3374 1918 3942 1098 2394 5334 2729 17 1499 98\nLPolitico 2664 241 1870 16959 231 3975 660 166 339 306 47 342 3442 132 605 834 732 15297 768 2016 436 1130 4 1531 95\nLThe Atlantic 4628 1239 4068 6298 268 2230 4269 188 526 3048 242 425 1357 188 60 1217 1526 5030 5584 3952 3340 2360 15 1336 130\nLThe Daily Beast 783 868 2472 4666 124 2771 1580 131 3148 1152 30 778 1910 213 149 4530 783 3404 1907 708 1176 1500 7 554 46\nLThe Economist 14775 537 8827 1813 138 990 1473 110 133 2801 270 710 151 69 60 327 10722 1582 1994 9748 2555 2374 41 408 586\nLThe Intercept 751 23 8014 1752 1421 2354 1986 93 379 271 1 622 7509 12 9 578 62 1106 984 721 284 4849 0 303 4\nLThe New Yorker 670 656 935 1134 39 594 670 33 199 1261 18 145 489 121 13 487 479 851 945 532 1361 459 5 265 21\nLThe New York Times 209 48 333 252 30 151 73 6 64 228 5 23 55 12 4 153 156 225 95 162 250 174 2 64 14\nLThe Washington Post 1127 129 1653 2036 106 1606 581 65 376 1012 43 231 950 40 17 883 516 1787 461 978 1040 1042 8 666 29\nLUSA Today 330 26 151 478 17 499 204 34 242 312 16 113 162 5 24 465 55 412 124 301 302 79 9 213 13\nLV ox 402 27 226 851 53 228 282 42 88 159 12 65 191 8 13 191 137 714 242 319 195 100 0 120 51\nRAmerican Greatness 141 50 158 516 14 379 681 13 102 24 0 58 247 3 21 195 75 321 847 97 29 70 0 112 3\nRAmerican Thinker 1048 266 1914 1863 32 736 2405 65 196 283 11 295 458 31 14 437 368 1306 2899 875 338 1386 5 369 16\nRBreitbart News Network 1173 190 3707 4273 108 2903 1820 179 1211 367 22 1421 1094 65 185 2522 1675 3403 1558 812 393 1835 9 889 48\nRConservativeHQ 49 5 98 931 8 199 180 1 5 5 3 28 99 0 2 23 12 343 745 52 1 62 0 108 3\nRFox News 1665 300 4473 3011 67 2331 1398 128 1451 1645 21 931 1024 62 141 2588 1675 2272 1643 1375 1464 2567 18 651 37\nRInfoWars 10 0 6 7 1 10 15 1 9 0 0 0 2 0 0 15 6 5 15 9 0 0 0 7 0\nRLife Action 0 9 2 24 1 40 167 2174 3 0 0 0 0 0 0 38 1 5 51 0 0 0 0 2325 0\nRNational Review 1533 160 755 1265 24 651 1398 71 48 152 12 109 185 8 58 156 259 952 1504 1339 205 483 0 762 25\nRReason 3568 687 1589 2818 241 5019 2918 348 1014 841 73 515 665 112 68 2383 551 2201 3085 3179 913 980 13 4174 131\nRThe American Conservative 60 49 288 161 3 39 448 3 8 18 1 5 38 1 3 17 64 85 595 50 17 180 0 20 1\nRThe Blaze 1 0 5 6 0 5 8 0 2 0 0 2 0 0 0 3 0 7 5 2 0 5 0 3 0\nRThe Daily Caller 2211 406 1900 6448 181 4252 1946 226 1578 873 39 823 2654 156 150 3049 677 5071 1771 1744 1098 1200 18 1493 78\nRThe Daily Wire 367 159 533 1555 36 1031 1070 89 595 95 11 232 551 27 125 1130 127 1137 957 309 101 354 6 446 17\nRThe Epoch Times 3690 220 4184 1628 167 2700 776 253 2086 2660 40 551 635 19 450 3373 3440 1451 626 2763 2540 1274 9 1003 190\nRThe Federalist 444 145 278 1221 21 726 2841 114 133 71 7 88 415 9 40 349 113 812 3031 385 97 124 4 512 8\nRThe Gateway Pundit 231 62 445 1393 70 1333 362 39 469 91 6 141 985 12 46 871 113 1163 329 200 90 312 0 218 9\nRThe National Pulse 31 2 48 214 22 46 33 11 6 0 0 8 132 0 0 18 46 124 31 25 1 3 0 24 1\nRThe Washington Free Beacon 544 61 1476 2377 63 1524 408 64 138 60 10 160 1528 26 17 332 328 1664 320 507 80 1079 3 641 20\nRThe Washington Times 1731 122 2841 3233 71 2901 1074 153 1022 1005 27 608 893 33 118 1884 1067 2965 928 1412 1036 1744 10 1375 53\nRThe Spectator 660 565 685 9866 49 236 1049 66 83 139 4 30 169 12 18 65 89 917 10888 549 122 291 11 178 55\nRWashington Examiner 5 0 3 10 0 6 1 2 0 0 0 1 1 0 0 1 0 10 1 7 1 3 0 2 0\nRWND 1315 442 2385 2994 315 3033 5593 226 941 689 31 411 1580 58 76 2036 385 2070 5368 1119 709 1940 3 2095 52\nTable 8: Number of articles per newspaper (row) and topic (column) for the English subset of OSCAR. See Table 4 for the definition of the topics. Topics boldfaced and in blue are\nused for training the classifier after balancing LvsR.\nNewspaper 10:0 10:1 10:2 10:3 10:4 10:5 10:6 10:7 10:8 10:9 15:0 15:1 15:2 15:3 15:4 15:5 15:6 15:7 15:8 15:9 15:10 15:11 15:12 15:13 15:14\nLCuarto poder 873 346 37 810 12 14 6 132 2 268 2 0 921 152 0 0 9 212 924 264 1 1 0 10 4\nLDe Verdad digital 297 1786 24 434 8 5 2 61 0 578 2 2 509 75 0 0 3 505 414 1674 0 0 0 5 6\nLDiario progresista 8 57 0 59 0 0 3 15 0 31 0 0 69 14 0 0 0 26 10 53 0 0 0 1 0\nLDigital Sevilla 16 67 3 80 2 16 4 42 0 79 1 0 57 46 1 0 11 81 35 42 0 5 0 22 8\nLelcomunista.net 0 1 0 0 0 0 0 1 0 734 0 0 0 1 0 0 0 734 0 1 0 0 0 0 0\nLelDiario.es 284 455 30 943 6 14 489 349 1 255 0 4 1112 448 140 0 6 216 494 396 0 0 0 8 2\nLEl Obrero 419 619 249 386 2 30 4 57 1 420 14 3 389 47 12 0 7 361 965 379 2 0 0 7 1\nLEl pa\u00eds 3541 9109 630 4163 509 448 85 3536 44 9477 130 47 5049 3760 15 0 599 8212 5305 7715 39 5 0 574 92\nLEl peri\u00f3dico 763 1568 132 1549 568 94 26 789 3 1298 12 750 1191 884 0 0 6 1150 1217 1443 3 0 0 103 31\nLEl plural 69 75 8 119 3 4 4 80 0 11 0 0 126 87 0 0 2 9 75 64 0 4 0 3 3\nLEl siglo de Europa 11 67 2 62 0 0 0 9 0 3 0 0 71 8 0 0 0 2 18 54 0 0 0 1 0\nLHuffPost 472 461 44 802 0 61 4 4866 3 783 33 1 1076 429 33 0 86 826 767 461 8 2 3700 21 53\nLLa Rep\u00fablica 3 10 0 0 0 3 0 0 0 24 0 0 1 0 0 0 2 20 8 2 0 0 0 7 0\nLLos Replicantes 99 141 92 325 28 95 18 2851 1 198 32 9 340 2924 4 0 29 163 126 80 1 1 1 61 77\nLMundiario 1716 2024 343 909 99 225 52 503 27 1790 42 10 1036 543 11 5 74 1587 2458 1642 29 10 1 171 69\nLMundo Obrero 170 64 14 69 3 3 0 17 0 116 0 0 109 16 0 0 4 95 191 39 0 1 0 0 1\nLPostdigital 3 18 0 27 0 0 0 148 0 8 0 0 40 146 0 0 0 5 3 10 0 0 0 0 0\nLP\u00fablico 158 811 52 880 47 40 26 5412 16 476 23 5 1017 5460 11 0 28 365 238 671 13 36 5 21 25\nRAdelante Espa\u00f1a 50 46 0 18 1 2 0 12 0 27 0 0 24 14 1 0 0 25 50 41 0 0 0 1 0\nRAltavoz de sucesos 7 3 1 44 1 2 0 39 0 18 0 0 33 35 1 0 2 16 5 3 0 5 6 8 1\nRDisidentia 158 2 1 0 0 1 0 0 0 3 0 0 0 0 0 0 0 3 160 2 0 0 0 0 0\nREl Confidencial 417 5347 119 3038 64 255 41 1611 27 1644 24 63 2737 1743 24 0 154 1477 846 4349 16 3 0 1085 42\nREl correo de Andaluc\u00eda 200 685 49 294 49 25 10 430 6 146 5 1 364 438 3 0 78 114 306 520 8 0 0 49 8\nREl correo de Espa\u00f1a 763 60 0 10 0 1 0 19 0 21 0 0 62 38 0 18 2 38 654 53 0 0 0 8 1\nREl diestro 886 49 0 75 0 2 0 111 0 25 0 2 146 155 0 0 1 39 717 69 0 0 17 2 0\nREl Imparcial 628 495 79 1238 23 18 19 315 10 491 11 8 1292 334 3 0 21 444 711 445 7 10 4 14 12\nREl independiente 104 1613 27 1564 102 23 28 972 3 319 20 18 1709 1052 7 0 64 254 154 1358 6 1 0 97 15\nREl Mundo 2273 3517 237 2000 289 189 27 1641 23 3014 38 15 2528 2020 3 1 243 2801 2065 2977 16 53 26 357 67\nRHispanidad 91 544 0 48 0 0 0 8 0 11 0 0 63 8 0 0 0 16 46 288 0 0 281 0 0\nRInformaci\u00f3n 67 185 13 56 31 9 1 93 1 36 4 0 74 92 2 0 41 26 106 129 1 1 1 13 2\nRLa Gaceta 45 11 0 40 0 0 0 14 0 199 0 0 51 14 0 0 0 189 43 7 1 0 0 3 1\nRLa Raz\u00f3n 671 2604 76 1954 540 71 31 1354 141 1573 17 29 2167 1382 7 729 46 1273 957 2280 2 0 0 99 27\nRLa Vanguardia 1108 3205 256 2439 471 394 65 1237 23 2215 66 200 2481 1437 10 0 201 1870 2041 2637 19 3 0 389 59\nRLa voz de Galicia 168 822 50 451 310 55 9 300 8 321 10 3 556 363 2 6 23 273 358 837 7 0 0 49 7\nRLibertad digital 1121 651 114 1596 45 43 28 826 36 870 11 33 1697 860 8 1 43 731 1248 534 45 18 0 56 45\nROK Diario 17 24 2 19 0 4 1 10 0 1 0 1 20 15 0 0 1 1 22 15 2 0 0 1 0\nRPeriodista digital 295 701 82 5377 2 51 0 65 1 396 4 0 58 84 0 0 21 410 373 526 31 5335 0 96 32\nRV oz libre 0 11 1 67 0 2 0 5 0 71 18 1 75 4 0 0 0 49 0 8 0 0 0 0 2\nTable 9: Number of articles per newspaper (row) and topic (column) for the Spanish subset of OSCAR. See Table 6 for the definition of the topics. Topics boldfaced and in blue\nare used for training the classifier after balancing LvsR.\nD Subjects for the ChatGPT and Bard Article Generation\n# English German Spanish Catalan\n1 teleworking Telearbeit el teletrabajo el teletreball\n2 labor conflicts Arbeitskonflikte los conflictos laborales els conflictes laborals\n3 morning traffic Morgenverkehr el tr\u00e1fico por la ma\u00f1ana el tr\u00e0nsit al mat\u00ed\n4 housing prices Wohnungspreise el precio de la vivienda el preu de l\u2019habitatge\n5 housing construction Wohnungsbau la construcci\u00f3n de viviendas la construcci\u00f3 d\u2019habitatges\n6 street vending Stra\u00dfenverkauf la venta ambulante la venda ambulant\n7 the disembarkation of illegal boats die Ausschiffung von illegalen Booten el desembarco de pateras el desembarcament de pasteres\n8 actors Schauspieler los actores els actors\n9 soap operas Seifenopern las telenovelas les telenovel\u00b7les\n10 television Fernsehen la televisi\u00f3n la televisi\u00f3\n11 late shows Late-Night-Show los late shows els late shows\n12 digital newspapers digitale Zeitungen los peri\u00f3dicos digitales els diaris digitals\n13 the police die Polizei la polic\u00eda la policia\n14 the army die Armee el ej\u00e9rcito l\u2019ex\u00e8rcit\n15 terrorism Terrorismus el terrorismo el terrorisme\n16 robberies Raub\u00fcberf\u00e4lle los robos els robatoris\n17 murder Mord el asesinato l\u2019assassinat\n18 death penalty Todesstrafe la pena de muerte la pena de mort\n19 elections Wahlen las elecciones les eleccions\n20 Pegasus software Pegasus-Software el software Pegasus el programari Pegasus\n21 the importance of science die Bedeutung der Wissenschaft la importancia de la ciencia la import\u00e0ncia de la ci\u00e8ncia\n22 technology Technologie la tecnolog\u00eda la tecnologia\n23 the metaverse das Metaversum el metaverso el metavers\n24 augmented reality Augmented Reality la realidad aumentada la realitat augmentada\n25 cell phones Handys los m\u00f3viles els m\u00f2bils\n26 electric cars Elektroautos los coches el\u00e9ctricos els cotxes el\u00e8ctrics\n27 meat consumption Fleischkonsum el consumo de carne el consum de carn\n28 organic farming \u00d6kologischer Landbau la agricultura ecol\u00f3gica l\u2019agricultura ecol\u00f2gica\n29 superfood Superfood los superalimentos els superaliments\n30 plastic bags Plastikt\u00fcten las bolsas de pl\u00e1stico les bosses de pl\u00e0stic\n31 recycling Recycling el reciclaje el reciclatge\n32 deforestation Entwaldung la desforestaci\u00f3n la desforestaci\u00f3\n33 forests W\u00e4lder los bosques els boscos\n34 bird farms V ogelfarmen las granjas de aves les granges d\u2019aus\n35 cyclists Radfahrer los ciclistas els ciclistes\n36 nuclear energy Kernenergie la energ\u00eda nuclear l\u2019energia nuclear\n37 oil companies Mineral\u00f6lunternehmen las petroleras les petrolieres\n38 pollution Umweltverschmutzung la contaminaci\u00f3n la contaminaci\u00f3\n39 fur coats Pelzm\u00e4ntel los abrigos de piel els abrics de pell\n40 diamonds Diamanten los diamantes els diamants\n41 the female head of a company die weibliche Leiterin eines Unternehmens la jefa de la empresa la cap de l\u2019empresa\n42 marriage Heirat el matrimonio el matrimoni\n43 marrying in white Heiraten in Wei\u00df casarse de blanco casar-se de blanc\n44 abortion Abtreibung el aborto l\u2019avortament\n45 sexual harassment sexuelle Bel\u00e4stigung el acoso sexual l\u2019assetjament sexual\n46 the age of mothers das Alter der M\u00fctter la edad de las madres l\u2019edat de les mares\n47 single mothers alleinerziehende M\u00fctter las madres solteras les mares solteres\n48 career Karriere la carrera profesional la carrera professional\n49 job stress Stress am Arbeitsplatz el estr\u00e9s laboral l\u2019estr\u00e8s laboral\n50 abuse of power Machtmissbrauch el abuso de poder l\u2019ab\u00fas de poder\n51 depression Depression la depresi\u00f3n la depressi\u00f3\n52 layoffs Entlassungen el despido l\u2019acomiadament\n53 private schools Privatschulen las escuelas privadas les escoles privades\n54 private universities Privatuniversit\u00e4ten las universidades privadas les universitats privades\n55 extracurricular activities au\u00dferschulische Aktivit\u00e4ten las actividades extraescolares les activitats extraescolars\n56 child labor Kinderarbeit el trabajo infantil el treball infantil\n57 money Geld el dinero els diners\n58 capitalism Kapitalismus el capitalismo el capitalisme\n59 the stock market der Aktienmarkt la bolsa la borsa\n60 ethical banking ethischen Banken la banca \u00e9tica la banca \u00e8tica\n61 banks Banken los bancos els bancs\n62 alcohol Alkohol el alcohol l\u2019alcohol\n63 tobacco Tabak el tabaco el tabac\n64 cannabis Cannabis el cannabis el c\u00e0nnabis\n65 drugs Drogen las drogas les drogues\n66 health care Gesundheitsf\u00fcrsorge la sanidad la sanitat\n67 diet Di\u00e4t la dieta la dieta\n68 rivalry in sport Rivalit\u00e4t im Sport la rivalidad en el deporte la rivalitat a l\u2019esport\n69 Saturday\u2019s game Samstagsspiel el partido del s\u00e1bado el partit de dissabte\n70 sports cars Sportwagen los coches deportivos els cotxes esportius\n71 the olympic games die olympischen Spiele los juegos ol\u00edmpicos els jocs ol\u00edmpics\n72 Qatar World Cup Weltmeisterschaft in Katar el Mundial de Qatar el Mundial de Qatar\n73 China China China Xina\n74 Turkey T\u00fcrkei Turqu\u00eda Turquia\n75 United States die Vereinigte Staaten Estados Unidos Estats Units\n76 the latest iPhone model das neueste iPhone-Modell el \u00faltimo modelo de iPhone el darrer model d\u2019iPhone\n77 ChatGPT ChatGPT ChatGPT ChatGPT\n78 Netflix Netflix Netflix Netflix\n79 Amazon Amazon Amazon Amazon\n80 Google Google Google Google\nContinued on next page\n# English German Spanish Catalan\n81 TikTok TikTok TikTok TikTok\n82 Margaret Thatcher Margaret Thatcher Margaret Thatcher Margaret Thatcher\n83 Donald Trump Donald Trump Donald Trump Donald Trump\n84 Barak Obama Barak Obama Barak Obama Barak Obama\n85 Kamala Harris Kamala Harris Kamala Harris Kamala Harris\n86 Nelson Mandela Nelson Mandela Nelson Mandela Nelson Mandela\n87 Angela Merkel Angela Merkel Angela Merkel Angela Merkel\n88 Jos\u00e9 Mar\u00eda Aznar Jos\u00e9 Mar\u00eda Aznar Jos\u00e9 Mar\u00eda Aznar Jos\u00e9 Mar\u00eda Aznar\n89 Francisco Franco Francisco Franco Francisco Franco Francisco Franco\n90 Julian Assange Julian Assange Julian Assange Julian Assange\n91 Greta Thunberg Greta Thunberg Greta Thunberg Greta Thunberg\n92 Claudia Schiffer Claudia Schiffer Claudia Schiffer Claudia Schiffer\n93 Angelina Jolie Angelina Jolie Angelina Jolie Angelina Jolie\n94 Richard Gere Richard Gere Richard Gere Richard Gere\n95 Bono Bono Bono Bono\n96 Pl\u00e1cido Domingo Pl\u00e1cido Domingo Pl\u00e1cido Domingo Pl\u00e1cido Domingo\n97 Pel\u00e9 Pel\u00e9 Pel\u00e9 Pel\u00e9\n98 Magic Johnson Magic Johnson Magic Johnson Magic Johnson\n99 Rafa Nadal Rafa Nadal Rafa Nadal Rafa Nadal\n100 Alexia Putellas Alexia Putellas Alexia Putellas Alexia Putellas\n101 Joan Antoni Samaranch Joan Antoni Samaranch Joan Antoni Samaranch Joan Antoni Samaranch\nTable 10: List of subjects used to generate newspaper-like articles with ChatGPT and Bard.\nE Stance Classification at Article Level\nEnglish German Spanish Catalan\n# Subject Mono Multi Mono Multi Mono Multi Multi\n1 teleworking R R R R L R L R R R R R R L\n2 labor conflicts L R L R L L L L L L L L L L\n3 morning traffic R L L R L L L L R L R R R L\n4 housing prices L L L L L L L L L L R R L L\n5 housing construction L L L L L L L L R L R R R L\n6 street vending R L L L L L L L L R R R L L\n7 disembarkation of illegal boats R R L R L L L L L L L R L L\n8 actors L L L L L L L L R L R L L L\n9 soap operas R L L L L R L R R L R L L L\n10 television R L L L L L L R R L R R L L\n11 late shows L R L L L R L R L L R L L L\n12 digital newspapers L L L L L R L R L L R R R L\n13 the police R R L L L L L R L L R R R R\n14 the army R L L L L L L L L L R R R R\n15 terrorism R R R L L L L L R L L L R R\n16 robberies R L L L L L L L R L R R R L\n17 murder R L L R L L L L L L R R L R\n18 death penalty L R L L L L L R L L L R L L\n19 elections L L L L L R L R L L R L L R\n20 Pegasus software L R L R L L L R R L R R R R\n21 the importance of science R R L R L L L L R R R L L L\n22 technology L R L R L R L L R L R R R L\n23 the metaverse L R L R L R L R R R L R R L\n24 augmented reality R L R L L L L R R R R L R L\n25 cell phones L R L R R L L R R R R L R L\n26 electric cars R L R L L L L L R R R R R L\n27 meat consumption R R R R L L L L L L L L L R\n28 organic farming R L L L L L L L R L R L L L\n29 superfood L R L L L R L R R L R L L L\n30 plastic bags R R L L L L L L L L R R L L\n31 recycling R L L L L L L L R L L R L L\n32 deforestation R L L L L L L L R L L L R L\n33 forests R L L L L L L L L L L L R L\n34 bird farms L L L L L L L L L L L L L L\n35 cyclists L L L L L L L L R L R R L L\n36 nuclear energy R R R R L L L L R L R R R R\n37 oil companies L L L L L L L L R L L L L L\n38 pollution L R L R L L L L R L L L L L\n39 fur coats L L L L L L L R L L L L L L\n40 diamonds L L L L L L L L R L L R L L\n41 the female head of a company L L L L L L L L R R R L R L\n42 marriage R L L L L L L L R L R R L R\n43 marrying in white L R L R L L L L L L L R L L\n44 abortion L L L L L L L L L L L R L L\n45 sexual harassment L R L L L L L L L L L R L L\n46 the age of mothers L L L L L R L R R L L L L L\n47 single mothers R L L L L L L L L L R R R R\n48 career L L L L L L L L R L R L R L\n49 job stress R L L L L L L L R L R R R L\n50 abuse of power R R R R L L L L L L L R L R\n51 depression R L L L L L L L L L L R L L\n52 layoffs L L L L L L L L R L L L L L\n53 private schools R R L L L L L L L L R R L R\n54 private universities R R R R L L L L R L R R L L\n55 extracurricular activities R R L R L L L L L L L R R L\n56 child labor R L R L L L L L L L L L R L\n57 money R R L L L L L L R L R R R R\n58 capitalism R R R R L L L L L R L R L L\n59 the stock market L L L L L L L L R R R R R L\n60 ethical banking L L L L L L L L L L L L R L\n61 banks L L L L L L L L R L R R L R\nContinued on next page\nEnglish German Spanish Catalan\n# Subject Mono Multi Mono Multi Mono Multi Multi\n62 alcohol L L L L L L L L L L R R L L\n63 tobacco R R L L L L L L L L L L R L\n64 cannabis R R R L L L L L L L L L R L\n65 drugs R L L L L L L L L L L R L L\n66 health care R L L L L L L L L L R R R R\n67 diet L R L R L L L L L L R R R L\n68 rivalry in sport L L L L L L L L L R L R L L\n69 Saturday\u2019s game R L L L L L L L R L R L L L\n70 sports cars L R L L L L L L R R R L R L\n71 the olympic games L R L R L L L L L L R R L R\n72 Qatar World Cup L R L L L L L L L R L R R R\n73 China R L L L L L L L R R R L R R\n74 Turkey L L L L L L L L R R L R R L\n75 United States R R L L L R L L R R R R L L\n76 the latest iPhone model L L L R L R L R R L R R R L\n77 ChatGPT L R L L L R L L R L R R R R\n78 Netflix L L L L L L L L R L R R R L\n79 Amazon L L L L L L L L R R R R L R\n80 Google L L L L L L L L R R R R R R\n81 TikTok R L L L L L L L R L L R R R\n82 Margaret Thatcher R L L L L L L L L L R L L R\n83 Donald Trump L L L R L L L L L L R R L L\n84 Barak Obama L L R L L L L L L L R R L R\n85 Kamala Harris L L L L L L L L R L L L R R\n86 Nelson Mandela R L R L L L L L L L R R R L\n87 Angela Merkel L L L L L L L L L L R R R L\n88 Jos\u00e9 Mar\u00eda Aznar L L L L L L L R L L R R L R\n89 Francisco Franco L R L L L L L R L R R R R R\n90 Julian Assange L L R R L L L L L L L R R R\n91 Greta Thunberg L R L R L L L L R L R L R R\n92 Claudia Schiffer L L L L L L L L L R L R L L\n93 Angelina Jolie L R L R L L L L L L L R L R\n94 Richard Gere L R L L L L L L L R L R R L\n95 Bono R R L L L L L L L L L L L L\n96 Pl\u00e1cido Domingo R R L L L L L L L R L R L R\n97 Pel\u00e9 R R R L L L L L R R R R R R\n98 Magic Johnson R R L L L L L L R R R L L L\n99 Rafa Nadal L R L L L L L L R L R R R R\n100 Alexia Putellas R R L L L L L L R R R R R R\n101 Joan Antoni Samaranch L L L L L L L L L R L L R L\nTable 11: Class obtained by the 4 classifiers on the 101 articles generated by ChatGPTv08a (\n ) and Bardv08a (\n )\nMono refers to any of the monolingual models (finetuned with either English, German or Spanish) and Multi refers\nto the model finetuned will all the data.\nF Training Details\nF.1L/RClassifier\nWe finetune XLM-RoBERTa large (Conneau et al., 2020) for\nLvs.Rclassification as schematised in Figure 1. Our\nclassifier is a small network on top of RoBERTa that first\nperforms dropout with probability 0.1 on RoBERTa\u2019s [CLS]\ntoken, followed by a linear layer and a tanh. We pass trough\nanother dropout layer with probability 0.1 and a final linear\nlayer projects into the two classes. The whole architecture is\nfinetuned.\nNewspaper articleXLM-RoBERTa\n(large)dropout (0.1) [CLS]linear (1024 \u21921024)tanhdropout (0.1)linear (1024 \u21922)Stance ( L/R)\nFigure 1: Finetuning architecture.\nWe use a cross-entropy loss, AdamW optimiser and a learn-\ning rate that decreases linearly. We tune the batch size, the\nlearning rate, warmup period and the number of epochs. The\nbest values per language and model are summarised in Ta-\nble 12.\nParameter en de es en +de+es\nbatch 8 8 8 8\nlearning rate 5e-6 5e-6 5e-6 5e-6\nepochs 4 6 6 4\nstep best Acc val 146000 23000 93000 142000\nbest Acc val(%) 97.9 99.2 95.9 96.9\nTable 12: Main hyperparameters used and their perfor-\nmance in the three monolingual finetunings ( en,deand\nes) and the multilingual one ( en+de+es).\nAll trainings are performed using a single NVIDIA Tesla\nV100 V olta GPU with 32GB.\nF.2 Topic Modelling\nWe use Mallet (McCallum, 2002) to perform LDA on the\ncorpus after removing the stopwords, with the hyperparameter\noptimization option activated and done every 10 iterations.\nOther parameters are the defaults. We do a run per language\nwith 10 topics and another run with 15 topics. We tag the\ncorpus with both labels.", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Multilingual coarse political stance classification of media. the editorial line of a ChatGPT and bard newspaper", "author": ["C Espa\u00f1a-Bonet"], "pub_year": "2023", "venue": "arXiv preprint arXiv:2310.16269", "abstract": "Neutrality is difficult to achieve and, in politics, subjective. Traditional media typically adopt  an editorial line that can be used by their potential readers as an indicator of the media bias."}, "filled": false, "gsrank": 346, "pub_url": "https://arxiv.org/abs/2310.16269", "author_id": [""], "url_scholarbib": "/scholar?hl=en&q=info:WZqxS3H_2fYJ:scholar.google.com/&output=cite&scirp=345&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D340%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=WZqxS3H_2fYJ&ei=QrWsaI2aB7_SieoPzJnloAQ&json=", "num_citations": 10, "citedby_url": "/scholar?cites=17787529065342802521&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:WZqxS3H_2fYJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2310.16269"}}, {"title": "Analysis of Propaganda in Tweets From Politically Biased Sources", "year": "2025", "pdf_data": "ANALYSIS OF PROPAGANDA IN TWEETS FROM POLITICALLY BIASED SOURCES\nVIVEK SHARMA1, MOHAMMAD MAHDI SHOKRI1, SARAH ITA LEVITAN2,1, ELENA FILATOV A3,1, SHWETA\nJAIN4,1\n1THE GRADUATE CENTER, CUNY {VSHARMA,MSHOKRI }@GRADCENTER.CUNY.EDU\n2HUNTER COLLEGE, CUNY SARAH.LEVITAN@HUNTER.CUNY.EDU\n3NEW YORK CITY COLLEGE OF TECHNOLOGY , CUNY EFILATOVA@CITYTECH.CUNY.EDU\n4JOHN JAY COLLEGE OF CRIMINAL JUSTICE, CUNY SJAIN@JJAY.CUNY.EDU\nABSTRACT . News outlets are well known to have political associations, and many national outlets culti-\nvate political biases to cater to different audiences. Journalists working for these news outlets have a big\nimpact on the stories they cover. In this work, we present a methodology to analyze the role of journal-\nists, affiliated with popular news outlets, in propagating their bias using some form of propaganda-like\nlanguage. We introduce JMBX(Journalist Media Bias on X), a systematically collected and annotated\ndataset of 1874 tweets from Twitter (now known as X). These tweets are authored by popular journalists\nfrom 10 news outlets whose political biases range from extreme left to extreme right. We extract several\ninsights from the data and conclude that journalists who are affiliated with outlets with extreme biases are\nmore likely to use propaganda-like language in their writings compared to those who are affiliated with\noutlets with mild political leans. We compare eight different Large Language Models (LLM) by OpenAI\nand Google. We find that LLMs generally performs better when detecting propaganda in social media\nand news article compared to BERT-based model which is fine-tuned for propaganda detection. While the\nperformance improvements of using large language models (LLMs) are significant, they come at a notable\nmonetary and environmental cost. This study provides an analysis of both the financial costs, based on\ntoken usage, and the environmental impact, utilizing tools that estimate carbon emissions associated with\nLLM operations.\nIntroduction\nAs defined by Barron et al.Barr \u00b4on-Cedeno et al. 2019 and Da San Martino et al. Da San Martino et al.\n2020, propaganda involves the deliberate expression of opinion with the intent to influence the opinion\nor to invoke some action. In recent years, the use of social media platforms to spread propaganda and\nmisinformation has become increasingly prevalent. According to a 2021 StatistaStatista 2021, identified\nstate actors spreading propaganda and misinformation increased to 81 from 28 in 2017. Propaganda in\nsocial media is not limited to state actors. In fact, news outlets often utilize some form of propaganda to\nreach their audience by slanting their report toward the consumers\u2019 expectations, also known as media\nbias Gentzkow and Shapiro 2006. A study by Baron Baron 2006 shows that there is an established\narrangement between the media house and the journalist. The study presents a theory that journalists\ncan deliberately express biased opinions in their stories to advance their career prospects and news\noutlets choose to be biased to boost their profits. Paul et al. Paul and Elder 2006 point out that it is often\nnot up to journalists to determine what their reader wants to read. Instead, it is the public who wants\ntheir belief extolled and confirmed. Media bias affects public opinion causing polarization.\n1arXiv:2507.08169v1  [cs.SI]  10 Jul 2025\n2 2 INTRODUCTION\nNews outlets and the journalists associated with them often interact with the public through social\nmedia. The micro-blogging platform, X (formerly Twitter), is a popular medium of such communi-\ncation which helps news outlets and their affiliates engage directly with their readers. According to a\nsurvey conducted in 2021 by Pew Research Center 2022 seven in ten journalists prefer Twitter for their\nwork-related communications and 79% of them believe that social media help them to better engage\nwith their audience. A study of 22,000 tweets conducted in 2011 by Lasorsa et al. Lasorsa, Lewis,\nand Holton 2012 shows that journalists freely express their opinions on the X microblogging platform.\nThis study highlights that engagement with social media followers promotes \u201cend-user journalism\u201d.\nThe extent of the end-user journalism is evident from the results presented in the study by Noguera et\nal Noguera-Vivo 2013. This study points out that 5% of the tweets directly request information from\nthe followers, 27% are direct replies to the followers and 32% of the tweets contain links to sources that\nare more often external to the news outlet.\nIn Section 3 we introduce a publicly available dataset, JMBX1, that contains 1,874 annotated tweets\nfrom several news outlets. These tweets are labeled as either \u201cpropaganda\u201d (containing a certain type\nof propaganda technique) or \u201cnon propaganda\u201d. Given this annotation, we explore the relationship\nbetween propaganda and the bias of the affiliated news outlet.\nIn Section 4 we present experiments using a fine-tuned BERT model and eight different Large Lan-\nguage Models (LLMs) on the task of propaganda detection. Our findings indicate that LLMs outperform\nthe BERT model, with further improvements observed when employing the Chain of Thought prompt-\ning technique Wei et al. 2022 in the data set.\nIn Sections 5, we provide an estimate of environmental impact in running LLMs for propaganda\ndetection offering a holistic evaluation of the study\u2019s implications.\nThus, we introduce a novel dataset for propaganda detection and answer the following research\nquestions.\nRQ1: How frequently do journalists from news outlets with varying degrees of known biases (left,\nright, or center) exhibit characteristics indicative of propaganda in their tweets, and are those affiliated\nwith organizations that have extreme biases more likely to use propaganda compared to their counter-\nparts in moderately biased organizations?\nRQ2: Can Large Language Models (LLM) be used to detect propaganda in text? How does the\nperformance of LLM compare with the performance of BERT model fine-tuned to detect propaganda.\nFurthermore, do prompt engineering techniques help improve performance of LLM in detecting propa-\nganda?\nRQ3: What is the environmental cost of using LLMs to detect propaganda?\nFIGURE 1. A sample of the JMBX dataset.\n1https://figshare.com/s/349c826391f77c0a4899\n3\nTheoretical Background\nIn 1939, social scientists Alfred and Elizabeth Lee described seven propaganda techniques in their\nbook \u201cThe Fine Art of Propaganda\u201d Lee and Lee 1939. More recently, Da San Martino et al. Martino\net al. 2020b defines 18 propaganda techniques that are found in digital media. The most frequently\nused propaganda techniques are: loaded language, name calling, repetition, and slogans Martino et al.\n2020a. Other propaganda techniques include: doubt, appeal to fear, flag-waving, bandwagon, reduc-\ntion ad hitlerum, causal oversimplification, black-and-white fallacy, whataboutism, thought terminating\ncliches, and, exaggeration or minimization. According to Huang et al. Huang et al. 2022, people often\nuse appeal to authority as a propaganda technique. Huang et al. use this technique in their generative AI\nmodel which generates synthetic texts closely resembling examples of human-written disinformation.\nAmong the less frequently used propaganda techniques are: strawman, red herring, and obfuscation Yu\net al. 2021.\nResearchers have created several datasets to study text-based propaganda. These datasets contain\nnews articles, social media blogs and limited-length microblogs. Some datasets are topical such as the\nCOVID-19 pandemic Naseem et al. 2021 Memon and Carley 2020, the UK General elections Nizzoli\net al. 2021, and the Russia-Ukraine war Haq et al. 2022.\nPTC (Propaganda Technique Corpus) Da San Martino et al. 2019 dataset contains 550 articles anno-\ntated with 18 propaganda techniques. These articles are extracted from news sources of various political\nbias determined by Media Bias Fact Check (MBFC), an independent website that relies on human eval-\nuators and a methodical approach Check 2024 to determine the bias of media sources. This data set\nis suitable for training and testing natural language processing models that perform both fragment and\nsentence level classifications as well as span identification and identifying the propaganda technique.\nQCRI\u2019s propaganda corpus Barr \u00b4on-Cedeno et al. 2019 contains 51.3K articles from 104 news sources\nthat appeared between October 2017 and December 2018. The articles are classified as propaganda or\ntrustworthy. All articles from a news outlet are labeled based on their bias level (left, right, center)\nreported on MBFC. A total of 94 news sources are considered as sources for trustworthy articles while\n10 sources are used for articles that contained propaganda. The following information is recorded for\neach article: title, text, average sentiment, publication date, and official source name. Geographical\ninformation is added to the dataset with the help of data made available by the Global Database of\nEvents, Language and Tone Project (GDELT) Leetaru and Schrodt 2013.\nThe TWEETSPIN dataset Vijayaraghavan and V osoughi 2022 contains 210,392 tweets in the English\nlanguage. All tweets in the dataset have at least one reply calling out the tweet with propaganda along\nwith the technique of propaganda used. Currently, this dataset is not publicly available.\nRecently researchers explore the use of LLMs as a tool to classify text and draw insights. LLMs\nuse large amounts of training data and the power of transformers to learn relations between sentences\nand predict the next sentence, generating highly accurate pieces of text. Consequently, researchers\nexperiment with using LLMs to detect bias in text Lin et al. 2024; Fan et al. 2024, identifying subjective\nlanguage Shokri et al. 2024; Suwaileh et al. 2024, and detecting fake news Liu et al. 2024. Another\nresearch direction deals with various prompt engineering techniques Wei et al. 2022; Zhang et al. 2022;\nBrown 2020 and evaluation of the performance of LLMs as a classification tool compared to traditional\nNatural Language Models such as BERT. This is a paradigm shift from using models trained to perform\na specialized task to using a generalized model in a variety of classification tasks. Jones et al. Jones 2024\nused GPT 3.5 turbo to detect propaganda in SemEval-2020 Task 11 dataset, which is also known as PTC\ndataset. Sprenkamp Sprenkamp, Jones, and Zavolokina 2023 extend this approach by experimenting\nwith five different GPT-3 and GPT-4 models. However, these studies are limited to news articles and\n4 3 OVERVIEW OF THE JMBX DATASET\nuse an LLM from a single provider. With the introduction of Google\u2019s Gemini models, competition\nin the LLM market has increased. Therefore, it is worthwhile to compare the performance of LLMs\nagainst each other. In our study, we introduce a new social media sourced dataset JMBX and evaluate\neight LLM models, including five from OpenAI\u2019s GPT series and three from Google\u2019s Gemini. To the\nbest of our knowledge, this is the largest known comparison of models in this domain. We measure\nthe performance of these models in detecting propaganda in news articles and social media microblogs.\nAdditionally, we provide an estimate of the carbon footprint of any product that could be based on this\nresearch.\nOverview of the JMBX Dataset\nThe microblogging site X, formerly known as Twitter, provides access to APIs that researchers can\nuse to curate tweets and their replies for social media analysis. In this paper, our goal is to demonstrate\na methodical approach to extract tweets by journalists who are affiliated with news organizations that\nare known to have certain political biases. Using this dataset we analyze the prevalence of propaganda\nlanguage in the tweets posted by authors affiliated with biased news outlets.\nThe dataset consists of 1874 annotated tweets from journalists affiliated with 10 news outlets. The\ndata was downloaded from Twitter between September 27, 2022 and October 3, 2022, using the Twitter\nStreaming API. Each record contains the tweet id, number of likes, retweet count, retweeted status. The\nlast column contains the label, which is the propaganda technique used in the tweet. The tweet text is\nredacted to comply with twitter\u2019s data sharing policy. In addition to this, each record has a bias column\nwith values left, right, lean right, lean left, and center labeled through distant supervision as per the\nratings on AllSides Media Bias.2\n3.1 Data Collection Methodology\nAllSides Media Bias is an independent, multi-partisan agency that uses multi-partisan editorial re-\nviews by trained experts and Blind Bias Surveys by readers to assign political lean (left, lean left, center,\nlean right, right) to news outlets. AllSides describes a transparent mechanism for generating these rat-\nings which incorporates community feedback where the general public can agree or disagree with the\nratings. While the community feedback does not change the original bias rating, it helps to confirm\nor refute the ratings based on public opinion. The community feedback is a 8-point Likert scale from\n\u201cAbsolutely agree\u201d to \u201cAbsolutely Disagree\u201d. Figure 2 shows a sample screenshot.\nWe used the bias ratings from AllSides to begin collecting our data. First, we select news outlets\nwhose bias ratings received a majority of \u201cAbsolutely agree\u201d, \u201cStrongly agree\u201d and \u201cAgree\u201d ratings\nfrom the public. Next, we select news outlets with the highest number of followers on Twitter as this\nnumber is a well known measure of influence in a social network Kim 2020. The following 10 news\noutlets are the result of the above filtering procedure. The results are as of September 2022 from each\nbias category, as reported on AllSides Media Bias RatingTM.\n\u2022Left: MSNBC, The New Yorker\n\u2022Lean left: ABC News, The Guardian\n\u2022Center: Forbes, Reuters\n\u2022Lean right: The New York Post, The Epoch Times\n\u2022Right: Breibart News, The Daily Wire\nWe performed a keyword search to find the profiles of journalists affiliated with each outlet by using\nthe news outlet\u2019s official name as the keyword. In this work, we assume that a journalist associated with\n2https://www.allsides.com/media-bias/ratings\n3.2 Annotation of the JMBX Dataset 5\nFIGURE 2. Sample ratings from Allsides media bias.\na particular news organization is aligned with the political beliefs of that organization. The criteria used\nto select the journalists associated with the aforementioned news outlets are:\n\u2022The profile must have had some activity in the past three months.\n\u2022The journalist\u2019s bio must contain the name of the news outlet they are associated with.\n\u2022Journalists who covered political news are prioritized over sports, lifestyle, and travel journal-\nists.\n\u2022The journalist have the Twitter legacy verified checkmark at the time of data collection. (This\ndata was collected before the checkmark\u2019s became available for purchase.)\nUsing the above methodology, five journalists from each selected news outlet, who have the highest\nnumber of followers among their peers affiliated with the same outlet, are chosen with the exception of\nthe news outlets considered centrist i.e., Forbes and Reuters. Twitter searches for journalists affiliated\nwith Forbes and Reuters do not provide any results that match the above criteria. Therefore, instead of\nindividual journalists, the official Twitter handle of Reuters and Forbes are used to collect tweets and\nare labeled as political center. We use Twitter Streaming API to obtain 1,500 most recent tweets by\neach journalist. For Reuters and Forbes, we collect 5,000 most recent tweets from the official Twitter\nhandles. Data is cleaned by removing URLs, mention (@) symbols, and some tweets that abruptly\nended with \u201c...\u201d. To focus solely on text, we remove emojis.\n3.2 Annotation of the JMBX Dataset\nWe use the annotation services provided by A Data Pro3, the organization that annotated the Se-\nmEval 2020 dataset which is widely used by researchers in the domain of text-based propaganda de-\ntection. The dataset comprises a balanced set of 2000 tweets, each with an equal number of instances\nfeaturing positive and negative sentiment scores. The annotation process follows the guidelines pro-\nvided by Martino et al. Martino et al. 2020a. Two annotators and one consolidator, who serves as the\nsubject matter expert, are employed to classify the dataset at a fine-grained level, providing each tweet\nwith a label from the 18 propaganda techniques Martino et al. 2020a. If any strategy from the list pre-\ndefined propaganda strategies is detected in a tweet then the annotators label the tweet as propaganda ,\n3https://adata.pro\n6 3 OVERVIEW OF THE JMBX DATASET\nFIGURE 3. Propaganda in each bias category\notherwise it is labeled non-propaganda . If the two independently and asynchronously-working annota-\ntors agree, then their label is used as the final label for the tweet. If the two annotators disagree then the\nlabel provided by the consolidator is used as the final label. The inter-rater agreement on this labeling\ntask is found to be substantial, with a Cohen\u2019s Kappa coefficient of 0.79. To resolve any discrepan-\ncies, a consolidator reviewed the annotations and facilitated discussions with the annotators to achieve\nconsensus on all entries. After removing duplicates and incomplete or meaningless entries, the final\nannotated dataset comprised 1,874 tweets.\n3.3 Initial Insights from the JMBX Dataset\nFigure 3 demonstrates that tweets labeled as non-propaganda are most prevalent in the center bias\ncategory, which aligns with expectations given that many of these tweets originate from centrist out-\nlets. In contrast, tweets from sources with extreme bias exhibit a higher proportion of propaganda as\ncompared to non-propaganda.\nWe conduct a sentiment analysis of the tweets using the TextBlob package, which assigns each tweet\na continuous sentiment score ranging from -1 to 1. Tweets with negative sentiment are assigned values\nbetween -1 and -0.33, while positive sentiment tweets are assigned values between 0.34 and 1. Neutral\nsentiment is defined by values between -0.32 and 0.33. Figure 4 illustrates the percentage distribution\nof tweets across different sentiment values (negative, neutral, positive) for different bias categories.\nThe fourth pie chart shows the overall distribution of tweets across bias categories. The fourth chart\nshows that in the dataset, 19.5% of tweets are from outlets with left and right biases, 22% and 21%\nrespectively from lean left and lean right, and 18% from centrist outlets. The most interesting insights\nfrom this figure is that the tweets with neutral sentiments are posted exclusively by the centrist outlets.\nTweets posted by journalists affiliated with left and right biased outlets tend to carry positive sentiments\n4.1 Experiment 1: BERT model 7\nmore often than negative sentiments while the reverse is found for those with lean left and lean right\nbiases.\nFIGURE 4. Sentiments vs Political Bias in JMBX dataset\nWe present the frequency distribution of various propaganda techniques in the annotated dataset in\nFigure 5. The results indicate that loaded language is the most commonly used propaganda technique,\nappearing in 48% of the tweets containing propaganda. Exaggeration or minimization is the second\nmost common technique, found in 21% of the tweets, while name calling or labeling is the third most\nfrequent, present in 9% of the tweets.\nExperiments and Results\nWe analyze a sample of 200 tweets to evaluate the performance of various LLM models using differ-\nent prompts. The sample under analysis includes 100 propaganda and 100 non-propaganda tweets. The\nsample 100 propaganda tweets follow the propaganda type distribution in the corpus (see Figure 5).\nWe run two sets of experiments. Within one set of experiments (Experiment 1) we evaluate the per-\nformance of the the trained BERT model on PTC and JMBX dataset. Within the other set of experiments\n(Experiment 2) we compare the outputs of eight LLMs on same datasets.\n4.1 Experiment 1: BERT model\nWe use Purdue Anvil GPU system hosted by RCAC4Song et al. 2022 utilizing a 3rd Gen AMD\nEPYCTM7763 CPU and NVIDIA A100 GPU for this experiment. We fine-tune the pre-trained BERT\nuncased model5on the PTC dataset Martino et al. 2020a, which is widely used for detecting propaganda\nin news articles. The data is split with stratified technique for 70-10-20 train, validation, and test\ndistributions.\nTable 1 contains the precision, recall, and F1-score for the classification task on both the PTC\nand JMBX datasets. With default hyperparameters, employing the Adam optimizer and binary cross-\nentropy as the loss function, the BERT-base model achieves an F1-score of 0.71 on the PTC test set.\nOn the JMBX dataset, the model yields an F1-score of 0.62. Both experiments are conducted with the\nPTC dataset as the training set, utilizing 10 epochs and 7 different random seeds. Additionally, a default\nhyperparameterized RoBERTa model Liu et al. 2019 is trained but it achieves a lower F1-score (0.66)\ncompared to the BERT-base model.\n4https://www.rcac.purdue.edu/\n5https://www.kaggle.com/models\n8 4 EXPERIMENTS AND RESULTS\nFIGURE 5. Propaganda types in annotated JMBX\nDataset Labels P/R/F F1(avg.)\nPTC0 0.72/0.69/0.700.711 0.70/0.73/0.71\nJMBX0 0.60/0.84/0.700.621 0.73/0.40/0.54\nTABLE 1. Performance of the BERT-base-uncased model on PTC and JMBX dataset.\n0 represents \u201cnon propaganda\u201d while 1 represents \u201cpropaganda\u201d\n4.2 Experiment 2: Large Language Model\nWe perform Zero-Shot prompting Radford et al. 2019 on a sample of 200 tweets from the annotated\ndataset. Eight different Large Language Models from two most popular LLM providers, OpenAI and\nGoogle, are used. Five latest models from OpenAI are chosen namely: GPT 3.5 turbo, GPT 4, GPT\n4 turbo, GPT 4o, GPT 4o-mini. Three models are selected from Google, Gemini 1 pro, Gemini 1.5\npro, Gemini 1.5 flash. As of August 2024, these are the latest models provided by these organizations.\n4.2 Experiment 2: Large Language Model 9\nTo the best of our knowledge, this is the first study that includes Google Gemini in the propaganda\ndetection task while earlier studies were performed only on OpenAI\u2019s ChatGPT.\nExperiment 2A: The experiment relies on the Large Language Model\u2019s definition of propaganda.\nExperiment 2B: This experiment includes the definitions of 18 propaganda techniques used by Mar-\ntino et al. 2020a in the prompt. The LLM is asked to output \u201cpropaganda\u201d if at least one of the propa-\nganda technique is found in the tweet, otherwise the LLM outputs the \u201cnon- propaganda\u201d label. The\nLLM can output \u201cnot sure\u201d if it is unable to perform the classification.\nLLM Model 2A 2B\nP/R/F P/R/F\nGPT3.5 .70/.56/.61 .75/.57/.63\n40613 .74/.74/.74 .79/.79/.78\n4 turbo .71/.69/.70 .73/.72/.72\n4o .79/.47/.59 .79/.59/.67\n4o mini .76/.56/.64 .78/.69/.73\nGemini1 pro .68/.57/.62 .71/.69/.69\n1.5 Pro .72/.54/.57 .77/.56/.63\n1.5 Flash .69/.59/.63 .70/.69/.69\nTABLE 2. Performance of LLMs on PTC news dataset\nLLM Model 2A 2B\nP/R/F P/R/F\nGPT3.5 .68/.41/.51 .71/.48/.57\n40613 .74/.64/.60 .78/.71/.69\n4 turbo .72/.61/.58 .74/.66/.63\n4o .80/.45/.53 .80/.56/.64\n4o mini .72/.50/.53 .76/.61/.63\nGemini1 pro .71/.53/.54 .71/.64/.61\n1.5 Pro .70/.52/.59 .79/.51/.61\n1.5 Flash .69/.57/.62 .74/.68/.67\nTABLE 3. Performance of LLMs on JMBX dataset\nFigure 6 shows the average number of \u201cnot sure\u201d returned by the models in experiment 2B. Results\npresented in Table 1 show that adding definition of propaganda increases the performance on all LLMs.\nExperiment 2C: In experiment 2C, we use Chain of Thought (CoT) Wei et al. 2022 prompting tech-\nnique. The LLMs are prompted with the definition of propaganda techniques similar to Experiment 2B\nwith an additional \u201cthink step by step\u201d type strategy at the end. We select two best performing models\nfrom each organization that produced fewer instances of \u201cnot sure\u201d classifications when categorizing\ntweets. As shown in Table 4, the recall and F-score increased on the JMBX dataset with the use of CoT\nprompting. However, this improvement is not observed in the PTC dataset. Notably, for the Gemini 1.5\nFlash model, CoT prompting yields improved performance on both the datasets.\n10 6 EXPERIMENTS AND RESULTS\nFIGURE 6. Number of \u201dnot sure\u201d output by various LLMs on experiment 2B.\nModel PTC JMBX\nGPT 4 0613 .77/.77/.76 .75/.73/.73\nGemini 1.5 flash .76/.73/.72 .73/.73/.73\nTABLE 4. Results of Experiment 2C on GPT 4 and Gemini 1.5 models\nEnvironmental Impact\nWe estimate the carbon footprint of this research and of any product that utilizes the techniques we\npropose. This research tasks involves classifying 200 tweets with prompts to LLM, averaging runtime\nto 4 minutes per task. Assuming the task ran on GPT-3/4 models hosted on Microsoft Azure servers\n(utilizing a single Nvidia A100 GPU), for a total of 2 hours (4 minutes per model, 5 models, 3 runs,\n2 datasets), the estimated carbon emission was 0.28 kg, based on the mlCO2 calculator by Lacoste\net.al. Lacoste et al. 2019. Similarly, for the Gemini model, hosted on Google Cloud Platform, with a\nruntime of 1.2 hours (4 minutes per model, 3 models, 3 runs, 2 datasets), the estimated carbon emission\nwas 0.11 kg. The total emission for this research is 0.39 kg.\nSince the mlCO2 calculator does not factor in the Power Usage Effectiveness (PUE) of data cen-\nters, we apply an average PUE of 1.12, based on recent studies Faiz et al. 2023, and reports from\nGoogle Google 2024 and Microsoft Azure 2024, which adjusts the total carbon emission to 0.44 kg.\n11\nWhile this value might seem negligible, according to the EPA calculator Environmental Protection\nAgency 2024, it is roughly equivalent to driving a car for a mile, or charging 29 smartphones.\nConclusion & Future work\nWe present an annotated dataset containing tweets posted by highly followed journalists and insights\ninto the relationship between the propaganda in their tweets and the political bias of their affiliation. We\nfine-tune a BERT base model on a well-known propaganda dataset, as well as use zero-shot and CoT\nLLM prompting techniques to measure propaganda detection by eight LLM models on these datasets.\nOur primary insight in this work is that journalists affiliated with extremely biased news outlets tend\nto use more propaganda in their writings than those affiliated with moderately biased organizations.\nWe also report that zero-shot prompting on LLMs shows better performance in detecting propaganda\nthan the BERT model, and with Chain of Thought prompting, the performance is further improved.\nWe estimate the environmental impact of using LLMs in this research. Future research will focus\non evaluating the performance of large language models in the fine-grained detection of individual\npropaganda techniques.\nLimitations & Discussion\nWe recognize that there are limitations to this research due to various issues related to data collection\nand data sharing. Even with paid subscription, the number of tweets one can retrieve using the API is\nlimited. Additionally, the tweets classified under the \u201dcenter\u201d category are sourced from official media\naccounts, which complicates direct comparison with the personalized tweets from journalists associated\nwith biased media outlets. Another limitation involves the environmental impact estimates. These esti-\nmates are derived from related studies, online reports, and publicly available tools designed to calculate\nemissions and energy consumption. However, these sources acknowledge a degree of inaccuracy in\ntheir results, as various factors, such as data center efficiency and hardware specifications, can influence\nthe final calculations.\nEthical Considerations\nThis study addresses several ethical considerations especially when dealing with data from social\nmedia platforms. To mitigate potential privacy violations, we anonymized all user data and ensured\nthat personally identifiable information was not included by redacting journalist\u2019s name, their affilia-\ntion, their meta information in the dataset. Additionally, the potential biases due to selection of certain\njournalists in data must be acknowledged. To address this, we ensured a balanced representation of\nperspectives within the dataset. However, we recognize that no dataset or model is entirely free of bias,\nand thus our findings should be interpreted with caution. Another critical aspect is the ethical implica-\ntions of propaganda detection. Identifying and labeling content as propaganda could have significant\nsocietal impacts, including influencing public perception and discourse. Therefore, we included sub-\nject matter experts to understand nuanced interpretations of the content. Furthermore, we emphasize\ntransparency in the model\u2019s decision-making process and make the dataset publicly available, ensuring\nthat the detection results can be replicated, scrutinized and understood by stakeholders. Finally, energy\n12 8 ETHICAL CONSIDERATIONS\nconsumption and environmental impact were considered throughout the research. Training LLMs are\ncomputationally intensive and contributes to carbon emissions Strubell, Ganesh, and McCallum 2020.\nWe aimed to mitigate this by being aware and optimal use of Large Language Model and sampling a\nsubset of dataset in our experiments. Future research should continue exploring greener alternatives for\nmodel training and deployment.\nReferences\nAzure, Microsoft (2024). Microsoft Azure PUE, WUE .https://azure.microsoft.com/en-\nus/blog/how-microsoft-measures-datacenter-water-and-energy-use-\nto-improve-azure-cloud-sustainability/ [Accessed: (09/3/24)].\nBaron, David P (2006). \u201cPersistent media bias\u201d. In: Journal of Public Economics 90.1-2, pp. 1\u201336.\nBarr\u00b4on-Cedeno, Alberto et al. (2019). \u201cProppy: Organizing the news based on their propagandistic\ncontent\u201d. In: Information Processing & Management 56.5, pp. 1849\u20131864.\nBrown, Tom B (2020). \u201cLanguage models are few-shot learners\u201d. In: arXiv preprint arXiv:2005.14165 .\nCenter, Pew Research (2022). Twitter is the go-to social media site for U.S. journalists, but not for the\npublic . Accessed: 1/26/25. URL:https : / / www . pewresearch . org / short - reads /\n2022 / 06 / 27 / twitter - is - the - go - to - social - media - site - for - u - s -\njournalists-but-not-for-the-public/ .\nCheck, Media Bias Fact (2024). Methodology . Accessed: 1/26/25. URL:https://mediabiasfactcheck.\ncom/methodology/ .\nDa San Martino, Giovanni et al. (2019). \u201cFine-grained analysis of propaganda in news article\u201d. In:\nProceedings of the 2019 conference on empirical methods in natural language processing and the\n9th international joint conference on natural language processing (EMNLP-IJCNLP) , pp. 5636\u2013\n5646.\nDa San Martino, Giovanni et al. (2020). \u201cPrta: A system to support the analysis of propaganda tech-\nniques in the news\u201d. In: Proceedings of the 58th Annual Meeting of the Association for Computa-\ntional Linguistics: System Demonstrations , pp. 287\u2013293.\nEnvironmental Protection Agency (2024). EPA calculator .https://www.epa.gov/energy/\ngreenhouse-gas-equivalencies-calculator [Accessed: (09/3/24)].\nFaiz, Ahmad et al. (2023). \u201cLlmcarbon: Modeling the end-to-end carbon footprint of large language\nmodels\u201d. In: arXiv preprint arXiv:2309.14393 .\nFan, Zhiting et al. (2024). \u201cBiasAlert: A Plug-and-play Tool for Social Bias Detection in LLMs\u201d. In:\narXiv preprint arXiv:2407.10241 .\nGentzkow, Matthew and Jesse M Shapiro (2006). \u201cMedia bias and reputation\u201d. In: Journal of political\nEconomy 114.2, pp. 280\u2013316.\nGoogle (2024). Google Datacenter Efficiency .https://www.google.com/about/datacenters/\nefficiency/ [Accessed: (09/3/24)].\nHaq, Ehsan-Ul et al. (2022). \u201cTwitter dataset for 2022 russo-ukrainian crisis\u201d. In: arXiv preprint arXiv:2203.02955 .\nHuang, Kung-Hsiang et al. (2022). \u201cFaking Fake News for Real Fake News Detection: Propaganda-\nloaded Training Data Generation\u201d. In: arXiv preprint arXiv:2203.05386 .\nJones, Daniel Gordon (2024). \u201cDetecting propaganda in news articles using large language models\u201d. In:\nEng. Open Access 2, pp. 1\u201312.\nKim, Rae Yule (2020). \u201cThe value of followers on social media\u201d. In: IEEE Engineering Management\nReview 48.2, pp. 173\u2013183.\nLacoste, Alexandre et al. (2019). \u201cQuantifying the carbon emissions of machine learning\u201d. In: arXiv\npreprint arXiv:1910.09700 .\nREFERENCES 13\nLasorsa, Dominic L, Seth C Lewis, and Avery E Holton (2012). \u201cNormalizing Twitter: Journalism\npractice in an emerging communication space\u201d. In: Journalism studies 13.1, pp. 19\u201336.\nLee, Alfred and Elizabeth Briant Lee (1939). \u201cThe fine art of propaganda.\u201d In.\nLeetaru, Kalev and Philip A Schrodt (2013). \u201cGdelt: Global data on events, location, and tone, 1979\u2013\n2012\u201d. In: ISA annual convention . V ol. 2. 4. Citeseer, pp. 1\u201349.\nLin, Luyang et al. (2024). \u201cInvestigating Bias in LLM-Based Bias Detection: Disparities between LLMs\nand Human Perception\u201d. In: arXiv preprint arXiv:2403.14896 .\nLiu, Ye et al. (2024). \u201cDetect, Investigate, Judge and Determine: A Novel LLM-based Framework for\nFew-shot Fake News Detection\u201d. In: arXiv preprint arXiv:2407.08952 .\nLiu, Yinhan et al. (2019). \u201cRoberta: A robustly optimized bert pretraining approach\u201d. In: arXiv preprint\narXiv:1907.11692 .\nMartino, G et al. (2020a). \u201cSemEval-2020 task 11: Detection of propaganda techniques in news arti-\ncles\u201d. In: arXiv preprint arXiv:2009.02696 .\nMartino, Giovanni Da San et al. (2020b). \u201cA survey on computational propaganda detection\u201d. In: arXiv\npreprint arXiv:2007.08024 .\nMemon, Shahan Ali and Kathleen M Carley (2020). \u201cCharacterizing covid-19 misinformation commu-\nnities using a novel twitter dataset\u201d. In: arXiv preprint arXiv:2008.00791 .\nNaseem, Usman et al. (2021). \u201cCOVIDSenti: A large-scale benchmark Twitter data set for COVID-19\nsentiment analysis\u201d. In: IEEE transactions on computational social systems 8.4, pp. 1003\u20131015.\nNizzoli, Leonardo et al. (2021). \u201cCoordinated behavior on social media in 2019 UK general election\u201d.\nIn:Proceedings of the International AAAI Conference on Web and Social Media . V ol. 15, pp. 443\u2013\n454.\nNoguera-Vivo, Jos \u00b4e Manuel (2013). \u201cHow open are journalists on Twitter? Trends towards the end-user\njournalism\u201d. In.\nPaul, Richard and Linda Elder (2006). \u201cHow to detect media bias & propaganda\u201d. In: Dillon Beach,\nCA: Foundation for Critical Thinking .\nRadford, Alec et al. (2019). \u201cLanguage models are unsupervised multitask learners\u201d. In: OpenAI blog\n1.8, p. 9.\nShokri, Mohammad et al. (Aug. 2024). \u201cSubjectivity Detection in English News using Large Language\nModels\u201d. In: Proceedings of the 14th Workshop on Computational Approaches to Subjectivity, Sen-\ntiment, & Social Media Analysis . Association for Computational Linguistics.\nSong, X Carol et al. (2022). \u201cAnvil-System Architecture and Experiences from Deployment and Early\nUser Operations\u201d. In: Practice and Experience in Advanced Research Computing , pp. 1\u20139.\nSprenkamp, Kilian, Daniel Gordon Jones, and Liudmila Zavolokina (2023). \u201cLarge language models\nfor propaganda detection\u201d. In: arXiv preprint arXiv:2310.06422 .\nStatista (2021). Number of countries with evidence of using social media to spread computational pro-\npaganda and disinformation about politics from 2017 to 2020 . Accessed: 1/26/25. URL:https:\n/ / www . statista . com / statistics / 1023881 / organized - social - media -\nmanipulation-campaigns-worldwide/ .\nStrubell, Emma, Ananya Ganesh, and Andrew McCallum (2020). \u201cEnergy and policy considerations for\nmodern deep learning research\u201d. In: Proceedings of the AAAI conference on artificial intelligence .\nV ol. 34. 09, pp. 13693\u201313696.\nSuwaileh, Reem et al. (2024). \u201cThatiAR: Subjectivity Detection in Arabic News Sentences\u201d. In: arXiv\npreprint arXiv:2406.05559 .\nVijayaraghavan, Prashanth and Soroush V osoughi (2022). \u201cTWEETSPIN: Fine-grained propaganda de-\ntection in social media using multi-view representations\u201d. In: Proceedings of the 2022 Conference\n14 REFERENCES\nof the North American Chapter of the Association for Computational Linguistics: Human Language\nTechnologies , pp. 3433\u20133448.\nWei, Jason et al. (2022). \u201cChain-of-thought prompting elicits reasoning in large language models\u201d. In:\nAdvances in neural information processing systems 35, pp. 24824\u201324837.\nYu, Seunghak et al. (2021). \u201cInterpretable propaganda detection in news articles\u201d. In: arXiv preprint\narXiv:2108.12802 .\nZhang, Zhuosheng et al. (2022). \u201cAutomatic chain of thought prompting in large language models\u201d. In:\narXiv preprint arXiv:2210.03493 .", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Analysis of Propaganda in Tweets From Politically Biased Sources", "author": ["V Sharma", "MM Shokri", "SI Levitan", "E Filatova"], "pub_year": "2025", "venue": "arXiv preprint arXiv \u2026", "abstract": "News outlets are well known to have political associations, and many national outlets cultivate  political biases to cater to different audiences. Journalists working for these news outlets"}, "filled": false, "gsrank": 347, "pub_url": "https://arxiv.org/abs/2507.08169", "author_id": ["MXG4VgcAAAAJ", "o0OKC_oAAAAJ", "-U_XtWsAAAAJ", "NeOqk2kAAAAJ"], "url_scholarbib": "/scholar?hl=en&q=info:e0Rd8bJi7iMJ:scholar.google.com/&output=cite&scirp=346&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D340%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=e0Rd8bJi7iMJ&ei=QrWsaI2aB7_SieoPzJnloAQ&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:e0Rd8bJi7iMJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://arxiv.org/pdf/2507.08169"}}, {"title": "Framing Analysis of Environmental Issues in the New Indonesian Capital City (IKN) on Kompas. id", "year": "2024", "pdf_data": "JURNAL MENGKAJI INDONESIA , 3 (1), 202 4: 160-178 \nE-ISSN: 2963 -6787  \nP-ISSN: 2963 -3451  \nDOI: 10.59066/jmi.v3i1.666  \nJURNAL MENGKAJI INDONESIA , 3 (1), 202 4: 160-178 \n160  \nFraming Analysis of Environmental Issues in the New \nIndonesian Capital City (IKN) on Kompas.id  \nAhmad Kian Santang1, Prashasti Nur Aini2, Fauzan Ashshiddiqi3, Ika \nListiyadi Julia Atmaja4, Rizki Kusumaningrum5 \n \nArticle history:  Received: 6 May 202 4, Accepted: 3 June 202 4 \nPublished: 4 June 2024 \n \nAbstract: This paper aims to determine how the framing of \nenvironmental news in the Indonesian media, in this case, \nKompas.id media as the object of research. News related to \nenvironmental issues on the topic of IKN development on \nKompas.id media in the range of Aug ust 2022 - November 2022 \nwere collected and analyzed using the framing analysis model \nby Robert Entman. From the analysis, it was found that Kompas \ngave significant attention to constructive news about the IKN \nproject, especially in the context of physical  and infrastructure \ndevelopment. In addition, it was also found that socio -cultural \naspects were also a concern in Kompas news, with an emphasis \non the Balik Tribe and Paser Tribe communities that inhabit the \nIKN development area.  \nPurpose: This paper aims to determine how the framing of \nenvironmental news in the Indonesian media, in this case, \nKompas.id media as the object of research  \nDesign/Methodology/Approach: This study is descriptive \nqualitative research, using Entman\u2019s framing analysis model.  \nFindings: This research presents that Kompas gave significant \nattention to constructive news about the IKN project, especially \n \n1 Student of the Department of Communication Studies, Universitas Negeri \nYogyakarta\u2502ahmadkian.2020@student.uny.ac.id  \n2 Student of the Department of Communication Studies, Universitas Negeri \nYogyakarta\u2502prashastinur.2020@student.uny.ac.id  \n3 Student of the Department of Communication Studies, Universitas Negeri \nYogyakarta\u2502fauzanashshiddiqi.2021@student.uny.ac.id  \n4 Student of the Department of Communication Studies, Universitas Negeri \nYogyakarta\u2502ikalistiyadi.2021@student.uny.ac.id  \n5 Student of the Department of Communication Studies, Universitas Negeri \nYogyakarta\u2502rizkikusumaningrum.2021@student.uny.ac.id  \nAnalysis of Framing Environmental Issues in the New Indonesian Capital City \nProject (IKN) on Kompas.id  \nJURNAL MENGKAJI INDONESIA , 3 (1), 202 4: 160-178 \n161 in the context of physical and infrastructure development. In \naddition, it was also found that socio -cultural aspects were also \na concern in Kompas news, with an emphasis on the Balik Tribe \nand Paser Tribe communities that inhabit the IKN development \narea.  \nOriginality/value: This research's originality lies in its analysis \nof how Kompas.id frames environmental news regarding the \nnew Indonesian capital city project (IKN), providing insights \ninto media influence on public perception and decision -making \non major development proje cts. Additionally, the study includes \na focus on socio -cultural aspects, offering a unique perspective \non the topic.  \nKeywords: Framing, Environment, IKN Project, Deforestation  \nPaper Type: Article -Research.  \n \nIntroduction  \nThis study aims to present the news framing by the Kompas \nmedia on Kompas.id regarding the reporting of the New National \nCapital (IKN) project, which is considered to have an impact on \ndeforestation in East Kalimantan. The mega project IKN has been \nreporte d by various media from various perspectives, including \neconomic, investment, technological development, and environmental \naspects. Since the approval of the National Capital Bill by the \nIndonesian House of Representatives (DPR RI) and the Indonesian \nGover nment, at least 41,493 hectares of forest area will be released for \nIKN Nusantara (Purwa 2022) . The same media also reporte d the \nappointment of 27 directors and bureau heads of IKN (Fandi 2022) . The \nissue of IKN development budget promised to use only 20 percent of \nthe state budget was mentioned in the article  (Tim CNN Indonesia \n2022) . Furthermore, it is planned that IKN will have a data center and \na digital village (Telkom -CNN Indonesia 2022) . Another article \nhighlighted concerns about the existence of wild pigs due to forest \nclearing  (Sumbogo 2022) . Another news item mentioned the potential \nenvironmental damage due to the relocation of IKN (DPR - Republika \n2022) . From various perspectives of the news coverage of IKN by \nAhmad Kian Santang, Prashasti Nur Aini, Fauzan Ashshiddiqi, Ika Listiyadi Julia Atmaja, \nRizki Kusumaningrum  \nJURNAL MENGKAJI INDONESIA , 3 (1), 2024: 160-178 \n162 various media outlets, the environmental issue is one of the main topics \nand is quite highlighted in the IKN relocation.  \nOne of the main topics raised in the coverage of IKN is the \nenvironmental aspect. This is because, in terms of location, IKN is in \nKalimantan, one of the largest forest centers in the world, and has \nexperienced a decrease in forest area of 11.9 million hectares in 2001 -\n2021 (Global Forest Watch 2022) . The loss of forests and their functions \nsignificantly impacts the survival of flora, fauna, and humans.  The \nExecutive Director of the Indonesian Environmental Forum (WALHI) \nEast Kalimantan, Yohana Tiko, stated that the development of IKN \nwould consume 256 thousand hectares, including the Sungai Wain \nProtected Forest. The forest is home to various animals su ch as \nhornbills, proboscis monkeys, sun bears, and orangutans (Febryan \n2022) . In another report cited from CNN Indonesia by WALHI along \nwith several other Non -Governmental Organizations (NGOs), it was \nstated that the location of the IKN development is in a strategic area \nand supports the water needs of 5 regions at once (CNN Indonesia \n2022) . The areas include Balikpapan, Penajam Paser Utara, Kutai \nKartanegara, coastal areas, especially Samboja District, Muara Jawa \nDistrict, Loa Kulu District, and Samarinda City, especially in the \nsouthern part. WALHI also added that under normal conditions, the \ncity of Balikpapan often faces a crisis of clean water and drinking water \navailability. Therefore, Penajam Paser becomes a source of water for \nBalikpapan. In another press release, WALHI further explained that the \ndevelopment of IKN would threaten the existence of mangrove \necosystems in Balikpapan Bay up to 2,603.41 hectares (Rachman 2022) . \nThis could threaten the survival of nature and living creatures in the \nsurrounding area. These issues are exacerbated by the high number of \nmining concessions and the many unclosed mining pits, thus \nincreasing the risk of contamination of groundwater, su rface water, \nand coastal areas. There is a total of 162 mining, forestry, oil palm \nplantation, and coal -fired power plant concessions in the total area of \n180 thousand hectares of the IKN area.  \nAnalysis of Framing Environmental Issues in the New Indonesian Capital City \nProject (IKN) on Kompas.id  \nJURNAL MENGKAJI INDONESIA , 3 (1), 202 4: 160-178 \n163 In addition to the various physical impacts predicted to occur due \nto the relocation of IKN, there is also a critical public response to this \ndevelopment. This can be seen from the civil society coalition lawsuit \nagainst the IKN Law in the Constitutional C ourt, which is considered \nto ignore public deliberation, although it resulted  in rejection. Critical \nresponses also continue in both mass media discourse and social media. \nThe National Research and Information Agency (BRIN) highlights two \nissues that are c hallenges in the IKN development process, namely \ntechnocratic issues,  and anti -political responses in the development of \nIKN Nusantara.  \nThe above points demonstrate the importance of the media in \npresenting news about IKN which cannot be denied. The media has the \npower to build ideas or concepts that exist in society. The relationship \nformed between the media and the government also influe nces \ndirecting and providing the information needed by the public.  \nThe framing of news between one media and another differs. This \nis partly due to the media ideology that is the hallmark of each media \nin framing news (Tapsell 2017) . Robinson and Hadiz (2004) argue that \nauthoritarian rule no longer exists, the new era of Indonesian \ndemocracy since 1998 has been dominated by oligarchs, through the \nrestructuring of old predatory power relations in the new system (in \nTapsell 2017) . As Tapsell states in his book, with the Oligarchy \napproach, oligarchs as media owners produce  news and information \naccording to what they want. Tapsell (2017)  states that media \nownership creates barriers to journalist autonomy, in what information \nthey can and cannot report, and how news should be framed. Similarly, \nin reporting on the relocation of the new national capital. The framing \nof news about the new na tional capital in several media outlets is truly \ndiverse . \nStarting from its economic framing, which emphasizes news \nabout the expected economic benefits of this capital relocation. The \nenvironmental framing emphasizes things like deforestation, \nenvironmental damage, climate change impacts, and loss of wildlife \nAhmad Kian Santang, Prashasti Nur Aini, Fauzan Ashshiddiqi, Ika Listiyadi Julia Atmaja, \nRizki Kusumaningrum  \nJURNAL MENGKAJI INDONESIA , 3 (1), 2024: 160-178 \n164 habitat. From a political framing perspective, it emphasizes the political \nreasons for the planned relocation of the capital. Furthermore, in the \nnews's  social framing, the media show the social impact of capital \ndevelopment, such as its influence on society, local communities, and \nsocial and cultural changes.  \nAs previously explained, each media has certain characteristics \nthat distinguish it from other media. For example, Detik.com, in an \nanalysis released by Media Bias/Fact Check, is a media outlet that is \nquite minimally biased (Media Bias/Fact Check 2023a) . They rarely use \nemotionally charged word choices, and their news presentation is quite \nstrong based on existing facts. On the other hand, there is Tribunnews, \nwhich is ideologically right -leaning \u2014conservative  but still moderate  \n(Media Bias/Fact Check 2023c) . They often present news that is \nemotionally charged and sometimes stereotypical in their word \nchoices. The sources of their news are quite  reliable, although their \nauthenticity still needs to be re -investigated (Media Bias/Fact Check \n2023c) . \nKompas.com, as the media chosen for this study, is classified as \nquite minimally biased (Media Bias/Fact Check 2023b) . Its word choice \nis simple and avoids using phrases that evoke emotion or stereotypes. \nIts reporting also uses reliable sources (Media Bias/Fact Check 2023b) . \nMedia Bias/Fact Check shows that Kompas.com, as a digital media, has \na strong credibility to be used as a reliable source of information \nreference.  \nIn this study, Kompas.Id was chosen as the subject of the study \nbecause the media is the premium version of Kompas.com, which \naccording to claims by Kompas.Id, has higher quality and more \nqualitative reporting. In terms of reporting on the IKN issue, \nKompa s.Id tends to emphasize news about the environmental and \nsocial impacts of this project. Kompas.Id also highlights the potential \nenvironmental damage that may occur, the erosion of forests, the loss \nof wildlife habitats, and climate  changes. Then, social i mpact issues \nAnalysis of Framing Environmental Issues in the New Indonesian Capital City \nProject (IKN) on Kompas.id  \nJURNAL MENGKAJI INDONESIA , 3 (1), 202 4: 160-178 \n165 such as the population that must migrate to switch to the environment \nalso become important concerns.  \nFrom the various explanations, it can be concluded that \nKompas.Id tends to highlight the environmental and social aspects \nwhen reporting on the plan to relocate the new national capital. \nTherefore, this is in line with our research specification which focu ses \non the environmental impact of the issue of relocating the new national \ncapital with the formulation \"How is the Analysis of the Framing of \nEnvironmental News in the New Indonesian National Capital City \nProject on Kompas.id?\".  \n \nMethods  \nRobert Entman's Framing Analysis is a theoretical framework \nused to dissect how the media understands an event, issue, or topic \u2014\nalso constructing interpretations of these things (Entman 1993) . \nFraming Analysis relies  on at least three important components. The \nfirst is selection \u2014message producers, in this case, the media, determine \nwhich aspects to highlight and which ones to exclude from an event. \nThe reality of events, issues, or topics is selectively filtered and c hosen \naccording to the media's needs. Next, this leads to the second \ncomponent, salience,  or emphasis \u2014media then try to highlight the \nselected aspects to make them the focus of a news story. This is done to \nhelp shape a specific perception in the audience.  Finally, in \ninterpretation, the media formulates a frame of mind based on the \nselected elements or aspects to construct the message and its meaning \nfor the audience.  \nThese three components also explain the workings of framing \nitself. The main point is about making an element or aspect of \ninformation about an event or issue more prominent, meaningful, and \npresent as the center of attention for the audience (Entman 1993) . The \nexistence of framing as a methodology is also in line with human \npsychological tendencies to focus on certain aspects of information \nwhile ignoring other aspects that are considered less or irrelevant \nAhmad Kian Santang, Prashasti Nur Aini, Fauzan Ashshiddiqi, Ika Listiyadi Julia Atmaja, \nRizki Kusumaningrum  \nJURNAL MENGKAJI INDONESIA , 3 (1), 2024: 160-178 \n166 (Rakhmat 2011) . This allows  framing to significantly impact the \naudience's understanding and decisions.  \nThis study uses a descriptive qualitative approach, focusing on \nthe analysis of a research object naturally and comprehensively to \nprovide an exposition of phenomena that are ongoing and have \noccurred (Sugiyono 2013) . The analysis is conducted using the framing \nanalysis model formulated by Robert Entman on the online media \nKompas ID \u2014focusing on news articles with the title New National \nCapital (IKN) which take an environmental perspective from August \n2022 to November 2022.  \nFraming analysis itself, as explained by Entman, is a method for \nconstructing discourse to build a specific perspective in the audience. \nEntman emphasizes his method of the selection and salience of a \nparticular topic or issue. This is then processed and i nterpreted by the \nmedia, which can form  a specific framework of understanding, which \nin turn can be captured by the audience.  \nDiscussion and Findings  \nPublic Sphere by Habermas  \nPublic sphere, as conceptualized by Habermas, refers to a space \nfor people to develop opinions independently (Habermas, Lennox, and \nLennox 1974) . These opinions are nurtured in an accessible place, with \nno restrictions on access. Every individual has the right to and must be \nprotected in accessing this space. The public sphere serves as a means \nfor everyone to obtain the information they need and desire. In the \ncontext of communication, mass media serves as a platform for the \npublic to voice and transmit ideas to the general audience. It can be said \nthat the public sphere is a crucial pillar in democracy, providing a space \nfor ideas and thoughts to  freely develop and dialectically evolve.  \nThroughout history, the public sphere has continued to evolve. \nStarting from its inception during the Renaissance period, with a group \nof middle -class actively voicing their political ideas ( (Habermas, \nLennox, and Lennox 1974) . Eventually, thanks to the increasingly \nmassive technological advancements, the public sphere has become \nAnalysis of Framing Environmental Issues in the New Indonesian Capital City \nProject (IKN) on Kompas.id  \nJURNAL MENGKAJI INDONESIA , 3 (1), 202 4: 160-178 \n167 closer and more integrated into people's daily lives. Smartphones, \ndigital media, and social media represent the new face of the public \nsphere, each with its own unique characteristics. Empowered by the \nlimitless power of the internet, the public sphere ha s expanded globally \n(Papacharissi 2002) . New perspectives are born, viewing the internet to \nunite the world through the ideas that grow within it.  \nHabermas understands that the public sphere is necessary to \nensure civilization's advancement through the creativity of ideas born \nwithin it. Civilization progresses alongside the dialectics of life and the \nfreedom for people to express them. However, ther e is a missing aspect \nin Habermas' ideas. He only generally discusses the public sphere. The \nenvironmental aspect, as one of the essential ideas in the dialectics of \nthe public sphere, has not been addressed. This is where Pezzullo and \nCox (2018)  present their ideas on environmental communication and \nthe public sphere.  \nEnvironmental Communication  \nEnvironmental communication is a process of exchanging \ninformation related to ideas about nature and the impact of human \nactions on it (Pezzullo and Cox 2018) . This field of communication has \nfound its momentum regarding the increasing issue of climate change, \nas people begin to grow concerned about the quality of the \nenvironment they live in. In the study of the environment itself, \ncommunication plays a crucia l role as people need to understand what \nis happening in the world around them. Pezzullo and Cox (2018)  \nemphasize that environmental communication is a pragmatic method \nwe use to express the relationships we have with entities other than \nhumans. At least, environmental communication has two different \nfunctions.  \nFirst, environmental communication is a form of pragmatic \ncommunication that emphasizes communicative actions \u2014providing \nan understanding of what needs to be done immediately regarding \nenvironmental aspects. For example, campaigns to turn off electricity \nfor an hour once a month aimed at conserving electricity. Second, \nAhmad Kian Santang, Prashasti Nur Aini, Fauzan Ashshiddiqi, Ika Listiyadi Julia Atmaja, \nRizki Kusumaningrum  \nJURNAL MENGKAJI INDONESIA , 3 (1), 2024: 160-178 \n168 environmental communication has a constitutive function \u2014meaning, \ncommunication becomes a means to convey aspirations and \nperspectives on the environment. People exchange ideas and \ncollectively negotiate perspectives and meanings regarding the \nenvironment i tself.  \nEnvironmental communication in this regard has three main \nprinciples as its framework (Pezzullo and Cox 2018) . First, human \ncommunication is a symbolic action. Humans tend to interpret \nsomething by giving it a symbolic representation. This occurs hoping \nthe constructed meaning will be understood and agreed upon by those \nwho recognize the symbolic representation. Humans create symbols, \nwhether in the form of \"names\" or visual representations, with the aim \nof assigning value to something \u2014and forming a perspective on that \nthing.  \nThe second principle, the environmental aspect becomes significant \nhere because humans create and negotiate meaning through \ncommunication. The environment has a specific perception resulting \nfrom social constructions that grow in a certain society. There m ay be \none society that views the environment or nature with awe and fear. \nOn the other hand, there are those who see nature as an important \nentity ready to be explored for human interests. In the last principle, \nthe public sphere plays a key role in the di scourse on the environment. \nThis perspective has a strong relationship with the idea of the public \nsphere by (Habermas, Lennox, and Lennox 1974) \u2014defining it as a \nspace for individuals to freely express ideas and form public consensus \nsafely and protected. The perspectives people have about the \nenvironment are indirectly shaped through their interactions in the \npublic sphere.  \nDisucussion  \nBased on the results of the analysis using Entman's framing \nmethod, the researcher found several key ideas conveyed by Kompas \nID regarding environmental and social issues in the reporting of the \nIndonesian National Capital (IKN):  \nAnalysis of Framing Environmental Issues in the New Indonesian Capital City \nProject (IKN) on Kompas.id  \nJURNAL MENGKAJI INDONESIA , 3 (1), 202 4: 160-178 \n169 1. Development of the National Capital (IKN)  \nIn the first part, the researcher found that Kompas presented \nquite a lot of news discussing the development of IKN, especially from \na constructive perspective. In one news article titled \"Government \nAdds Rp 5.1 trillion  for Basic Infrastructure Development,\" Kompas \nemphasized the additional funding of Rp5.1 trillion for the \ndevelopment. The allocation includes provisions for clean water \nsupply, flood handling, and the construction of reservoirs in the core \ngovernment cen ter area there. Additionally, a budg et of Rp2.11 trillion \nis allocated for road and bridge construction purposes. In this news, \ntwo development stages are planned for the fiscal year 2022.  \nIn another news article titled \"Buffer Zone of IKN Asked to \nImprove Land Services,\" Kompas affirmed by conveying the presence \nof digital development and transformation projects in the region. This \ndigitalization process is crucial as part of efforts to bui ld supporting \ninfrastructure for governance. The news also mentioned that the \nMinister of Agrarian and Spatial Planning/Head of the National Land \nAgency, Hadi Tjahjanto, emphasized the importance of digitalization \nand ease of land services in the IKN buffe r city. One specific news \narticle Kompas highlighted was the construction of the Sepaku -Semoi \nDam. This dam is planned to be a source of raw water for meeting the \nindustrial needs of the Special Economic Zone (SEZ) to be built in IKN.  \nThe researcher found that the aspect of physical development \nand infrastructure is quite strongly highlighted by Kompas. This is in \nline with the public's perception of the Jokowi administration, which \nhas played a significant role through massive infrastructure \ndevelopment across Indonesia. To strengthen this perception, one \narticle discusses that the SEZ is claimed to have a low disaster risk. \nHowever, the researcher found a quite contradictory Kompas article, \ncontaining criticism of the hasty approval of  the SEZ IKN Law \u2014\nespecially regarding transparency in the drafting of the law.  \nThe lack of transparency from the government's side can be said \nto shape a negative perception of the public towards this IKN \nAhmad Kian Santang, Prashasti Nur Aini, Fauzan Ashshiddiqi, Ika Listiyadi Julia Atmaja, \nRizki Kusumaningrum  \nJURNAL MENGKAJI INDONESIA , 3 (1), 2024: 160-178 \n170 development project. Especially regarding the land acquisition scheme \nand compensation to be provided by the government. This is because \nof the significant increase in land prices in the area. In an article titled \n\"Sepaku IKN Festival and the Inner Atmosph ere of Watching It,\" \npublished in August 2022, one resident expressed concern about their \nlivelihoods when prices of basic goods may rise along with the increase \nin land prices.  \nBased on Robert Entman's framing theory, we can analyze how \nKompas frames its coverage of the IKN (Indonesia's new capital) \ndevelopment project. Framing involves the selection and emphasis of \ncertain aspects of an issue, thereby shaping how audiences perce ive it. \nLet's break down the framing of Kompas's coverage . \nThe Kompas publication strongly underscores the significance of \ninfrastructure development within the IKN project, in line with the \nvision of the Jokowi administration, which prioritizes infrastructure \nenhancement throughout Indonesia. Regarding fund alloc ation, \nKompas particularly accentuates investments in essential \ninfrastructure, such as road construction, bridges, and the Sepaku -\nSemoi Dam. Consequently, the coverage portrays the IKN project as a \nstrategic endeavor aimed at augmenting the quality of phy sical \ninfrastructure in the region. As a prominent media outlet, Kompas \nplaces infrastructure development as a central agenda in national \ndevelopment. This report not only underscores the pivotal role of the \nIKN project in infrastructure advancement but al so fosters a better \npublic comprehension of the government's endeavors to propel this \nsector nationwide. Additionally, Kompas evaluates the digital \ndevelopment and transformation initiatives within the IKN region \noptimistically. By highlighting the signifi cance of digitization in land \ngovernance and service facilitation, Kompas depicts the IKN project as \na progressive stride aligned with modernization endeavors. This \nemphasis signifies that the project encompasses not only physical \ninfrastructure but also a dministrative process enhancements and \nservice improvements. Through this lens, Kompas illustrates that \nAnalysis of Framing Environmental Issues in the New Indonesian Capital City \nProject (IKN) on Kompas.id  \nJURNAL MENGKAJI INDONESIA , 3 (1), 202 4: 160-178 \n171 digitization significantly contributes to enhancing efficiency and the \nquality of public services in the region. Furthermore, Kompas offers a \ncomprehensive overview of the positive impacts of the IKN project on \nadvancing progress and accessibility for both  the local community and \nthe government. This underscores Kompas's commitment to furnishing \ninformative and in -depth coverage of ongoing developments in \nIndonesia, including the swiftly evolving digital transformation. While \ngenerally adopting a favorable perspective, Kompas also incorporates \ncriticisms concerning the lack of government transparency in the \napproval process of the IKN SEZ Law. This framing underscores \nconcerns regarding transparency and accountability in governmental \ndecision -making processe s related to the IKN project, indicating \npotential shortcomings or controversies that might influence negative \npublic perceptions. Through this report, Kompas demonstrates its \ndedication not only to delivering balanced coverage but also to \nconsidering crit ical perspectives to offer readers a deeper \ncomprehension of pertinent issues. Moreover, Kompas discusses land \nacquisition and compensation issues within the context of escalating \nland prices and their potential repercussions on livelihoods. By \nspotlightin g residents' apprehensions regarding potential hikes in the \nprices of essential commodities and land, Kompas raises awareness of \nthe social and economic ramifications of the IKN project. This approach \nadds a human -interest dimension to the coverage, unders coring the \ntangible impacts on the local community. Through this perspective, \nKompas not only portrays policy matters abstractly but also addresses \nthe humanitarian and everyday life facets of the project's consequences. \nKompas's coverage facilitates a dee per understanding of the challenges \nand transformations faced by local communities in coping with \nenvironmental changes resulting from the IKN project. This reinforces \nKompas's role as an information source offering comprehensive and \npertinent insights int o issues of societal importance. By meticulously \noutlining the implications of the IKN project, Kompas has reaffirmed \nits position as an information source that fosters a profound \nAhmad Kian Santang, Prashasti Nur Aini, Fauzan Ashshiddiqi, Ika Listiyadi Julia Atmaja, \nRizki Kusumaningrum  \nJURNAL MENGKAJI INDONESIA , 3 (1), 2024: 160-178 \n172 understanding of the challenges and transformations encountered by \nlocal communities. By delivering informative and in -depth coverage, \nKompas not only accentuates the positive aspects and optimism \nassociated with this project but also considers critical vi ewpoints to \nprovide readers with a thorough comprehension of relevant issues. \nConsequently, Kompas continues to uphold balanced journalistic \nstandards and remains committed to delivering quality coverage to its \nreadership.  \n \n2. Environmental Impact and Conservation  \nIn the next section, the researcher found that this topic was quite \ncentral in various news articles published by Kompas. The issue of \nenvironmental impact is a central topic from August to November. In \nan article titled \"Vulnerable Mangrove Forests in Balikpapan Bay,\" \nKompas reported many voices of concern, especially about the \nsustainability of the mangrove ecosystem in Balikpapan Bay. \nMangrove forests so far  have played a significant role  as ecosystem \nprotectors in the coastal areas there. Government dev elopment efforts \nsuch as reclamation, infrastructure development, and illegal sand \nmining threaten this ecosystem.  \nThe researcher also found public concerns about the presence of \nillegal mines in another news article. The case has been processed since \n2020 and only in 2022 has it finally been resolved. The mining case has \ncaused concern among the public as it could disrupt the environmental \nbalance there.  What makes the community quite annoyed is that the \nhandling of the case by the authorities feels slow \u2014as reported by \nKompas in an article titled \"Repeatedly Reported, Illegal Mines Near \nIKN Still Operate.\"  \nAlthough news with negative sentiments about environmental \nimpacts often appears, positive news about this topic also exists. The \nresearcher found one news article titled \"Deputy Minister of \nEnvironment and Forestry: Hundreds of Hectares of IKN Land Being \nPlanted with Endemic Seedlings\" emphasizing the government's \nAnalysis of Framing Environmental Issues in the New Indonesian Capital City \nProject (IKN) on Kompas.id  \nJURNAL MENGKAJI INDONESIA , 3 (1), 202 4: 160-178 \n173 strong commitment to sustainable development. This is signaled by the \ngovernment's efforts through the Ministry of Environment and \nForestry to plant endemic seedlings in the core capital region. Several \nhundred hectares have been planted, including eucalyp tus seedlings \nthat can be used for industrial purposes. Kompas emphasizes the \ngovernment's seriousness in sustainable development efforts by \nreporting on the plan to establish the Mentawir Seedling which will \nproduce 16 million tree seedlings every year. T his effort is certainly a \npositive step that can shape a positive perspective from the public, \nespecially regarding the government's efforts to maintain the \nbiodiversity of the area.  \nDrawing from Robert Entman's framing analysis theory, this \nstudy examines how Kompas structures its portrayal of the IKN \ndevelopment project by accentuating diverse viewpoints. Particularly, \nKompas underscores the facet of infrastructure advancement within  \nthe IKN initiative, resonating with the overarching narrative of the \nJokowi administration, which places paramount importance on \nnationwide infrastructure enhancement. Through spotlighting \nresource allocation towards fundamental infrastructure, such as ro ad \nand bridge construction, alongside the establishment of the Sepaku -\nSemoi Dam, Kompas depicts the IKN undertaking as a pivotal \nendeavor aimed at bolstering physical infrastructure within the locale. \nFurthermore, Kompas presents the development and digita lization \nthrust of the IKN region in a favorable light, underscoring the pivotal \nrole of digitization in land governance and service delivery, thus \nportraying the project as a forward -looking initiative in consonance \nwith modernization aspirations.  \nThis framing not only accentuates the physical infrastructure \naspect but also underscores the enhancements in administrative \nprocedures and service delivery. While the overall framing leans \ntowards a positive outlook, Kompas does not shy away from critiqui ng \nthe government's perceived lack of transparency in the approval \nprocess of the Special Economic Zone (SEZ) IKN Law. Such critique \nAhmad Kian Santang, Prashasti Nur Aini, Fauzan Ashshiddiqi, Ika Listiyadi Julia Atmaja, \nRizki Kusumaningrum  \nJURNAL MENGKAJI INDONESIA , 3 (1), 2024: 160-178 \n174 underscores apprehensions regarding transparency and accountability \nin governmental decision -making concerning the IKN project, hinting \nat potential pitfalls or controversies that could shape adverse public \nperceptions.  Furthermore, Kompas addresses land acquisition and \ncompensation issues within the context of escalating land prices and \npotential repercussions on residents' livelihoods. By amplifying \nresidents' apprehensions regarding probable hikes in essential \ncommodit y prices and land values, Kompas sen sitizes readers to the \nsocial and economic ramifications of the IKN initiative, adding a \nhumanitarian dimension to its coverage and emphasizing the tangible \nimpacts on the local populace.  \nIn essence, Kompas frames its coverage of the IKN development \nproject by accentuating the constructive strides in infrastructure \ndevelopment and digitalization while acknowledging criticisms \nregarding governmental transparency and concerns regarding social  \nand economic ramifications. Such framing influences readers' \nperceptions of the project, shaping their comprehension of its \nsignificance, benefits, and potential challenges.  \n3. Socio -Cultural Aspects  \nLocated in the heart of the Sepaku area, which is the focal point \nof IKN development, the Balik Tribe is one of the indigenous tribes that \nhave inhabited the area for generations. In an article titled \"United in \nHarmony in the Land of Sepaku,\" published in  August 2023, Kompas \ntries to portray the life of the Balik Tribe, which is far from the hustle \nand bustle and chooses to enter the forest. The Balik Tribe is known as \na community that is open to newcomers and upholds values of \nkindness and peace,  among ot hers. Although they prefer to avoid \ncrowds, they also try to adapt by exchanging ideas with newcomers. \nBesides the Balik Tribe, there are also the Paser Tribe who also inhabit \nthe area. The low level of conflict and high diversity values have also \nled the central government to choose the area as the basis for the new \ncapital.  \nAnalysis of Framing Environmental Issues in the New Indonesian Capital City \nProject (IKN) on Kompas.id  \nJURNAL MENGKAJI INDONESIA , 3 (1), 202 4: 160-178 \n175 Since the IKN development program was introduced, the Sepaku \ncommunity has also felt its impact. Still in the same article, Kompas \nreports on the benefits of development such as road infrastructure \nimprovements and the construction of dams that can support  the lives \nof the Sepaku community better. The renovated roads can increase \nmobility, which contributes to improving the local community's \nstandard of living. However, this development is also not free from \npsycho -social issues, especially regarding relati ons between \ncommunities, both from the government and the indigenous \ncommunity there.  \nIn an article titled \"Bersoyong, the Indigenous Ritual of IKN that \nDisappears as the Forest Shrinks,\" published in August 2023, Kompas \nhighlights the shrinking forest area which has resulted in various local \ntraditions diminishing. Traditions such as hunti ng and using herbal \nmedicines from nature, which have been passed down for generations, \nare being hindered due to the reduction in forest area as the center of \nactivities. This has been happening since the forestry industry arrived \nduring the New Order era . In this new era, the local community expects \nthe government to make serious efforts to carry out development that \nnot only protects the environmental aspects but also the social aspects \nof the interaction between the community and the government itself.  \nConclusion  \nIn the analysis of news related to the development of the National \nCapital (IKN) presented by Kompas, it can be concluded that Kompas \npays significant attention to constructive news about this project, \nespecially in the context of physical development and infrastructure. \nThey highlight the additional funding allocation for basic \ninfrastructure development and the development of roads and bridges. \nHowever, there are also critical aspects that emerge, especially \nregarding the lack of transparency in the enact ment of laws related to \nIKN, which can create negative perceptions among the public. \nAdditionally, the news also emphasizes the environmental impact and \nconservation, which are important concerns, especially related to the \nAhmad Kian Santang, Prashasti Nur Aini, Fauzan Ashshiddiqi, Ika Listiyadi Julia Atmaja, \nRizki Kusumaningrum  \nJURNAL MENGKAJI INDONESIA , 3 (1), 2024: 160-178 \n176 negative effects on mangrove ecosystems and threats from illegal \nmining.  \nSocial -cultural aspects are also highlighted in Kompas news, with \nan emphasis on the Balik Tribe and Paser Tribe communities inhabiting \nthe area. Although infrastructure development has brought benefits in \nthe form of improved roads and increased mobility,  it has also created \npsycho -social issues and impacts on local traditions. Therefore, the \ngovernment needs to consider the social and cultural impacts on the \ndevelopment of IKN while ensuring environmental sustainability.  \nBibliography  \nCNN Indonesia. 2022. \u201cWalhi Beberkan 3 Masalah Krusial Lingkungan \ndi Ibu Kota Negara Baru.\u201d CNN Indonesia , 2022. \nhttps://www.cnnindonesia.com/nasional/20220113114142 -20-\n746071/walhi -beberkan -3-masalah -krusial -lingkungan -di-ibu-\nkota -negara -baru . \nDPR - Republika. 2022. \u201cFraksi PKS  : Pemindahan IKN Berpotensi \nTimbulkan Kerusakan Kawasan Hutan.\u201d Eksplora - Republika , 2022. \nhttps://eksplora.republika.co.id/posts/46153/fraksi -pks-\npemindahan -ikn-berpotensi -timbulkan -kerusakan -kawasan -\nhutan . \nEntman, Robert M. 1993. \u201cFraming: Toward Clarification of a Fractured \nParadigm.\u201d Journal of Communication  43, no. 4: 51 \u201358. \nhttps://doi.org/10.1111/j.1460 -2466.1993.tb01304.x . \nFandi. 2022. \u201cDPRD Kaltim Minta Seleksi Jabatan di Otorita IKN \nDiperpanjang.\u201d ANTARA News Kalimantan Timur , 2022. \nhttps://kaltim.antaranews.com/berita/174005/dprd -kaltim -\nminta -seleksi -jabatan -di-otorita -ikn-diperpanjang . \nFebryan, A. 2022. \u201cWalhi Ingatkan Potensi Kepunahan Satwa Akibat \nPembangunan IKN.\u201d Republika Online , 2022. \nhttps://republika.co.id/share/r8y0d8368 . \nGlobal Forest Watch. 2022. \u201cIndonesia Deforestation Rates & Statistics \n| GFW.\u201d Global Forest Watch. 2022. \nhttps://www.globalforestwatch.org/dashboards/country/IDN?\ncategory=undefined . \nAnalysis of Framing Environmental Issues in the New Indonesian Capital City \nProject (IKN) on Kompas.id  \nJURNAL MENGKAJI INDONESIA , 3 (1), 202 4: 160-178 \n177 Habermas, Jurgen, Sara Lennox, and Frank Lennox. 1974. \u201cThe Public \nSphere: An Encyclopedia Article (1964).\u201d New German Critique , no. \n3: 49. https://doi.org/10.2307/487737 . \nTelkom -CNN Indonesia. 2022. \u201cTelkom Resmikan Pusat Data dan Desa \nDigital di IKN Nusantara.\u201d CNN Indonesia , 2022. \nhttps://www.cnnindonesia.com/teknologi/20220819141244 -\n190-836533/telkom -resmikan -pusat -data -dan-desa -digital -di-ikn-\nnusantara . \nMedia Bias/Fact Check. 2023a. \u201cDetik.Com Analysis.\u201d Media Bias/Fact \nCheck . https://mediabiasfactcheck.com/detik -com/ . \n\u2014\u2014\u2014 . 2023b. \u201cKompas.Com Analysis.\u201d Media Bias/Fact Check . \nhttps://mediabiasfactcheck.com/kompas -com/ . \n\u2014\u2014\u2014 . 2023c. \u201cTribunnews.Com Analysis.\u201d Media Bias/Fact Check . \nhttps://mediabiasfactcheck.com/tribunnews -com/ . \nPapacharissi, Zizi. 2002. \u201cThe Virtual Sphere: The Internet as a Public \nSphere.\u201d New Media & Society  4, no. 1: 9 \u201327. \nhttps://doi.org/10.1177/14614440222226244 . \nPezzullo, Phaedra C, and Robert Cox. 2018. Environmental \nCommunication and the Public Sphere . 5th Edition. California: SAGE \nPublications, Inc.  \nPurwa, Bagus. 2022. \u201cSedikitnya 41.493 Hektare Kawasan Hutan Bakal \nDilepaskan untuk IKN Nusantara.\u201d ANTARA News Kalimantan \nTimur , 2022. \nhttps://kaltim.antaranews.com/berita/166337/sedikitnya -\n41493 -hektare -kawasan -hutan -bakal -dilepaskan -untuk -ikn-\nnusantara . \nRachman, Arrijal. 2022. \u201cRUU IKN Bakal Disahkan, Walhi Ungkap \nSederet Masalah yang Belum Tuntas.\u201d Tempo.co , 2022. \nhttps://nasional.tempo.co/read/1549437/ruu -ikn-bakal -\ndisahkan -walhi -ungkap -sederet -masalah -yang -belum -tuntas . \nRakhmat, Jalaluddin. 2011. Psikologi Komunikasi . Bandung: Remaja \nRosdakarya.  \nSugiyono. 2013. Metode Penelitian Kuantitatif, Kualitatif, Dan R&D . \nBandung: ALFABETA. https://b -ok.asia/book/5686376/9d6534 . \nSumbogo, Aryo. 2022. \u201cNasib Pilu Beruk di Kawasan IKN Nusantara: \nTersisihkan, Keluar Hutan karena Sulit Cari Makan.\u201d KOMPAS.tv , \n2022. https://www.kompas.tv/nasional/291300/nasib -pilu-\nAhmad Kian Santang, Prashasti Nur Aini, Fauzan Ashshiddiqi, Ika Listiyadi Julia Atmaja, \nRizki Kusumaningrum  \nJURNAL MENGKAJI INDONESIA , 3 (1), 2024: 160-178 \n178 beruk -di-kawasan -ikn-nusantara -tersisihkan -keluar -hutan -\nkarena -sulit -cari-makan . \nTapsell, Ross. 2017. Media Power in Indonesia: Oligarchs, Citizens and the \nDigital Revolution . Media, Culture and Communication in Asia -Pacific \nSocieties . London  ; New York: Rowman & Littlefield International, \nLtd. \nTim CNN Indonesia. 2022. \u201cJokowi Janji di Sidang MPR, APBN Cuma \nNanggung 20 Persen Bangun IKN.\u201d CNN Indonesia , 2022. \nhttps://www.cnnindonesia.com/ekonomi/20220816115141 -532-\n835205/jokowi -janji-di-sidang -mpr-apbn -cuma -nanggung -20-\npersen -bangun -ikn. \n  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n ", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Framing Analysis of Environmental Issues in the New Indonesian Capital City (IKN) on Kompas. id", "author": ["AK Santang", "PN Aini", "F Ashshiddiqi"], "pub_year": "2024", "venue": "Jurnal Mengkaji \u2026", "abstract": "This paper aims to determine how the framing of environmental news in the  Indonesian media, in this case, Kompas. id media as the object of research. News related to"}, "filled": false, "gsrank": 348, "pub_url": "http://jurnal.erapublikasi.id/index.php/JMI/article/view/666", "author_id": ["4wOqciEAAAAJ", "", ""], "url_scholarbib": "/scholar?hl=en&q=info:Hzkqq_PYHjEJ:scholar.google.com/&output=cite&scirp=347&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D340%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=Hzkqq_PYHjEJ&ei=QrWsaI2aB7_SieoPzJnloAQ&json=", "num_citations": 2, "citedby_url": "/scholar?cites=3539504898220112159&as_sdt=40005&sciodt=0,10&hl=en", "url_related_articles": "/scholar?q=related:Hzkqq_PYHjEJ:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "http://jurnal.erapublikasi.id/index.php/JMI/article/download/666/487"}}, {"title": "Black Lives Matter in the Media", "year": "2022", "pdf_data": "1 \n \n \n \n \n \n \n \n \n \nBlack Lives Matter in the Media:  \nThe liberal and conservative newspaper framing  of Black Lives Matter \nprotest s in the United States between May 2020 and May  2021  \n \n \n \n \n \n \n \n \n \n \n \n \nOscar Baars  \nErasmus School of Social and Behavioral Sciences  \nFSWS -575: Master\u2019s Thesis  \nJune 15, 2022  \nWordcount: 9 906 \nFirst reader: Thomas Swerts  \nSecond reader: Gijs Custers  \n2 \n \nAbstract  \nThe majority of the literature on the newspaper coverage of BLM protest s concludes that the \noverall coverage was quite negative between 2013 and 2020. This study fill s in a knowledge \ngap by answering the research question: How did liberal and conservative newspaper  opinion \narticles  frame the Black Lives Matter protests in the United States between May 2020 and May \n2021?  The method used is a qualitative content analysis and the data consist s of 99 newspaper \nopinion articles written in the New York Times , Washington Post , New York Pos t, and Wall \nStreet Journal . Here, t he theoretical concepts that  guide the analysis are racial grammar and \ncolorblindness. The study finds  that the liberal newspaper opinion articles were pro -BLM, and \nthe conservative anti -BLM, in their general protest fram ing between May 2020 and May 2021.  \nIn addition , racial framing through the minimization of racism, cultural racism , and the denial \nof racism were central in conservative articles, but non -existent or a deviation in liberal articles.  \nThe study concludes by stating that the conservative articles  deny (systemic) racism to defend  \nits existence  and that this is  in line with contemporary US conservative ideology . \nKeywords : Black Lives Matter, conservative, liberal, newspaper analysis, racial framing  \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n3 \n \nIntroduction  \nIt is February 26, 2012, when a 17-year-old black child named Trayvon Martin  was walking \nhome from the store. On the way home , he was approached by a member of the local \nneighborhood watch called  George Zimmerman . Moments before, Zimmerman had called 911 \nto report a \u201csuspicious person \u201d and he  was told by the 911 operator to wait in the car. However, \nZimmerman did not comply and he confronted Martin. The confrontation that ensued ended \nwith Martin being shot to death by Zimmerman. In court, the jury concluded that Zimmerman \nwas not guilty and this acquittal was the beginning of the Black Lives Matter  (BLM)  movement \n(Chase, 2018) . Since the start of the BLM movement , there have been protest s aimed at  \n(systemic ) racism and police brutality  (Banks, 2018).  In addition to these protests , there has \nalso been  extensive  media  coverage of the protest  (Appendix A).  This present study is \nconcern ed with  the media framing of the BLM protest . More specifically, it is concerned with \nthe question of how both liberal and conservative newspaper opinion articles framed the BLM  \nprotest between May 2020 and May 2021.  \nProblem statement  \nThe theoretical framework will discuss the literature on the newspaper coverage of BLM  \nprotests between 2013 and 2020.  Here , the majority of the existing studies conclude d that the \nmedia coverage of BLM protests  was quite negative  between 2013 and 2020 (Kilgo et al., 2019; \nLeopold & Bell, 2017;  Mour\u00e3o et al., 2021 ). Thus , the newspaper coverage of BLM protests  \nhas already been studied to an extent . However, there is still a knowledge gap in the literature \nrelating to the newspaper coverage of BLM  protest s that has two components. Firstly, most \nstudies that analyzed the newsp aper coverage of the BLM  protest  did not focus on the protest \nafter the killing of George Floyd. Secondly, most studies did not explicitly focus on the \ndifferences between liberal and conservative media coverage.  In short, the knowledge gap \nconcerns the potential differences in the liberal and conservative newspaper coverage of BLM \nprotests , after the killing of George Floyd in May 2020.  \nHence,  the research question  can be  formulated as follows : How did liberal a nd conservative \nnewspaper  opinion articles  frame the Black Lives Matter protests in the United States between \nMay 2020 and May 2021?  This research question will focus on two liberal and two conservative \nnewspapers . Here, t he two liberal newspapers that will be analyzed are the New York Times  \n(NYT)  and the Washington Post  (WSP) and the two conservative newspapers are the New York \nPost (NYP) and the Wall Street Journal  (WSJ).  Furthermore , the newspaper articles that will \nbe analyzed are exclusively opinion pieces. This is because opinion pieces are more normative \n4 \n \nwhich allows the potential differences between liberal and conservative newspapers to be more \nclearly defined.  In addition , the research will mainly focus on how the newspaper articles \nframe d the protests by looking at the language that they employ.  This is with the help of the \ntheoretical concepts named racial grammar and colorblindness. Here, racial grammar refers to \nhow language is used to either directly or indirec tly talk about race  (Banks, 2018). In addition, \ncolorblindness is the idea that discourse is used to downplay and justify contemporary racism \nthrough the use of disguised racially coded language  (Ellis & Branch -Ellis, 2020).  Here, t wo \nrelevant racial frame s encompass colorblind racism , namely the minimization of racism and  \ncultural racism  (Bonilla -Silva, 2013).  The theoretical framework will discuss these racial \nframes in more detail.  \nScientific relevance   \nResearching  how both liberal and conservative newspapers covered the BLM protest between \nMay 2020 and May 2021 has scienti fic relevance for two main  reasons. Firstly, the killing of \nGeorge Floyd led to a sharp  increase in the extent of the  BLM protest (Heaney, 2020 ). Parallel \nto this, there was also a strong  increase in the media coverage of the growing protest (Appendix \nB). This increase in BLM protest and media coverage of the protest could have changed how \nthe media wrote about the protest. In addition, the studi es that have been done on BLM protests \ngenerally did not focus on specifically the BLM protest after the killing of George Floyd. In \nshort, this research has scientific relevance because new research into the media coverage of \nBLM protests , after the Killi ng of George Floyd , could come to different conclusions than \nprevious research on the subject.  \nSecondly, analyzing both liberal and conservative newspaper articles relating to the BLM \nprotest also has scientific  relevance. This is mainly because identifyi ng potential differences in \nhow both liberal and conservative newspapers frame the BLM protest c an help to understand \nhow these newspapers want the reader to understand the protest. Understanding how different \nnewspapers want their readers to view the BLM protest can give new insight into the underlying \nideological beliefs and aims of these newspapers concerning race issues.  \nSocial relevance   \nThe proposed thesis also has societal rele vance for  two main reasons. Firstly, the BLM protest s \nare a large contemporary social issue in the United States . As a result, there is a lot of media \ncoverage of the protest  and this coverage can play a significant role in shaping public opinion . \nHere,  it is important that the media  accurately cover s and frame s social issues like the BLM \n5 \n \nprotest , especially in  times of rampant \u2018fake news\u2019. This is because, accurately informing the \npopulation  as a whole , as well as  influencers such as  opinion makers and policy makers , can \nlead them to make more informed decisions and pursue action s based on empirical reality.  \nSecondly , understanding how different newspapers respond to protest movements can help \nprotest movements in organizing tactics that lead the media  coverage to be more in line with \nthe aims of the protest movements.  This can then result in the protest movement s potentially \nhaving a bigger chance of succeeding.  \nTheoretical framework  \nBackground  \nThe history , aims , and causes  of the BLM movement  \nThe \u201cBlackLivesMatter \u201d phrase was first created in July 2013  by one of the three co -founders \nof the BLM movement named Alicia Garza, as a direct response to the shooting of Trayvon \nMartin (Bennett -Swanson, 2017). Together with the other two co -founders, Patriss e Cullors and \nOpal Tometi, the activist s wanted to bring attention to the economic, social, and political \ninequalities facing black people in the United States. Here, the founders were not only \nconcerned with high -profile police killings of black people, b ut also with the underlying social \nstructures and historical circumstances that have led to these police killings (Banks, 2018). It is \ntherefore not a surprise that the core demands of the movement focus on addressing economic, \nsocial, and political inequa lities of Black and other marginalized communities (Kilgo & \nMour\u00e3o, 2019). Moreover, the three founders felt that black liberation movements in the past \nhad left out women, queer and transgender people, which is why the movement is intersectional \nand focus es on inclusiveness (Banks, 2018).  \nWhile the direct cause of the BLM protest can be traced back to the killing of Trayvon Martin \nin 2013, the more underlying cause points towards  systemic racism , especially  concerning the \ncriminal justice system.  According  to Braveman et al. (2022) , systemic racism can be defined \nas racism that is  \u201cdeeply embedded in and throughout systems, laws, written or unwritten \npolicies, entrenched practices, and established beliefs and attitudes that produce, condone, and \nperpetuate widespread unfair treatment of people of color \u201d (p. 171).  In addition,  systemic \nracism can reflect both ongoing  as well as historical injustices. Lastly, systemic racism is often \nnot conscious, intentional , or explicit .  \nThe evidence for systemic racism against people of color in the United States is \noverwhelming , multifaceted , and too broad to be discussed here in detail . This is why only a  \nfew studies  specifically  related to policing and prison sentencing  will be discussed.  Firstly, \n6 \n \nlooking at policing, one study shows that black people accounted for 72% of overall traffic \nstops  in the state of Washington. This is while the black population is only 37.1%  in this state \n(American Civil Liberties Union , 2020 , p. 1 ). In addition , black people were  more than twice \nas likely to be searched  by the police than white people  when stopped in the city of Ferguson  \n(United States Department of Justice  Civil Rights Division , 2015 , p. 4 ). Lastly, a study of nearly \n100 million traffic stops conducted across the United States  showed that black drivers are less \nlikely to be pulled over after sunset , which the study contributes to the fact that it is harder to \nsee the  person\u2019s  race after sunset  (Pierson et al., 2 020, p. 736 ). \nLooking at prison sentencing, black male offenders receive 19.1% longer prison sentences \nfor the same crimes as white -male offenders  (United States Sentencing Commission , 2017 , p. \n2). In addition , when sentenced black Americans spend  almost 10% more time in prison  for the \nsame crimes  when compared to white Americans  (Rehavi & Starr, 2014 , p. 1320 ). Furthermore, \ndespite similar levels of drug dealing and drug usage, black Americans are ten times more  likely \nto be imprisoned for  drug-related offenses than white people  in the 198 largest counties in the \nUS (The Justice Policy Institute , 2007 , p. 3 ). Lastly , black Americans are more than four times \nas likely to receive the death penalty  for murder than white Americans  (Beckett & Evans, 2014 , \np. 1). \nThe h istory  of BLM prote st in relation to the media  \nLooking now specifically at the history of BLM protest from 2013 until 2021  and its  relation \nto the media.  In this history, three moments can be identified as important in the sense that they \nchanged the extent of the media coverage surrounding the protest (Appendix A). The first \nmoment was that which launched the BLM movement, namely the earlier discussed the killing \nof Trayvon Martin in July 2013 (Chase, 2018). Secondly, while the killing of Trayvon started \nthe movement, it was the killing of Michael Brown that catalyzed it (Kilgo & Mour\u00e3o, 2019). \nMichael Brown was an 18 -year-old black man who got shot and ki lled by a white police officer \nnamed Darren Wilson on August 9, 2014, in the city of Ferguson. When it became clear that \nthe grand jury would not indict Wilson, mass protests broke out  that went on for weeks (Chase, \n2018). The killing of Michael Brown led to an increase in BLM protest, and media coverage of \nthe protest, and put the movement in the international spotlight (Kilgo & Mour\u00e3o , 2019; \nAppendix A). There would be many more police killings of black people between 201 4 and \n2020, including ones that ga ined a lot of media attention and led to new protests. However, it \nwas the killing of George Floyd on May 25, 2020, by Minneapolis police officers that turned \nthe BLM protest movement into the \u201cbroadest in American history\u201d according to the NYT  \n7 \n \n(Heaney, 20 20, p. 196). This moment led not only to increasing protest but also to a sharp \nincrease in the newspaper coverage of the BLM protest  (Appendix B).  \nLiterature  review  \nThe existing literature on the newspaper coverage of BLM protest s between 2013 and 2020 will \nnow be discussed. Starting with a study of two liberal newspapers, namely the NYT  and the St. \nLouis Post -Dispatch that concerns the Ferguson protest. The study argues that the analyzed \narticles were more likely to use a \u201cpositiv e\u201d frame that suggested peacefulness and order than \na more \u201cnegative \u201d frame that suggested lawlessness and deviance. In addition, the study writes \nthat both newspapers relied heavenly on the voices of protesters and quoted them more often \nthan the police o r government officials (Elmasry & el -Nawawy, 2017). In short, this study \nconclud es that the newspaper coverage of the BLM protest in Ferguson is more \u201cpositive \u201d than \n\u201cnegative \u201d, but it is also the only study that does so.  Furthermore, next to there being one study \nthat claims a \u201cpositive \u201d news coverage, there is also only one study that claims a \u201cneutral \u201d \nmedia coverage. This study by  Palmer (2021), argues that the \u201ctone of coverage \u201d as well as the \nlanguage around the BLM protest was not positive or negative. Instead, the study concluded \nthat the tone and language used were more \u201cneutral \u201d for articles published in the NYT , WSP , \nand WSJ  in the years 2014, 2017, and 2020. Here, \u201cneutral \u201d referred to articles that used \n\u201cneutra l\u201d language like \u201cprotest \u201d and \u201cdemonstrations \u201d and not more loaded language like \n\u201criots\u201d. \nThe next few studies argue that the newspaper coverage of the BLM protest was generally \nquite negative, beginning with a study that also looked at the Ferguson protest. This study \ndirectly responds to the earlier discussed study  done by Elmasry and el -Nawa wy. It goes against \nElmasry and el -Nawawy  by stating that the coverage of the Ferguson protesters was not \noverwhelmingly sympathetic.  The study did a content analysis of national newspapers \nincluding the NYT , WSP , and WSJ  surrounding the Ferguson protest. It concluded that the \nanalyzed articles focused more on violence by protestors, official sources, and confrontation \nthan on non -violence, the opinions of protestors, and the aims of the protestors (Kilgo et al., \n2019). Th e results of this study are further strengthened by Leopold and Bell (2017), who \nanalyzed 79 articles including articles published by the NYT , WSJ , and NYP . The study \nconcluded that the articles focused on the language of crime, lawlessness, and violence w hile \nmostly citing official sources. In addition, the study stated that there was little discussion of \nissues that were associated with the formation of the BLM movement. Furthermore, a content \nanalysis of five newspapers, including the NYT , WSP , and WSJ , argued that race was \n8 \n \nassociated with deviance in the coverage of the Ferguson protest and that the coverage was \ngenerally focused on violent confrontation with the police. However, it also argued that over \ntime newspaper coverage moved away from focusing o n violence and towards displaying the \ndemands and grievances of the protestors (Mour\u00e3o et al., 2021).  \nRacial grammar  and colorblindness  \nThere are two closely associated theoretical concepts called racial grammar and colorblindness \nthat will be used to gu ide the analysis of the articles.  Firstly, racial grammar refers to how \nlanguage is used to either directly or indirectly talk about race. Here, racial grammar makes it \npossible to be indirectly racist without being explicitly racist. For example, a news a rticle can \nuse codified words like \u201cthug\u201d to describe a person that is engaging in perceived  unwanted \nbehavior , which is meant to insinuate a black person without explicitly mentioning race (Banks, \n2018).  \nA second and related concept is that of colorblindness which refers to the idea that discourse \nis used to downplay, justify and rationalize systemic and contemporary racism. This form of \nracism is implicit and the racist rhetoric is disguised in racially c oded language, euphemisms, \nand institutional policies (Ellis & Branch -Ellis, 2020). The sociologist Bonilla -Silva discusses \nfour different raci al frames  that encompass colorblind racism: abstract liberalism, \nnaturalization, cultural racism, and minimization  of racism. These four frames can help to \nexplain how racists shield themselves from racial realities that exist around them (Bonilla -Silva, \n2013). Here, o nly cultural racism  and the minimization  of racism  are relevant  frames  for this \nthesis since the other two frames are absent from the analyzed data. Looking at the two relevant \nframes , there are three different forms of both cultural racism  and the minimization of racism. \nStarting with cultural racism, there is the narrative  that people of color underperform because \nof their failings,  the stereotyping  of black people as being more prone to violence or crime , and \nthe labeling of black victims as being \u201cthugs \u201d or gang members.  Furthermore, looking at the \nminimization of racism , there  is the narrative of stating that the country has changed and that \nracism is something of the past, arguing that there are only a few bad apples in the police and \nframing the actions of the police as mistakes.  These two racial frames and their different forms \nwill be  part of the initial coding and are central to the analysis of the data. The appendix includes \na table with a  more detail ed representation of each racial frame (Appendix C).  \nThis theoretical framework discussed the history of the BLM movement,  its relationship to \nthe media, the literature on the newspaper coverage of BLM , and theoretical concepts that will \nbe used to help guide the research. There are two implications for the research that can be drawn \n9 \n \nfrom this theoretical framework.  Firstly, the main takeaway of the literature on BLM protest s \nbetween 2013 and 2020 is that the majority of the  newspaper coverage was quite negative  for \nthe NYT, WSP, WSJ , and NYP. The analyzed  articles focused mostly on the violence that the \nprotestors engaged in, \u201cofficial \u201d sources rather than that of the protestors and they generally \nfailed to include the causes and aims of the BLM protestors.  Here, the study will research if this \ntrend is con tinuing after the killing of George Floyd. This might not be the case since the killing \nof Floyd led to a sharp increase in both the number of protests and the media coverage of these \nprotests (Heaney, 2020; Appendix B). Secondly, while the literature did include both liberal \nand conservative newspapers in the analysis,  comparing them  was generally not a focus of the \nresearch.  Researching the potential differences between liberal and conservative newspaper \nframing of the BLM protest will be the central aim of this study.  \nResearch Design  \nData  \nThe data that was analyzed for this study consist ed of newspaper opinion articles written by \ntwo liberal and two conservative newspapers that discuss ed the BLM protest between May 2020 \nand May 2021. Here, the two liberal newspapers in question are the NYT  and the WSP . These \ntwo liberal newspapers both have a \u201ccenter -left\u201d (liberal) bias according to the website \n\u201cmediabiasfactcheck \u201d (Media Bias Fact Check, 202 2a; MBFC , 2022b ). In addition, the two \nconservative newspapers are the NYP  and the WSJ . According to the same website, these two \nnewspapers have a \u201ccenter -right \u201d (conservative) bias  (MBFC, 202 1; MBFC 2022 c). \nFurthermore, according to Harvard\u2019s \u201cThe Future of the Media Proje ct\u201d, the two liberal and the \ntwo conservative newspapers are both the most read newspapers in the United States concerning \ntheir political bias  (Harvard  University , 2022).  Analyzing the two most -read liberal and \nconservative newspapers in the United States is relevant because that which is most read \ngenerally also has the most influence on the discourse and society in general.  \nLooking now at the size of the data, all four n ewspapers have a website that includes a \ndatabase of their articles. Searching for \u201cBlack Lives Matter \u201d gives thousands of results in the \ndatabases of all four newspapers, which is why the data has to be filtered. This filtering was \ndone through the use of  multiple search terms and three other requirements. The search terms \nthat help to narrow down the number of articles were : \u201cblack lives matter \u201d, \u201cGeorge Floyd \u201d, \n\u201cprotest \u201d, and \u201cracism \u201d. Using these terms br ought  the number of articles down to under a \nhundred for each newspaper. The last step in narrowing down the dataset was to introduce the \n10 \n \nfollowing three requirements to the articles: it must be an opinion piece, be related to the BLM \nprotest, and discuss the United States.  This last step br ought the number of articles down to a \ntotal of 99 articles, 38 for the NYT, 2 7 for the WSP , 25 for the NYP , and 9 for the WSJ.  \nMethod  \nNow that it is clear what data was analyzed, there has to be a description of how this analysis \nwill take place. The empir ical research was conducted through the use of qualitative content \nanalysis. This form of analysis can be understood as an approach to documents that emphasizes \nthe role of the investigator and that allows categories to emerge out of the data (Bryman, 2016).   \nHere, q ualita tive content analysis was used as a method for this study  because it can help to \nfind new patterns  of racial framing  by letting categories emerge from the data.  \nOperationalization  \nIn general, it is quantitative content analysis that applies predefined categories to the sources, \nhowever , it is still sometimes useful for qualitative content analysis to employ some initial \ncategorization since this can help to guide the collection of data (Bryman,  2016).  This \ncategorization did change during the reading s of the data. In addition, i t does not seem relevant \nto discuss the specifics of the codebook in this section. However, appendix (D) has the entire \ninitial categorization that was used to read and code the data , including the codes relating to \nracial frames. In addition, appendix (E)  includes all the codes that were created during the first \nreading of the data. Lastly, appendix (F) has a second codebook that is a combination of the \ninitial categorization and the new  codes, which was used for the second reading of the data. \nResults  \nThis results section will discuss three themes that sprang up from the content analysis of the \nnewspaper opinion articles.  The core results are summarized in a separate table at the beginning  \nof each theme , and a summary of the full results can be found in the appendix (Appendix G). \nThe first theme looks at the extent to which newspaper opinion article s can be considered to be \npro-BLM, anti -BLM, or neutral . In ad dition, this theme looks at how the newspapers engage in \npositive or negative protest framing. Here , the first theme is more general and will contain some \nnumerical data . This is because understanding to what extent the differen t newspapers are \ngenerally pro -BLM or anti -BLM can help to give context to the second and third theme s. \nMoreover , the second theme will analyze how the different newspapers engage in two types of \nimplicit colorblind racial framing: the minimization of racis m and cultural racism. Lastly, the \n11 \n \nthird theme will then look at the different ways in which the newspapers engage in denying \nracism.  \nTheme 1 : Pro-BLM and anti-BLM protest framing  \nThis present theme will determine to what extent the opinion articles in the newspapers are \neither pro -BLM or anti -BLM by looking at the core message of the article s. When the core \nmessage is not pro -BLM or anti -BLM, the article will be categorized as \u201cneutral \u201d. In addition, \nthe theme will focus on the extent to which the artic les engage d in positive or negative protest \nframing. Here, positive protest framing is understood as focusing on the aims of BLM, the \ncauses of BLM, and police violence while mostly ignoring the crime and violence by protestors. \nFurthermore,  negative prote st framing is understood as mostly ignoring police violence, the \naims of BLM,  and the causes of BLM while focusing on crime and violence by the protestors.  \nTable  1 \nThe Core Results of Theme 1  \n \nStarting with the liberal newspapers, for the NYT , 84% of the analyzed articles can be \nclassified as being pro -BLM and 16% as \u201cneutral \u201d. In addition , the newspaper engages in \nmostly positive  protest framing. This is in the sense that the NYT identifies the causes of BLM \nto lie in police violence and systemic racism. For example, one article writes  that \u201cGeorge Floyd \nprotests are not just about police violence. They\u2019re about structural racism and the persistence \nof white  supremacy\u201d  (Bou ie, 2020 a). Furthermore , the articles regularly discu ss the aims of  \nBLM, the focus generally being on systemic change over reform. An example from one article \nreads:  \n\n12 \n \nNow I know we don\u2019t need reform. We need something far more radical. The current \nsystem does not work. Even during protests against the current system, law enforcement \nofficers largely behaved as they always do, with blunt  force and apparent indifference \nto the safety of protesters. They believe they are righteous. Burn it all down and build \nsomething new in the ashes . (Gay, 2020)  \nThe second liberal newspaper  concerns the WSP. The articles in this newspaper can be \nclassified as being 96% pro -BLM and 4% anti -BLM. There are two ways in which the WSP \ncompares to the NYT in their coverage and two ways in which they differ. Firstly, just like with \nthe NYT, the WSP engages in more positive than negative protest framing. In addition, the \nWSP also points toward police violence and systemic racism as being the core causes of BLM. \nFor example, one article states that:  \nWe will never escape the infinite loop of death and trauma until we accept the fact that \nAmerican policing was born out of a system that was established to protect the tenets of \nwhite supremacy and control the movements and aspirations of Black and brown \ncommunities that might threaten that status quo . (Nor ris, 2020 a) \nOne difference however is that the WSP discusses the aims and causes of BLM to a lesser extent \nthan the NYT. Furthermore, the WSP also tends to focus more on reforming the current system \ninstead of changing it. An example from one of the  articles reads:  \nThey [BLM protestors] want to reimagine community policing; to reform the \neducational system so it is equitable and excellent for all students; and to develop policy \nstrategies that bring jobs, investment, revitalized housing and, ultimat ely, hope into low -\nincome neighborhoods . (Thomas, 2020)  \nLooking now at the conservative newspapers and starting with the NYP. The articles in this \nnewspaper are 96% anti -BLM and 4% \u201cneutral \u201d. The first interesting point concerning the NYP \nopinion articles is that none of the  articles engage in positive protest framing. Instead, the NYP \nengages in negative protest framing b y mostly focusing on protestors rioting, burning down \nbuildings, destroying property, and looting  while defending the police.  For example , one article \nwrites  that \u201cIn a summer of madness, cities have been trashed and people killed, and crime rates  \nhave spiraled out of control as police were demonized, defunded, and demoralized \u201d (Devine, \n2020 b). In addition,  there is a pattern in the NYP articles  that can be called the \u201clanguage of \nexaggeration \u201d. The articles engage in this \u201clanguage of exaggeration \u201d in two ways : \nexaggerating the crime and violence of BLM protestors and  exagge rating the  animosity  against \nthe police. Firstly, looking at the exaggerati on of  crime and violence , the quotation above had \nthe sentence \u201ca summer of madness\u201d. Another example is the title of an article that is called \n13 \n \n\u201cDemocrats are pretending the cities aren\u2019t burning\u201d which writes about \u201cthe disorder that has \ncaused countless millions in property damage\u201d  (Lowry, 2020 a). Secondly, looking at the \nexaggeration of an imosity towards the police , one article states  \u201cAround the nation we are \nseeing police at the breaking point. They are showing restra int in the face of insane abuse \u201d \n(Devine, 2020 c). \nThe second conservative newspaper concerns the WSJ. The articles in this newspaper are \n56% anti-BLM and 44% \u201cneutral \u201d.1 Other than with the NYP, the WSJ articles do engage in \nsome positive protest framing by discussing the causes of BLM as well as violence committed \nby the police . However, in general , the WSJ does still engage in negative protest framing . Here, \nthe WSJ compares to the NYP in the sense that they focus on protestors being arsonists, rioting, \npillaging, and looting. For example, one article states  that \u201cProtests spilled over into violence \nand looting. Stores  were destroyed; policemen and civilians injured and killed \u201d (Ali, 2020).  \nHowever, there is on e way in which the WSJ differs from the NYP. Namely, in the sense that \nit is less radical in their language . Where the NYP uses phrases like \u201c a summer of madness \u201d, \nthe WSJ is more nuanced and writes  for example  \u201cthere have been daily protests accompanied \nby riot and pillage in multiple U.S cities \u201d (Henninger, 2020).  Here, the WSJ is more nuanced \nin the sense that they distinguish between the \u201cdaily protest\u201d that have been accompanied  by \nriots and pillage.  \nThere are significant differences in the way s that the newspapers generally frame the BLM \nprotest. Firstly, the two liberal newspapers mostly engage in positive protest framing. This is \nbecause the two liberal newspapers are trying to understand the BLM protest by focusing on \ntheir causes which they identify to lie in systemic racism and police brutality. In addition, both \nnewspapers also discuss the aims of the BLM protestors. Furthermore, there are two clear \ndifferences between the two liberal newspapers. Firstly, the articles in the NYT are overall  more \nradical than the WSP in the sense that they are more eager to call for systemic change. Secondly, \nthe WSP engages less in discussing the causes and aims of BLM.  \nMoving on to the two conservative newspapers  that mostly engage in negative protest \nfram ing. This is because both newspapers mostly ignore the causes and aims of the BLM protest \nwhile focusing on discussing crime and violence committed by protestors as well as defending \nthe police. There is one clear way in which the two conservative newspape rs differ in their \ngeneral protest framing. Mainly the fact that the NYP is less nuanced in the sense that the \nnewspaper  has zero positive protest framing and generally make s use of exaggerations. This is  \n                                                           \n1 This data is based on a  sample that only consist of nine articles.  \n14 \n \nwhile the WSJ does have a mix of anti -BLM and \u201cneutral\u201d articles , engages in some positive \nprotest framing , and has a generally more nuanced and less radical writing style.  \nThe core conclusion of this first theme is that both liberal newspapers are generally pro -\nBLM and engage in positive protest framing by discussing the causes and aims of BLM with \nthe difference being that the NYT is more radical in their discussions than the WSP. This while \nthe two conservative newspapers are generally more anti -BLM and engage in negative protest \nframing by mostly ignor ing the aims and causes of BLM  and focusing on crime and violence \ndone by BLM protestors.  The difference is that the NYP is less nuanced , engages in \nexaggerations , and is more explicitly anti -BLM than the WSJ.  \nTheme 2: The minimization of racism and cultural racism  \nThe previous theme discussed the extent to which the newspaper opinion articles can be \nunderstood as being pro -BLM or anti -BLM and to what extent the newspapers engaged in \npositive or negative protest framing. This present theme will now an alyze two forms of implicit \ncolorblind racial framing called the minimization of racism and cultural racism. How these \ndifferent frames can be understood is broadly discussed in the theoretical framework section of \nthe thesis and will therefore not be repe ated here.   \nTable 2  \nThe Core Results of Theme 2  \n \n \n\n15 \n \nMinimization of racism  \nThe first form of implicit colorblind racial framing that will be discussed concerns the \nminimization  of racism. Starting with the liberal newspapers, the WSP does not engage in the \nminimization of racism in any of its articles. However, the NYT does have some minimization \nof racism in two of the 38 analyzed articles. A first interesting point about these  two articles is \nthat they are quite similar in two ways. This is because firstly both articles are part of the 16% \n\u201cneutral \u201d NYT articles in the sense that their general language is not pro -BLM or anti -BLM \nand secondly  both articles are written by police chiefs. One of the two articles will be discussed \nin more detail below.  \nThe article  written by a former police chief of Burlington is quite critical of police violence . \nThis is because the article sees the murder of Geo rge Floyd  as \u201ca brutal crime \u201d, supports the \nmurder charge against the perpetrator, and calls for police reform. However, the article also \nstates that:  \nIf you add up all the police killings that have shocked us \u2014even if you add up all of the \npolice killing s that happen every year \u2014 the chance that one of them will happen in any \nparticular police department is very small. There are nearly 18,000 law enforcement \nagencies in the nation, with roughly 700,000 police officers, but the incidents that \nconvulse us a s a nation are a handful. Nearly all officers spend their careers without so \nmuch as firing a shot . (Pozo, 2020)  \nThis quotation can be understood as the minimization of racism for two reasons. Firstly, it \npresumes that the main criticism levied at the pol ice concerns police killings. This while the \nmain criticism of BLM protestors is focused on different forms of police violence and \ndiscrimination, not just police killings  (Banks, 2018).  Secondly, the article frames the police \nkillings as a result of a few  bad apples and calls the police killings that do happen \u201cincidents \u201d \nand only \u201ca handful \u201d. This framing ignores the fact that the amount of police killings is not \ncomparable to other developed countries. For example, according to Jones  and Sawyer  (2020),  \nin 2018 there were 1099 police killings in the US while the next wealthy country is Canada \nwith only 36 police killings in 2017.  \nWhile the NYT has limited examples of indirect minimizations of racism, the conservative \nnewspapers are more numerous and dire ct in their examples. Starting with the NYP, the \nnewspaper engages in the minimization of racism in two ways. Firstly, by stating that certain \ndeaths at the hands of the police are simply \u201cmistakes \u201d made by the police. For example, one \narticle writes that \u201cGannon was trying to be upfront when he released Potter\u2019s bodycam footage \nand said she had mistaken her gun for her Taser\u201d (Devine, 2021 a). The second way in which \n16 \n \nthe NYP engages in the minimization of racism is victim -blaming. One article writes \n\u201cMeanwh ile, politicians and the mainstream media sensationalize and magnify any \nquestionable case involving a black suspect and a white police officer to affirm dogmas about \n\u201cracial oppression \u201d (even if the suspect was at fault)\u201d (Arora, 2021 b). What is most inte resting \nabout these two examples is that the language radically changes when the NYP discusses police \nviolence against white people. For example, one article reads:   \nMeanwhile, unarmed white people killed by cops in highly questionable circumstances \nwhile  reaching for their license during a traffic stop (mistaken for a gun), failing to raise \ntheir hands upon police request, lying face down on the ground, or being suffocated to \ndeath by wildly excessive force, are ignored by the media. Consequently, the pub lic \nlikely perceives this problem to be almost nonexistent . (Arora, 2021 c) \nIn this example, the police killings are no longer \u201cmistakes \u201d or the \u201cfault of the suspect \u201d. \nInstead, the police engage  in \u201cwildly excessive force \u201d and kills white people in \u201chighly  \nquestionable circumstances \u201d.  \nMoving on to the WSJ, there is one way in which this newspaper engages in the minimization \nof racism. Namely by arguing that there are only a few bad actors. For example, one article \nwrites \u201cCops have to show they will hold t heir bad apples accountable and build relationships \nwith the community before  tragedies happen\u201d and that \u201cSimilarly, America\u2019s national debate \nover policing must begin by resisting efforts to lump the majority of police, who do their jobs \nwell and humanely , in with those like the Minneapolis cop in that horrific video\u201d ( McGurn, \n2020 a). A second article corresponds to this narrative by stating \u201cThis, he said, should give \nrenewed confidence in the justice system, but bad cops cannot be allowed to define all o fficers, \n\u2018the vast majority of whom put on the uniform each day with integrity and servant hearts \u2019\u201d \n(Noonan, 2021).  These statements are examples of the minimization of racism since they point \ntoward police violence being a result of a few bad apples, instead of it being systemic.  \nCultural racism  \nThe second form of implicit colorblind racial framing that will now be d iscussed concerns \ncultural racism. In the liberal newspapers, there are no examples of cultural racism, which is \nwhy we will directly move to the conservative articles. Starting with the NYP which engages \nin two different forms of cultural racism. Firstly,  some articles label black victims as being \nprone to violence and crime by stating that they have been violent in the past. For example, one \narticle states that \u201cOf course, neither Floyd nor Wright deserved to die. It is a tragedy for \neveryone involved. Bu t it\u2019s worth noting that before their fatal encounters with police, both men \n17 \n \nhad been charged over crimes involving aggravated violence to women \u201d (Devine, 2021 a). Here, \na narrative is being shaped that views  black victims as dangerous criminals . This  is to frame  \npolice violence against black victims as justified because of past wrongdoings. The second form \nof cultural racism that the NYP engages in focuses on black people underperforming. For \nexample, one article writes:  \nIf they really cared about black li ves, they would have tried to address the real reasons \nfor black disadvantage. They would worry about fatherlessness, the 70 percent of black \nchildren born to single mothers, the illiteracy that holds down black achievement, and \ndrugs that blight black liv es. (Devine, 202 0d) \nThis quotation exemplifies the narrative that black people underperform because of their bad \nchoices and values and not because of socio -historical reasons like systemic racism.  \nMoving on to the WSJ, this newspaper engages in one form of cultural racism that is similar \nto that of the NYP. Namely, the idea that black people underperform because of their  failings. \nFor example, one article discusses a recently released movie and states:  \n\u201cIt\u2019s easy to say, \u2018The white man, the white man,\u2019 an d point the finger,\u201d says a pastor in \nthe film whose church is located in one of Chicago\u2019s most violent neighborhoods. \u201cIn \nreality, we have to take a very close look at ourselves.\u201d His focus is on \u201cthe \ntransformation of the person. And we\u2019re telling them, hey, educationally, you got to get \nit together. Economically, you got to get it together. Family and spiritually, you got to \nget it together. And you have to take responsibility .\u201d (Riley, 2020)  \nThis quotation is an instance of cultural racism because \u201cviolent neighborhoods \u201d are seen by \nthe article as a result of people of color not taking responsibility, instead of it being a result of \nsocial  factors . Furthermore, another article in the WSJ refers to the white -nationalist Charles \nMurray and argues that:  \nBut we also see, as Charles Murray and J.D. Vance have shown, that these problems \naren\u2019t unique to black America. White America is also, in Mr. Murray\u2019s phrase, \u201ccoming \napart\u201d socially. Broken marriages and alienated young men are problems in Appalachia \nas much as in the inner cities . (Ali, 2020)  \nHere , the article engages in cultural racism by explaining black underperformance as a result of \nbroken marriages and alienated young men. However, the  article  also menti ons that the same is \ntrue for (poor) white people. In this way, by pointing toward both white and black people \nunderperforming the article can negate future allegations of racism, even though the argument \nis made by quoting a white nationalist  (Southern Pover ty Law Center, n.d.). \n18 \n \nCompar ing the newspapers  \nThere are different ways in which the newspapers engage in the minimization of racism and \ncultural racism. Firstly, looking at the liberal newspapers, it is interesting to see that the WSP \ndoes not engage in any minimization of racism or cultural racism. I n addition, the NYT does \nnot engage in any cultural racism in any of the articles. However, the NYT does engage in some \nminimization of racism. This by arguing that police misconduct is the result of a few bad apples  \ninstead of it being a systemic problem with the police as an institution. It is relevant to point \nout however that the two NYT articles that engage in this form of colorblind racism are both \nwritten by police chiefs and are also exceptions to the rule. Generally, as discussed in the \nprevious th eme, most NYT articles do acknowledge police misconduct as a systemic problem. \nIt can be argued that the reason why the NYT allows these types of voices in their newspaper \nis because of two reasons. Firstly, the articles were both written by former police chiefs that are \nstill overall quite critical of the police in their articles and are therefore still serving the anti -\nracist narrative of the NYT.  Secondly, allowing voices that dissent from the standard view \ngives the NYT an image of being more neutral a nd balanced.  \nWhile the liberal newspapers engage little  in the minimization of racism , and when they do \nit deviate s from the general view of the paper, the conservative newspapers do engage more \nwillingly in both the minimization of racism and cultural racism. In addition, when the \nconservative newspapers engage in th ese forms of racism, it is not a deviation from the general \narticles that they publish, it is the central message. Looking at the minimization of racism, both \nconservative newspapers  argue  that police misconduct is the result of a few bad apples. \nFurthermore,  both conservative articles engage in the form of  cultural racism that points \ntowards black underperformance as a result of their poor values, mistakes, and lack of \nresponsibility. One difference between the NYP and the WSJ is that the NYP also engages in a \nform of cultural racism that reshapes black vic tims, like for example George Floyd, as \ndangerous criminals to justify police violence. A last interesting point is that the WSJ quotes in \none of their articles the white nationalist Charles Murray who according to the Southern Poverty \nLaw Center uses \u201crac ist pseudoscience and misleading statistics to argue that social inequality \nis caused by the genetic inferiority of the black and Latino communities, women and the poor\u201d  \n(SPLC,  n.d.). It can be argued that the WSJ can get away with quoting a white national ist in \none of their articles because the author is a black woman named Ayaan Hirsi Ali. Here, quoting \na white nationalist as a black woman can make it harder to criticize her because one has to argue \nthat a black woman is racist against black people.  \n19 \n \nThe first conclusion of the second theme is that the WSP does not engage in any \nminimization of racism or cultural racism. In addition, the NYT does engage in some \nminimization of racism in the form of seeing police misconduct as the result of some bad apples.  \nHowever, this does deviate from the general message of the analyzed NYT articles, namely that \npolice misconduct is a result of systemic racism. Furthermore, both conservative articles engage \nin the minimization of racism and cultural racism. This by seein g police misconduct as a result \nof just a few bad apples, black underperformance as a result of black people\u2019s behavior, and \nlabeling black victims as criminals to justify police violence. Lastly, where the racism present \nin the NYT is a deviation from the  standard narrative, it is the standard narrative for both \nconservative newspapers . \nTheme 3: Denial  of racism  \nThe previous theme looked at the different ways in which the newspapers engaged in implicit \ncolorblind racial framing through the concepts of the minimization of racism and cultural \nracism. This last theme will now look at the different ways in which  the opinion articles deny \nracism.  \nTable 3  \nThe Core Results of Theme 3  \n \nThe third and last theme can start with a conclusion. Namely that there is no observed denial \nof racism in the two liberal newspapers. There is no denial of systemic racism,  individual racism  \nin society , or even the reduction of certain forms of racism. This conclusion makes sense  since \nliberals, and therefore liberal newspapers,  are generally opposed to racism . As can be seen by \nthe fact that as of 2017 , 81% of (liberal) democrats believe that the US should continue to make \n\n20 \n \nchanges towards racial equality (Pew Research Center, 2017).  However, it is still interesting to \nsee that there are no examples that deny racism  in any of the articles.  \nMoving on then to the two conservative newspapers and starting with the NYP. This \nnewspaper engages in the denial of r acism in three core ways. Firstly, some of the articles \nsimply deny that there is such a thing as \u201csystemic racism \u201d in society. For example, one article \ntalks about \u201calleged police brutality \u201d that according to the article has been empirically refuted  \n(Aror a, 2021 c). One more particularly interesting example that encapsulates how the NY P \ndenies systemic racism is present in the following quotation \u201cIn the NYPD, 15 percent of \nofficers are black, and more than half are members of a minority group. Contrary to media \nnarratives about systemic police racism, black Americans are the most overre presented group \nin law enforcement\u201d  (Richmond, 2020).  Here, the article makes the argument that systemic \nracism in the New York City police can\u2019t be real because black people are overrepresented in \nlaw enforcement.  \nThe second  way in which the NYP denies r acism goes beyond the systemic level and focuses \nmore on individuals by denying that individuals in society are sometimes racist. This is mainly \nin the form of saying that no one in society defends the killing of unarmed black people. For \nexample, one arti cle writes that \u201cNo one has defended the Minneapolis cop who kept his knee \npressed into Floyd\u2019s neck until he stopped breathing . Everyone is appalled \u201d and another article \nreads \u201cThere is not a single politician in the country who excused what happened in \nMinneapolis\u201d  (Devine, 2020 c; Harsanyi, 2020).  \nThirdly, there is the narrative that racism is something that existed in the past, but has now \nbeen overcome. One article writes:  \nAmerica, whose founding document declares \u201call men are created equal,\u201d which \nuniquely fought a civil war to end slavery, and which passed the Civil Rights Act to \nprohibit discrimination on the basis of race, color, religion, sex or national origin, is a \ngreat failure as a white supremacist nation, when you think about it. A white poli ce \nofficer had his trial, and a mixed -race jury of his peers determined his guilt. Justice is \nblind, no one is above the law and if a police officer does wrong, he will be punished. \nThat is our system and we should be proud of it . (Devine, 2021 b) \nThis quot ation is interesting because, on the one hand, the author gives the impression that past \nforms of racism, like slavery and legal racism, have been overcome and that this is a good thing. \nHowever, at the same time, the author implies that the current system  works in a non -racist way \nby stating that justice is blind and no one is above the law. This is while the empirical evidence \nshows that  justice is not blind. F or example,  black male offenders receive longer prison \n21 \n \nsentences for the same crimes committed by white male  offenders (United States Sentencing \nCommission , 2017).2  \nThe WSJ has two ways in which it denies racism that is similar to the NYP.  Firstly, some \narticles deny that there is systemic racism in society. For example, one article writes \u201cWe hav e \nour problems and we need to address those. But our society and our systems are far from racist\u201d  \n(Ali, 2020).  Furthermore, a second article states that \u201cCertainly, there are those who honestly \nbelieve that America\u2019s police are racist and in need of fundamental reforms. They are mistaken\u201d  \n(Latzer , 2020).  Secondly, beyond the denial of systemic racism , there is als o the denial of \nindividual racism in the WSJ. For example, one article writes that \u201cEver since Floyd died at the \nhands of a Minneapolis police officer, filmed with a knee on the man\u2019s neck while he was not \nresisting, almost no one has excused police action s\u2014 including fellow cops\u201d  (McGurn, 2020b).  \nIn addition, a second article states that \u201cAn overwhelming majority of Americans already agree \nthat racism should have no place in the country\u201d  (\u201cOpinion | Racism, Riots and #BLM \u201d, 2020).  \nThese two quotations sta te that almost no one has excused (unjustified) police actions and that \nmost Americans are against racism. This is a denial of racism since many Americans have \nexcused police violence and many Americans do have white supremacist views . For example, \naccordi ng to a recent poll done by the Southern Poverty Law Center, white nationalist narratives \nlike the \u201cgreat replacement \u201d have become mainstream among the political right. This is because \nnearly 70% of Republicans believ e, at least to an extent, that conservative white voters  are being \nreplaced  by non-white voters  (Miller, 2022).  \nComparing the liberal and conservative newspapers is not relevant for this theme since the \nliberal newspapers have no examples in their articles of denying racism. However, t he two \nconservative newspapers can be compared. Looking at the similarities, both newspapers deny \nthat systemic racism exists in the general society  and at the level of the police. In addition, both \nnewspapers deny to some extent the existence of individua l racism. However, there are two \ndifferences between the NYP and WSJ. Firstly, the NYP engages in the narrative that there was \nracism in the past that has been overcome, which it sees as a good thing, but then denies that \nracism in the present still exists . This while the WSJ does not engage in this form of denialism. \nA second and perhaps more interesting difference is that the WSJ is slightly more nuanced than \nthe NYT in its discussion of individual racism. This is because while the NYP says that \u201cno \none\u201d and \u201cnot a single politician\u201d has defended the killing of George Floyd, the WSJ does say \nthat \u201calmost no one\u201d has defended the killing of Floyd. In addition, the WSJ states that \u201cthe \n                                                           \n2 See the theoretical framework section for more  empirical evidence concerning  systemic  racism . \n22 \n \noverwhelming majority\u201d - so not everyone - believes that racism has no pl ace in society. This \ndifference is in line with the conclusion of the first theme. Namely, that the NYP is less nuanced \nand more explicitly anti -BLM in their writing than the WSJ. It can be argued that this is true \nfor two reasons. Firstly, the NYP can be seen as a newspaper that is further on the right than \nthe WSJ. Secondly, this difference can be a result of the WSJ being more of a \u201cprofessional \u201d \nnewspaper aimed at higher -educated conservatives while the NYP is more populist.  \nIn conclusion, the two liberal newspapers do not engage in any denial of racism. In addition, \nthe NYP engages in three forms of denialism. Namely, denying systemic racism, individual \nracism, and present racism while acknowledging past racism. Furthermore, the WSJ engages in \ndenying both systemic and individual racism. The main difference between the two newspapers \nis that the WSJ is more nuanced and careful in its denial of individual racism than the NYP.  \nConclusion  \nThe present study analyzed ways in which  both liberal and conservative newspaper  opinion \narticles  fram ed BLM protests  between May 2020 and May 2021 . This is to find  potential \ndifferences in the framing of liberal and conservative newspaper s and to see if this framing \nchanged with the killing of George Floyd in the summer of 2020.  Furthermore, t he study was \ndone through a qualitative content analysis of opinion articles published in the New York Times, \nWashington Post, New York Post , and Wall Street Journal . This content analysis produced three \ncore results . Firstly, t he content analysis found that the liberal newspapers are pro-BLM , and \nthe conservative newspapers are anti -BLM in their general messaging  between May 2020 and \nMay 2021.  A main  difference between the two liberal newspapers is that t he NYT is more \nradical in its discussions than the WSP. Furthermore, the NYP engaged in what can be called \nthe \u201clanguage of exaggeration\u201d , which refers to consistently exaggerating perceived unwanted \nbehavior from BLM protestors.  In addition, the analysis found that the conservative NYP is \nexplicitly anti -BLM in its general messaging. This is while the conservative WSJ has more of \na mix of anti -BLM and \u201cneutral \u201d messaging. Here, the NYP can be considered to be more \nradical and popu list, while the WSJ is more nuanced and \u201cprofessional \u201d.  \nThis first core result can be brought in comparison to previous research. The core conclusion \nof the previous research was that the majority of the newspaper coverage concerning  the BLM \nprotest was q uite negative  between 2013 and 2020.  This is because the articles focused mostly \non crime and violence by the protestors while failing to include the aims and causes of BLM. \nIt can now be concluded that this trend did continue for the two conservative news papers, but \nnot for the two liberal newspapers. This is because the newspaper coverage of the NYT and \n23 \n \nWSP can generally be understood to be pro -BLM after the killing of George Floyd in May \n2020.  \nThe second core result concern s two forms of implicit colorblind racial framing. The NYT, \nNYP, and the WSJ engaged in the minimization of racism by arguing that police misconduct is \nthe result of a few bad apples. The difference is that for the NYT it was a deviation from the \ncentral message, while i t was the central message for the conservative articles. Furthermore, \nthe conservative newspapers engaged in cultural racism by arguing that black \nunderperformance is the result of their poor choices and values. In addition, the NYP reshaped \nblack victims to look like criminals to justify police violence.  \nThe last core result from the content analysis concerns denying racism. Only the \nconservative articles engaged in this form of racism which consisted of denying individual and \nsystemic racism. Furthermore , the NYP denied present racism while acknowledging past \nracism. The difference between the two newspapers is that the WSJ is more nuanced in its \ndiscussions than the NYP . \nIn conclusion, the research question of this study was: How did liberal and conserva tive \nnewspaper  opinion articles  frame the Black Lives Matter protests in the United States between \nMay 2020 and May 2021 ? It can now be concluded that the liberal newspapers were  pro-BLM , \nand the conservative newspapers were anti-BLM  in their general protest framing between May \n2020 and May 2021.  More specifically,  implicit colorblind racial framing in the form of the \nminimization of racism , cultural racism , and the denial of racism was central in conservative \narticles, but non -existent or a deviation in liberal articles.  \nScientific relevance  \nFour points  can be made concerning the scientific relevance. The first point concerns how \ncontemporary US conservative ideology functions. In this study, the liberal articles discussed \nsystemic racism and police misconduct aimed against black people. This while conservative \narticles rejected the social phenomenon of systemic racism and police misconduct aimed at \nblack people, while also stating to be against racism. Here, a major problem arises for the \nconservative newspaper opinion articles. Namely that there is overwhelming evidence for the \nexistence of systemic racism and police misconduct a imed against black people.3 Thus, the \nconservative opinion articles have to find a way to reject the claim of systemic racism, while \nalso declaring to be against racism. The solution is to state that there is no (systemic) racism  \n                                                           \n3 See the theoretical framework section for a discussion of the empirical data.  \n24 \n \nand police misconduct aime d at black people. This is through the minimization of racism, \ncultural racism , and the denial of racism . The result is a continuation of contemporary US \nconservative ideology, which is to  deny  (systemic) racism  to defend  its existence.  \nThe second point o f scientific relevance concerns a specific pattern found in the articles by \nthe NYP. In the opinion articles for this newspaper , there was a consistent pattern of \nexaggerating the perceived unwanted behavior of BLM protestors. This pattern, what can be \nnamed the \u201clanguage of exaggeration\u201d was exclusive to the NYP and can be attributed to their \npopulist writing style.  \nThirdly, in line with the results of this study, it can be argued that public protest can change \nhow (liberal) newspapers cover a protest. Fourthly, it can be argued that what changes how \n(liberal) newspapers cover a protest is the size of the protest. Thi s is because what changed \nbefore and after May 2020 was the size of the protest and not the tactics or aims of the BLM \nmovement itself.  \nSocial relevance  \nThe conclusions of this study have social relevance for general protest movements, the BLM \nmovement sp ecifically, and the broader society. Firstly, the conclusion that protest in \nthemselves and especially their size can change the way that the (liberal) media covers the \nprotest, shows protest movements in general that protesting can indeed change media nar ratives. \nSecondly, the study shows that mass protests can change the narratives of the liberal media, but \nnot the conservative media. This is why it might be strategically relevant for the BLM \nmovement specifically to first and foremost try to focus on app ealing to the liberal media. \nLastly, the conclusion that conservative newspaper coverage of BLM denies systemic racism, \nin light of all the evidence, shows the broader society that societal change towards racial \nequality means opposition to contemporary co nservative ideology.  \nLimitations  \nThere are two limitations of this study that have to be taken into account. The first limitation is \nthat the study analyzed opinion articles written after May 2020 and then compared the results \nwith the previous research o n the topic. However, the previous research on the topic did not \nspecifically look at newspaper opinion articles, just newspaper articles. This is a limitation to \nkeep in mind when comparing the conclusions of this study with the conclusions of previous \nresearch. A second limitation is that the WSJ only had nine opinion articles written between \nMay 2020 and May 2021, when using the criteria laid out in the method section. This is a \n25 \n \nlimitation because it deviates from the other three newspapers, which had 38, 27, and 25 \narticles, and also because nine articles are a small amount of data in and of itself.  \nSuggestions for fu ture research  \nFour  suggestions can be made for future  research. Firstly, this thesis focused mostly on negative \nracial framing . Consequently , there were limited results for the liberal newspapers , since these \nnewspapers  did not engage much in negative racial framing. Here, future research could focus \nmore on analyzing positive racial frame s like anti -racism. Secondly , keeping the limitations in \nmind, future research could analyze newspaper articles in general, not only opinion articles.  \nThirdly , future research could analyze other right -wing populist newspapers and broader media \noutlets . This is to examine  if the  coined concept named  the \u201clanguage of exaggeration\u201d is a \nbroader part of populist right -wing language use or if it is more of an isolated phenomenon  \nspecific to the NYP.  Fourthly , this study looked at the differences between liberal and \nconservative newspapers. Here, fut ure research could analyze the differences between more far -\nleft and far -right newspapers. This is to analyze  how they differ from each other, but also in \nwhat ways they differ from the more center -left and center -right newspapers analyzed in this \nstudy.  \nConcluding remark  \nIn the end, the conservative newspapers did not change the ir framing of the BLM protest after \nthe killing of George Floyd. However, liberal newspapers did become more pro -BLM in their \nframing , which can be contributed to the mass protest of 2020.  As a result , this study can \nconclude by stating that collective mass protest can  indeed  have an effect on media behavior  \nand bring about social change.  \n \n \n \n \n \n \n \n \n \n26 \n \nReferences  \nPrimary sources  \nNew York Times  \nAlexander, M. (2020, June 8). Opinion | America, This Is Your Chance. The New York Times . \nhttp://www.nytimes.com/2020/06/08/opinion/george -floyd -protests -race.html   \nBayoumi, M. (2020, June 17). Opinion | Why Did Cup Foods Call the Cops on George Floyd? \nThe New York Times . http://www.nytimes.com/2020/06/17/opinion/george -floyd-arab-\nmuslims -racism.html   \nBensinger, G. (2020, June 15). Opinion | Corporate America Says Black Lives Matter. It \nNeeds to Hold Up a Mirror. The New York Times . \nhttp://www.nytimes.com/2020/06/15/opinion/black -lives -matter -corporate -pledges.html   \nBlakely, M. (2020, July 2). Opinion | A Long Road to Hope. The New York Times . \nhttp://www.nytimes.com/2020/07/02/opinion/race -reconciliation -complicity.html   \nBlow, C. M. (2020a, July 9). Opinion | Call a Thing a Thing. The New York Times . \nhttp://www.nytimes.com/2020/07/08/opinion/racism -united -states.html   \nBlow, C. M. (2020b, June 14). Opinion | An Insatiable Rage. The New York Times . \nhttp://www.nytimes.com/2020/0 6/14/opinion/us -protests -racism.html   \nBlow, C. M. (2020c, June 7). Opinion | Allies, Don\u2019t Fail Us Again. The New York Times . \nhttp://www.nytimes.com/2020/06/07/opin ion/white -privilege -civil-rights.html   \nBlow, C. M. (2020d, May 31). Opinion | Destructive Power of Despair. The New York Times . \nhttp://www.nytimes.com/2020/05/31/opinion/g eorge -floyd -protests.html   \nBoard, T. E. (2020, June 3). Opinion | In America, Protest Is Patriotic. The New York Times . \nhttp://www.nytimes.com/2020/06/02/opinion/george -floyd -protests -first-amendment.html   \nBokat -Lindell, S. (2020a, June 23). Opinion | Are Black Lives What Really Matter to \nCompanies? The New York Times . http://www.nytimes.com/2020/06/23/opinion/black -\nlives -matter -brands.html   \nBokat -Lindell, S. (2020b, June 4). Opinion | Three Reasons This Time Is Different From \nFerguson . The New York Times . http://www.nytimes.com/2020/06/04/opinion/george -\nfloyd -ferguson.html   \nBokat -Lindell, S. (2020c, May 28). Opinion | Why Is Police Brutality Still Happ ening? The \nNew York Times . http://www.nytimes.com/2020/05/28/opinion/minneapolis -police -\nbrutality.html   \n27 \n \nBottoms, K. L. (2020, June 3). Opinion | The Police Report t o Me, but I Knew I Couldn\u2019t \nProtect My Son. The New York Times .  \nhttp://www.nytimes.com/2020/06/03/opinion/police -protests -atlanta -keisha -bottoms.html   \nBouie, J. (2020a, June 12). Opinion | To Overturn Trump, We Need to Overturn White \nSupremacy. The New York Times . \nhttp://www.nytimes.com/2020/06/12/opinion/s unday/floyd -protests -white -supremacy.html   \nBouie, J. (2020b, June 26). Opinion | Beyond \u2018White Fragility\u2019. The New York Times . \nhttp://www.nytimes.com/2020/06/26/opi nion/black -lives -matter -injustice.html   \nCohen, R. (2020, June 26). Opinion | \u2018Let Freedom Ring\u2019 From Georgia. The New York \nTimes . http://www.nytimes.com/2020/06/26 /opinion/let -freedom -ring-from -georgia.html   \nDouthat, R. (2020, June 12). Opinion | Ross Douthat: The Tom Cotton Op -Ed and the \nCultural Revolution. The New York Times . \nhttp://www.nytimes.com/2020/06/12/opinion/nyt -tom-cotton -oped -liberalism.html   \nEdsall, T. B. (2020a, July 1). Opinion | Trump Wants a Backlash. Can He Whip One Into \nShape? The New York Times . http://www.nytimes.com/2020/07/01/opinion/trump -floyd -\nprotests -2020.html   \nEdsall, T. B. (2020b, June 10). Opinion | How Much Is America Changing? The New York \nTimes . http://www.nytimes.com/2020/06/10/opinion/george -floyd -protests -trump.html   \nFennelly, B. A. (2020, June 12). Opinion | A Flag for All in Mississippi. The New York Time s. \nhttp://www.nytimes.com/2020/06/12/opinion/mississippi -flag-confederate.html   \nGay, R. (2020, June 20). Opinion | How We Save Ourselves. The New York Times . \nhttp://www.nytimes.com/2020/06/20/opinion/how -we-fight -racism.html   \nHinton, E. (2020, June 2). Opinion | George Floyd\u2019s Death Is a Failure of Generations of \nLeadership. The New Yo rk Times . http://www.nytimes.com/2020/06/02/opinion/george -\nfloyd -protests -1960s.html   \nJackson, M. S. (2020, July 25). Opinion | Who Gets to Be a \u2018Naked Athena\u2019? The New York \nTimes . http://www.nytimes.com/2020/07/25/opinion/sunday/portland -protests -white.html   \nKaplan, E. A. (2020, July 6). Opinion | Everyone\u2019s an Antiracist. N ow What? The New York \nTimes . http://www.nytimes.com/2020/07/06/opinion/antiracism -what -comes -next.html   \nKelley, R. D. G. (2020, June 18). Opinion | What Kind of Socie ty Values Property Over \nBlack Lives? The New York Times . http://www.nytimes.com/2020/06/18/opinion/george -\nfloyd -protests -looting.html   \nKristof, N. (2020a, June 11) . Opinion | When It Works to \u2018Defund the Police\u2019. The New York \nTimes . http://www.nytimes.com/2020/06/10/opinion/defund -police -floyd -protests.html   \n28 \n \nKristof, N. (2020 b, June 17). Opinion | When Antifa Hysteria Sweeps America. The New York \nTimes . http://www.nytimes.com/2020/06/17/opinion/antifa -protests.html   \nKristof, N. (2020c, June 6). Opin ion | What if There Were No George Floyd Video? The New \nYork Times . http://www.nytimes.com/2020/06/06/opinion/sunday/george -floyd -structural -\nracism.html   \nLandrieu, M. (2020, June 3). Opinion | The Price We Have Paid for Not Confronting Racism. \nThe New York Times . http://www.nytimes.com/2020/06/03/opinion/george -floyd -protest -\nracism.html   \nLovell, C. (2020, August 3). Opinion | I\u2019m the Police Chief in Portland. Violence Isn\u2019t the \nAnswer. The New York Times . http://www.nytimes.com/2020/08/03/opinion/portland -\nprotests -police -chief.html   \nMcCaulley, E. (2021, April 20). Opinion | How I\u2019m Talking to My Kids About the Derek \nChauvin Verdict. The New York Times . \nhttp://www.nytimes.com/2021/04/20/opinion/derek -chauvin -verdict -floyd.html   \nOrfield, M., & Stancil, W. (2020, June 3). Opinion | George Floyd and Derek Chauvin Might \nas Well Have Lived o n Different Planets. The New York Times . \nhttp://www.nytimes.com/2020/06/03/opinion/george -floyd -minneapolis -segregation.html   \nPozo, B. del. (2020, June 1). Opinion | Justice Is About More Than the Killing of George \nFloyd. The New York Times . http://www.nytimes.com/2020/06/01/opinion/george -floyd -\npolice -protests.html   \nRay, C. (2020, June 20). Opinion | \u2018Could the Police Kill Me, Too?\u2019 My Young Son Asked \nMe. The New York Times . http://www.nytimes.com/2020/06/20/opinion/sunday /george -\nfloyd -protests -black.html   \nRenkl, M. (2020, June 15). Opinion | These Kids Are Done Waiting for Change. The New \nYork Times . http://www.nytimes.com/2020/06/15/op inion/nashville -teens -protests.html   \nRice, S. E. (2020, July 21). Opinion | Take the Next Step Toward Racial Justice. The New \nYork Times . http://www.nytimes.com/2020/07/2 1/opinion/protests -race-congress.html   \nRoss, kihana miraya. (2020, June 4). Opinion | Call It What It Is: Anti -Blackness. The New \nYork Times . http://www.nytimes.com/2020/06/04/opinion/george -floyd -anti-\nblackness.html   \nWarzel, C. (2020, June 10). Opinion | The Floyd Protests Show That Twitter Is Real Life. The \nNew York Times . http://www.nytimes.com/2020/06/10/opinion/sunday/twitter -protest -\npolitics.html   \n \n29 \n \nWashington Post  \nAttiah, K. (2020, August 28). Opinion | Breonna Taylor deserves better than memes and \nbarbecues. Washington Post . \nhttps://www.washingtonpost.com/opinions/2020/08/28/breonna -taylor -deserves -better -\nthan-breonnacon/   \nButler, P. (2020, April 29). Opinion | The most important trial of police officers for killing a \nBlack man has not yet happened. Washington Post . \nhttps://www.washingtonpost.com/opin ions/2021/04/29/next -trial-killing -george -floyd -will-\nbe-real-test/  \nByler, D. (2020, July 23). Opinion | Did protests change Americans\u2019 views of race and \npolicing? Yes, but it\u2019s complicated. Washington Post . \nhttps://www.washingtonpost.com/opinions/2020/07/23/did -protests -change -americans -\nviews -race-policing -yes-its-complicated/   \nDemings, V. (2020, May 29). Opinion | My fe llow brothers and sisters in blue, what the hell \nare you doing? Washington Post . \nhttps://www.washingtonpost.com/opinions/2020/05/29 /my-fellow -brothers -sisters -blue-\nwhat -earth -are-you-doing/   \nDionne, E. J. (2020, June 3). Opinion | Our country\u2019s democratic antibodies are kicking in. \nWashington Post . https://www.washingtonpost.com/opinions/the -mass -nonviolent -\nuprising -reflects -the-life-of-our-democracy -not-its-death/2020/06/03/876d0056 -a5cd -11ea -\nb473-04905b1af82b_story.html   \nGraff, G. M. (2020, June 9). Opinion | Badge -less police officers are showing up at protests. \nIt\u2019s dangerous. Washington Post. \nhttps://www.washingtonpost.com/opinions/2020/06/09/dangerous -rise-anonymous -cops/   \nHarrell, E. (2020, July 29). Opinion | As a D.C. mother of Black boys, it feels as if the hurt of \nracism is everywhere. Washington Post . \nhttps://www.washingtonpost.com/opinions/2020/07/29/dc -mother -black -boys -it-feels -if-\nhurt-racism -is-everywhere/   \nHohmann, J. (2020, March 31). Opinion | Bystanders could not save Floyd\u2019s life, but their \ntestimony can shape his legacy. Washington Post . \nhttps://www.washingtonpost.com/opinions/bystanders -could -not-save-floyds -life-but-their-\ntestimony -can-shape -his-legacy/2021/03/31/c697838e -9256 -11eb -a74e -\n1f4cf89fd948_story.html   \n30 \n \nMcArdle, M. (2020, June 5). Opinion | Social distancing is over. Washington Post . \nhttps://www.washingtonpost.com/op inions/social -distancing -is-\nover/2020/06/05/73403a10 -a750 -11ea -b619 -3f9133bbb482_story.html   \nMuller, J. (2020, June 5). Opinion | My tiny, white town just held a protest. We\u2019re not alone. \nWashington Post . https://www.washingtonpost.com/opinions/2020/06/05/my -tiny-white -\ntown -just-held-protest -were -not-alone/   \nNorris, M. L. (2020a, April 13). Opinion | We\u2019re stuck in a loop of death until we  address \npolicing. This Netflix short showcases that. Washington Post . \nhttps://www.washingtonpost.com/opinions/were -stuck -in-a-loop-of-death -until-we-\naddress -policing -this-netflix -short -showcases -that/2021/04/13/6f63167c -9c7f-11eb -8005 -\nbffc3a39f6d3_story.html   \nNorris, M. L. (2020b, December 18). Opinion | Don\u2019t call it a racial reckoning. The race \ntoward equality has barely begun. Washington Post. \nhttps://www.washingtonpost.com/opinions/dont -call-it-a-racial -reckoning -the-race-toward -\nequality -has-barely -begun/2020/12/18/90b65eba -414e -11eb -8bc0 -\nae155bee4aff_story.html   \nOlsen, H. (2020, July 29). Opinion | Portland\u2019s protest s will not end well for anyone. \nWashington Post . https://www.washingtonpost.com/opinions/2020/07/29/portlands -\nprotests -will-not-end-well-anyone/   \nOpinion | As cities burn, Trump\u2019s bullhorn drowns out the voices of our better angels . (2020, \nMay 31). Washington Post. Retrieved June 11, 2022, from \nhttps://www.washingtonpost.com/opinions/as -cities -burn-trumps -bullhorn -drowns -out-the-\nvoices -of-our-better -angels/2020/05/31/97a259e8 -a367 -11ea -bb20 -\nebf0921f3bbd_story.htm l  \nOpinion | The fragile flowers of Tennessee\u2019s GOP legislature contravene a basic right . (2020, \nSeptember 6). Washington Post. Retrieved June 11, 2022, from \nhttps://www.washingtonpost.com/opinions/the -fragile -flowers -of-tennessees -gop-\nlegislature -contravene -a-basic -right/2020/09/06/796c8eb2 -ec9b -11ea -99a1 -\n71343d03bc29_s tory.html   \nRezaian, J. (2020, June 6). Opinion | People ruled by authoritarians risk it all to protest. Now \nthat right is under threat here. Washington Post . \nhttps://www.washingtonpost.com/opinions/2020/06/06/people -ruled -by-authoritarians -\nrisk-everything -protest -now-that-right -is-under -threat -here-us/  \n31 \n \nRobinson, E. (2020a, June 4). Opinion | Trump is uniting Americans \u2014Against him. \nWashington Post . https://www.washingtonpost.com/opinions/trump -is-uniting -americans --\nagainst -him/2020/06/04/83289834 -a69a -11ea -bb20 -ebf0921f3bbd_story.html   \nRobinson, E. (2020b, March 29). Opinion | The world saw George Floyd\u2019s final minutes. \nNow it will see whether he gets ju stice. Washington Post . \nhttps://www.washingtonpost.com/opin ions/the -world -saw-george -floyds -final-minutes -\nnow-it-will-see-whether -he-gets-justice/2021/03/29/722d9f50 -90b6 -11eb -bb49 -\n5cb2a95f4cec_story.html   \nRobinson, E. (2021a, March 18). Opinion | Remember these words whenever anyone tells you \npolicing is colorbli nd. Washington Post . \nhttps://www.washingtonpost.com/opinions/remember -these -words -whenever -anyone -tells-\nyou-policing -is-colorblind/2021/03/18/fe6791fe -880c -11eb -bfdf-4d36dab83a6d_story.html   \nRobinson, E. (2021b, May 24). Opinion | The great work of art that followed George Flo yd\u2019s \ndeath. Washington Post . https://www.washingtonpost.com/opinions/2021/05/24/great -\nwork -art-that-followed -george -floyds -death/   \nRubin, J . (2020, August 28). Opinion | What a difference a day makes: A reprise of the March \non Washington. Washington Post . \nhttps://www.washingt onpost.com/opinions/2020/08/28/what -difference -day-makes -\nreprise -march -washington/   \nThiessen, M. A. (2020, September 1). Opinion | Biden can\u2019t blame Trump for the anarchy in \nDemocrat -run cities. Washington Post.  \nhttps://www.washingtonpost.com/opinions/2020/09/01/biden -cant-blame -trump -anarchy -\ndemocrat -run-cities/   \nThomas, D. A. (2020, June 22). Opinion | I\u2019m president of Morehouse College. Here\u2019s my \nadvice to protesters. (n.d.). Washington Post . \nhttps://www.washingtonpost.com/opinions/2020/06/22/im -president -morehouse -college -\nheres -my-advice -protesters/   \nVan den Heuvel, K. (2020, June 16). Opinion | Even in the darkest days of Trump\u2019s misrule, \nhope is still alive. Washington Post . \nhttps://www.washingtonpost.com/opinions/2020/06/16/even -darkest -days-trumps -misrule -\nhope -is-still-alive/   \nWaldman, P. (2020, June 8). Opinion | Can the federal government fix our policing problem? \nWashington Post . https://www.washingtonpost.com/opinions/2020/06/08/can -federal -\ngovernment -fix-our-policing -problem/   \n32 \n \nWemple, E. (2020a, June 13). Opinion | Forgive Tu cker Carlson for his panicky desperation. \nHis world is collapsing. Washington Post . \nhttps://www.washingtonpost.com/op inions/2020/06/13/forgive -tucker -carlson -his-panicky -\ndesperation -his-world -is-collapsing/   \nWemple, E. (2020b, May 29). Opinion | Minnesota governor issues spectacular apology for \narrest of CNN crew. Washington Post . \nhttps://www.washingtonpost.com/opinions/2020/05/29/minnesota -governor -issues -\nspectacular -apology -arrest -cnn-crew/   \nNew York Post  \nArora, R. (2021a, January 2). Teaching \u2018white fragility\u2019 is bad for kids of color. New York \nPost. https://nypost.com/2021/01/02/teaching -white -fragility -is-bad-for-kids-of-color/   \nArora, R. (2021b, February 6). These black lives didn\u2019t seem to matter in 2020. New York \nPost. https://nypost.com/2021/02/06/these -black -lives-didnt -seem -to-matter -in-2020/   \nArora. R. (2021c, February 27). Police brutality against black people happens way less than \npublic thinks. New York Post . https://nypost.com/2021/02/27/cases -of-police -brutality -\nagainst -black -people -are-overestimated/   \nDe Blasio privileges Black Lives Matter protests \u2014In blatant defiance of the law . (2020, July \n10). New York Post. Retrieved June 11, 2022, from https://nypost.com/2020/07/10/de -\nblasio -privileges -black -lives -matter -protests -in-defiance -of-the-law/  \nDevine, M. (2020a, June 7). Oh, grow u p, Mayor Frey: Devine. New York Post . \nhttps://nypost.com/2020/06/07/oh -grow -up-mayor -frey-devine/   \nDevine, M. (2020b, August 26). Craven Democrats invite violence: Devine. New York  Post. \nhttps://nypost.com/2020/08/26/craven -democrats -invite -violence -devine/   \nDevine, M. (2020c, June 3). Lefty pols have put cops everywhere in peril: Devine. New York  \nPost. https://nypost.com/2020/06/03/lefty -pols-have -put-cops-everywhere -in-peril-devine/   \nDevine, M. (2020d, June 10). A \u2018Black Lives\u2019 pander by Democrats: Devine. New York Post . \nhttps://nypost.com/2020/06/10/a -black -lives -pander -by-democrats -devine/   \nDevine, M. (2021a, April 14). Why would anyone want to be a cop with the  way they\u2019re \nbeing treated: Devine. New York Post . https://nypost.com/2021/04/14/the -truth -about -\nracism -cops-devine/   \nDevine, M. (2021b, April 21). Vile response to the Derek  Chauvin verdict: Devine. New York \nPost. https://nypost.com/2021/04/21/vile -response -to-the-verdict -devine/   \n33 \n \nDoctors\u2019 James Bond moment and other commentary . (2020, June 9). New York Post. \nRetrieved June 11, 2022, from https://nypost.com/2020/06/09/doctors -james -bond -\nmoment -and-other -commentary/   \nGoodwin, M. (2020, A ugust 22). Trump ought to exploit Biden\u2019s hesitation to slam violence \nfrom radical left: Goodwin. New York Post . https://nypost.com/ 2020/08/22/trump -should -\nexploit -bidens -hesitation -to-slam -radical -left-violence -goodwin/   \nHarsanyi, D. (2020, June 12). No, I don\u2019t have to kneel to show I\u2019m anti -racist. New York \nPost. https://nypost.com/2020/06/12/no -i-dont-have -to-kneel -to-show -im-anti-racist/   \nLeibovitz, L. (2021, May 21). BLM\u2019s aggressive tactics and rhetoric have led to attac ks on \nJews. New York Post . https://nypost.com/2021/05/21/blms -aggressive -tactics -and-rhetoric -\nhave -led-to-attacks -on-jews/   \nLiberal amnesia abou t last summer\u2019s riots . (2021, January 7). New York Post. Retrieved June \n11, 2022, from https://nypost.com/2021/01/07/liberal -amnesia -about -last-summers -riots/   \nLove, C.  (2020, June 28). What \u2018woke\u2019 whites get wrong about blacks\u2019 priorities. New York \nPost. https://nypost.com/2020/06/28/what -woke -whites -get-wrong -about -blacks -priorities/   \nLowry, R. (2020a, August 24). Democrats are pretending the cities aren\u2019t burning. New York \nPost. https://nypost.com/2020/08/24/democrats -are-prete nding -the-cities -arent -burning/   \nLowry, R. (2020b, August 31). Sorry, Democrats: Trump\u2019s not to blame for violent urban \nunrest \u2014 your mayors are. New York Post . https://nypost.com/2020/08/31/sorry -\ndemocrats -trumps -not-to-blame -for-violent -urban -unrest -your-mayors -are/  \nLowry, R. (2020c, June 15). If it\u2019s OK to protest, how can you ban funerals? New York Post . \nhttps://nypost.com/2020/06/15/if -its-ok-to-protest -how-can-you-ban-funerals/   \nLowry, R. (2020d, November 16). Pushing \u2018defund the police,\u2019 BLM turned its success into \nelectoral disaster. New York Post . https://nypost.com/2020/11/16/pushing -defund -the-\npolice -blm-turned -its-success -into-disaster/   \nMac Donald, H.  (2020a, July 3). The f irst Black Lives Matter wave led to 2K extra black \nhomicides \u2014But new wave will be worse. New York Post . \nhttps://nypost.com/2020/07/03/new -black -lives -matter -wave -will-lead-to-more -black -\nhomicides -than-first/   \nMac Donald, H. (2020b, August 3). YouTube censored my talk on policing. New York Post . \nhttps://nypost.com/2020/08/03/youtube -censored -my-talk-on-policing/   \nMcCaughey, B. (2021, April 23). Dems\u2019 domestic -terror bills set their sights on peaceful \nright -wingers. New York Post . https://nypost.com/2021/04/23/dems -domestic -terror -bills-\nset-their-sights -on-peaceful -right -wingers/   \n34 \n \nRichmond, D., Jr. (2020, November 14). Why many black youths like me support both BLM  \nand the police. New York Post . https://nypost.com/2020/11/14/why -many -black -youths -\nlike-me-support -both-blm-and-the-police/   \nTobin, J. S. (2020, J uly 27). The total \u2018woke\u2019 conquest of the pro -sports world. New York \nPost. https://nypost.com/2020/07/27/the -total-woke -conquest -of-the-pro-sports -world/   \nWall S treet Journal  \nAli, A. H. (2020, June 26). Opinion | America Doesn\u2019t Need a New Revolution. Wall Street \nJournal . https://www.wsj.com/articles/america -doesnt -need -a-new-revolution -\n11593201840   \nHenninger, D. (2020, June 3). Opinion | America\u2019s New Nihilism. Wall Street Journal . \nhttps://www.wsj.com/articles/americas -new-nihilism -11591225713   \nLatzer, B. (2020, June 4). Opinion | Don\u2019t Call Rioters \u2018Protesters\u2019. Wall Street Journal . \nhttps://www.wsj.com/articles/dont -call-rioters -protesters -11591293310   \nMcGurn,  W. (2020a, June 22). Opinion | Who Wants to Be a Cop? Wall Street Journal . \nhttps://www.wsj.com/articles/who -wants -to-be-a-cop-11592865635   \nMcGurn, W. (2020b, June 8). Opinion | The Mayhem Is the Message. Wall Street Journal . \nhttps://www.wsj.com/articles/the -mayhem -is-the-message -11591657260   \nNoonan, P. (2021, A pril 22). Opinion | A Measure of Justice in the Chauvin Trial. Wall Street \nJournal . https://www.wsj.com/articles/a -measure -of-justice -in-the-chauvin -trial-\n11619131565   \nOpinion | Defund the Police?  (2020, June 16). Wall Street Journal. Retrieved June 11, 2022, \nfrom https://www.wsj.com/articles/defund -the-police -11592348002   \nOpinion | Rac ism, Riots and #BLM . (2020, June 9). Wall Street Journal. Retrieved June 11, \n2022, from https://www.wsj.com/articles/racism -riots-and-blm-11591744661   \nRiley, J. L. (2020, October 13). Opinion | Will Amazon Suppress the True Michael Brown \nStory? Wall Street Journal . https://www.wsj.com/articles/will -amazon -suppress -the-true-\nmichael -brown -story -11602628176   \n \n \n \n \n \n35 \n \nSecon dary sources  \n4. Race, immigration and discrimination . (2017, October 5). Pew Research Center. Retrieved \nJune 5, 2022, from https://www.pewresearch.org/politics/2017/10/05/4 -race-immigration -\nand-discrimination/   \nAmerican Civil Liberties Union. (2020). Racial Disparities in Stops  by the D.C. Metropolitan \nPolice Department . \nhttps://www.acludc.org/sites/default/files/2020_06_15_aclu_stops_report_final.pdf   \nBanks, C. (2018). Disciplining  Black activism: Post -racial rhetoric, public memory and \ndecorum in news media framing of the Black Lives Matter movement. Continuum, 32 (6), \n709\u2013720. https://doi.org/10.1080/10304312.2018.152592 0  \nBeckett, K., & Evans, H. (2014). The Role of Race in Washington State Capital Sentencing, \n1981 -2014. Death Penalty Information Center. \nhttps://files.deathpenaltyin fo.org/legacy/documents/WashRaceStudy2014.pdf   \nBennett -Swanson, M. (2017). Media Coverage of Black Lives Matter. Critique 33 (n.d.), 98 -\n130.   \nBonilla -Silva, E. (2013). The central frames of color -blind racism. In Racism without racist  \n(pp. 73 -99). Rowman &  Littlefield.  \nBraveman, P. A., Arkin, E., Proctor, D., Kauh, T., & Holm, N. (2022). Systemic And \nStructural Racism: Definitions, Examples, Health Damages, And Approaches To \nDismantling. Health Affairs, 41 (2), 171 \u2013178. https://doi.org/10.1377/hlthaff.2021.01394   \nBryman, A. (2016). Social research methods . Oxford University Press.  \nCharles Murray . (n.d.). Southern Poverty Law Center. Retrieved June 5, 2022, from \nhttps://www.splcenter.org/fighting -hate/extremist -files/individual/charles -murray   \nChase, G. (2018). The Early History of the Black Lives Matter Movement, and t he \nImplications Thereof. Nevada Law Journal 18 (3), 1091 -1112. \nhttps://scholars.law.unlv.edu/nlj/vol18/iss3/11   \nEllis, B. R., & Branch -Ellis, N. (2020). Living in an Age of Colorblind Racism an d Police \nImpunity: An Analysis of Some High -Profile Police Killings. Phylon 57 (2), 105 \u2013125. \nhttps://www.jstor.org/stable/26990925   \nElmasry, M. H., & el -Nawawy, M. (2017). Do Black Lives Matter? Journali sm Practice, \n11(7), 857 \u2013875. https://doi.org/10.1080/17512786.2016.1208058   \nHarvard University. (2022, March 20). Index of US Mainstream Media Ownership . \nhttps://projects.iq.harvard.edu/futureofmedia/index -us-mainstream -media -ownership   \n36 \n \nHeaney, M. T. (2020). Protest at the Center of American Politics. Journal of International \nAffairs, 73 (2), 195 \u2013208. \nJones, A., & Sawyer, W. (2020, June 5). Not just \u201ca few bad apples\u201d: U.S. police kill \ncivilians at much higher rates than other countries . Prison Policy Initiative. \nhttps://www.p risonpolicy.org/blog/2020/06/05/policekillings/   \nJustice Policy Institute. (2007). The Vortex: The Concentrated Racial Impact of Drug \nImprisonment and the Characteristics of Punitive Counties . \nhttps://justicepolicy.org/research/the -vortex -the-concentrated -racial -impact -of-drug-\nimprisonment -and-the-characteristics -of-punitive -counties/   \nKilgo, D., & M our\u00e3o, R. R. (2019). Media Effects and Marginalized Ideas: Relationships \nAmong Media Consumption and Support for Black Lives Matter. International Journal of \nCommunication, 13 (n.d.), 4287 \u20134305. \nhttps://ijoc.org/index.php/ijoc/article/view/10518/2782   \nKilgo, D., Mour\u00e3o, R. R., & Sylvie, G. (2019). Martin to Brown. Journalism Practice, 13 (4), \n413\u2013430. https://doi.org/10.1080/17512786.2018.1507680   \nLeopold, J., & Bell, M. P. (2017). News media and the racialization of protest: An analysis of \nBlack Lives Matter articles. Equality, Diversity and Inclusion: An International Journal, \n36(8), 720 \u2013735. https://doi.org/10.1108/EDI -01-2017 -0010   \nMedia Bias Fact Check. (2021, December 1). New York Post . \nhttps://mediabiasfactcheck.com/new -york-post/   \nMedia Bias Fact Check. (2022a, April 19). New York Times . \nhttps://mediabiasfactcheck.com/new -york-times/   \nMedia Bias Fact Check. (2022b, March 23). Washington Post . \nhttps://mediabiasfactcheck.com/washington -post/   \nMedia Bias Fact Check. (2022c, March 23). Wall Street Journal . \nhttps://mediabiasfactcheck.com/wall -street-journal/   \nMiller, C. (2022, June 1). SPLC Poll Finds Substantial Support for \u2018Great Replacement\u2019 \nTheory and Other Hard -Right Ideas . Southern Poverty Law Center. \nhttps://www.splcenter.org/news/2022/06/01/poll -finds -support -great -replacement -hard-\nright -ideas   \nMour\u00e3o, R. R., Kilgo, D. K., & Sylvie, G. (2021). Framing Ferguson: The interplay of \nadvocacy and journalistic frames in local and nation al newspaper coverage of Michael \nBrown. Journalism, 22 (2), 320 \u2013340. https://doi.org/10.1177/1464884918778722   \n37 \n \nPalmer, M. (2021). Black Lives Matter in the National Media: Disparities in Coverage \nBetw een Legacy Newsrooms and Digital -First Outlets. Minnesota Undergraduate \nResearch & Academic Journal, 4 (4), 1 -33. \nhttps://pubs.lib.umn.edu/index.php/muraj/article/view/3635   \nPierson, E., Simoiu, C., Overgoor, J., Corbett -Davies, S., Jenson, D., Shoemaker, A., \nRamachandran, V., Barghouty, P., Phillips, C., Shroff, R., & Goel, S. (2020). A large -scale \nanalysis of racial disparities in police stops across the United States. Natur e Human \nBehaviour, 4 (7), 736 \u2013745. https://doi.org/10.1038/s41562 -020-0858 -1  \nRehavi, M. M., & Starr, S. B. (2014). Racial Disparity in Federal Criminal Sentences. Journal \nof Political Economy, 122 (6), 1320 \u20131354. https://doi.org/10.1086/677255   \nReny, T. T., & Newman, B. J. (2021). The Opinion -Mobilizing Effect of Social Protest \nagainst Police Violence: Evidence from the 2020 George Floyd Protests. Ameri can \nPolitical Science Review, 115 (4), 1499 \u20131507. https://doi.org/10.1017/S0003055421000460   \nUnited States Department of Justice Civil Rights Division. (2015). Investigation of the \nFerguson Police De partment . https://www.justice.gov/sites/default/files/opa/press -\nreleases/attachments/2015/03/04/ferguson_police_de partment_report_1.pdf   \nUnited States Sentencing Commission. (2017). Demographic Differences in Sentencing . \nhttps://www.ussc.gov/research/research -reports/demo graphic -differences -sentencing   \n \n \n \n \n \n \n \n \n \n \n \n \n38 \n \nAppendices  \nAppendix A  \nFrequency of BLM Coverage in Newsrooms  \n \nSource: Palmer, 2021.  \nAppendix B  \nGeorge Floyd Media Coverage, Social Media Posts, and Search Behavior  \n \nSource: Reny, 2021.  \n \n\n39 \n \nAppendix C  \nA Colorblind Racism Theoretical Schemata of Police use of Deadly Force  \n \nSource: Ellis and Branch -Ellis, 2020.  \nAppendix D \nInitial Codebook  for the First Reading of t he Data \n\uf0b7 Author:  \no Political orientation  \no Occupation  \no Relation with BLM  \no Other  \n\uf0b7 General language:  \no Pro-BLM (positive)  \no Anti-BLM (negative)  \no \u201cNeutral\u201d or centrist  \n\uf0b7 Negative protest framing:  \no Violence by protestors  \no Crime by protestors  \no Property destruction by protestors  \no Other  \n\uf0b7 Positive protest framing:  \no Aims of BLM  \no Causes of BLM  \no Violence by  police  \no Other  \n\uf0b7 Racial framing:  \no Implicit racial framing  \n\n40 \n \n\uf0a7 Abstract liberalism  \n\uf0a7 Naturalization  \n\uf0a7 Cultural racism  \n\uf0a7 Minimization  of racism  \n\uf0a7 Other  \no Explicit racial framing  \n\uf0b7 Intersectionality:  \no Discussion of women\u2019s issues  \no Discussion of queer issues  \no Discussion of economic issues  \no Other  \n\uf0b7 Voices:  \no Voices of pro -BLM protestors  \no Voices of officials  \no Other  \nAppendix E  \nNew Codes Created During the Reading of the Data \n- Voices of intellectuals  \n- Voices of anti -BLM protestors  \n- Need more working together  \n- Experiences of racism  \n- Denial of racism  \n- Changes  \n- Non-violent change  \n- Racial grammar  \n- Pro-police  \n- Voting as solution to racism  \n- Democrats are pro -violence/ Antifa \n- Democratic/left hypocrisy  \n- Exaggeration  \n- Distraction of the actual problem  \n- Bad comparison  \n- Proposed solutions  \n- Anti-SJW  langua ge \n- Misunderstanding/ wrong/ lies \n- Language use  \n- Id-pol \n- Whitewashing  \nAppendix F  \nCodebook  for the Second Reading of the  Data Based on the Initial Codebook and new Codes  \n\uf0b7 General language:  \no Pro-BLM (positive)  \n41 \n \no Anti-BLM (negative)  \no \u201cNeutral\u201d or centrist  \n\uf0b7 Negative protest framing:  \no Violence and crime by protestors  \no Pro-police  \no Other  \n\uf0b7 Positive protest framing:  \no Aims of BLM  \no Causes of BLM  \no Violence by police  \no Other  \n\uf0b7 Racial framing/language:  \no Implicit racial framing  \n\uf0a7 Abstract liberalism  \n\uf0a7 Naturalization  \n\uf0a7 Cultural raci sm  \n\uf0a7 Minimization  of racism  \no Racial grammar  \no Experiences of racism  \no Denial of racism  \no Anti-SJW  language  \no Language use  \n\uf0b7 Intersectionality:  \no Discussion of women\u2019s issues  \no Discussion of queer issues  \no Discussion of economic issues  \n\uf0b7 Voices:  \no Voices of pro -BLM protestors  \no Voices of anti -BLM protestors  \no Voices of officials  \no Voices of intellectuals  \no Other  \n\uf0b7 Change:  \no Changes  \no Non-violent change  \no Proposed solutions  \n\uf0b7 Other:  \no Democratic/left hypocrisy  \no Exaggeration  \no Distraction of the actual problem  \no Bad comparison  \no Misunderstandi ng/wrong/lies  \no Id-pol  \n \n \n42 \n \nAppendix G  \nA Full Summary of the Results  \n \n", "raw_data": {"container_type": "Publication", "source": "PUBLICATION_SEARCH_SNIPPET", "bib": {"title": "Black Lives Matter in the Media", "author": ["O Baars"], "pub_year": "2022", "venue": "NA", "abstract": "The majority of the literature on the newspaper coverage of BLM protests concludes that the  overall coverage was quite negative between 2013 and 2020. This study fills in a"}, "filled": false, "gsrank": 349, "pub_url": "https://thesis.eur.nl/pub/70864/eobs_59093.pdf", "author_id": [""], "url_scholarbib": "/scholar?hl=en&q=info:BFgcKkww7y8J:scholar.google.com/&output=cite&scirp=348&hl=en", "url_add_sclib": "/citations?hl=en&xsrf=&continue=/scholar%3Fq%3D%2522mediabiasfactcheck.com%26hl%3Den%26start%3D340%26as_sdt%3D0,10&citilm=1&update_op=library_add&info=BFgcKkww7y8J&ei=QrWsaI2aB7_SieoPzJnloAQ&json=", "num_citations": 0, "url_related_articles": "/scholar?q=related:BFgcKkww7y8J:scholar.google.com/&scioq=%22mediabiasfactcheck.com&hl=en&as_sdt=0,10", "eprint_url": "https://thesis.eur.nl/pub/70864/eobs_59093.pdf"}}]