[{"id": "http://arxiv.org/abs/2306.08871v1", "title": "Med-MMHL: A Multi-Modal Dataset for Detecting Human- and LLM-Generated\n  Misinformation in the Medical Domain", "contents": "\n\n\n\nMed-MMHL: A Multi-Modal Dataset for Detecting Human- and LLM-Generated Misinformation in the Medical Domain\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMed-MMHL: A Multi-Modal Dataset for Detecting Human- and LLM-Generated Misinformation in the Medical Domain\n\n\nYanshen Sun\n\nyansh93@vt.edu\n\nVirginia TechFalls ChurchVAUSA22043\n\n,\u00a0\nJianfeng He\n\njianfenghe@vt.edu\n\nVirginia TechFalls ChurchVAUSA22043\n\n,\u00a0\nLimeng Cui\n\nculimeng@amazon.com\n\nAmazonPalo AltoCAUSA95054\n\n,\u00a0\nShuo Lei\n\nslei@vt.edu\n\nVirginia TechFalls ChurchVAUSA22043\n\n\u00a0and\u00a0\nChang-Tien Lu\n\nctlu@vt.edu\n\nVirginia TechFalls ChurchVAUSA22043\n\n\n(2018)\n\nAbstract.\nThe pervasive influence of misinformation has far-reaching and detrimental effects on both individuals and society. The COVID-19 pandemic has witnessed an alarming surge in the dissemination of medical misinformation. However, existing datasets pertaining to misinformation predominantly focus on textual information, neglecting the inclusion of visual elements, and tend to center solely on COVID-19-related misinformation, overlooking misinformation surrounding other diseases. Furthermore, the potential of Large Language Models (LLMs), such as the ChatGPT developed in late 2022, in generating misinformation has been overlooked in previous works. To overcome these limitations, we present Med-MMHL, a novel multi-modal misinformation detection dataset in a general medical domain encompassing multiple diseases. Med-MMHL not only incorporates human-generated misinformation but also includes misinformation generated by LLMs like ChatGPT. Our dataset aims to facilitate comprehensive research and development of methodologies for detecting misinformation across diverse diseases and various scenarios, including human and LLM-generated misinformation detection at the sentence, document, and multi-modal levels. To access our dataset and code, visit our GitHub repository: https://github.com/styxsys0927/Med-MMHL.\n\nMedical misinformation,\nnews,\ntweets,\nLLM,\nmultimodal,\ndataset\n\n\u2020\u2020copyright: acmcopyright\u2020\u2020journalyear: 2018\u2020\u2020doi: 10.1145/3539618.XXXXXX\u2020\u2020conference: Make sure to enter the correct\nconference title from your rights confirmation emai; June 03\u201305,\n2018; Woodstock, NY\u2020\u2020booktitle: Woodstock \u201918: ACM Symposium on Neural Gaze Detection,\nJune 03\u201305, 2018, Woodstock, NY\u2020\u2020price: 15.00\u2020\u2020isbn: 978-1-4503-XXXX-X/18/06\u2020\u2020ccs: Information systems\u00a0Multimedia databases\n\n\n1. Introduction\n\nMisinformation, defined as wrong information compared to the original and verified data, has been proven to have a significantly negative impact on both society and individuals, as supported by recent surveys\u00a0(Zhou and Zafarani, 2020; Zubiaga et\u00a0al., 2018; Bondielli and Marcelloni, 2019; Guo et\u00a0al., 2020). Within the scope of misinformation, the medical domain is particularly crucial, as misinformation in this domain, including COVID-19, directly influences individual treatments and national policies. For instance, misinformation suggesting that drinking bleach protects against COVID-19\u00a0(Organization, 2022) has misguided individuals into using harmful substances\u00a0(Barron, 2022). Similarly, misinformation asserting that vaccines against SARS-CoV-2 cause infertility\u00a0(Abbasi, 2022) has impeded the swift implementation of vaccine policies\u00a0(Barron, 2022). Given the significant negative impact of medical misinformation on individuals and society, it is essential to research in medical misinformation detection\u00a0(Escol\u00e0-Gasc\u00f3n et\u00a0al., 2021; Capuano et\u00a0al., 2023; Wani et\u00a0al., 2021; Pranto et\u00a0al., 2022). To facilitate such research, we create a novel medical misinformation detection dataset by overcoming three limitations of previous datasets.\n\n\n\n\n\n\nFigure 1. An example that ChatGPT can generate misinformation given a text from the medical domain.\n\n\nTable 1. Comparison between our Med-MMHL dataset and the other datasets.\n\n\n\n\nMulti-Disease/General Medical\n\n\nMulti-Modal\n\n\nLLM-fake\n\n\nNews\n\n\nSocial Media\n\n\nDate Start\n\n\nDate End\n\n\n\n\nMedHelp\u00a0(Kinsora et\u00a0al., 2017)\n\n\u2713\u2713\\checkmark\u2713\n\u00d7\\times\u00d7\n\u00d7\\times\u00d7\n\u00d7\\times\u00d7\n\u2713\u2713\\checkmark\u2713\n2001\n2013\n\n\n\nCOAID\u00a0(Cui and Lee, 2020)\n\n\u00d7\\times\u00d7\n\u00d7\\times\u00d7\n\u00d7\\times\u00d7\n\u2713\u2713\\checkmark\u2713\n\u2713\u2713\\checkmark\u2713\n2019-Dec\n2020-Sep\n\n\n\nMM-COVID\u00a0(Li et\u00a0al., 2020)\n\n\u00d7\\times\u00d7\n\u2713\u2713\\checkmark\u2713\n\u00d7\\times\u00d7\n\u2713\u2713\\checkmark\u2713\n\u2713\u2713\\checkmark\u2713\n2020-Feb\n2020-Jul\n\n\n\nCHECKED\u00a0(Yang et\u00a0al., 2021)\n\n\u00d7\\times\u00d7\n\u2713\u2713\\checkmark\u2713\n\u00d7\\times\u00d7\n\u00d7\\times\u00d7\n\u2713\u2713\\checkmark\u2713\n2019-Dec\n2020-Aug\n\n\n\nTruthSeeker\u00a0(Dadkhah et\u00a0al., 2023)\n\n\u2713\u2713\\checkmark\u2713\n\u00d7\\times\u00d7\n\u00d7\\times\u00d7\n\u00d7\\times\u00d7\n\u2713\u2713\\checkmark\u2713\n2009\n2022\n\n\n\nANTi-Vax\u00a0(Hayawi et\u00a0al., 2022)\n\n\u00d7\\times\u00d7\n\u00d7\\times\u00d7\n\u00d7\\times\u00d7\n\u00d7\\times\u00d7\n\u2713\u2713\\checkmark\u2713\n2020-Dec\n2021-Jul\n\n\n\nCOVID-Rumor\u00a0(Cheng et\u00a0al., 2021)\n\n\u00d7\\times\u00d7\n\u00d7\\times\u00d7\n\u00d7\\times\u00d7\n\u2713\u2713\\checkmark\u2713\n\u2713\u2713\\checkmark\u2713\n2020-Jan\n2020-Dec\n\n\n\nReCOVery\u00a0(Zhou et\u00a0al., 2020)\n\n\u00d7\\times\u00d7\n\u2713\u2713\\checkmark\u2713\n\u00d7\\times\u00d7\n\u2713\u2713\\checkmark\u2713\n\u2713\u2713\\checkmark\u2713\n2020-Jan\n2020-May\n\n\n\nMonant\u00a0(Srba et\u00a0al., 2022)\n\n\u2713\u2713\\checkmark\u2713\n\u2713\u2713\\checkmark\u2713\n\u00d7\\times\u00d7\n\u2713\u2713\\checkmark\u2713\n\u2713\u2713\\checkmark\u2713\n1998-Jan\n2022-Feb\n\n\nMed-MMHL(Ours)\n\u2713\u2713\\checkmark\u2713\n\u2713\u2713\\checkmark\u2713\n\u2713\u2713\\checkmark\u2713\n\u2713\u2713\\checkmark\u2713\n\u2713\u2713\\checkmark\u2713\n2017-Jan\n2023-May\n\n\n\n\nPrevious datasets pertaining to medical misinformation exhibit three notable limitations. Firstly, many of these datasets focus solely on textual information, such as news or tweets\u00a0(Kinsora et\u00a0al., 2017; Cui and Lee, 2020; Dadkhah et\u00a0al., 2023; Hayawi et\u00a0al., 2022; Cheng et\u00a0al., 2021). However, they omit additional visual information beyond text, which can enhance task performance\u00a0(Li et\u00a0al., 2020; Ragkhitwetsagul et\u00a0al., 2018). Secondly, a majority of the previous datasets concentrate exclusively on COVID-19 misinformation, disregarding misinformation surrounding other diseases\u00a0(Cui and Lee, 2020; Li et\u00a0al., 2020; Yang et\u00a0al., 2021; Hayawi et\u00a0al., 2022; Cheng et\u00a0al., 2021; Zhou et\u00a0al., 2020). Considering the distinct symptoms and treatments associated with different diseases, it is important to detect medical misinformation with generalization, as what applies to COVID-19 may not be applicable to other medical conditions. Furthermore, the majority of previous datasets solely focus on human-generated misinformation, neglecting the emergence of LLMs like ChatGPT\u00a0(Ouyang et\u00a0al., 2022) as generators of misinformation. However, since the release of ChatGPT in Nov. 2022, it has demonstrated remarkable text generation capabilities across various domains\u00a0(Biswas, 2023; Firat, 2023; Surameery and Shakor, 2023; McGee, 2023). Notably, our findings indicate that ChatGPT can generate medical misinformation, as depicted in Figure\u00a01.\nConsidering the potential of LLMs like ChatGPT to generate misinformation\u2014evidenced by their capability to fabricate material for legal domain\u00a0(Times, 2023) and produce artificially constructed peer reviews\u00a0(Donker, 2023)\u2014it becomes imperative to ensure that any comprehensive dataset includes instances of such LLM-generated misinformation.\nThe limitations of previous medical misinformation datasets are summarized in Tab.\u00a01.\n\n\nTo address these limitations, we have developed a comprehensive multi-modal dataset named Med-MMHL, specifically designed for the detection of human- and LLM-generated misinformation in the medical domain. Our contributions are outlined below:\n\nWe created Med-MMHL by crawling both the text and relevant images from news and tweets. The inclusion of multi-modalities (text and images) in Med-MMHL facilitates research on utilizing visual features for misinformation detection.\n\nMed-MMHL comprises misinformation pertaining to 15 diseases, expanding beyond just COVID-19. This diverse misinformation across multiple diseases facilitates research about improving the generalization of medical misinformation detection solutions.\n\nTo the best of our knowledge, we are the first to incorporate LLM-generated misinformation in the medical domain. Med-MMHL includes LLM-generated fake news by ChatGPT. By incorporating both human- and LLM-generated misinformation sources, our dataset facilitates research in distinguishing misinformation across a broader range of scenarios.\n\nExtensive baseline experiments and data analysis are conducted on Med-MMHL. Specifically, We build a misinformation detection benchmark on sentence, document, and multi-modal levels. Plus, we thoroughly analyzed the data characteristics at both the text level and semantic level.\n\n\n\n\n2. Data Crawl\n\nWe collected news (including claims, summaries of news, and fact-check articles), tweets, and corresponding images from the medical domain. This specific time range was chosen to observe the trajectory of Covid-19 in relation to other significant diseases. We first introduce the news source, followed by the news and tweet crawl processes.\n\nTrusted real and fake news sources. To ensure the reliability of our trusted real news sources, we chose medical news articles that had been vetted by domain experts. Consequently, for the news source, our real news sources consist of news articles from authoritative medical authority websites; the fake news source comprises fake news articles archived by the fact-checking websites. For the claims respected to news, both the fake and real claims are extracted from the fact-check articles. Specifically, for authoritative medical authority websites such as \u201dClevelandClinic\u201d\u00a0(ClevelandClinic, 2023), \u201dNIH\u201d\u00a0(NIH, 2023), \u201dWebMD\u201d\u00a0(WebMD, 2023), \u201dMayo\u201d\u00a0(Mayo, 2023), \u201dHealthline\u201d\u00a0(Healthline, 2023), and \u201dScienceDaily\u201d\u00a0(ScienceDaily, 2023), we utilized all of their news articles as real news. As for the fact-checking websites, which include \u201dAFPFactCheck\u201d\u00a0(AFPFactCheck, 2023), \u201dCheckYourFact\u201d\u00a0(CheckYourFact, 2023), \u201dFactCheck\u201d\u00a0(FactCheck, 2023), \u201dHealthFeedback\u201d\u00a0(HealthFeedback, 2023), \u201dLeadStories\u201d\u00a0(LeadStories, 2023), and \u201dPolitiFact\u201d\u00a0(PolitiFact, 2023), we extracted three main text components: a link to the archived fake news article being verified, a claim summarizing the fake news\u2019s opinion, and a claim concluding the evidence that elucidates the deficiencies in the quoted fake news article. Therefore, we gathered the fake news articles archived in the fact-checking websites as fake news. Besides, we collected the summaries of the evidence as real claims and the summaries of fake news opinions as fake claims. We collected both news articles and their applicable claims (short summaries) to account for the variation in text lengths, thereby enhancing the diversity of our dataset.\n\n\n\n\n\n\nFigure 2. The data collection process. The numbers in the red circles indicate the three steps of data collection.\n\n\n\nStep 1: Content extraction. In this step, we acquired all the articles from the aforementioned websites, encompassing the text contents, images, and links, spanning from Jan-01-2017 to May-01-2023.\nThe real news articles can be obtained directly from the news released by the authorities.\nTo ensure the dataset\u2019s scalability to disease classification tasks, we collected real news containing only one disease label out of a disease list.\nWe specifically extracted disease labels that had more than fifty real news articles.\nAs for claims, in fact-checking articles, fact-checkers typically provide a one-sentence summary of the fake news\u2019 opinion, along with their own comments (usually presenting an opposing opinion of the fake news) as illustrated in Fig.\u00a02.\nIn this case, the summaries of news articles identified as \u201dincorrect,\u201d \u201dinaccurate,\u201d \u201dmisinformation,\u201d and similar terms by the fact-checkers were labeled as \u201dfake claims,\u201d while the corresponding corrections provided by the fact-check articles are considered \u201dreal claims.\u201d\n\nStep 2: Acquisition of human- and LLM-generated fake news. To assess the effectiveness of fake news detection models against fake content generated by both humans and LLMs, we developed strategies to acquire these two types of fake news.\nThe fake news articles extracted from Step 1 are human-generated and thus called \u201dhuman-generated fake news.\u201d Additionally, we devised a strategy to simulate adversarial attacks using chatGPT3.5\u00a0(AI, 2023) on real news articles. Each real news article had a 50%percent5050\\%50 % probability of being modified by chatGPT3.5. If chosen for modification, each sentence within the article had a random 10%percent1010\\%10 %\u201350%percent5050\\%50 % chance of being altered by providing the prompt \u201dWhat is the opposite opinion of \u00a1the sentence\u00bf.\u201d These modified sentences were labeled as \u201dfake sentences.\u201d Following sentence modification, the attacked article was further refined using the prompt \u201dRefine the language of \u00a1the article\u00bf.\u201d The resulting generated articles were then cleaned up by removing redundant terms such as \u201dthe refined version is\u201d or \u201drefinement:\u201d before being labeled as \u201dLLM fake news.\u201d\n\nStep 3: Real and fake tweet Crawl. We crawled tweets spanning from Jan-01-2022 to May-01-2023. This time range was chosen to comply with the size limitation specified in the Tweet Developer Agreement\u00a0(Agreement, 2023), as collecting tweets from the past six years would exceed the allowed size. Additionally, this range does not overlap with the time periods covered by the previous datasets in Tab. 1. Our method of tweet crawling is intrinsically tied to the corresponding news articles that we\u2019ve crawled. Specifically, we employed the titles of these news articles as key phrases to retrieve related tweets. If the news title is for real news, we categorize the resulting tweets as real. Conversely, if the news title is for fake news, the collected tweets are classified as fake. Owing to the Twitter Developer Agreement\u00a0(Agreement, 2023), we might not manipulate tweets by LLMs and could only release the tweet IDs, along with a code that enables users to retrieve the full content of the tweets by these IDs.\n\n\n\n\n3. Benchmark Tasks & Statistics\n\n\n\n\n(a) True News.\n\n\n\n\n(b) Human-generated Fake News.\n\n\n\n\n(c) LLM-generated Fake News.\n\n\n\nFigure 3. Word Cloud of the date in Med-MMHL.\n\n\nTable 2. Statistics of benchmark tasks on Med-MMHL, where \u201cfake news\u201d is human-generated fake news, \u201csent\u201d is an abbreviation of \u201csentence\u201d.\nSince a text might have more than one image, the \u201c#Image\u201d can be larger than \u201cw/image\u201d.\n\n\nTasks\nData Type\nCount\nW/ Image\n# Image\n\n\n \n\n\nFake news\n\ndetection\n \nReal news\n3,455\n/\n/\n\n\nFake news\n469\n/\n/\n\n\nLLM fake news\n2,095\n/\n/\n\n\nReal claim\n2,283\n/\n/\n\n\nFake claim\n3,567\n/\n/\n\n\n \n\n\nLLM-generated fake\n\nsent detection\n \nReal sent\n41,365\n/\n/\n\n\nLLM fake sent\n17,608\n/\n/\n\n\n \n\n\nMultimodal\n\nfake news\n\ndetection\n \nReal news\n4,554\n1,338\n1,747\n\n\nFake news\n469\n396\n5,496\n\n\nReal claim\n643\n641\n749\n\n\nFake claim\n1,135\n1,102\n1,102\n\n\n\n\n\nFake tweet\n\ndetection\n \nReal tweet\n7,738\n/\n/\n\n\nFake tweet\n6,927\n/\n/\n\n\n \n\n\nMultimodal tweet\n\ndetection\n \nReal tweet\n7,738\n1,334\n1,385\n\n\nFake tweet\n6,927\n639\n763\n\n\n\n\nWe propose and benchmark five different tasks that cover a range of challenges, each involving one or more of four types of inputs: long articles, claims(short articles, as described in Sec.\u00a02), tweets, and multimodal data. The statistics for each task are summarized in Tab. 2 and each task is detailed below.\n\n\nFake news detection task specifically concentrates on text-only tasks, encompassing both articles and claims. Images are excluded from this task due to the lack of specific image associations with the text generated by the LLM. Notably, the real news articles used for generating LLM fake news are not included in this task.\n\n\nLLM-generated fake sentence detection task is designed to evaluate the vulnerability to adversarial attacks introduced by LLM. It goals to assess a model\u2019s ability to distinguish between real sentences and LLM-generated fake ones. Therefore, this task excludes human-generated fake sentences.\n\n\nMultimodal fake news detection aims to investigate ways to enhance the detection of misinformation by leveraging multimodal resources. The specific approach employed for claim filtering is elaborated upon in Appendix\u00a0A.3.\n\n\nFake tweet detection and multimodal tweet detection tasks are devised to address the distinctive writing style exhibited in tweets as compared to news articles. In order to fully leverage the available data, all collected tweets are included in both tasks, despite the relatively small number of tweets accompanied by images.\n\n\nOther applicable tasks on Med-MMHL. Though we benchmark the above five tasks, Med-MMHL can also be applied to other tasks, given its data diversity. For example, a misinformation detection model can be trained using real news and human-generated fake news, and subsequently employed to identify LLM-generated fake news. Moreover, though our LLM-generated fake sentence detection task excludes the news context, Med-MMHL supports training a model for a more fine-grained misinformation detection at the sentence level.\n\n\n\n\n4. Misinformation Detection in Medical Domain\n\nTo demonstrate the main utility of the proposed dataset and evaluate the existing fake news detection methods, we conduct comparative experiments on the misinformation detection task.\n\n\n\n4.1. Baseline Methods\n\nWe consider seven text-only baseline models and two multimodal baseline models. Specifically, among the seven text-only models, four incorporate language transformer layers pretrained on long articles, two utilize language transformer layers pretrained on sentences, and one is trained using our own dataset. The multimodal models include state-of-the-art pretrained modules for both texts and images. The details of the baselines can be found in Appendix\u00a0A.4.\n\n\n\n\n4.2. Implementation Detail\n\nThe dataset is split into training, validation, and testing datasets with a ratio of 7:1:2:71:27:1:27 : 1 : 2.\nEach baseline model comprises a pre-trained module for learning hidden representations and a trainable module for fine-tuning the specific downstream task. During training, the parameters of the pre-trained models remain fixed, and they are utilized to extract hidden representations from the texts and images. A trainable two-layer feedforward neural network module maps the hidden representations to the downstream task. The optimizer is Adam, with a learning rate of 1\u2062e\u221251superscript\ud835\udc5251e^{-5}1 italic_e start_POSTSUPERSCRIPT - 5 end_POSTSUPERSCRIPT for all the models. The maximum number of epochs is 100 with a 15-step patience. The dropout rate is 0.1. Due to the limitation of our computation resources, the batch size is 4. We adopt commonly used metrics in related areas: Accuracy, Precision, Recall, F1 and Macro F1.\n\n\n\n\n4.3. Experimental Results\n\nWe conducted fake news detection and fake-news-related tweet detection experiments on the proposed Med-MMHL dataset. The experiment results are provided in Table\u00a03 and Table\u00a04. The metrics used for evaluation include accuracy (Acc), precision (Prc), recall (Rcl), f1-score (F1), and marco f1-score (F1-ma).\nWe observe that\n(i) Pretrained transformer-based methods perform better than simple methods, as they are more powerful in capturing contextual information better. However, as the dataset is quite imbalanced, the models tend to generate many fake positive cases. Thus, the recall value is lower than the accuracy and precision value.\n(ii) FN-BERT performs best on document-level fake news/tweet detections among all baselines. This indicates the importance of related fake news classification knowledge.\n(iii) Although baseline methods show strong performance in detecting fake news, the performance of the LLM sentence detection task is unsatisfactory. It is easier to detect LLM-generated fake news than detect LLM-generated fake sentences, mostly because the generated fake news is entirely opposite in intention to real news, but the generated fake sentences are only partially opposite in intention to real news. Therefore, learning to detect LLM-generated fake sentence detection is an important area for further research.\n\n\nTable 3. Baseline methods performance for fake news detection on Med-MMHL.\n\n\nModel\nAcc\nPrc\nRcl\nF1\nF1-ma\n\n\n\n \n\n\nFake news detection (both human and LLM-generated fake news)\n \n\n\n\ndEFEND\n89.174%\n97.361%\n81.240%\n88.573%\n89.144%\n\n\nBERT\n95.657%\n97.702%\n93.791%\n95.707%\n95.657%\n\n\nBioBERT\n94.941%\n98.084%\n91.993%\n94.941%\n94.941%\n\n\nFunnel\n94.604%\n98.668%\n90.768%\n94.553%\n94.603%\n\n\nFN-BERT\n95.784%\n99.472%\n92.320%\n95.763%\n95.784%\n\n\n\n \n\n\nLLM-generated fake sentence detection\n \n\n\n\ndEFEND\n92.183%\n88.168%\n85.264%\n86.692%\n90.579%\n\n\nSentenceBERT\n96.040%\n96.583%\n89.917%\n93.131%\n95.175%\n\n\nDistilBERT\n95.149%\n95.050%\n88.355%\n91.581%\n94.087%\n\n\n\n \n\n\nMultimodal fake news detection (only human-generated fake news)\n \n\n\n\nCLIP\n96.324%\n86.921%\n99.377%\n92.732%\n95.136%\n\n\nVisualBERT\n96.103%\n89.881%\n94.081%\n91.933%\n94.682%\n\n\n\n\nTable 4. Baseline methods performance for fake-news-related tweet detection on Med-MMHL.\n\n\nModel\nAcc\nPrc\nRcl\nF1\nF1-ma\n\n\n\n \n\n\nFake tweets detection (only human-generated fake news)\n \n\n\n\ndEFEND\n96.897%\n98.868%\n94.517%\n96.643%\n96.880%\n\n\nBERT\n98.056%\n99.552%\n96.318%\n97.908%\n98.046%\n\n\nBioBERT\n97.988%\n99.775%\n95.957%\n97.828%\n97.977%\n\n\nFunnel\n98.158%\n99.701%\n96.390%\n98.018%\n98.149%\n\n\nFN-BERT\n98.602%\n99.339%\n97.690%\n98.507%\n98.596%\n\n\n\n \n\n\nMultimodal fake tweets detection (only human-generated fake news)\n \n\n\n\nCLIP\n97.954%\n99.256%\n96.387%\n97.801%\n97.944%\n\n\nVisualBERT\n96.404%\n99.403%\n92.620%\n95.985%\n96.364%\n\n\n\n\n\n\n\n5. Conclusion\n\nMedical misinformation significantly affects individuals and societies, necessitating effective detection methods. However, existing datasets have limitations: overlooking visual information, focusing solely on COVID-19, or ignoring LLM-generated misinformation. To address these limitations, we introduce Med-MMHL, a multi-modal dataset for detecting misinformation in the broader medical field, incorporating both human and LLM-generated fake data across multiple diseases. Additionally, Med-MMHL extends its diversity by incorporating data from news and tweets. We also comprehensively analyze the dataset\u2019s characteristics at text and sentence levels. Finally, we establish a benchmark for misinformation detection at sentence, document, and multi-modal levels, laying the groundwork for future research in this critical domain.\n\n\n\nReferences\n\n\n(1)\n\n\n\n\nAbbasi (2022)\n\nJennifer Abbasi.\n2022.\n\n\nWidespread Misinformation About Infertility Continues\nto Create COVID-19 Vaccine Hesitancy.\n\n\nhttps://jamanetwork.com/journals/jama/fullarticle/2789477.\n\n\n\n\n\n\nAFPFactCheck (2023)\n\nAFPFactCheck.\n2023.\n\n\nAFPFactCheck.\n\n\nhttps://factcheck.afp.com/.\n\n\n\n\n\n\nAgreement (2023)\n\nTwitter\u00a0Developer Agreement.\n2023.\n\n\nDeveloper Agreement and Policy.\n\n\nhttps://developer.twitter.com/en/developer-terms/agreement-and-policy.\n\n\n\n\n\n\nAI (2021)\n\nOpen AI. 2021.\n\n\nCLIP.\n\n\nhttps://huggingface.co/openai/clip-vit-base-patch32.\n\n\n\n\n\n\nAI (2023)\n\nOpen AI. 2023.\n\n\nChatGPT 3.5.\n\n\nhttps://chat.openai.com/chat.\n\n\n\n\n\n\nBarron (2022)\n\nMadeline Barron.\n2022.\n\n\nHow to Spot and Combat Health Misinformation.\n\n\nhttps://shorturl.at/pMPW1.\n\n\n\n\n\n\nBiswas (2023)\n\nSom\u00a0S Biswas.\n2023.\n\n\nRole of chat gpt in public health.\n\n\nAnnals of Biomedical Engineering\n(2023), 1\u20132.\n\n\n\n\n\n\nBondielli and Marcelloni (2019)\n\nAlessandro Bondielli and\nFrancesco Marcelloni. 2019.\n\n\nA survey on fake news and rumour detection\ntechniques.\n\n\nInformation Sciences 497\n(2019), 38\u201355.\n\n\n\n\n\n\nCapuano et\u00a0al. (2023)\n\nNicola Capuano, Giuseppe\nFenza, Vincenzo Loia, and\nFrancesco\u00a0David Nota. 2023.\n\n\nContent Based Fake News Detection with machine and\ndeep learning: a systematic review.\n\n\nNeurocomputing (2023).\n\n\n\n\n\n\nCheckYourFact (2023)\n\nCheckYourFact.\n2023.\n\n\nCheckYourFact.\n\n\nhttps://checkyourfact.com/.\n\n\n\n\n\n\nCheng et\u00a0al. (2021)\n\nMingxi Cheng, Songli\nWang, Xiaofeng Yan, Tianqi Yang,\nWenshuo Wang, Zehao Huang,\nXiongye Xiao, Shahin Nazarian, and\nPaul Bogdan. 2021.\n\n\nA COVID-19 rumor dataset.\n\n\nFrontiers in Psychology\n12 (2021), 644801.\n\n\n\n\n\n\nClevelandClinic (2023)\n\nClevelandClinic.\n2023.\n\n\nClevelandClinic.\n\n\nhttps://newsroom.clevelandclinic.org/.\n\n\n\n\n\n\nCui and Lee (2020)\n\nLimeng Cui and Dongwon\nLee. 2020.\n\n\nCoaid: Covid-19 healthcare misinformation dataset.\n\n\narXiv preprint arXiv:2006.00885\n(2020).\n\n\n\n\n\n\nDadkhah et\u00a0al. (2023)\n\nSajjad Dadkhah, Xichen\nZhang, Alexander\u00a0Gerald Weismann, Amir\nFirouzi, and Ali\u00a0A Ghorbani.\n2023.\n\n\nTruthSeeker: The Largest Social Media Ground-Truth\nDataset for Real/Fake Content.\n\n\n(2023).\n\n\n\n\n\n\nDai et\u00a0al. (2020)\n\nZihang Dai, Guokun Lai,\nYiming Yang, and Quoc\u00a0V. Le.\n2020.\n\n\nFunnel-Transformer: Filtering out Sequential\nRedundancy for Efficient Language Processing.\n\n\nhttps://huggingface.co/funnel-transformer/medium-base.\n\n\narXiv:2006.03236\u00a0[cs.LG]\n\n\n\n\nDeka et\u00a0al. (2022)\n\nPritam Deka, Anna\nJurek-Loughrey, et\u00a0al. 2022.\n\n\nEvidence Extraction to Validate Medical Claims in\nFake News Detection.\nhttps://huggingface.co/pritamdeka/BioBERT-mnli-snli-scinli-scitail-mednli-stsb.\nIn International Conference on Health Information\nScience. Springer, 3\u201315.\n\n\n\n\n\n\nDevlin et\u00a0al. (2018)\n\nJacob Devlin, Ming-Wei\nChang, Kenton Lee, and Kristina\nToutanova. 2018.\n\n\nBERT: Pre-training of Deep Bidirectional\nTransformers for Language Understanding.\n\n\nhttps://huggingface.co/bert-base-cased.\n\n\nCoRR abs/1810.04805\n(2018).\n\n\narXiv:1810.04805\n\nhttp://arxiv.org/abs/1810.04805\n\n\n\nDonker (2023)\n\nTjibbe Donker.\n2023.\n\n\nThe dangers of using large language models for peer\nreview.\n\n\nThe Lancet Infectious Diseases\n(2023).\n\n\n\n\n\n\nEscol\u00e0-Gasc\u00f3n et\u00a0al. (2021)\n\n\u00c1lex Escol\u00e0-Gasc\u00f3n,\nNeil Dagnall, and Josep Gallifa.\n2021.\n\n\nCritical thinking predicts reductions in Spanish\nphysicians\u2019 stress levels and promotes fake news detection.\n\n\nThinking Skills and Creativity\n42 (2021), 100934.\n\n\n\n\n\n\nFactCheck (2023)\n\nFactCheck.\n2023.\n\n\nFactCheck.\n\n\nhttps://www.factcheck.org/.\n\n\n\n\n\n\nFirat (2023)\n\nMehmet Firat.\n2023.\n\n\nHow chat GPT can transform autodidactic experiences\nand open education.\n\n\nDepartment of Distance Education, Open\nEducation Faculty, Anadolu Unive (2023).\n\n\n\n\n\n\nGuo et\u00a0al. (2020)\n\nBin Guo, Yasan Ding,\nLina Yao, Yunji Liang, and\nZhiwen Yu. 2020.\n\n\nThe future of false information detection on social\nmedia: New perspectives and trends.\n\n\nACM Computing Surveys (CSUR)\n53, 4 (2020),\n1\u201336.\n\n\n\n\n\n\nHayawi et\u00a0al. (2022)\n\nKadhim Hayawi, Sakib\nShahriar, Mohamed\u00a0Adel Serhani, Ikbal\nTaleb, and Sujith\u00a0Samuel Mathew.\n2022.\n\n\nANTi-Vax: a novel Twitter dataset for COVID-19\nvaccine misinformation detection.\n\n\nPublic health 203\n(2022), 23\u201330.\n\n\n\n\n\n\nHealthFeedback (2023)\n\nHealthFeedback.\n2023.\n\n\nHealthFeedback.\n\n\nhttps://healthfeedback.org/.\n\n\n\n\n\n\nHealthline (2023)\n\nHealthline.\n2023.\n\n\nHealthline.\n\n\nhttps://www.healthline.com/.\n\n\n\n\n\n\nKinsora et\u00a0al. (2017)\n\nAlexander Kinsora, Kate\nBarron, Qiaozhu Mei, and VG\u00a0Vinod\nVydiswaran. 2017.\n\n\nCreating a labeled dataset for medical\nmisinformation in health forums. In 2017 IEEE\nInternational Conference on Healthcare Informatics (ICHI). IEEE,\n456\u2013461.\n\n\n\n\n\n\nLeadStories (2023)\n\nLeadStories.\n2023.\n\n\nLeadStories.\n\n\nhttps://leadstories.com/.\n\n\n\n\n\n\nLi et\u00a0al. (2020)\n\nYichuan Li, Bohan Jiang,\nKai Shu, and Huan Liu.\n2020.\n\n\nMM-COVID: A multilingual and multimodal data\nrepository for combating COVID-19 disinformation.\n\n\narXiv preprint arXiv:2011.04088\n(2020).\n\n\n\n\n\n\nMayo (2023)\n\nMayo. 2023.\n\n\nMayo.\n\n\nhttps://newsnetwork.mayoclinic.org/.\n\n\n\n\n\n\nMcGee (2023)\n\nRobert\u00a0W McGee.\n2023.\n\n\nIs chat gpt biased against conservatives? an\nempirical study.\n\n\nAn Empirical Study (February 15, 2023)\n(2023).\n\n\n\n\n\n\nNIH (2023)\n\nNIH. 2023.\n\n\nNIH.\n\n\nhttps://www.nih.gov/.\n\n\n\n\n\n\nNLP (2023)\n\nUCLA NLP. 2023.\n\n\nVisualBERT.\n\n\nhttps://huggingface.co/uclanlp/visualbert-vqa-coco-pre.\n\n\n\n\n\n\nOrganization (2022)\n\nWorld\u00a0Health Organization.\n2022.\n\n\nCoronavirus disease (COVID-19) advice for the public:\nMythbusters.\n\n\nhttps://shorturl.at/oCKP6.\n\n\n\n\n\n\nOuyang et\u00a0al. (2022)\n\nLong Ouyang, Jeffrey Wu,\nXu Jiang, Diogo Almeida,\nCarroll Wainwright, Pamela Mishkin,\nChong Zhang, Sandhini Agarwal,\nKatarina Slama, Alex Ray,\net\u00a0al. 2022.\n\n\nTraining language models to follow instructions\nwith human feedback.\n\n\nAdvances in Neural Information Processing\nSystems 35 (2022),\n27730\u201327744.\n\n\n\n\n\n\nPolitiFact (2023)\n\nPolitiFact.\n2023.\n\n\nPolitiFact.\n\n\nhttps://www.politifact.com/.\n\n\n\n\n\n\nPranto et\u00a0al. (2022)\n\nProtik\u00a0Bose Pranto, Syed\nZami-Ul-Haque Navid, Protik Dey, Gias\nUddin, and Anindya Iqbal.\n2022.\n\n\nAre You Misinformed? A Study of Covid-Related Fake\nNews in Bengali on Facebook.\n\n\narXiv preprint arXiv:2203.11669\n(2022).\n\n\n\n\n\n\nQudar and Mago (2020)\n\nMohiuddin Md\u00a0Abdul Qudar and\nVijay Mago. 2020.\n\n\nTweetbert: a pretrained language representation\nmodel for twitter text analysis.\n\n\narXiv preprint arXiv:2010.11091\n(2020).\n\n\n\n\n\n\nRagkhitwetsagul et\u00a0al. (2018)\n\nChaiyong Ragkhitwetsagul,\nJens Krinke, and Bruno Marnette.\n2018.\n\n\nA picture is worth a thousand words: Code clone\ndetection based on image similarity. In 2018 IEEE\n12th International workshop on software clones (IWSC). IEEE,\n44\u201350.\n\n\n\n\n\n\nScienceDaily (2023)\n\nScienceDaily.\n2023.\n\n\nScienceDaily.\n\n\nhttps://www.sciencedaily.com/.\n\n\n\n\n\n\nsentence transformer (2019a)\n\nsentence transformer.\n2019a.\n\n\ndistilBERT.\n\n\nhttps://huggingface.co/sentence-transformers/msmarco-distilbert-base-tas-b.\n\n\n\n\n\n\nsentence transformer (2019b)\n\nsentence transformer.\n2019b.\n\n\nsentenceBERT.\n\n\nhttps://huggingface.co/sentence-transformers/all-MiniLM-L6-v2.\n\n\n\n\n\n\nShu et\u00a0al. (2019)\n\nKai Shu, Limeng Cui,\nSuhang Wang, Dongwon Lee, and\nHuan Liu. 2019.\n\n\ndefend: Explainable fake news detection. In\nProceedings of the 25th ACM SIGKDD international\nconference on knowledge discovery & data mining.\n395\u2013405.\n\n\n\n\n\n\nSrba et\u00a0al. (2022)\n\nIvan Srba, Branislav\nPecher, Matus Tomlein, Robert Moro,\nElena Stefancova, Jakub Simko, and\nMaria Bielikova. 2022.\n\n\nMonant Medical Misinformation Dataset: Mapping\nArticles to Fact-Checked Claims. In Proceedings of\nthe 45th International ACM SIGIR Conference on Research and Development in\nInformation Retrieval. 2949\u20132959.\n\n\n\n\n\n\nSurameery and Shakor (2023)\n\nNigar M\u00a0Shafiq Surameery and\nMohammed\u00a0Y Shakor. 2023.\n\n\nUse chat gpt to solve programming bugs.\n\n\nInternational Journal of Information\nTechnology & Computer Engineering (IJITC) ISSN: 2455-5290\n3, 01 (2023),\n17\u201322.\n\n\n\n\n\n\nTimes (2023)\n\nThe New\u00a0York Times.\n2023.\n\n\nThe ChatGPT Lawyer Explains Himself.\n\n\nhttps://www.nytimes.com/2023/06/08/nyregion/lawyer-chatgpt-sanctions.html.\n\n\n\n\n\n\nungjus (2023)\n\nungjus. 2023.\n\n\nFN-BERT.\n\n\nhttps://huggingface.co/ungjus/Fake_News_BERT_Classifier.\n\n\n\n\n\n\nWani et\u00a0al. (2021)\n\nApurva Wani, Isha Joshi,\nSnehal Khandve, Vedangi Wagh, and\nRaviraj Joshi. 2021.\n\n\nEvaluating deep learning approaches for covid19\nfake news detection. In Combating Online Hostile\nPosts in Regional Languages during Emergency Situation: First International\nWorkshop, CONSTRAINT 2021, Collocated with AAAI 2021, Virtual Event, February\n8, 2021, Revised Selected Papers 1. Springer, 153\u2013163.\n\n\n\n\n\n\nWebMD (2023)\n\nWebMD. 2023.\n\n\nWebMD.\n\n\nhttps://www.webmd.com/.\n\n\n\n\n\n\nYang et\u00a0al. (2021)\n\nChen Yang, Xinyi Zhou,\nand Reza Zafarani. 2021.\n\n\nCHECKED: Chinese COVID-19 fake news dataset.\n\n\nSocial Network Analysis and Mining\n11, 1 (2021),\n58.\n\n\n\n\n\n\nZhou et\u00a0al. (2020)\n\nXinyi Zhou, Apurva Mulay,\nEmilio Ferrara, and Reza Zafarani.\n2020.\n\n\nRecovery: A multimodal repository for covid-19 news\ncredibility research. In Proceedings of the 29th\nACM international conference on information & knowledge management.\n3205\u20133212.\n\n\n\n\n\n\nZhou and Zafarani (2020)\n\nXinyi Zhou and Reza\nZafarani. 2020.\n\n\nA survey of fake news: Fundamental theories,\ndetection methods, and opportunities.\n\n\nACM Computing Surveys (CSUR)\n53, 5 (2020),\n1\u201340.\n\n\n\n\n\n\nZubiaga et\u00a0al. (2018)\n\nArkaitz Zubiaga, Ahmet\nAker, Kalina Bontcheva, Maria Liakata,\nand Rob Procter. 2018.\n\n\nDetection and resolution of rumours in social\nmedia: A survey.\n\n\nACM Computing Surveys (CSUR)\n51, 2 (2018),\n1\u201336.\n\n\n\n\n\n\n\n\n\n\nAppendix A Appendix\n\n\nA.1. Data Overview\n\nTable 5. Statistics between diseases and news/tweets.\n\n\nInformation Type\n\n\n\nanemia\n\u00a0\n\n\n\n\narthritis\n\u00a0\n\n\n\n\nasthma\n\u00a0\n\n\n\n\ncancer\n\u00a0\n\n\n\n\ncovid\n\u00a0\n\n\n\n\ndiabetes\n\u00a0\n\n\n\n\nepilepsy\n\u00a0\n\n\n\n\nflu\n\u00a0\n\n\n\n\nheadache\n\u00a0\n\n\n\n\nhypertension\n\u00a0\n\n\n\n\ninflammation\n\u00a0\n\n\n\n\nmonkeypox\n\u00a0\n\n\n\n\nparkinson\n\u00a0\n\n\n\n\npneumonia\n\u00a0\n\n\n\n\nstroke\n\u00a0\n\n\n\nTotal\n\n\n\nReal news\n64\n85\n148\n1,410\n859\n332\n48\n740\n70\n55\n282\n44\n81\n50\n286\n4,554\n\n\nFake news\n0\n1\n0\n27\n304\n1\n2\n114\n1\n0\n4\n3\n0\n2\n10\n469\n\n\nLLM fake news\n18\n35\n62\n615\n462\n161\n23\n339\n30\n25\n135\n19\n39\n11\n121\n2,095\n\n\nTrue claims\n3\n4\n7\n190\n1,619\n31\n2\n362\n11\n1\n12\n7\n4\n9\n21\n2,283\n\n\nFalse claims\n5\n6\n10\n269\n2,557\n38\n3\n575\n14\n2\n14\n19\n6\n15\n34\n3,567\n\n\nTotal news\n91\n133\n227\n2,560\n5,836\n569\n83\n2,152\n127\n84\n452\n94\n132\n88\n481\n12,968\n\n\nReal tweets\n53\n15\n28\n540\n1,161\n152\n29\n2,095\n36\n21\n174\n8\n35\n17\n106\n7,738\n\n\nFake tweets\n0\n0\n0\n120\n2,547\n0\n1\n2,436\n0\n0\n2\n1,799\n0\n0\n21\n6,927\n\n\nTotal tweets\n53\n15\n28\n660\n3,708\n152\n30\n4,531\n36\n21\n176\n1,807\n35\n17\n127\n27,633\n\n\n\n\n\nA.1.1. Relations to Multiple Disease\n\nAlthough we did not provide specific disease labels for the articles/tweets, we conducted a statistical analysis based on diseases. As indicated in Table 5, we examined fifteen disease categories that contained more than fifty real news articles. The statistical findings reveal that the number of real news articles is relatively evenly distributed across various types of diseases. In contrast, fake news articles and tweets tend to concentrate on \u201dhotspot\u201d topics such as Covid-19 and Monkeypox.\n\n\n\n\n\nA.2. Data Analysis\n\nWe analyze our dataset in two-fold: text-level and embedding-level. We detail these two folds below.\n\n\ntext-level. To understand the topic difference between the tweets of fake and real news, we analyze the top 30 frequent hashtags in tweets related to fake and true news articles, respectively. The frequency of hashtags in tweets related to fake and real news articles is shown in Figure\u00a05(a) and Figure\u00a05(b), respectively. We \ufb01nd that the hashtag distributions of tweets about fake and real news articles are quite different. While the hashtags in tweets about true news articles are mainly related to healthcare, those in tweets about fake news cover more diverse topics, including social media (#facebook, #foxnews) and natural disasters (#hurricane, #earthquake).\n\n\nembedding-level. In terms of news, we categorized our crawled content into three distinct sources: real, human-generated fake, and Language Learning Model (LLM)-generated fake news. As depicted in Figure\u00a04, we randomly selected 300 news articles from each of these categories and analyzed them using BERT embeddings. However, our analysis reveals that the BERT embeddings struggle to distinguish between real, human-fake, and LLM-fake news due to significant overlaps in these categories.\n\n\nThis observation highlights the significance of researching methodologies to accurately discern these three distinct sources of news. Moreover, our analysis shows minimal overlap between LLM-fake news and human-fake news, suggesting that a model adept at identifying human-fake news might not necessarily be effective at detecting LLM-generated misinformation, and vice versa. This calls for an approach that can adapt to these distinct categories effectively.\n\n\nCorrespondingly, we categorized the crawled tweets into two primary sources: real tweets and human-fake tweets. Due to the constraints imposed by Twitter\u2019s Developer Policy\u00a0(Agreement, 2023), the generation of LLM-fake tweets is not permissible. As a result, we randomly sampled 300 tweets from both sources for our analysis, as illustrated in Figure\u00a05. For analysis, we utilized TweetBERT embeddings\u00a0(Qudar and Mago, 2020). However, the figure shows that TweetBERT embeddings struggle to clearly demarcate between real and human-fake tweets, demonstrating significant overlap. This underlines the importance of exploring further research methodologies to distinguish these two categories accurately.\n\n\n\n\nFigure 4. A t-SNE figure of randomly sampled 300 real news, 300 human-fake news, and 300 LLM-fake news.\n\n\n\n\nFigure 5. A t-SNE figure of randomly sampled 300 real tweets, 300 human-fake tweets. Due to the Tweet Develop Policy\u00a0(Agreement, 2023), we cannot use ChatGPT to generate LLM-fake tweets.\n\n\n\n\n\n(a) Fake News.\n\n\n\n\n(b) True News.\n\n\n\nFigure 6. Frequency of hashtags in tweets about fake and true news articles.\n\n\n\n\nA.3. Multimodal Claim Filtering\n\nBy looking at the images of the real news, fact-check, and fake news articles, we notice a pattern where real news articles often incorporate decorative images sourced from the internet, while fake news articles frequently utilize screenshots of social media or videos. This stark contrast makes it relatively straightforward to distinguish between true and fake news.\nHowever, in the case of fact-check articles, we observe that \u201dAFPFactCheck\u201d tends to use screenshots, while \u201dCheckYourFact\u201d and \u201dPolitiFact\u201d lean towards using decorative images. Consequently, we included the true claims from \u201dAFPFactCheck\u201d and the false claims from \u201dCheckYourFact\u201d and \u201dPolitiFact\u201d as part of the multimodal fake news detection task.\nThis ensures that the models trained on our dataset do not get misled by features that are irrelevant to the content of the articles.\n\n\n\n\nA.4. Baseline Models\n\nThe following baseline fake news detection methods are considered for medical misinformation detection:\n\n\n\u2022\n\nBERT\u00a0(Devlin et\u00a0al., 2018): A bi-directional transformer model pretrained on a large corpus of English data in a self-supervised fashion.\n\n\n\n\u2022\n\nBioBERT\u00a0(Deka et\u00a0al., 2022): A sentence-transformers model built with medical dataset for fact-checking of online health information.\n\n\n\n\u2022\n\nFunnel Transformer\u00a0(Dai et\u00a0al., 2020): An efficient bidirectional transformer model by applying a pooling operation after each layer, akin to convolutional neural networks, to reduce the length of the input.\n\n\n\n\u2022\n\nFN-BERT\u00a0(ungjus, 2023): A BERT-based model recently finetuned on a Fake news classification dataset in 2023.\n\n\n\n\u2022\n\nsentenceBERT\u00a0(sentence transformer, 2019b): A sentence representation learning model pretrained using Siamese and triplet network structures.\n\n\n\n\u2022\n\ndistilBERT\u00a0(sentence transformer, 2019a): A dual-encoder then dot-product scoring architecture BERT model. The version employed in this paper is pre-trained with the TAS-Balanced method on the MSMARCO standard.\n\n\n\n\u2022\n\ndEFEND\u00a0(Shu et\u00a0al., 2019) utilizes the hierarchical attention network to model article content for misinformation detection.\n\n\n\n\u2022\n\nCLIP\u00a0(AI, 2021): A multi-modal vision and language model pretrained on 400 million image-text pairs.\n\n\n\n\n\u2022\n\nVisualBERT\u00a0(NLP, 2023): A multi-modal vision and language model. It uses a BERT-like transformer to prepare embeddings for image-text pairs.\n\n\n\n\n\n\n\n\n\nGenerated  on Thu Jul 13 18:26:10 2023 by LATExml\n\n\n\n\n"}, {"id": "http://arxiv.org/abs/2401.13480v2", "title": "The Dynamics of (Not) Unfollowing Misinformation Spreaders", "contents": "Just a moment...Enable JavaScript and cookies to continue"}, {"id": "http://arxiv.org/abs/2202.09445v1", "title": "Identifying the Adoption or Rejection of Misinformation Targeting\n  COVID-19 Vaccines in Twitter Discourse", "contents": "Just a moment...Enable JavaScript and cookies to continue"}, {"id": "http://arxiv.org/abs/2311.05656v1", "title": "Combating Misinformation in the Age of LLMs: Opportunities and\n  Challenges", "contents": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n | arXiv e-print repository\n\n\n\n\n\n\n\nSkip to main content\n\n\n\n\n\nWe gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors. Donate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHelp | Advanced Search\n\n\n\n\nAll fields\nTitle\nAuthor\nAbstract\nComments\nJournal reference\nACM classification\nMSC classification\nReport number\narXiv identifier\nDOI\nORCID\narXiv author ID\nHelp pages\nFull text\n\n\n\n\nSearch\n\n\n\n \n\n\nLogin \n \n\nNo HTML for '2311.05656v1'\nHTML is not available for the source.\nThis could be due to the source files not being HTML, LaTeX, or a conversion failure.\nIf you are an author, learn how you can help HTML conversions for your papers. \n\n\n\n\n\n\n\nAbout\nHelp\n\n\n\n\n\ncontact arXivClick here to contact arXiv\n Contact\n\n\nsubscribe to arXiv mailingsClick here to subscribe\n Subscribe\n\n\n\n\n \n\n\n\n\n\nCopyright\nPrivacy Policy\n\n\n\n\nWeb Accessibility Assistance\n\n\narXiv Operational Status \n              Get status notifications via\n              email\n              or slack\n\n\n\n\n\n \n \n\n\n"}, {"id": "http://arxiv.org/abs/2306.12466v1", "title": "Misinformation as Information Pollution", "contents": "\n\n\n\nMisinformation as Information Pollution\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMisinformation as Information Pollution\n\n\nAshkan Kazemi\n\nashkank@umich.edu\n\n0000-0002-2475-1007\n\n\u00a0and\u00a0\nRada Mihalcea\n\nmihalcea@umich.edu\n\n0000-0002-0767-6703\nUniversity of Michigan2260 Hayward St.Ann ArborMichiganUSA48109-2121\n\n\n\nAbstract.\nSocial media feed algorithms are designed to optimize online social engagements for the purpose of maximizing advertising profits, and therefore have an incentive to promote controversial posts including misinformation.\nBy thinking about misinformation as information pollution, we can draw parallels with environmental policy for countering pollution such as carbon taxes. Similar to pollution, a Pigouvian tax on misinformation provides economic incentives for social media companies to control the spread of misinformation more effectively to avoid or reduce their misinformation tax, while preserving some degree of freedom in platforms\u2019 response.\nIn this paper, we highlight a bird\u2019s eye view of a Pigouvian misinformation tax and discuss the key questions and next steps for implementing such a taxing scheme.\n\nMisinformation, Fake News, Information Pollution, Pigouvian Taxes, Internet Policy\n\n\n\n1. Introduction\n\nPollution is the introduction of harmful materials into the environment, either naturally such as volcanic ash or introduced by human activity such as runoff produced by factories111https://education.nationalgeographic.org/resource/pollution/.\nPollutants damage our air quality, water and the environment at large. We apply the famous \u201cduck test222https://en.wikipedia.org/wiki/Duck_test\u201d to pollution and misinformation: if misinformation looks like pollution and acts like pollution, then it is information pollution.\nSimilar to toxic water pollutants that poison city drinking waters, the spread of information pollution into our online social lives causes damages to individuals and societies that are sometimes beyond repair. Online misinformation has ignited catastrophic social distress in recent years such as a genocide in Myanmar (International, 2022) and worsening global public health during the COVID-19 pandemic (Caceres et\u00a0al., 2022).\nAs with environmental regulation policies around pollutants, when a company causes leaks into the environment, whether this is caused by an individual\u2019s negligence or structural and cultural faults of the company, the company is responsible for the environmental damage.\n\n\nThere are three main structural incentives in the social media economy that promote misinformation: (i) maximizing user engagement by all means necessary promotes controversial content such as misinformation as such posts are likely to yield higher user engagement (Vosoughi et\u00a0al., 2018), (ii) Algorithms can identify the right influencers for maximizing advertisement reach (Ahmadinejad et\u00a0al., 2014), or marketing firms use AB-tests to tailor ads to their target audiences (Wilson, 2019); in such settings adversarial actors can make use of such algorithms to spread misinformation more effectively, (iii) algorithms are not penalized for suggesting harmful content but receive rewards (i.e. ad revenue). The lack of penalty affords feed algorithms a larger playground for exploration that might include recommendation for extremist Facebook groups or Youtube channels.\n\n\nAdopting an environmentally inspired tax on misinformation, directed at the social media platforms, can curb the spread of misinformation.\nA Pigouvian tax (Pigou, 2002) suggests taxing negative externalities by setting a tax rate equal to the social marginal damages resulting from an additional unit of the externality. Different variations of this tax have been suggested to counter the negative externalities of carbon emissions (Metcalf and Weisbach, 2009; Metcalf, 2009), tobacco (Cnossen, 2006; Chaloupka et\u00a0al., 2012), alcohol (Cnossen, 2007; Bouchery et\u00a0al., 2011; Wagenaar et\u00a0al., 2010) and traffic congestion (Lindsney* and Verhoef*, 2001; Parry, 2002).\nFew proposals to implement a social media or fake news tax have been proposed: the Nobel-winning economist Paul Romer proposed that a tax on targeted advertising revenue would incentivize \u201cbig tech\u201d to shift their dangerous business model away from misinformation and hate speech (Romer, 2019) . In response to arguments against this tax, Romer noted that even if tech companies move away from this economy and make the tax obsolete, this would still bring in real change as the companies have found alternative revenue streams and therefore are not as prone to spread and promotion of toxic content. A similar proposal by Van Alstyne (Alstyne, 2019) suggests imposing monetary penalties to fake news posts and the individuals who created them, while also keeping the integrity of freedom of speech. Additionally, experimental evidence from (Rathje et\u00a0al., 2023) suggests economic incentives and more broadly motivation based. An incentive as little as a dollar for forming accurate judgements improved accuracy in judgments of political news headlines in the study\u2019s participants. At macro scale, research suggests that belief in conspiracies is strongly related to helplessness (Whitson and Galinsky, 2008) and inequality in relative socioeconomic status (Payne, 2018) in societies.\n\n\nIn this paper we contribute (i) a high-level framework for misinformation tax, (ii) discuss existing evidence and estimates of the financial and public health burdens of misinformation, and (iii) provide additional considerations for what such a tax might look like in practice.\n\n\n\n\n2. What counts as misinformation?\n\n\nWe define misinformation to be misleading information shared online, regardless of intent. While several other terms have been used to address the phenomenon such as fake news or disinformation, we assume the commonly used term \u201cmisinformation\u201d to encompass different aspects of misleading content.\n\n\nWe acknowledge that imposing large monetary penalties on internet companies such as an information pollution tax requires a careful deliberation on what constitutes as information pollution, and that often is a democratic task that might have different outcomes depending on the participants. We intentionally leave the interpretation of \u201cmisinformation\u201d to readers and operate on a \u201cknow it when we see it\u201d basis in regards to what counts as information pollution. Future open discussions are needed to further clarify and define the boundaries between pollution and safe information.\n\n\n\n\n3. Taxing information pollution\n\nAs previously noted in the carbon tax literature (e.g. (Metcalf and Weisbach, 2009)), it is considered \u201cheroic\u201d to estimate the optimal tax rate (the marginal abatement cost and benefit) as defined by Pigou\u2019s theory for CO2 and/or other greenhouse emissions, since calculating the optimal tax rate requires prediction about complex effects of climate change in the future. An alternative to calculating the optimal tax rate is to determine a set of taxes that overtime help to meet target emissions reduction goals and it has been shown that the two approaches converge to similar outcomes in practice (Metcalf and Weisbach, 2009). As misinformation is a more complex and less understood phenomenon compared to greenhouse emissions- and at times even fact-checkers struggle to identify fact from fiction, we also propose to set misinformation taxes by setting a misinformation reduction or information health target, rather than attempting to come up with accurate estimations of information pollution.\n\n\nTo meet our information health target through taxation of misinformation, we need to understand two fundamental questions: (i) How much misinformation exists on each internet platform? and (ii) What are the economic, social, and human costs of misinformation?\n\n\nIt requires far more research than just one paper to gain a deeper understanding of the two questions, so throughout the rest of the paper we aim to focus on raising the important questions and suggest high level directions that could eventually support operationalizing such a mechanism, if one is ever to be implemented.\n\n\nTo address the first question, we propose to focus on viral misinformation, misleading narratives that have reached more than some threshold of user engagement. Fringe misinformation is less likely to cause real damage and even fact-checking fringe misinformation might give such narratives more recognition they would normally receive (Phillips, 2018; Wardle et\u00a0al., 2019). Platforms already compute engagement metrics, and with the recently expanding fact-checking networks across the internet, keeping track of viral misinformation on each platform becomes a matter of record keeping that can be used to report aggregate engagement information (provided through the platforms.) We sketch out the important details regarding question (ii) in the following section.\n\n\n\n\n4. The stakeholders and implications of misinformation\n\nThere are no good public estimates of the cost of misinformation on individuals, society, the economy, and public health. In this section we take a high level view of this complex ecosystem and demonstrate the extent to which misinformation affects humans. We aim for more breadth, and we identify measuring economic impacts of misinformation as an important future research and governance direction.\n\n\n\n4.1. The stakeholders\n\n\n\n\n\u2022\n\nOnline media.\nThe owners of internet platforms stand to profit more from misinformation and controversy than from regular content. (Vosoughi et\u00a0al., 2018) They also experience political backlash because of online misinformation, which in effect imposes public relations related costs on platforms. Since online media control the apparatus of information circulation, they are the most leveraged of all stakeholders.\n\n\n\n\u2022\n\nAdvertisers.\nThe vast majority of revenue of online media is through the sale of user attention to advertisers. This gives advertisers noticeable power over the platforms, and therefore they can exert force on internet companies using their spending as leverage. In the United States\u2019 traditional broadcasting and news media, the advertisers\u2019 lobbying power has led the Federal Communications Commission (FCC)\u2019s to regulate \u201cobscenity, indecency, and profanity\u201d (Commission et\u00a0al., 2017), and fine media companies for publishing such content. Advertisers may choose to follow similar paths in response to online misinformation tainting their brands. According to Media Matters\u2019 report (Kann and Carusone, 2022), Twitter lost half of its top 100 advertisers- who purchased nearly $2 billion worth of ads since 2020, only a month after Elon Musk acquired the company. The advertisers included large corporations such as American Express, Citigroup, Chipotle, Nestle, Black Rock, and Chanel, and some publicly cited controversies and concerns around looser content moderation post Musk take over.\n\n\n\n\u2022\n\nJournalists and fact-checkers.\nAt the forefront of reporting on world events, journalists and fact-checking communities often have to spend extra time and energy to go against misinformation, by avoiding them in reporting and doing extra work debunking falsehoods.\nJournalism has become a more challenging and risky profession in recent years in part as a side effect of excessive information pollution.\nIt is worth noting that the rivalry among traditional news media and online media for user attention is a confounding factor that sometimes interferes with journalism\u2019s impartiality in promoting the best course of action against misinformation.\nNevertheless, journalists and fact-checkers remain our best source of professional and expert advocacy against misinformation, since they have an economic interest in protecting their work from falsehoods.\n\n\n\n\u2022\n\nCivil society.\nMisinformation can have far-reaching and harmful effects on civil society. When people are exposed to false or misleading information, they may form incorrect opinions and beliefs that can harm the social fabric of a community. For example, misinformation can create divisions among people by fueling prejudice, mistrust, and hate. It can also erode public trust in institutions, such as the government, media, and scientific community, which are critical for maintaining a healthy democracy. Misinformation can also lead to the spread of harmful practices and ideologies. For example, false information about vaccine safety can discourage people from getting vaccinated, leading to the spread of preventable diseases. Similarly, misinformation about climate change can undermine efforts to address this pressing global issue. In addition, misinformation can also have serious consequences for individual and collective decision-making. People who rely on false information to make decisions may end up taking actions that are not in their best interest or the interest of society as a whole. Therefore civil society and grassroots organizations are an important lobby against misinformation.\n\n\n\n\n\nWhile at first glance it seems that all parties must want to combat misinformation, they collectively have struggled to do so over the years. Social media owners prioritize short-term profits over the potential long-term risks of misinformation to their business. The architecture of online advertisement affords the advertisers to turn a blind eye and collect profits, since ads are targeted towards demographics and are not attached to content. The former two stakeholders possess the power, but lack the will to make structural changes to control misinformation. The other stakeholders, mainly civil society and journalists are in the reverse position, as they do not possess as much control over the flow of information, but have demonstrated interest and will to counter misinformation. As long as no governing entity addresses this power imbalance among stakeholders by applying appropriate regulation, we face the risks of widespread misinformation.\n\n\n\n\n4.2. Social cost of misinformation\n\nTo understand the magnitude of misinformation\u2019s social debt, we turn to prior research and reporting that associate a monetary value with negative outcomes of information pollution.\n\n\nIn a 2019 report (Cavazos, 2019), a group of economists and cybersecurity analysts placed a $78 billion price tag on the global damages of fake news, citing the most affected sectors as stock market losses and volatility ($39 billion), financial misinformation ($17 billion in US alone), and reputation management and public health (US only) costing an annual $9 billion each, all in a single year. According to research from the Economic Policy Institute published in 2017, retirement savers lose an annual $17 billion from acting on misleading advice from financial advisors with conflicts of interest. (Shierholz and Zipperer, 2017; Carson, 2018)\n\n\nAdditionally, activists and non-profit organizations have mobilized in recent years to study the finances driving online misinformation, and at times have successfully demonetized the interests behind pushing misleading narratives. Sleeping Giants are an activist organization comprised of mostly anonymous members with active chapters in the US, Australia, Brazil, Canada, France, and Germany. Since their inception in late 2016, they have successfully demonetized extremist and fake news websites as famous as Breitbart News, causing 820 corporations including AT&T, BMW, and Visa to stop advertising with the far right outlet. (Kerr, 2017)\nGlobal Disinformation Index (GDI)333https://www.disinformationindex.org is a not-for-profit organization that publishes open research on news markets around the world. GDI provides dynamic exclusion lists of global news organizations rated high risk for misinformation to adtech companies, effectively providing a mechanism for systematically defunding misinformation.\n\n\nIn late 2022 the families of the victims of the Sandy Hook elementary school massacre which occurred ten years prior, won two defamation cases against Alex Jones, the infamous conspiracy theorist that circulated baseless lies about the victims being hired actors by the government in a conspiracy to take away Americans\u2019 guns. Jones has been ordered to pay $1.49 billion in damages in two Sandy Hook defamation cases, and awaits a third trial pending investigation in Texas. (Queen, 2022) The ruling is a first of its kind in the United States, setting precedent in punishment for defamation through deploying misinformation.\n\n\nFurther research and inquiry is required to draw a clearer picture of the burdens information pollution imposes on society. We highlight a reoccurring theme in the reports we reference on economic damages of misinformation: the estimates surpass billions of USD, and the damages often directly affect the public. We believe these numbers are alarming enough to justify taxing internet platforms for information pollution.\n\n\n\n\n4.3. Public health implications of misinformation\n\nMisinformation can have serious public health implications, as it can spread false or misleading information about health issues, treatments, and interventions. Some of the key public health implications of misinformation include:\n\n\n\n\n\u2022\n\nDiscouraging vaccination. False information about vaccine safety can discourage people from getting vaccinated, leading to the spread of preventable diseases. This can have serious consequences for public health, especially in the context of outbreaks and pandemics. There is a growing body of research studying the impact of misinformation on vaccination and public health. (Loomba et\u00a0al., 2021; Lee et\u00a0al., 2022; Mutombo et\u00a0al., 2022; Garett and Young, 2021)\n\n\n\n\u2022\n\nPromoting risky treatments. Misinformation about health treatments can lead people to seek out dangerous or ineffective remedies, which can be harmful to their health. For example, false information about the dangers of conventional medical treatments can lead people to rely on unproven alternative therapies. (Xu et\u00a0al., 2021; Loeb et\u00a0al., 2020, 2022)\n\n\n\n\u2022\n\nUndermining public trust in science. Misinformation about health issues can erode public trust in science and scientific institutions.(Goldstein et\u00a0al., 2020; West and Bergstrom, 2021; Scheufele and Krause, 2019) This can make it difficult for public health authorities to effectively communicate important health information and promote evidence-based practices. (of\u00a0the Surgeon\u00a0General et\u00a0al., 2021; Murthy, 2022)\n\n\n\n\u2022\n\nDelaying treatment. False information about symptoms and treatments can lead people to delay seeking medical help, which can have serious consequences for their health. For example, false information about the causes of cancer can discourage people from seeking early detection and treatment, which can reduce the chances of successful treatment.\n\n\n\n\n\nSuch implications even at small scales pose huge risks to community and public health as social changes such as anti-vaccination movements can cause exponentially worse public health outcomes, leading the US surgeon general to declare misinformation as a public health emergency. (of\u00a0the Surgeon\u00a0General et\u00a0al., 2021) Many parts of the healthcare industry including doctors, nurses, and medical staff are impacted by misinformation in a variety of ways such as:\n\n\n\n\n\u2022\n\nHealthcare resource allocation. Misinformation can lead to an overuse or misuse of healthcare resources. For example, people may seek unnecessary medical treatments or tests based on false information, which can strain healthcare systems and divert resources away from those who need it most.\n\n\n\n\u2022\n\nHealth system costs. The unnecessary overuse of healthcare resources caused by exposure to information pollution can increase healthcare costs, which can negatively impact patients, hospitals, and governments.\n\n\n\n\u2022\n\nBurnout of hospital staff. Hospital staff, including doctors, nurses, and support staff, may experience stress and burnout as they work to manage the consequences of misinformation. For example, they may have to spend extra time educating patients about accurate health information or addressing the fallout from misinformation-driven health decisions. (Murthy, 2022)\n\n\n\n\n\nWhile there are arguments both for and against attaching a monetary value to pain and suffering (Taylor, 2020; Kling et\u00a0al., 2012) of patients and hospital staff, we find a \u201cfine\u201d designation to be appropriate for deterring the negative impact of health-related misinformation as a sound and promising regulatory path.\n\n\n\n\n\n5. Considerations for a misinformation tax\n\nThe negative externalities of misinformation on social media platforms adds to a growing number of concerns regarding the lack of accountability from big tech corporations that profit from information pollution. Information pollution will likely exacerbate due to the recent influx in misleading AI-generated content on the internet (Zellers et\u00a0al., 2019). In a recent U.S. Supreme Court hearing on \u201cGonzalez v. Google LLC444https://www.supremecourt.gov/docket/docketfiles/html/public/21-1333.html,\u201d the plaintiff argues that internet companies such as Google should no longer be exempt from liability under section 230 of the Communications Decency Act of 1996,555https://www.fcc.gov/general/telecommunications-act-1996 as personalized and targeted recommendations made by search engines and social media are intentionally selective about what content is displayed to users. Our arguments in this paper align with that of the defense, and we believe that a Pigouvian tax on misinformation has the potential to address the issues of content moderation in the absence of such publisher protections for internet companies.\n\n\n\n5.1. Implementation considerations\n\nHow platforms respond to these taxes will be different: some may start charging toxic users, others might move away from the online advertising-attention market, some might ban information pollution while others ban pollutants. We find the variability in platforms\u2019 response as a positive outcome, since it leaves room for platforms to make decisions that makes sense for their businesses. Since \u201cone size fits all\u201d solutions might succeed in one place but fail in others, the flexibility afforded by misinformation tax to platforms in choosing how to address misinformation is noteworthy.\n\n\nOnline media manifests in different shapes and forms. One particularly challenging-to-oversee category of online media are closed messaging social media platforms such as WhatsApp, Signal, and Telegram. Due to end-to-end encryption, such platforms have no effective way to review content, as the content only exists on end-user devices in encrypted format. While WhatsApp misinformation may be less prevalent in Western countries, billions of users in India, Brazil, and Iran make heavy use of WhatsApp and Telegram. A promising recent response to this issue called \u201ctipline\u201d (Kazemi et\u00a0al., 2022) enables opt-in inquiry and reporting about potentially misleading claims users come across on the closed platforms. Tiplines have been found to uncover a significant portion of viral misinformation on WhatsApp public group chats before they went viral, in a case study conducted on the 2019 Indian general elections. (Kazemi et\u00a0al., 2022)\n\n\n\n\n5.2. Ethical considerations\n\nFreedom of expression is a fundamental human right and stopping misinformation should not turn into censorship. Platforms often cite similar concerns explaining controversial takedowns (Paul, 2019). A misinformation tax directed at social media platforms avoids regulating speech at the government level and affords flexible moderation mechanisms to platforms while disincentivizing misleading consequential online interactions at a macro level. From this perspective, misinformation tax is a light-handed regulatory measure that can be tailored to the specific needs of communities and governing bodies. On the downside, compliance with misinformation tax for platforms might mean making consequential changes to company procedures that reduce their edge against international competitors and affect small businesses on their platforms. However, an emergency discipline designation to information pollution (Bak-Coleman et\u00a0al., 2021) requires us to view these consequences as secondary priorities next to protecting individuals and the society against information pollution. Such regulation should be applied justly to all companies, and that might mean a larger tax base for foreign firms to account for issues of competitiveness. Furthermore, one might argue that if social media cannot survive without misinformation, this could be just cause to look for alternatives to current platforms as they are not economically productive at the macro level.\n\n\n\n\n\n6. Conclusion\n\nWe drew analogies between misinformation and environmental pollution, and proposed similar regulatory frameworks\u2013namely a Pigouvian tax on information pollution, to limit the spread of online misinformation.\nIn this paper, we present a high level plan for implementing \u201cmisinformation tax.\u201d We acknowledge that this is only the tip of the iceberg and that adopting such proposals requires further research and considerations in practice, some of which will vary greatly depending on context. We identify macro-level estimations of both cost and reach of viral misinformation in online communities as an important direction for future work, while emphasizing the importance of soliciting community feedback and engagement in implementing such measures for reducing information pollution.\n\n\nAcknowledgements.\nWe thank Ashley Craig (Research School of Economics at Australian National University), Catherine Hausman (Ford School of Public Policy at University of Michigan), Eric Gilbert (School of Information at University of Michigan), and Isabelle Barroso (independent journalist) who provided feedback on earlier iterations of this work.\n\n\n\n\nReferences\n\n\n(1)\n\n\n\n\nAhmadinejad et\u00a0al. (2014)\n\nAmirMahdi Ahmadinejad,\nSina Dehghani, MohammadTaghi Hajiaghayi,\nHamid Mahini, Saeed Seddighin, and\nSadra Yazdanbod. 2014.\n\n\nHow effectively can we form opinions?. In\nProceedings of the 23rd International Conference on\nWorld Wide Web. 213\u2013214.\n\n\n\n\n\n\nAlstyne (2019)\n\nMarshall\u00a0Van Alstyne.\n2019.\n\n\nCould Taxes Deter the Spread of Harmful Fake News?\n\n\nThe Brink (Boston University Blog)\n(2019).\n\n\n\nhttps://www.bu.edu/articles/2019/deter-the-spread-of-harmful-fake-news/\n\n\n\nBak-Coleman et\u00a0al. (2021)\n\nJoseph\u00a0B. Bak-Coleman,\nMark Alfano, Wolfram Barfuss,\nCarl\u00a0T. Bergstrom, Miguel\u00a0A. Centeno,\nIain\u00a0D. Couzin, Jonathan\u00a0F. Donges,\nMirta Galesic, Andrew\u00a0S. Gersick,\nJennifer Jacquet, Albert\u00a0B. Kao,\nRachel\u00a0E. Moran, Pawel Romanczuk,\nDaniel\u00a0I. Rubenstein, Kaia\u00a0J. Tombak,\nJay J.\u00a0Van Bavel, and Elke\u00a0U. Weber.\n2021.\n\n\nStewardship of global collective behavior.\n\n\nProceedings of the National Academy of\nSciences 118, 27\n(2021), e2025764118.\n\n\n\nhttps://doi.org/10.1073/pnas.2025764118\narXiv:https://www.pnas.org/doi/pdf/10.1073/pnas.2025764118\n\n\n\n\nBouchery et\u00a0al. (2011)\n\nEllen\u00a0E Bouchery,\nHenrick\u00a0J Harwood, Jeffrey\u00a0J Sacks,\nCarol\u00a0J Simon, and Robert\u00a0D Brewer.\n2011.\n\n\nEconomic costs of excessive alcohol consumption in\nthe US, 2006.\n\n\nAmerican journal of preventive medicine\n41, 5 (2011),\n516\u2013524.\n\n\n\n\n\n\nCaceres et\u00a0al. (2022)\n\nMaria Mercedes\u00a0Ferreira Caceres,\nJuan\u00a0Pablo Sosa, Jannel\u00a0A Lawrence,\nCristina Sestacovschi, Atiyah\nTidd-Johnson, Muhammad Haseeb\u00a0UI Rasool,\nVinay\u00a0Kumar Gadamidi, Saleha Ozair,\nKrunal Pandav, Claudia Cuevas-Lou,\net\u00a0al. 2022.\n\n\nThe impact of misinformation on the COVID-19\npandemic.\n\n\nAIMS public health 9,\n2 (2022), 262.\n\n\n\n\n\n\nCarson (2018)\n\nRon Carson.\n2018.\n\n\nRetirement Savers Are Losing $17 Billion A Year\nFrom Fake News And Conflicts of Interest.\n\n\nForbes (2018).\n\n\n\nhttps://www.forbes.com/sites/rcarson/2018/10/14/retirement-savers-are-losing-17-billion-a-year-from-fake-news-bad-advice-conflicts-of-interest/?sh=4c6e6e6abec7\n\n\n\nCavazos (2019)\n\nR Cavazos.\n2019.\n\n\nThe Economic cost of bad actors on the Internet: Fake\nNews.\n\n\n\n\n\n\n\n\nChaloupka et\u00a0al. (2012)\n\nFrank\u00a0J Chaloupka, Ayda\nYurekli, and Geoffrey\u00a0T Fong.\n2012.\n\n\nTobacco taxes as a tobacco control strategy.\n\n\nTobacco control 21,\n2 (2012), 172\u2013180.\n\n\n\n\n\n\nCnossen (2006)\n\nSijbren Cnossen.\n2006.\n\n\nTobacco taxation in the European Union.\n\n\nFinanzArchiv/Public Finance Analysis\n(2006), 305\u2013322.\n\n\n\n\n\n\nCnossen (2007)\n\nSijbren Cnossen.\n2007.\n\n\nAlcohol taxation and regulation in the European\nUnion.\n\n\nInternational Tax and Public Finance\n14, 6 (2007),\n699\u2013732.\n\n\n\n\n\n\nCommission et\u00a0al. (2017)\n\nFederal\u00a0Communications Commission\net\u00a0al. 2017.\n\n\nObscene, indecent and profane broadcasts.\n\n\nFederal Communications Commission Consumer\nGuides 13 (2017).\n\n\n\n\n\n\nGarett and Young (2021)\n\nRenee Garett and Sean\u00a0D\nYoung. 2021.\n\n\nOnline misinformation and vaccine hesitancy.\n\n\nTranslational behavioral medicine\n11, 12 (2021),\n2194\u20132199.\n\n\n\n\n\n\nGoldstein et\u00a0al. (2020)\n\nCarly\u00a0M Goldstein,\nEleanor\u00a0J Murray, Jennifer Beard,\nAlexandra\u00a0M Schnoes, and Monica\u00a0L\nWang. 2020.\n\n\nScience communication in the age of\nmisinformation.\n\n\nAnnals of Behavioral Medicine\n54, 12 (2020),\n985\u2013990.\n\n\n\n\n\n\nInternational (2022)\n\nAmnesty International.\n2022.\n\n\nMYANMAR: FACEBOOK\u2019S SYSTEMS PROMOTED VIOLENCE\nAGAINST ROHINGYA; META OWES REPARATIONS.\n\n\nAmnesty International\n(2022).\n\n\n\nhttps://www.amnesty.org/en/latest/news/2022/09/myanmar-facebooks-systems-promoted-violence-against-rohingya-meta-owes-reparations-new-report/\n\n\n\nKann and Carusone (2022)\n\nSharon Kann and Angelo\nCarusone. 2022.\n\n\nIn less than a month, Elon Musk has driven away\nhalf of Twitter\u2019s top 100 advertisers.\n\n\nMedia Matters for America\n(2022).\n\n\n\nhttps://www.mediamatters.org/elon-musk/less-month-elon-musk-has-driven-away-half-twitters-top-100-advertisers\n\n\n\nKazemi et\u00a0al. (2022)\n\nAshkan Kazemi, Kiran\nGarimella, Gautam\u00a0Kishore Shahi, Devin\nGaffney, and Scott\u00a0A Hale.\n2022.\n\n\nResearch note: Tiplines to uncover misinformation\non encrypted platforms: A case study of the 2019 Indian general election on\nWhatsApp.\n\n\nHarvard Kennedy School Misinformation\nReview (2022).\n\n\n\n\n\n\nKerr (2017)\n\nDara Kerr.\n2017.\n\n\nTech companies\u2019 newest cause celebre? Boycott\nBreitbart.\n\n\nCNET (2017).\n\n\n\nhttps://www.cnet.com/tech/tech-industry/boycott-breitbart-lyft-hewlett-packard-t-mobile-autodesk-uber-amazon/\n\n\n\nKling et\u00a0al. (2012)\n\nCatherine\u00a0L Kling,\nDaniel\u00a0J Phaneuf, and Jinhua Zhao.\n2012.\n\n\nFrom Exxon to BP: Has some number become better\nthan no number?\n\n\nJournal of Economic Perspectives\n26, 4 (2012),\n3\u201326.\n\n\n\n\n\n\nLee et\u00a0al. (2022)\n\nSun\u00a0Kyong Lee, Juhyung\nSun, Seulki Jang, and Shane Connelly.\n2022.\n\n\nMisinformation of COVID-19 vaccines and vaccine\nhesitancy.\n\n\nScientific Reports 12,\n1 (2022), 13681.\n\n\n\n\n\n\nLindsney* and Verhoef* (2001)\n\nRobin Lindsney* and Erik\nVerhoef*. 2001.\n\n\nTraffic congestion and congestion pricing.\n\n\n(2001).\n\n\n\n\n\n\nLoeb et\u00a0al. (2022)\n\nStacy Loeb, Hala\u00a0T Borno,\nScarlett Gomez, Joseph Ravenell,\nAkya Myrie, Tatiana Sanchez\u00a0Nolasco,\nNataliya Byrne, Renee Cole,\nKristian Black, Sabrina Stair,\net\u00a0al. 2022.\n\n\nRepresentation in online prostate cancer content\nlacks racial and ethnic diversity: implications for Black and Latinx men.\n\n\nThe Journal of Urology\n207, 3 (2022),\n559\u2013564.\n\n\n\n\n\n\nLoeb et\u00a0al. (2020)\n\nStacy Loeb, Jacob Taylor,\nJames\u00a0F Borin, Rada Mihalcea,\nVeronica Perez-Rosas, Nataliya Byrne,\nAustin\u00a0L Chiang, and Aisha Langford.\n2020.\n\n\nFake news: spread of misinformation about\nurological conditions on social media.\n\n\nEuropean urology focus 6,\n3 (2020), 437\u2013439.\n\n\n\n\n\n\nLoomba et\u00a0al. (2021)\n\nSahil Loomba, Alexandre de\nFigueiredo, Simon\u00a0J Piatek, Kristen de\nGraaf, and Heidi\u00a0J Larson.\n2021.\n\n\nMeasuring the impact of COVID-19 vaccine\nmisinformation on vaccination intent in the UK and USA.\n\n\nNature human behaviour 5,\n3 (2021), 337\u2013348.\n\n\n\n\n\n\nMetcalf (2009)\n\nGilbert\u00a0E Metcalf.\n2009.\n\n\nDesigning a carbon tax to reduce US greenhouse gas\nemissions.\n\n\nReview of Environmental Economics and\nPolicy (2009).\n\n\n\n\n\n\nMetcalf and Weisbach (2009)\n\nGillbert\u00a0E Metcalf and\nDavid Weisbach. 2009.\n\n\nThe design of a carbon tax.\n\n\nHarv. Envtl. L. Rev. 33\n(2009), 499.\n\n\n\n\n\n\nMurthy (2022)\n\nVivek\u00a0H. Murthy.\n2022.\n\n\nConfronting Health Worker Burnout and Well-Being.\n\n\nNew England Journal of Medicine\n387, 7 (2022),\n577\u2013579.\n\n\n\nhttps://doi.org/10.1056/NEJMp2207252\narXiv:https://doi.org/10.1056/NEJMp2207252\n\n\n\n\nMutombo et\u00a0al. (2022)\n\nPolydor\u00a0Ngoy Mutombo,\nMosoka\u00a0P Fallah, Davison Munodawafa,\nAhmed Kabel, David Houeto,\nTinashe Goronga, Oliver Mweemba,\nGladys Balance, Hans Onya,\nRoger\u00a0S Kamba, et\u00a0al.\n2022.\n\n\nCOVID-19 vaccine hesitancy in Africa: a call to\naction.\n\n\nThe Lancet Global Health\n10, 3 (2022),\ne320\u2013e321.\n\n\n\n\n\n\nof\u00a0the Surgeon\u00a0General et\u00a0al. (2021)\n\nOffice of\u00a0the Surgeon\u00a0General\net\u00a0al. 2021.\n\n\nConfronting health misinformation: The US surgeon\ngeneral\u2019s advisory on building a healthy information environment\n[internet].\n\n\n(2021).\n\n\n\n\n\n\nParry (2002)\n\nIan William\u00a0Holmes Parry.\n2002.\n\n\nComparing the efficiency of alternative policies\nfor reducing traffic congestion.\n\n\nJournal of public economics\n85, 3 (2002),\n333\u2013362.\n\n\n\n\n\n\nPaul (2019)\n\nKari Paul.\n2019.\n\n\nZuckerberg defends Facebook as bastion of \u2019free\nexpression\u2019 in speech.\n\n\nThe Guardian (2019).\n\n\n\nhttps://www.theguardian.com/technology/2019/oct/17/mark-zuckerberg-facebook-free-expression-speech\n\n\n\nPayne (2018)\n\nKeith Payne.\n2018.\n\n\nThe broken ladder: How inequality affects\nthe way we think, live, and die.\n\n\nPenguin.\n\n\n\n\n\n\nPhillips (2018)\n\nWhitney Phillips.\n2018.\n\n\nThe oxygen of amplification.\n\n\n(2018).\n\n\n\n\n\n\nPigou (2002)\n\nArthur Pigou.\n2002.\n\n\nThe economics of welfare.\n\n\nRoutledge.\n\n\n\n\n\n\nQueen (2022)\n\nJack Queen.\n2022.\n\n\nAlex Jones ordered to pay $473 million in punitive\ndamages in Sandy Hook defamation case.\n\n\nReuters (2022).\n\n\n\nhttps://www.reuters.com/legal/alex-jones-must-pay-473-million-punitive-damages-sandy-hook-defamation-case-2022-11-10/\n\n\n\nRathje et\u00a0al. (2023)\n\nSteve Rathje, Jon\nRoozenbeek, Jay\u00a0J Van\u00a0Bavel, and Sander\nvan\u00a0der Linden. 2023.\n\n\nAccuracy and social motivations shape judgements of\n(mis) information.\n\n\nNature Human Behaviour\n(2023), 1\u201312.\n\n\n\n\n\n\nRomer (2019)\n\nPaul Romer.\n2019.\n\n\nA Tax That Could Fix Big Tech.\n\n\nNew York Times (2019).\n\n\n\nhttps://www.nytimes.com/2019/05/06/opinion/tax-facebook-google.html\n\n\n\nScheufele and Krause (2019)\n\nDietram\u00a0A. Scheufele and\nNicole\u00a0M. Krause. 2019.\n\n\nScience audiences, misinformation, and fake news.\n\n\nProceedings of the National Academy of\nSciences 116, 16\n(2019), 7662\u20137669.\n\n\n\nhttps://doi.org/10.1073/pnas.1805871115\narXiv:https://www.pnas.org/doi/pdf/10.1073/pnas.1805871115\n\n\n\n\nShierholz and Zipperer (2017)\n\nHeidi Shierholz and Ben\nZipperer. 2017.\n\n\nHere is what\u2019s at stake with the conflict of\ninterest (\u2018fiduciary\u2019) rule.\n\n\n(2017).\n\n\n\n\n\n\nTaylor (2020)\n\nTimothy Taylor.\n2020.\n\n\nValue of a Statistical Life: Where Does It Come\nFrom?\n\n\nConversable Economist\n(2020).\n\n\n\nhttps://conversableeconomist.com/2020/03/27/value-of-a-statistical-life-where-does-it-come-from/\n\n\n\nVosoughi et\u00a0al. (2018)\n\nSoroush Vosoughi, Deb\nRoy, and Sinan Aral. 2018.\n\n\nThe spread of true and false news online.\n\n\nscience 359,\n6380 (2018), 1146\u20131151.\n\n\n\n\n\n\nWagenaar et\u00a0al. (2010)\n\nAlexander\u00a0C Wagenaar,\nAmy\u00a0L Tobler, and Kelli\u00a0A Komro.\n2010.\n\n\nEffects of alcohol tax and price policies on\nmorbidity and mortality: a systematic review.\n\n\nAmerican journal of public health\n100, 11 (2010),\n2270\u20132278.\n\n\n\n\n\n\nWardle et\u00a0al. (2019)\n\nC Wardle, A Pimenta,\nG Conter, and ND andPedro Burgos.\n2019.\n\n\nComprova: an evaluation of the impact of a\ncollaborative journalism project on brazilian journalists and audiences.\n\n\nFirst Draft (2019).\n\n\n\n\n\n\nWest and Bergstrom (2021)\n\nJevin\u00a0D. West and\nCarl\u00a0T. Bergstrom. 2021.\n\n\nMisinformation in and about science.\n\n\nProceedings of the National Academy of\nSciences 118, 15\n(2021), e1912444117.\n\n\n\nhttps://doi.org/10.1073/pnas.1912444117\narXiv:https://www.pnas.org/doi/pdf/10.1073/pnas.1912444117\n\n\n\n\nWhitson and Galinsky (2008)\n\nJennifer\u00a0A. Whitson and\nAdam\u00a0D. Galinsky. 2008.\n\n\nLacking Control Increases Illusory Pattern\nPerception.\n\n\nScience 322,\n5898 (2008), 115\u2013117.\n\n\n\nhttps://doi.org/10.1126/science.1159845\narXiv:https://www.science.org/doi/pdf/10.1126/science.1159845\n\n\n\n\nWilson (2019)\n\nRichard Wilson.\n2019.\n\n\nCambridge analytica, Facebook, and Influence\nOperations: A case study and anticipatory ethical analysis. In\nEuropean conference on cyber warfare and\nsecurity. Academic Conferences International Limited,\n587\u2013XX.\n\n\n\n\n\n\nXu et\u00a0al. (2021)\n\nAlex\u00a0J Xu, Jacob Taylor,\nTian Gao, Rada Mihalcea,\nVeronica Perez-Rosas, and Stacy Loeb.\n2021.\n\n\nTikTok and prostate cancer: misinformation and\nquality of information using validated questionnaires.\n\n\n(2021).\n\n\n\n\n\n\nZellers et\u00a0al. (2019)\n\nRowan Zellers, Ari\nHoltzman, Hannah Rashkin, Yonatan Bisk,\nAli Farhadi, Franziska Roesner, and\nYejin Choi. 2019.\n\n\nDefending Against Neural Fake News. In\nAdvances in Neural Information Processing\nSystems, H.\u00a0Wallach,\nH.\u00a0Larochelle, A.\u00a0Beygelzimer,\nF.\u00a0d'Alch\u00e9-Buc,\nE.\u00a0Fox, and R.\u00a0Garnett (Eds.),\nVol.\u00a032. Curran Associates, Inc.\n\n\n\nhttps://proceedings.neurips.cc/paper/2019/file/3e9f0fc9b2f89e043bc6233994dfcf76-Paper.pdf\n\n\n\n\n\n\n\nGenerated  on Thu Jul 13 17:55:33 2023 by LATExml\n\n\n\n\n"}, {"id": "http://arxiv.org/abs/2310.02095v2", "title": "A Survey on the Role of Crowds in Combating Online Misinformation:\n  Annotators, Evaluators, and Creators", "contents": "\n\n\n\nA Survey on the Role of Crowds in Combating Online Misinformation: Annotators, Evaluators, and Creators\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1 Introduction\n\n1.1 Motivation\n1.2 Our Work\n1.3 Related Survey\n1.4 Contributions\n\n\n2 Method of Identifying Relevant Papers\n\n3 Data Statistics of Papers\n\n\n3.1 Misinformation\n\n3.1.1 Formats and Topics\n3.1.2 Platforms\n\n\n\n3.2 Crowd Inputs\n\n3.2.1 Content Formats\n3.2.2 Features Extracted from Crowd Inputs\n\n\n\n\n\n4 Crowds as Annotators for Identifying Misinformation\n\n4.1 Individual Labeling\n4.2 Collaborative Labeling\n4.3 Machine-assisted Labeling\n\n\n\n5 Crowds as Evaluators for Assessing Counter-Misinformation Effectiveness\n\n\n5.1 Crowd-based Evaluation Methods\n\n5.1.1 Direct Assessment\n5.1.2 Indirect Assessment\n\n\n\n5.2 Findings from Effective Counter-Misinformation\n\n5.2.1 Media Formats\n5.2.2 Content Traits\n5.2.3 Communication Styles\n5.2.4 Audience Factors\n5.2.5 Countering Order and Word Placement\n\n\n\n\n\n6 Crowds as Creators of Counter-Misinformation\n\n6.1 Characterization Methods\n\n6.2 Creation Patterns\n\n6.2.1 Language Analysis\n6.2.2 Network Analysis\n6.2.3 User Engagement Analysis\n6.2.4 Temporal Analysis\n\n\n\n6.3 Creator Profiles\n\n6.3.1 Demographics\n6.3.2 Mindsets\n\n\n\n\n\n7 Discussion and Future Directions\n\n7.1 Discussion\n7.2 Future Directions\n\n\n8 Conclusions\n\n\n\n\n\nA Survey on the Role of Crowds in Combating Online Misinformation: Annotators, Evaluators, and Creators\n\n\nBing He\n\nGeorgia Institute of TechnologyUSA\n\nbhe46@gatech.edu\n\n,\u00a0\nYibo Hu\n\nGeorgia Institute of TechnologyUSA\n\nyibo.hu@gatech.edu\n\n,\u00a0\nYeon-Chang Lee\n\nUlsan National Institute of Science and Technology (UNIST)Korea\n\nyeonchang@unist.ac.kr\n\n,\u00a0\nSoyoung Oh\n\nSaarland UniversityGermany\n\nsoyoung@lst.uni-saarland.de\n\n,\u00a0\nGaurav Verma\n\nGeorgia Institute of TechnologyUSA\n\ngverma@gatech.edu\n\n\u00a0and\u00a0\nSrijan Kumar\n\nGeorgia Institute of TechnologyUSA\n\nsrijan@gatech.edu\n\n\n\nAbstract.\nOnline misinformation poses a global risk with significant real-world consequences. To combat misinformation, current research relies on professionals like journalists and fact-checkers for annotating and debunking false information, while also developing automated machine learning methods for detecting misinformation. Complementary to these approaches, recent research has increasingly concentrated on utilizing the power of ordinary social media users, a.k.a. \u201cthe crowd\u201d, who act as eyes-on-the-ground proactively questioning and countering misinformation. Notably, recent studies show that 96% of counter-misinformation responses originate from them. Acknowledging their prominent role, we present the first systematic and comprehensive survey of research papers that actively leverage the crowds to combat misinformation.\nIn this survey, we first identify 88 papers related to crowd-based efforts111https://github.com/claws-lab/awesome-crowd-combat-misinformation, following a meticulous annotation process adhering to the PRISMA framework (preferred reporting items for systematic reviews and meta-analyses).\nWe then present key statistics related to misinformation, counter-misinformation, and crowd input in different formats and topics.\nUpon holistic analysis of the papers, we introduce a novel taxonomy of the roles played by the crowds in combating misinformation:\n(i) crowds as annotators who actively identify misinformation;\n(ii) crowds as evaluators who assess counter-misinformation effectiveness;\n(iii) crowds as creators who create counter-misinformation.\nThis taxonomy explores the crowd\u2019s capabilities in misinformation detection, identifies the prerequisites for effective counter-misinformation, and analyzes crowd-generated counter-misinformation.\nIn each assigned role, we conduct a detailed analysis to categorize the specific utilization of the crowd. Particularly, we delve into (i) distinguishing individual, collaborative, and machine-assisted labeling for annotators; (ii) analyzing the effectiveness of counter-misinformation through surveys, interviews, and in-lab experiments for evaluators; and (iii) characterizing creation patterns and creator profiles for creators.\nFinally, we conclude this survey by outlining potential avenues for future research in this field.\n\nMisinformation, Combat misinformation, Crowd, Survey, Counter-misinformation\n\n\u2020\u2020copyright: acmlicensed\u2020\u2020journal: TKDD\u2020\u2020journalyear: 2024\u2020\u2020journalvolume: 1\u2020\u2020journalnumber: 1\u2020\u2020article: 1\u2020\u2020publicationmonth: 1\u2020\u2020doi: 10.1145/3694980\u2020\u2020price: 15.00\u2020\u2020isbn: 978-1-4503-XXXX-X/18/06\u2020\u2020ccs: Information systems\u00a0Data mining\u2020\u2020ccs: Information systems\u00a0Social networks\n\n\n1. Introduction\n\nMost individuals today rely on social media platforms as their primary source of news and information (Walker and Matsa, 2021).\nHowever, such platforms contain a plethora of unreliable information, including misinformation, which unfortunately spreads more rapidly and widely than truth (Vosoughi et\u00a0al., 2018).\nOnline misinformation harms individuals and society at multiple levels.\nAt the micro-level, misinformation harms well-being\u00a0(Verma et\u00a0al., 2022), increases polarization\u00a0(Stewart et\u00a0al., 2018), and leads to online harassment and violent attacks on individuals and communities\u00a0(Chua et\u00a0al., 2017).\nAt the macro-level, misinformation questions democratic processes and elections\u00a0(Silverman, 2016),\nimpacts science and global public health\u00a0(Memon and Carley, 2020; Dai et\u00a0al., 2022; Xue et\u00a0al., 2022).\nFor instance, misinformation about the COVID-19 vaccine (e.g., the vaccine causes infertility) has reduced vaccine uptake and prolonged the pandemic (Memon and Carley, 2020; Dai et\u00a0al., 2022; Xue et\u00a0al., 2022); misinformation about elections can undermine trust in democratic processes and institutions (Cohen et\u00a0al., 2020).\nTherefore, it is crucial to curb the spread of online misinformation and to counter misinformation (Sun et\u00a0al., 2020; Zhao et\u00a0al., 2016; Vosoughi et\u00a0al., 2018).\n\n\nMotivated by this, research has focused on detecting misinformation by utilizing different approaches, including automated machine learning (ML) solutions\u00a0(Sharma et\u00a0al., 2019; Guo et\u00a0al., 2019; Islam et\u00a0al., 2020) and the use of professional fact-checkers\u00a0(Micallef et\u00a0al., 2022; Porter and Wood, 2021; Markowitz et\u00a0al., 2023).\nNotably, there has been a growing interest in research on developing ML models\u00a0(Sharma et\u00a0al., 2019) based on post content, poster attributes, social network, temporal aspects, and propagation features\u00a0(Shu et\u00a0al., 2020).\nThese models have been deployed across widely-used web and social media platforms (e.g., Twitter (\nTwitter was renamed as \u201cX\u201d in July 2023. We continue to refer to the platform as \u201cTwitter\u201d for illustration in this survey.), Facebook, and YouTube).\nIn the meantime, ML solutions rely on ground truth labels of misinformation for their training and validation, whereas professional fact-checkers typically label the misinformation with fact-check labels.\nThese professionals also write fact-checking articles to explain their reasoning for the label determinations.\nFor example, Snopes.com provides fact-check labels that range from \u201ctrue\u201d and \u201cmostly true\u201d to \u201cmostly false\u201d and \u201cfalse\u201d, accompanied by corresponding explanations.\n\n\nDespite these solutions, the \u201cinfodemic\u201d, or the epidemic of misinformation\u00a0(Borah et\u00a0al., 2021; Chen and Fu, 2022; Xue et\u00a0al., 2022), continues to grow at an alarming rate.\nOne contributing factor is that automated ML models respond slowly to changes in the information ecosystem, rely on fact-check labels provided by professional fact-checkers, and are vulnerable to manipulation by adversaries (Allen et\u00a0al., 2021; He et\u00a0al., 2021a; Roitero et\u00a0al., 2021).\nOn the other hand, professional fact-checkers face constraints in terms of the limited number of fact-checkers and the significant time required for label generation; moreover, their fact-checks tend to address only a small number of viral claims\u00a0(Allen et\u00a0al., 2021; Pennycook and Rand, 2019; Micallef et\u00a0al., 2022).\nImportantly, both approaches only detect misinformation but do not actively engage with misinformation spreaders.\nIn this context, it is worth noting that there has been a noticeable absence of discussion on structured methods for countering misinformation once it is identified.\n\n\n\n1.1. Motivation\n\nTo address the drawbacks of these two approaches, leveraging crowds offers a promising solution in a scalable and proactive manner (Allen et\u00a0al., 2021; Ma et\u00a0al., 2023).\nIn this study, we focus on the \u201ccrowd\u201d \u2014 defined as ordinary users of social media platforms (i.e., not fact-checkers, journalists, or organizations).\nThey serve as eyes on the ground who proactively question and counter misinformation, including emerging misinformation\u00a0(Bode and Vraga, 2018; He et\u00a0al., 2023).\nLiterature has shown that crowd-based \u201csocial correction\u201d is effective and works well across topics\u00a0(Bode and Vraga, 2018; Ma et\u00a0al., 2023).\n\nCrowds combat misinformation by contributing significantly to diverse tasks\n, including identifying misinformation, assessing counter-misinformation effectiveness, and creating counter-misinformation.\nIn addition, crowds also have the key benefit of being \u201ccost-effective \u201d by countering online misinformation voluntarily for collective efforts\u00a0(Mujumdar and Kumar, 2021; Allen et\u00a0al., 2022),\nespecially when compared to the expensive and time-consuming recruitment of professional fact-checkers.\nTherefore, there has been a surge of research efforts to develop crowd-based methodologies to annotate misinformation, evaluate counter-misinformation effectiveness, and characterize counter-misinformation creation in recent years (Bhuiyan et\u00a0al., 2020; Chen et\u00a0al., 2021; Zhang et\u00a0al., 2022; Wang et\u00a0al., 2022b, 2021; Allen et\u00a0al., 2021; Mujumdar and Kumar, 2021; Shabani and Sokhn, 2018).\nGiven the growing and significant interest in this area, we investigate the crowd-based research efforts in combating online misinformation.\n\n\n\n{forest}\n\n\nfor tree=\ngrow\u2019=0,\ndraw,\nalign=c,\nrounded corners,\nparent anchor=east,\nchild anchor=west,\nl sep=30,\ntext centered,\ntext width=90,\nedge path=[\\forestoptionedge] (!u.parent anchor) \u2013 ++(20pt,0) \u2014- (.child anchor)\\forestoptionedge label;\n\n,\n[Combating\nMisinformation,text width=60\n[By Automated\nML Classifiers, l=5, text width=60]\n[By Professionals, l=5, text width=60]\n[By Crowds\n(Our survey), l=5, text width=60\n[Annotators for\nIdentifying Misinformation\n(Section 4),\n[Individual Labeling\n(Section 4.1)]\n[Collaborative Labeling\n(Section 4.2)]\n[Machine-assisted Labeling\n(Section 4.3)]\n]\n[Evaluators for Assessing\nCounter-Misinformation\nEffectiveness (Section 5),\n[Evaluation Methods\n(Section 5.1)]\n[Findings from Effective\nCounter-Misinformation\n(Section 5.2)]\n]\n[Creators of Counter-\nMisinformation\n(Section 6),\n[Characterization Methods\n(Section 6.1)]\n[Creation Patterns\n(Section 6.2)]\n[Creator Profiles\n(Section 6.3)]\n]\n]\n]\n\n\n\nFigure 1. Two existing approaches to combat misinformation and our proposed taxonomy hierarchy related to crowd-based efforts.\n\n\n\n\n1.2. Our Work\n\nIn this survey, we aim to provide a comprehensive overview of the collaborative efforts made by crowds in combating misinformation.\nTo clarify our scope, we focus on online misinformation222The term \u201cmisinformation\u201d in this survey is commonly represented as the terms \u201cfake news\u201d, \u201crumor\u201d, \u201cfalse information\u201d, \u201cfalse news\u201d, and \u201cconspiracy theory.\u201d , rather than all information or offline information.\n\nMore specifically, our investigation centers on actively pursued efforts in combating misinformation within this field.\n\n\nFigure 2. Illustration of the roles of crowds in combating misinformation.\n\n\nWe first identify 88 relevant papers by following the guidelines of the preferred reporting items for systematic reviews and meta-analyses (PRISMA framework) (Moher et\u00a0al., 2009) (Section\u00a02).\nWe then present a detailed overview of misinformation formats, topics, social media platforms, and crowd inputs (Section\u00a03).\nUpon holistic analysis of the papers, we propose a novel taxonomy of the crowd-based efforts, as depicted in Figure\u00a01.\nTo this end, we categorize crowd users based on their roles, as shown in Figure\u00a02:\n\n\n\n\n\u2022\n\nCrowds as Annotators: Crowds help identify and label online misinformation accurately at scale\u00a0(Bhuiyan et\u00a0al., 2020), leveraging their extensive numbers compared to the limited professional fact-checker pool, and their widespread presence across social media platforms.\nAdditionally, crowds can amplify the efforts of fact-checkers by sharing fact-checking articles out of a sense of social responsibility (Pal et\u00a0al., 2019), driven by emotions such as anger or concern provoked by fact-checks (Sun et\u00a0al., 2021), and a desire to warn others against misinformation (Veeriah, 2021).\n\n\n\n\u2022\n\nCrowds as Evaluators: Crowds help evaluate the effectiveness and limitations of different counter-misinformation messages across various aspects. They contribute by providing their first-hand experiences and tangible responses to misinformation and counter-misinformation.\nThis valuable input facilitates the design of effective strategies to counter misinformation and offers a unique perspective not always accessible to professional fact-checkers\u00a0(Borah et\u00a0al., 2021).\n\n\n\n\u2022\n\nCrowds as Creators: Crowds create posts on social media platforms to combat misinformation\u00a0(Nadamoto et\u00a0al., 2013; Chua et\u00a0al., 2017).\nThey also respond to and comment on misinformation with accurate information (Guo et\u00a0al., 2019).\nAnalyzing such activities allows us to characterize the creators and patterns of their counter-misinformation messages.\n\n\n\n\n\nWe frame our examination of this topic around three research questions (RQs) that naturally align with the aforementioned roles of the crowds:\n\n\n\n\n\u2022\n\n(RQ1) Capabilities of crowds in identifying misinformation:\nHow do crowds contribute to identifying or detecting misinformation, and how effective are they in this task?\n\n\n\n\u2022\n\n(RQ2) Evaluation of counter-misinformation effectiveness by crowds:\nHow can crowds be leveraged to evaluate counter-misinformation efficacy, and how effective are different types of counter-misinformation?\n\n\n\n\u2022\n\n(RQ3) Characterization of counter-misinformation messages by crowds: What are the characteristics of crowd-generated counter-misinformation messages and crowds who counter misinformation?\n\n\n\n\n\nHowever, addressing the above RQs systematically poses several challenges.\nFirst, online misinformation spans a wide range of topics, including politics and natural disasters, and is disseminated across various platforms like Twitter and YouTube.\nMeanwhile, crowds engage differently based on their roles, including annotators, evaluators, and creators.\nAdditionally, they counter misinformation across a range of content formats, including text and images.\nLastly, researchers employ diverse approaches, such as in-lab experiments, interviews, and surveys, when analyzing crowd-based efforts in countering misinformation.\n\n\nTo navigate these challenges, our work to address each RQ can be summarized as follows:\n\n\n\n\n\u2022\n\nCrowds as annotators for identifying misinformation (for RQ1; Section\u00a04): We investigate the capability of crowds to identify misinformation and compare it with that of professional fact-checkers.\nWe analyze individual and collective labeling scenarios, as well as the machine-assisted setting where humans and machines collaborate to enhance the annotation performance.\n\n\n\n\u2022\n\nCrowds as evaluators for assessing the effectiveness of counter-misinformation (for RQ2; Section 5):\nWe examine direct and indirect evaluation methods, including expressed sentiment and stance, in-lab experiments, interviews, and surveys, to quantify the efficacy of a given counter-misinformation message. Then, we investigate the distinct advantages offered by each counter-misinformation approach.\n\n\n\n\u2022\n\nCrowds as counter-misinformation creators (for RQ3; Section\u00a06):\nWe examine two aspects of counter-misinformation characteristics:\ni) the characteristics of counter-misinformation messages generated by the crowds on social media platforms;\nii) typical attributes of crowds who counter misinformation.\n\n\n\n\n\nThrough these investigations, we provide valuable insights into the effectiveness and limitations of existing crowd-based efforts in combating misinformation.\n\n\nTable 1. Comparison with existing surveys. In this table, \u2018\u2713\u2019 and \u2019\n\\textpdfrender\nTextRenderingMode=Stroke,\nLineWidth=1.0pt,\nLineDashPattern=[1 2]0,\n\u2713\n\u2019 denote that the relevant survey fully and partially covered the corresponding topic, respectively.\n\n\n\n\nCrowds\u2019 Roles\n\n\n\n\n\n\n\nAnnotators for identi-\n\n\n\nfying misinformation\n\n\n\n\n\n\n\nEvaluators for assessing\n\n\n\ncounter-misinformation\n\n\n\n\n\n\n\nCreators of\n\n\n\ncounter-misinformation\n\n\n\n\n\n(Wang et\u00a0al., 2019; Suarez-Lledo and Alvarez-Galvez, 2021)\n\n\n\n\n\n(Sharma et\u00a0al., 2019; Guo et\u00a0al., 2019; Shuhud et\u00a0al., 2017)\n\n\\textpdfrender\nTextRenderingMode=Stroke,\nLineWidth=1.0pt,\nLineDashPattern=[1 2]0,\n\u2713\n\n\n\n\n\n(Chan et\u00a0al., 2017; Hartwig et\u00a0al., 2023)\n\n\n(Chan et\u00a0al., 2017): \u2713, (Hartwig et\u00a0al., 2023): \n\\textpdfrender\nTextRenderingMode=Stroke,\nLineWidth=1.0pt,\nLineDashPattern=[1 2]0,\n\u2713\n\n\n\n\nOur work\n\u2713\n\u2713\n\u2713\n\n\n\n\n\n\n\n1.3. Related Survey\n\nWhile most surveys on misinformation focus on automated machine learning solutions\u00a0(Islam et\u00a0al., 2020), it is worth noting that a few surveys (Sharma et\u00a0al., 2019; Shuhud et\u00a0al., 2017; Guo et\u00a0al., 2019; Chan et\u00a0al., 2017; Hartwig et\u00a0al., 2023) cover crowd-based efforts.\nHowever, these previous surveys have certain limitations, and we aim to provide a more comprehensive perspective. Here\u2019s a comparison between our survey and previous ones, as shown in Table 1.\n\n\nFirst, some surveys (Sharma et\u00a0al., 2019; Shuhud et\u00a0al., 2017; Guo et\u00a0al., 2019) have examined crowds\u2019 ability to identify misinformation (i.e., annotators).\nThey infer misinformation-related signals from indirect crowd behaviors, such as replies and comments, and incorporate those signals into ML solutions as labels.\nHowever, as mentioned in Section\u00a01.1, our survey recognizes and investigates the potential for crowds to serve as a direct and potent means for accurately identifying and labeling misinformation at a large scale. This distinction sets our survey apart from the prior research.\nSecond, Chan et\u00a0al. (2017) summarize the effectiveness of various types of counter-misinformation evaluated by crowds (i.e., evaluators).\nHowever, this survey has limitations as it only covers 8 papers, is restricted to literature published before 2018, and does not explore the evaluation methods employed by crowds.\nHartwig et\u00a0al. (2023) analyze the user-centered misinformation interventions where crowds implicitly or explicitly evaluate certain intervention techniques. Nevertheless, some interventions are not related to counter-misinformation contents, e.g., the removal of misinformation.\nIn contrast, our survey addresses these limitations through a rigorous paper search process for recent papers and summarizes the metrics and methods used to evaluate the efficacy of counter-misinformation.\nThird, none of the existing surveys cover the characterization of counter-misinformation from the perspective of the crowds (i.e., creators).\nThis is a notable gap as understanding the characteristics of crowd-generated counter-misinformation can offer valuable insights for devising effective strategies to combat misinformation.\nOur survey fills this gap by comprehensively analyzing\nthe patterns of existing counter-misinformation messages generated by crowds, and identifying and profiling typical attributes of these crowd creators.\n\n\n\n\n1.4. Contributions\n\nIn sum, the main contributions of this survey are:\n\n\n\u2022\n\nComprehensive Survey: We systematically identify the relevant papers on the crowd-based efforts in combating misinformation and then review them regarding detection of misinformation, evaluation of counter-misinformation effectiveness, and characterization of counter-misinformation creation.\nTo the best of our knowledge, this is the first review of the literature that encompasses crowds\u2019 contributions to these three crucial aspects.\n\n\n\n\u2022\n\nKey Statistics: We summarize important data statistics regarding misinformation and crowds found in the literature.\nThis contains the common formats and topics of misinformation, the social media platforms where crowds engage, and the inputs made by the crowds.\n\n\n\n\u2022\n\nNovel Taxonomy: We provide a novel taxonomy of approaches that comprehensively covers the diverse functions of crowds.\nThis is designed to help researchers understand the current research trends in this area.\n\n\n\n\u2022\n\nThorough Analysis: We conduct a comprehensive analysis of each crowd role, including individual, collaborative, and machine-assisted labeling for annotators, survey, interview, and in-lab experiment-based counter-misinformation effectiveness assessment for evaluators, and the characterization of creation patterns and creator profiles for creators.\n\n\n\n\u2022\n\nFuture Directions: We discuss the limitations of existing crowd-based approaches to combat misinformation and suggest several promising research directions for the future.\n\n\n\n\n\n\n\n\n2. Method of Identifying Relevant Papers\n\nFollowing PRISMA guidelines (Moher et\u00a0al., 2009), we conducted a comprehensive search for relevant papers on www.scopus.com, a reputable scientific database.\nThe following query was executed on September 22, 2022, and yielded 3,956 papers.\n\n\n\n\nTITLE-ABS-KEY\u00a0(\u00a0(Category\u00a0#1)\u00a0AND\u00a0\u00a0(\u00a0Category\u00a0#2\u00a0)\u00a0AND\u00a0\u00a0(\u00a0Category\u00a0#3\u00a0)\u00a0AND\u00a0\u00a0(\u00a0Category\u00a0#4\u00a0)\u00a0)\nAND\u00a0\u00a0PUBYEAR\u00a0\u00a0>\u00a0\u00a01999\u00a0\u00a0AND\u00a0\u00a0(\u00a0LIMIT-TO\u00a0(\u00a0LANGUAGE,\u00a0\u00a0\"English\"\u00a0)\u00a0)\n\n\n\nWe specifically targeted research articles in English published after 1999.\nThe search utilized information from titles, abstracts, and keywords of these articles, referred to as \u201cTITLE-ABS-KEY\u201d. The search combined four categories of information using logical \u201cAND\u201d.\nThese categories and their definitions are provided in Table 2.\nKeywords within each category were combined using the \u201cOR\u201d operator to ensure that all related concepts were included, and the wildcard \u201c*\u201d was used to account for multiple spelling variations.\nSpecifically, Category 1 deals with terms related to crowds, particularly non-experts, engaged in countering misinformation.\nCategory 2 is related to online platforms where crowd reactions to misinformation are observed.\nCategory 3 covers misinformation-related terms and synonyms.\nLastly, Category 4 indicates actions that hinder the spread of misinformation.\n\n\nTable 2. The collection of keywords used to search relevant papers.\n\n\n\nCategories\n\n\nKeywords\n\n\n\n\n\n\nCategory 1\n\n\ncrowd OR citizen OR community OR crowdsourcing OR group OR user OR people OR society OR human OR individual\n\n\n\n\nCategory 2\n\n\nweb OR \"social media\" OR \"social network\" OR internet OR online OR twitter OR facebook OR instagram OR whatsapp OR weibo OR wechat OR reddit OR tumblr\n\n\n\n\nCategory 3\n\n\nmisinformation OR fake OR misleading OR disinformation OR conspiracy OR rumors OR \"false information\" OR hoax OR *infodemic\n\n\n\n\nCategory 4\n\n\ncounter* OR fight* OR respond* OR argu* OR negate* OR \"fact check*\" OR reply* OR dispute* OR respond* OR refute* OR debunk* OR flag* OR judg* OR combat* OR censor* OR correct* OR block*\n\n\n\n\n\n\n\nTo ensure the inclusion of only relevant papers in our survey, we rigorously followed PRISMA guidelines and established the following inclusion criteria:\nFirst, the paper must explicitly mention crowds\u2019 active community engagement. This involvement typically encompasses crowd inputs such as annotations, replies to, or comments on online misinformation; or responses related to counter-misinformation collected through surveys, in-lab experiments, and interviews.\nSecond, the purpose of the aforementioned  crowd engagements or the associated research papers should be combating misinformation.\nThis implies that the paper should employ these  crowd engagements to mitigate the negative impacts of misinformation and promote the positive effects of counter-misinformation for combating misinformation.\nThese actions may include detecting misinformation, evaluating counter-misinformation effectiveness, and characterizing counter-misinformation.\n\n\nThese criteria were established through extensive discussions between two authors to ensure the selection of papers within the intended topic.\nEach author initially assessed a batch of 200 papers among the total of 3,956 papers together to establish the annotation criteria and check the inter-rater agreement score.\nPapers were categorized as \u201cYes\u201d if they explicitly met both criteria,\n\u201cNo\u201d if they didn\u2019t focus on the research topic or were proposal articles, and \u201cMaybe\u201d if there was some degree of confidence in their relevance.\nSubsequently, an inter-rater reliability analysis was conducted, yielding a Krippendorff\u2019s alpha score (Krippendorff, 2011) of 0.571, indicating a moderate level of agreement\u00a0(McHugh, 2012).\nThis seemingly low but acceptable value accounts for some overlap between \u201cMaybe\u201d and \u201cYes\u201d labels for the same papers, which was resolved during the collaborative review.\nParticularly, in the collaborative review, two authors discuss and finalize the label for the confusing \u201cMaybe\u201d papers after reading the full paper.\nWe eventually had 19 \u201cYes\u201d papers and 181 \u201cNo\u201d papers for the initial batch of 200 papers.\nNext, we repeat the process for the remaining 3,756 papers where each author annotated 1,878 papers separated and finally had 40 \u201cYes\u201d, 121 \u201cMaybe\u201d, and 3,595 \u201cNo\u201d papers. Likewise, two authors had the collaborative review for these 121 \u201cMaybe\u201d papers and identified 29 \u201cYes\u201d papers.\n\nUltimately, this comprehensive process identified 88 papers for our survey by combining the results of the first, second, and third passes \u2013 the first pass identified 19 \u201cYes\u201d papers, the second identified 40 papers, and the third identified 29 papers.\nFigure 3 displays the annual distribution of our selected papers categorized by the role of the crowd.\n\n\nFigure 3. Annual distribution of annotated relevant papers in our survey categorized by the role of the crowd. \n\n\n\n\n3. Data Statistics of Papers\n\nWe  summarize the selected papers in the survey, examining relevant statistics regarding the formats of misinformation, covered topics, utilized social media platforms, and crowd inputs. This overview offers scholars a preliminary understanding of the research field.\n\n\n\n3.1. Misinformation\n\nTable 3. Overview of misinformation statistics in surveyed papers.\n\n\n\n\nCategories\nReferences\n\n\n\n\n(a) Topics\n\nPolitics\n(Chua et\u00a0al., 2017; Masullo and Kim, 2021; Cohen et\u00a0al., 2020; Chua and Banerjee, 2017; Goh et\u00a0al., 2017; Shabani and Sokhn, 2018; Soprano et\u00a0al., 2021; Li et\u00a0al., 2020; Dang et\u00a0al., 2016; Martel et\u00a0al., 2021)\n\n\nNatural Disasters\n(Nadamoto et\u00a0al., 2013; Flores-Saviaga and Savage, 2021; Bhuiyan et\u00a0al., 2020; Hunt et\u00a0al., 2020; Wang and Zhuang, 2018; Weber et\u00a0al., 2020; Li et\u00a0al., 2020)\n\n\nHealth Issues\n(Gunaratne et\u00a0al., 2019; Stojanov, 2015; Featherstone and Zhang, 2020; Kim et\u00a0al., 2021; Vraga et\u00a0al., 2021; van\u00a0der Meer and Jin, 2020; Masullo and Kim, 2021; Allen et\u00a0al., 2021; Pal et\u00a0al., 2019, 2018; Memon and Carley, 2020; Ahmed et\u00a0al., 2020; Micallef et\u00a0al., 2020; Igbinovia et\u00a0al., 2021; Borah et\u00a0al., 2021; Veeriah, 2021; Al-Motlaq, 2021; Sun et\u00a0al., 2021; Bode and Vraga, 2018; Xue et\u00a0al., 2022; Kim and Chen, 2022)\n\n\nCrisis Events\n(Zeng et\u00a0al., 2019; Wang and Zhuang, 2018; McCreadie et\u00a0al., 2015; Jung et\u00a0al., 2020; Lee et\u00a0al., 2021; Babcock et\u00a0al., 2019b; Arif et\u00a0al., 2017; Zhao et\u00a0al., 2016; Zubiaga et\u00a0al., 2016)\n\n\nCivic Topics\n(Pal et\u00a0al., 2018, 2017; Tanaka and Hirayama, 2019; Mancosu and Vegetti, 2021; Chua et\u00a0al., 2017; Chua and Banerjee, 2017; Allen et\u00a0al., 2021; Li et\u00a0al., 2020; Pennycook and Rand, 2019; Babcock et\u00a0al., 2019b, a; Vafeiadis et\u00a0al., 2019; Tchakount\u00e9 et\u00a0al., 2020)\n\n\nGeneral Topics\n(Vo and Lee, 2019; Kirchner and Reuter, 2020; Mitra and Gilbert, 2015; Ramachandran et\u00a0al., 2020; Pal et\u00a0al., 2019; Giachanou et\u00a0al., 2022)\n\n\n\n\n(b) Platforms\n\nSocial Media\nTwitter\n(Nadamoto et\u00a0al., 2013; Lee et\u00a0al., 2021; Chua and Banerjee, 2017; Gunaratne et\u00a0al., 2019; Zubiaga et\u00a0al., 2016; Micallef et\u00a0al., 2020; Babcock et\u00a0al., 2019b; Ahmed et\u00a0al., 2020; Flores-Saviaga and Savage, 2021; Hunt et\u00a0al., 2020; Jung et\u00a0al., 2020; Goh et\u00a0al., 2017; Babcock et\u00a0al., 2019a; Arif et\u00a0al., 2017; Memon and Carley, 2020; Wang and Zhuang, 2018; Weber et\u00a0al., 2020; Pal et\u00a0al., 2018, 2017; Charlesworth\u00a0Z., 2021; Giachanou et\u00a0al., 2022; Buchanan et\u00a0al., 2022)\n\n\nFacebook\n(Al-Motlaq, 2021; Allen et\u00a0al., 2021; Flores-Saviaga and Savage, 2021; Charlesworth\u00a0Z., 2021; Xue et\u00a0al., 2022)\n\n\nYouTube\n(Kim and Chen, 2022; Buchanan et\u00a0al., 2022)\n\n\nReddit\n(Dang et\u00a0al., 2016; Achimescu and Chachev, 2020)\n\n\nSina Weibo\n(Zeng et\u00a0al., 2019; Li et\u00a0al., 2020)\n\n\nZhihu\n(Chen et\u00a0al., 2022)\n\n\nWhatsapp\n(Kligler-Vilenchik, 2022)\n\n\nCrowdsourcing\nAMT\n(Featherstone and Zhang, 2020; Pennycook and Rand, 2019; Soprano et\u00a0al., 2021; Martel et\u00a0al., 2021; Sun et\u00a0al., 2021)\n\n\nOthers\n(Orosz et\u00a0al., 2016; Stojanov, 2015; Mancosu and Vegetti, 2021; van\u00a0der Meer and Jin, 2020; Sun et\u00a0al., 2020; Igbinovia et\u00a0al., 2021; Bhuiyan et\u00a0al., 2020; Borah et\u00a0al., 2021; Veeriah, 2021; Pundir et\u00a0al., 2021; Zhao et\u00a0al., 2016; Masullo and Kim, 2021; Cohen et\u00a0al., 2020; Vraga et\u00a0al., 2021; Mitra and Gilbert, 2015; Tanaka and Hirayama, 2019; Kim et\u00a0al., 2021; Bode and Vraga, 2018; McCreadie et\u00a0al., 2015; Vafeiadis et\u00a0al., 2019; Pal et\u00a0al., 2019; Kirchner and Reuter, 2020; Shabani and Sokhn, 2018)\n\n\nOther Platforms\n(Ramachandran et\u00a0al., 2020; Pal et\u00a0al., 2019)\n\n\n\n\n\n\n3.1.1. Formats and Topics\n\nCountered misinformation mainly comprises textual content e.g., posts on social media platforms .\nResearch has explored a diverse range of misinformation topics, as summarized in Table\u00a03-(a).\nThese topics consist of politics (e.g., elections (Cohen et\u00a0al., 2020) and immigration (Masullo and Kim, 2021)); natural disasters (e.g., earthquakes (Nadamoto et\u00a0al., 2013) and climate change (Bhuiyan et\u00a0al., 2020));\nhealth issues (e.g., COVID-19 pandemic (Micallef et\u00a0al., 2020; Xue et\u00a0al., 2022; Kim and Chen, 2022; Buchanan et\u00a0al., 2022), vaccines (Stojanov, 2015; Gunaratne et\u00a0al., 2019; Xue et\u00a0al., 2022), and genetically modified organisms\u00a0(Chen et\u00a0al., 2022)); crisis events (e.g., mass shooting (Lee et\u00a0al., 2021));\nand other civic subjects, including rumors about brands KFC (Pal et\u00a0al., 2018, 2017), celebrities (Chua et\u00a0al., 2017; Chua and Banerjee, 2017), and movies (Babcock et\u00a0al., 2019b, a).\nThe research also addresses generic misinformation topics obtained from online fact-checking sources like Snopes.com and PolitiFact.com (Vo and Lee, 2019; Kirchner and Reuter, 2020).\n\n\n\n\n3.1.2. Platforms\n\nThe crowds actively combat misinformation across various online platforms  primarily  as counter-misinformation creators, including social media platforms like Twitter and Facebook.\nAdditionally, crowd-sourcing platforms like Amazon Mechanical Turk (AMT) are leveraged to collect annotation of misinformation and evaluation of counter-misinformation effectiveness .\nA summary of these platforms can be found in Table\u00a03-(b).\n\n\nTable 4. Overview of crowd inputs statistics in surveyed papers.\n\n\n\nCategories\nReferences\n\n\n\n\n\n\n(a)\n\nFormat\n\n\n\nText\n(Zeng et\u00a0al., 2019; Ahmed et\u00a0al., 2020; Flores-Saviaga and Savage, 2021; Jung et\u00a0al., 2020; Goh et\u00a0al., 2017; Arif et\u00a0al., 2017; Memon and Carley, 2020; Wang and Zhuang, 2018; Li et\u00a0al., 2020; Pal et\u00a0al., 2017; Xue et\u00a0al., 2022; Giachanou et\u00a0al., 2022; Micallef et\u00a0al., 2020; Chen et\u00a0al., 2022; Kligler-Vilenchik, 2022)\n\n\n\nImage\n(Dang et\u00a0al., 2016; Pal et\u00a0al., 2017; Chua and Banerjee, 2017; Buchanan et\u00a0al., 2022)\n\n\n\nVideo\n(Kim and Chen, 2022)\n\n\n\n\n(b) Features\n\nExplicit\nFlagging Misinformation\n(Mujumdar and Kumar, 2021; Allen et\u00a0al., 2022)\n\n\nCredibility of News\n(Bhuiyan et\u00a0al., 2020; Mitra and Gilbert, 2015; Allen et\u00a0al., 2021; McCreadie et\u00a0al., 2015; Vraga et\u00a0al., 2021; Orosz et\u00a0al., 2016; Mancosu and Vegetti, 2021; van\u00a0der Meer and Jin, 2020; Kim et\u00a0al., 2021; Kirchner and Reuter, 2020; Bode and Vraga, 2018; Martel et\u00a0al., 2021; Vafeiadis et\u00a0al., 2019)\n\n\nDebunking Websites\n(Micallef et\u00a0al., 2020; Veeriah, 2021; Allen et\u00a0al., 2021; Pennycook and Rand, 2019; McCreadie et\u00a0al., 2015)\n\n\nCountermeasures\n(Ramachandran et\u00a0al., 2020; Shabani and Sokhn, 2018; Kirchner and Reuter, 2020; Featherstone and Zhang, 2020; Masullo and Kim, 2021; Martel et\u00a0al., 2021; Vafeiadis et\u00a0al., 2019; Bode and Vraga, 2018; Kim et\u00a0al., 2021; van\u00a0der Meer and Jin, 2020; Cohen et\u00a0al., 2020; Stojanov, 2015; Sun et\u00a0al., 2021; Pal et\u00a0al., 2018, 2019)\n\n\nImplicit\nTextual Embedding\n(Micallef et\u00a0al., 2020)\n\n\nPsycholinguistic Features\n(Micallef et\u00a0al., 2020; Shabani and Sokhn, 2018; Memon and Carley, 2020; Pal et\u00a0al., 2018; Chua and Banerjee, 2017; Gunaratne et\u00a0al., 2019; Xue et\u00a0al., 2022; Giachanou et\u00a0al., 2022)\n\n\nTopic\n(Shabani and Sokhn, 2018; Dang et\u00a0al., 2016)\n\n\nSentiment\n(Pal et\u00a0al., 2018; Micallef et\u00a0al., 2020; Shabani and Sokhn, 2018; Li et\u00a0al., 2020; Dang et\u00a0al., 2016)\n\n\nEmotion\n\n(Kim and Chen, 2022) (Sun et\u00a0al., 2020; Pundir et\u00a0al., 2021; van\u00a0der Meer and Jin, 2020)\n\n\n\nDemographics\n(Pal et\u00a0al., 2018, 2019; Igbinovia et\u00a0al., 2021; Zhao et\u00a0al., 2016)\n\n\nMedia Literacy\n(Vraga et\u00a0al., 2021; Veeriah, 2021; Pundir et\u00a0al., 2021)\n\n\nConspiracy Mentality\n(Mancosu and Vegetti, 2021; Orosz et\u00a0al., 2016; Bode and Vraga, 2018)\n\n\nHashtag\n(Ahmed et\u00a0al., 2020; Babcock et\u00a0al., 2019a; Weber et\u00a0al., 2020)\n\n\n\nURL\n(Chua and Banerjee, 2017; Ahmed et\u00a0al., 2020; Hunt et\u00a0al., 2020; Jung et\u00a0al., 2020; Weber et\u00a0al., 2020; Micallef et\u00a0al., 2020)\n\n\n\nNumber of Likes/Shares\n(Hunt et\u00a0al., 2020; Pal et\u00a0al., 2017)\n\n\n\nGroup Identity Language\n(Chen et\u00a0al., 2022)\n\n\n\n\n\n\n\n\n3.2. Crowd Inputs\n\n\n3.2.1. Content Formats\n\nCrowds counter misinformation through diverse content formats, as outlined in Table\u00a04-(a).\nThe primary involves utilizing various textual formats such as posting counter-misinformation content, commenting on news articles, replying to social media posts, and retweeting or sharing corrective information\u00a0(Zeng et\u00a0al., 2019; Ahmed et\u00a0al., 2020; Flores-Saviaga and Savage, 2021; Jung et\u00a0al., 2020; Goh et\u00a0al., 2017; Arif et\u00a0al., 2017; Memon and Carley, 2020; Wang and Zhuang, 2018; Li et\u00a0al., 2020; Pal et\u00a0al., 2017).\nAdditionally, images often supplement textual content to enhance the effectiveness of countering misinformation (Pal et\u00a0al., 2017; Chua and Banerjee, 2017).\nLastly, video content serves as an effective tool to debunk misinformation on platforms like YouTube and has demonstrated its potential to educate the general public (Kim and Chen, 2022).\n\n\n\n\n3.2.2. Features Extracted from Crowd Inputs\n\nCrowds provide a diverse range of content in response to misinformation, offering researchers valuable features that can be utilized for misinformation detection and counter-misinformation characterization.\nIn this survey, we categorize them into explicit and implicit features, as shown in Table\u00a04-(b).\nExplicit features involve a direct examination of raw inputs.\nThis includes activities such as rating and flagging misinformation\u00a0(Mujumdar and Kumar, 2021; Allen et\u00a0al., 2022), assessing credibility scores of news articles\u00a0(Bhuiyan et\u00a0al., 2020; Mitra and Gilbert, 2015; Allen et\u00a0al., 2021; McCreadie et\u00a0al., 2015; Vraga et\u00a0al., 2021; Orosz et\u00a0al., 2016; Mancosu and Vegetti, 2021; van\u00a0der Meer and Jin, 2020; Kim et\u00a0al., 2021; Kirchner and Reuter, 2020; Bode and Vraga, 2018; Martel et\u00a0al., 2021; Vafeiadis et\u00a0al., 2019), identifying valuable debunking websites\u00a0(Micallef et\u00a0al., 2020; Veeriah, 2021; Allen et\u00a0al., 2021; Pennycook and Rand, 2019; McCreadie et\u00a0al., 2015), suggesting countermeasures\u00a0(Ramachandran et\u00a0al., 2020; Shabani and Sokhn, 2018; Kirchner and Reuter, 2020; Featherstone and Zhang, 2020; Masullo and Kim, 2021; Martel et\u00a0al., 2021; Vafeiadis et\u00a0al., 2019; Bode and Vraga, 2018; Kim et\u00a0al., 2021; van\u00a0der Meer and Jin, 2020; Cohen et\u00a0al., 2020; Stojanov, 2015; Sun et\u00a0al., 2021; Pal et\u00a0al., 2018, 2019).\nImplicit features, on the other hand, are derived through applying computation methods to raw inputs or giving questionnaires to crowds.\nThese computational methods generate new feature vectors, such as textual embeddings\u00a0(Micallef et\u00a0al., 2020), psycholinguistic features (Micallef et\u00a0al., 2020; Shabani and Sokhn, 2018; Memon and Carley, 2020; Pal et\u00a0al., 2018; Chua and Banerjee, 2017; Gunaratne et\u00a0al., 2019; Xue et\u00a0al., 2022; Giachanou et\u00a0al., 2022), sentiment\u00a0(Pal et\u00a0al., 2018; Shabani and Sokhn, 2018; Li et\u00a0al., 2020; Dang et\u00a0al., 2016), and other computational metrics\n\u00a0(Li et\u00a0al., 2020; Babcock et\u00a0al., 2019a; Chua and Banerjee, 2017; Ahmed et\u00a0al., 2020; Hunt et\u00a0al., 2020; Jung et\u00a0al., 2020; Weber et\u00a0al., 2020; Micallef et\u00a0al., 2020; Pal et\u00a0al., 2017; Chen et\u00a0al., 2022) for (counter-)misinformation analysis.\n\nAdditionally, the user-related implicit features from answered questionnaires by crowds contain demographic information \u00a0(Pal et\u00a0al., 2018, 2019) (e.g., age and education\u00a0(Vijaykumar et\u00a0al., 2022)), emotion\u00a0(Sun et\u00a0al., 2020; Pundir et\u00a0al., 2021; van\u00a0der Meer and Jin, 2020) (e.g., fear of missing out\u00a0(Pundir et\u00a0al., 2021)), media literary indicating the ability to critically analyze and evaluate various news information\u00a0(Vraga et\u00a0al., 2021; Veeriah, 2021; Pundir et\u00a0al., 2021), conspiracy mentality\u00a0(Mancosu and Vegetti, 2021; Orosz et\u00a0al., 2016; Bode and Vraga, 2018), the mindset to generally believe in conspiracy theories, and group identity language\u00a0(Chen et\u00a0al., 2022) where people who share social factors and belong to the same social group are more likely to use the similar language terms.\n\n\n\n\n\n\n4. Crowds as Annotators for Identifying Misinformation\n\nFollowing our meta-level summary of relevant papers, we now dive deeper into the functional categorization of the roles of crowds. Our taxonomy, represented in Figure\u00a02, categorizes the contributions of crowds along three axes: annotators, evaluators, and creators. In this section, we focus on the \u201cannotator\u201d category, where crowds serve as annotators for identifying misinformation.\n\n\nFigure 4. Illustration of crowds\u2019 role as annotators for identifying misinformation.\n\n\nTo identify misinformation, many ML methods have emerged for automated detection (Sharma et\u00a0al., 2019).\nHowever, these methods heavily rely on the expertise of fact-checkers to obtain ground-truth annotations (e.g., fact-check labels), whose population and bandwidth are unfortunately limited.\nIn contrast, emerging approaches  harness the fact-checking competence of the crowd, especially laypeople, for efficient and effective misinformation annotation (Ramachandran et\u00a0al., 2020; Mitra and Gilbert, 2015).\nIn this context, crowds can directly label potential misinformation articles.\nNotably, recent research suggests that crowd-based annotation performance rivals that of professionals (Bhuiyan et\u00a0al., 2020; Roitero et\u00a0al., 2021), enabling the use of these labels in downstream tasks such as misinformation classification (Shabani and Sokhn, 2018) and (counter-)misinformation analysis (Goh et\u00a0al., 2017).\nTherefore, we review the relevant studies where crowds annotate misinformation. These studies fall into three key categories: individual labeling of misinformation, collaborative labeling by a group of  users, and machine-assisted labeling with crowd inputs. Figure\u00a04 provides a visual representation, and Table 5 offers a  list of reference papers.\nWe then provide detailed descriptions of each category in the subsequent subsections.\n\n\nTable 5. Taxonomy of crowd annotators for identifying misinformation.\n\n\n\nCategories\nReferences\n\n\n\n\nIndividual Labeling\n(Roitero et\u00a0al., 2021; Ramachandran et\u00a0al., 2020; Mitra and Gilbert, 2015; Xu et\u00a0al., 2022; Bhuiyan et\u00a0al., 2020)\n\n\nCollaborative Labeling\n(Mujumdar and Kumar, 2021; Allen et\u00a0al., 2022)\n\n\nMachine-assisted Labeling\n(Shabani and Sokhn, 2018; Mitra and Gilbert, 2015; Ramachandran et\u00a0al., 2020; Farooq et\u00a0al., 2022)\n\n\n\n\n\n\n4.1. Individual Labeling\n\nIndividual labeling of misinformation requires independent judgments about the credibility of the given misinformation by each crowd member.\nTo  achieve it, platforms such as Amazon Mechanical Turk (Roitero et\u00a0al., 2021) and Upwork (Bhuiyan et\u00a0al., 2020) are used to facilitate direct user labeling (Ramachandran et\u00a0al., 2020; Mitra and Gilbert, 2015).\n Labels obtained from crowds are typically verified through majority voting.\nDuring this process, the credibility levels of the crowds increase as they accurately identify misinformation.\n\n\nFurthermore, several factors  influence the quality of individual labeling (Xu et\u00a0al., 2022; Bhuiyan et\u00a0al., 2020; Roitero et\u00a0al., 2021).\nOne significant factor is evidence from other peers\u00a0(Xu et\u00a0al., 2022), which can either aid or mislead  crowds\u2019 judgments.\nCrowds who effectively use provided evidence tend to make more accurate annotations.\nMoreover, the demographic and political composition can  influence crowds\u2019 credibility ratings and annotations.\nFor example, Bhuiyan et\u00a0al. (2020) found that Democrats, males, those between the ages of 26 and 30, and those with higher levels of education are more likely to agree with experts on climate science.\n\n\nAdditionally, characteristics of the annotation task itself, such as\nthe genre of the article and partisanship of the publication\n,\nalso have an impact.\nBhuiyan et\u00a0al. (2020) found that crowds demonstrate a higher correlation with experts in opinion articles and left-leaning publications.\nLastly, the length of the annotation period can also affect the quality of the judgments .\nNotably, Roitero et\u00a0al. (2021) found that annotations collected at different time spans for the same document may yield different results.\nInstead, annotations collected  close to each other tend to produce similar outcomes.\n\n\n\n\n4.2. Collaborative Labeling\n\nIn addition to individual labeling, collaborative labeling indicates that multiple individuals  can contribute to annotations collaboratively, which enhances quality through shared insights and community engagement (Mujumdar and Kumar, 2021; Allen et\u00a0al., 2022).\nTwitter\u2019s Birdwatch/Community Notes333https://help.twitter.com/en/using-twitter/community-notes, introduced in 2021, is a prominent example.\nIn this initiative, crowds review the annotations of others and then label tweets that may contain misinformation by providing supporting material .\nIt is worth noting that, unlike majority-based aggregation commonly used in individual labeling scenarios, collaborative labeling involves group-level interactions that occur before final label consensus. This aspect makes collaborative labeling a more crowd-enabled process\u00a0.\n Subsequent research efforts investigate and address challenges within the Birdwatch collaborative labeling ecosystem.\nFor instance, crowds have different levels of credibility in their annotations, which can result in biased or unfair labeling.\nTo tackle this issue, Mujumdar and Kumar (2021) proposed HawkEye, a robust reputation system for fair user ranking and misinformation labeling.\nAdditionally, Allen et\u00a0al. (2022) investigated the impact of crowds\u2019 partisanship\u00a0. They found that crowds tend to offer negative annotations for tweets from counter-partisans and consider their annotation less helpful.\n\n\n\n\n4.3. Machine-assisted Labeling\n\nMachine-assisted labeling methods combine computational power and crowd inputs to efficiently detect misinformation (Shabani and Sokhn, 2018; Mitra and Gilbert, 2015).\nIn the human-in-the-loop pipeline proposed by Shabani and Sokhn (2018), crowds initially verify misinformation labels assigned by ML classifiers, and this feedback is then used to refine the classifiers\u00a0(Shabani and Sokhn, 2018).\nAdditionally, Farooq et\u00a0al. (2022) proposed a blockchain-based framework that leverages the inherent immutability and incentive features of blockchains to record crowd annotations, ensuring accountability while also rewarding accurate contributions and penalizing malicious annotations.\nSimilarly, Ramachandran et\u00a0al. (2020) incorporated the blockchain framework to collect the given genuineness score of news articles from crowds to improve the downstream fake news detection algorithms.\nLastly, topic modeling techniques can be used to cluster tweets on similar topics, and crowds can assess the credibility of these tweets to ensure a coherent and consistent annotation process (Mitra and Gilbert, 2015).\n\n\n\n\n\n5. Crowds as Evaluators for Assessing Counter-Misinformation Effectiveness\n\nFigure 5. Illustration of crowds\u2019 role as evaluators to assess counter-misinformation effectiveness.\n\n\nOnce misinformation is identified by crowds, ML classifiers, or professionals, different counter-misinformation messages are created on social media platforms for debunking.\nIn this case, crowds can help evaluate the effectiveness and limitations of various counter-misinformation messages.\nTo introduce evaluation methods utilizing crowds as evaluators in the literature, we  group them into two categories, i.e., direct and indirect assessments  (see Figure\u00a05).\nEach category consists of three sub-categories: direct assessment\u2013in-lab experiment, interview, and survey; indirect assessment\u2013sentiment, stance, and the number of shares.\nNext, we describe the details of each category and  discuss findings regarding effective counter-misinformation across different factors, such as  media formats, content traits, communication styles, audience factors, countering order, and word placement, in the subsequent subsections.\nThe taxonomy of evaluation methods and factors can be found in Table\u00a06-(a) and -(b), respectively.\n\n\n\n5.1. Crowd-based Evaluation Methods\n\nAs mentioned above, two  paradigms can be employed to evaluate the efficacy of counter-misinformation using  crowds.\nThe first method, referred to as direct assessment, involves  using quantitative questions where crowds rate the believability of misinformation after viewing counter-misinformation messages.\nThis approach directly assesses the preferences and perceptions of the crowd, with lower believability indicating more effective countermeasures.\nIn contrast, the second method, termed indirect assessment, involves  using  proxy metric.\n\nParticularly, we can analyze the sentiment, stance, or the number of shares of counter-misinformation to measure its effectiveness.\n\n\n\n5.1.1. Direct Assessment\n\nDirect assessment of counter-misinformation through quantitative questions involves various research methodologies, including in-lab experiments, interviews, and surveys.444Some reviewed papers use the term questionnaire. In this work, we use \u201csurvey\u201d to cover questionnaire- as well as survey-based methodologies.\nIn-lab experiments are a common approach in many studies (Stojanov, 2015; Kim et\u00a0al., 2021; Pasquetto et\u00a0al., 2022; Kessler and Bachmann, 2022; Tay et\u00a0al., 2022; Dai et\u00a0al., 2022; Pillai et\u00a0al., 2022; Masullo and Kim, 2021; Vraga et\u00a0al., 2021). Crowds are presented with both misinformation and various types of countering-misinformation articles. They then answer questions to assess the plausibility and believability of misinformation or counter-misinformation (Yu et\u00a0al., 2022).\nAs an advanced design for this methodology, Orosz et\u00a0al. (2016)  ask crowds their initial belief in misinformation,  present them counter-misinformation, and  finally reevaluate their belief.\nThe change in belief  measures the effectiveness of counter-misinformation.\n\n\nThese in-lab experiments investigate diverse factors in countering strategies\u00a0(van\u00a0der Meer and Jin, 2020; Tanaka and Hirayama, 2019; Kim et\u00a0al., 2021; Allen et\u00a0al., 2021; Featherstone and Zhang, 2020; Pennycook and Rand, 2019; Soprano et\u00a0al., 2021; Kirchner and Reuter, 2020; Bode and Vraga, 2018; McCreadie et\u00a0al., 2015; Martel et\u00a0al., 2021; Sun et\u00a0al., 2021), e.g., independent or mainstream news sources\u00a0(Mancosu and Vegetti, 2021).\n\n\nTable 6. Taxonomy of crowd evaluators for counter-misinformation effectiveness.\n\n\n\n\nCategories\nReferences\n\n\n\n\n(a) Methods\n\nDirect\nIn-lab Experiment\n(Stojanov, 2015; Kim et\u00a0al., 2021; Pasquetto et\u00a0al., 2022; Kessler and Bachmann, 2022; Tay et\u00a0al., 2022; Dai et\u00a0al., 2022; Pillai et\u00a0al., 2022; Masullo and Kim, 2021; Vraga et\u00a0al., 2021; Yu et\u00a0al., 2022; van\u00a0der Meer and Jin, 2020; Tanaka and Hirayama, 2019; Kim et\u00a0al., 2021; Allen et\u00a0al., 2021; Featherstone and Zhang, 2020; Pennycook and Rand, 2019; Soprano et\u00a0al., 2021; Kirchner and Reuter, 2020; Bode and Vraga, 2018; McCreadie et\u00a0al., 2015; Martel et\u00a0al., 2021; Sun et\u00a0al., 2021)\n\n\nInterview\n(Borah et\u00a0al., 2021)\n\n\nSurvey\n(Kessler and Bachmann, 2022; Kirchner and Reuter, 2020)\n\n\nIndirect\nSentiment\n(Zhang et\u00a0al., 2022)\n\n\nStance\n(Wang et\u00a0al., 2022b, 2021)\n\n\nNumber of Shares\n(Chen et\u00a0al., 2021)\n\n\n\n\n(b) Findings\n\nMedia Formats\n(Kirchner and Reuter, 2020; Veeriah, 2021; Yu et\u00a0al., 2022; Yang and Overton, 2022; Vraga et\u00a0al., 2021; Kessler and Bachmann, 2022; Masullo and Kim, 2021; Pasquetto et\u00a0al., 2022)\n\n\nContent Traits\n(Wang et\u00a0al., 2021; Kessler and Bachmann, 2022; Orosz et\u00a0al., 2016; Stojanov, 2015; Kirchner and Reuter, 2020; Yu et\u00a0al., 2022)\n\n\nCommunication Styles\n(Kim et\u00a0al., 2021; Masullo and Kim, 2021; Orosz et\u00a0al., 2016; Wang et\u00a0al., 2022b; Yu et\u00a0al., 2022)\n\n\nAudience Factors\n(Tanihara et\u00a0al., 2022; Wang et\u00a0al., 2022b; Pasquetto et\u00a0al., 2022; Yang and Overton, 2022; Primig, 2022)\n\n\nCountering Order\n(Dai et\u00a0al., 2022; Tay et\u00a0al., 2022)\n\n\nWord Placement\n(Pillai et\u00a0al., 2022)\n\n\n\n\n\nInterviews offer personal interactions for crowds to engage in conversations and  answer open-ended questions about effective strategies for countering misinformation.\nDuring the COVID-19 pandemic in 2020, Borah et\u00a0al. (2021) interviewed young adults and active social media users regarding their COVID-19 perceptions, coping strategies, and recommended countermeasures.\n\nThese young crowds recommend calling out people who share misinformation and bring up media literacy programs.\n\n\nFinally, online surveys efficiently expand sample sizes and enhance inclusivity and accessibility for geographically dispersed  participants, thereby complementing in-lab experiments and interviews.\nThese surveys collect demographic information and gather crowd opinions on misinformation and counter-misinformation, including how individuals handle potential false posts\u00a0(Kirchner and Reuter, 2020) and their evaluations of countering efforts\u00a0(Kessler and Bachmann, 2022).\n\n\n\n\n5.1.2. Indirect Assessment\n\n\nIn contrast to direct assessment, indirect assessment utilizes proxy metrics to measure the effectiveness of counter-misinformation messages in a data-driven manner.\nFor instance, Zhang et\u00a0al. (2022) analyzes the sentiment in the comments on and replies to counter-misinformation messages by crowds on the Sina Weibo platform.\nThey mention that positive sentiment is a valid indicator to model the efficacy of counter-misinformation messages.\nPractically, they use a Python library named SnowNLP to extract sentiment scores from the text\u00a0(Zhang et\u00a0al., 2022).\nTo have a comprehensive measurement, they also consider the number of likes and retweets in a weighted sum manner together to derive the final effectiveness score.\nSimilarly, other works assess the stance expressed in comments on rumor rebuttals as a proxy for countering acceptance (Wang et\u00a0al., 2022b, 2021).\nThey first categorize stances as supporting, denying, questioning, and commenting and compute the stance of each comment by a BERT-based textual classifier\u00a0(Wang et\u00a0al., 2021).\nNext, for each rumor rebuttal, they use the ratio of \u201cthe di\ufb00erence between the denying and supporting stances\u201d to \u201cthe sum of the two stances, i.e., omitting other stances that do not contribute to the veracity of a rumor from all stances\u201d to calculate the degree of denial. This ratio could normalize the denying and supporting stances and make the metric comparable across rumors and events after dividing the redundant comments among all comments.\nFinally, the inverse of this normalized ratio indicates the debunking effectiveness\u00a0(Wang et\u00a0al., 2021).\nAdditionally, Chen et\u00a0al. (2021) use the number of shares.\nThey particularly count the number of shares or reposts of fact-checks and explore the influence of peripheral cues (e.g., media richness and source credibility) and central cues (content importance and content theme) on the number of shares.\nResults show that the peripheral and central cues play critical roles in the sharing of fact-checks.\nFor example, media richness and content importance significantly promote the number of shares.\n\n\n\n\n\n5.2. Findings from Effective Counter-Misinformation\n\nAfter establishing the appropriate crowd-based evaluation methods, we utilize these crowd evaluators to gain  insights into the effectiveness of counter-misinformation efforts.\nSpecifically, we aim to uncover the underlying factors contributing to these endeavors,  such as media formats, content traits, communication styles, audience factors, countering order, and word placement.\n\n\n\n5.2.1. Media Formats\n\nWe examine the impacts of different formats employed in counter-misinformation efforts.\n\n\nThe predominant format is text-based countermeasures responding to textual misinformation\u00a0(Kirchner and Reuter, 2020; Veeriah, 2021; Yu et\u00a0al., 2022; Yang and Overton, 2022).\n\nFurthermore, a study by Vraga et\u00a0al. (2021) explored text-based responses to video misinformation on health topics.\nCrowd evaluators viewed misinformation videos and accompanied debunking comments. The result showed that real-time crowd debunking in text partially reduced belief in misinformation (p<0.01\ud835\udc5d0.01p<0.01italic_p < 0.01).\n\n\nAdditionally, Kessler and Bachmann (2022) investigated the format of text plus images.\nThey found that credible text-based debunking supported by evidence effectively countered misinformation while images alone had limited impact.\n\n\n\nMoreover, Masullo and Kim (2021) studied the countering text that is accompanied by emojis.\nThey discovered that while the uncivil expression impedes the perceived credibility of news stories, emoji reactions like \u201cangry\u201d mitigate incivility, especially across different political leanings (p<0.01\ud835\udc5d0.01p<0.01italic_p < 0.01).\n\nMeanwhile, Pasquetto et\u00a0al. (2022) found that audio-based corrections on WhatsApp platforms generate more interest and are more effective than text- or image-based messages in countering misinformation (p=0.01\ud835\udc5d0.01p=0.01italic_p = 0.01).\n\n\n\n\n5.2.2. Content Traits\n\nWe further delve into the  content characteristics that are crucial to  counter misinformation.\n\n\nThese include uncovering the motivations behind misinformation\u00a0(Stojanov, 2015), using evidenced and logical counter-arguments\u00a0(Wang et\u00a0al., 2021; Orosz et\u00a0al., 2016), containing warnings to remind readers of potential misinformation\u00a0(Kirchner and Reuter, 2020), and selecting credible sources for correction\u00a0(Yu et\u00a0al., 2022).\nWe elaborate on them below.\n\n\nRegarding  uncovering the motivations behind misinformation,\nStojanov (2015) examined the impact of debunking messages that reveal the motives behind conspiracy theories, particularly in the context of vaccine-related medical topics.\nTheir findings suggest that  this revelation  indeed reduces belief in medical conspiracy theories (p<0.05\ud835\udc5d0.05p<0.05italic_p < 0.05), although the effect on  general conspiracy theories is less clear.\nFor using evidenced counter-arguments,\nWang et\u00a0al. (2021) highlighted the importance of citing evidence to enhance the debunking effect, which is better than debunking  with uncited evidence (p<0.001\ud835\udc5d0.001p<0.001italic_p < 0.001).\nSubsequently, Kessler and Bachmann (2022) extended these findings by confirming that the text with evidence rather than images matters.\n\nTo investigate logical counter-arguments, Orosz et\u00a0al. (2016) presented them with conspiracy theory statements to subjects and found that this approach reduces belief in conspiracy theories (p\u22640.01\ud835\udc5d0.01p\\leq 0.01italic_p \u2264 0.01).\n\n\nStojanov (2015) additionally demonstrated that the countering works when it points out the fallacies in the reasoning behind the original misinformation post.\n\n\nConcerning displaying warning messages,\nKirchner and Reuter (2020) revealed that German adults preferred them as a strategy to combat fake news (65% agreement compared to the baseline of 51-57%).\nThey also highlighted providing explanations for flagged misinformation (71% agreement compared to the baseline of 51-57%).\nThese results demonstrate the effectiveness of warning-based countering, particularly when accompanied by explanatory text.\n\n\nLastly, about selecting credible sources for correction, researchers identified variations in the persuasiveness of different sources\u00a0(Yu et\u00a0al., 2022).\nFor example, Yu et\u00a0al. (2022) found that in authoritative societies, corrections from government sources tend to have greater credibility than those from professionals or laypeople (p\u22640.05\ud835\udc5d0.05p\\leq 0.05italic_p \u2264 0.05).\nThis underscores the need to tailor source selection to specific societal contexts, particularly when the impact of corrections varies across different societies (e.g., authoritative societies).\n\n\n\n\n5.2.3. Communication Styles\n\nAnalyzing different communication styles of counter-misinformation, such as humorous and uncivil responses, provides an additional dimension to evaluating its effectiveness.\n\nRegarding humor, researchers have explored its potential by comparing humorous and non-humorous corrective messages to HPV vaccine-related misinformation\u00a0(Kim et\u00a0al., 2021).\n\n\nThey found that humor increased the visual attention of crowds toward the image portion of the counter-misinformation counts.\nThis indirectly reduced HPV misperceptions.\n\nFor uncivil responses, Masullo and Kim (2021) investigated\n\nits effect\non readers\u2019 attitudes and perceptions.\nIn an online survey, crowd evaluators were exposed to misinformation articles, uncivil comments, and corresponding social reactions to the comments, followed by questions about their feelings.\nThe findings revealed that while uncivil counter-comments influenced how readers viewed the comments and the commentators themselves, they did not affect the credibility of the underlying articles. This suggests that uncivil responses may not contribute significantly to countering misinformation.\n\n\nIn addition, the literature has explored other factors such as  ridicule, empathy, readability, and tone of correction.\nAccording to research works by Orosz et\u00a0al. (2016), ridiculing arguments  reduce belief in conspiracy theories, while empathetic counterarguments have no significant impact .\nWang et\u00a0al. (2022b) investigated the  effect of the readability \n They found that higher readability positively influenced users\u2019 acceptance of the rebuttal.\nImproved readability indicates that users can easily understand and absorb the rebuttal, thereby enhancing its effectiveness.\nLastly, Yu et\u00a0al. (2022) examined the impact of the tone of corrective messages .\n Their research indicated that a formal tone was more believable than a less formal and conversational tone.\n\n\n\n\n5.2.4. Audience Factors\n\nIn addition to the inherent characteristics of counter-misinformation, a number of external factors related to the audience, including media literacy, cognitive capability, political stance, trust in media, and concern about misinformation, also  influence its effectiveness.\n\n\nResearch has extensively explored the impact of media literacy on the perception of misinformation.\nFor instance, Tanihara et\u00a0al. (2022) found that crowd evaluators with lower levels of media literacy are more likely to change their perceptions  when exposed to corrective messages.\nIn a study conducted by Wang et\u00a0al. (2022b),\n\n\nthey assessed cognitive capability based on an individual\u2019s language-related cues (e.g., vocabulary size) and found that\n\ncrowd evaluators with lower cognitive capabilities tend to rely on the credibility of the source and the quality of the argument in the rebuttal text to accept it.\nOn the other hand,  crowd evaluators with high cognitive capability have a  higher demand for  readability, even when the sources and arguments are solid.\n For political stance, Pasquetto et\u00a0al. (2022) found that the correction from people with strong ties (e.g., the same political stance) can lead crowds to more actively re-share these debunks and counter misinformation.\nThis tendency was corroborated by Yang and Overton (2022), who observed that crowd evaluators are more likely to accept corrections from sources that align with their existing attitudes.\n Concerning trust in media,\nPrimig (2022) discovered that higher trust in media sources corresponds to higher believability in fact-checking sources and messages, especially when combined with user trust in politics.\n\n\nConversely, Yang and Overton (2022) noted that lower levels of certainty on social media platforms lead to less effectiveness of corrections on these platforms.\n\n For concern about misinformation, Yang and Overton (2022) found that social corrections work better among users who are more concerned or worried about the potential harm caused by misinformation on social media platforms.\n\n\n\n\n5.2.5. Countering Order and Word Placement\n\nResearchers have also examined other less prominent factors such as the order of counter-misinformation and the placement of negation.\nRegarding countering order, two contrasting approaches emerge: debunking starts by presenting misinformation and then offers a counterresponse, while prebunking reverses this order by introducing counter-misinformation as a preemptive warning or reminder.\nDai et\u00a0al. (2022) confirmed that prebunking messages, especially when combined with fact-checks or inoculation messages,  made crowd evaluators more skeptical of misinformation.\n Tay et\u00a0al. (2022) conducted a more comprehensive evaluation that extended  traditional questionnaires to assess user behaviors  (e.g., information seeking and misinformation promoting).\nThe results highlighted the effectiveness of both prebunking and debunking in reducing belief in misinformation.\n\n\nAnother studied nuanced aspect  is how the placement of negation during debunking impacts crowd memory and, consequently, the effectiveness of debunking\u00a0(Pillai et\u00a0al., 2022).\n On social media, brief affirmations or negations are often used to clarify claims.\nIn this context, Pillai et\u00a0al. (2022) found that when crowd evaluators encounter negated messages (e.g., \u201cThis is wrong.\u201d), they often remember the main claim but forget the negative part.\nThey tested placing the negation before or after the entire claim and found that both methods were equally memorable.\n This finding underlines the possibility of diverse approaches to conveying affirmations and negations for misinformation correction.\n\n\n\n\n\n\n6. Crowds as Creators of Counter-Misinformation\n\nFigure 6. Illustration of crowds\u2019 role as creators of counter-misinformation.\n\n\nIn addition to serving as annotators and evaluators, crowds  can create their own counter-misinformation messages on social media platforms.\nIn this section, we aim to examine their role as content creators (see Figure\u00a06) to investigate their unique perspective and proactive involvement in combating misinformation while characterizing their content.\nTo achieve this goal, we first present three characterization methods that measure how crowds actively combat misinformation as creators.\nThese methods are data-driven analysis, in-lab experiment, and survey (see Table\u00a07-(a)).\nBased on these methods, we discuss findings  after analyzing crowd-generated counter-misinformation , with a  focus on creation patterns of counter-misinformation and its creator profiles (see Tables\u00a07-(b) and (c)).\n\n\nTable 7. Taxonomy of crowd creators for analyzing crowd-generated counter-misinformation.\n\n\n\n\n\nCategories\nReferences\n\n\n\n\n(a) Methods\n\n\n\n\nCreation\n\nPatterns\n\n\n\n\nData-driven Analysis\n\n(Al-Motlaq, 2021; Micallef et\u00a0al., 2020; Xue et\u00a0al., 2022; Kim and Chen, 2022; Hunt et\u00a0al., 2020; Pal et\u00a0al., 2017; Giachanou et\u00a0al., 2022)\n\n\n\n\n\nCreator\n\nProfiles\n\nIn-lab Experiment\n(Pal et\u00a0al., 2018, 2019; Cohen et\u00a0al., 2020; Igbinovia et\u00a0al., 2021; Sun et\u00a0al., 2020; Huber et\u00a0al., 2022; Veeriah, 2021)\n\n\n\nSurvey\n(Chen and Fu, 2022)\n\n\n\n\n(b) Creation Patterns\n\nLanguage\nSentiment\n(Al-Motlaq, 2021; Micallef et\u00a0al., 2020)\n\n\nEmotion\n(Xue et\u00a0al., 2022; Micallef et\u00a0al., 2020; Kim and Chen, 2022)\n\n\nPsycholinguistic Features\n(Micallef et\u00a0al., 2020; Xue et\u00a0al., 2022; Giachanou et\u00a0al., 2022)\n\n\nURL\n(Micallef et\u00a0al., 2020; Pal et\u00a0al., 2017; Hunt et\u00a0al., 2020)\n\n\nHashtag\n(Gunaratne et\u00a0al., 2019; Babcock et\u00a0al., 2019a)\n\n\nOthers\n(Zubiaga et\u00a0al., 2016; Nadamoto et\u00a0al., 2013; Chen et\u00a0al., 2022)\n\n\nNetwork\nNetwork Co-existence Pattern\n(Gunaratne et\u00a0al., 2019)\n\n\nInformation Transmission\n(Zubiaga et\u00a0al., 2016)\n\n\nUser Connectivity Pattern\n(Ahmed et\u00a0al., 2020; Chiu et\u00a0al., 2022)\n\n\n\n\n\nUser\n\nEngagement\n\nPost Volume\n(Wang et\u00a0al., 2022a; Micallef et\u00a0al., 2020)\n\n\nPost Sharing\n(Micallef et\u00a0al., 2020; Chua et\u00a0al., 2017)\n\n\nTemporal\nTemporal Trend\n(Gunaratne et\u00a0al., 2019)\n\n\nLife Cycle\n(Zubiaga et\u00a0al., 2016)\n\n\n\n\n(c) Creator Profiles\n\nDemographics\nAge and Education\n(Vijaykumar et\u00a0al., 2022)\n\n\nPolitical Ideology\n(Cohen et\u00a0al., 2020; Steinfeld, 2022)\n\n\nMedia Literacy\n(Igbinovia et\u00a0al., 2021; Vijaykumar et\u00a0al., 2022; Veeriah, 2021; Huber et\u00a0al., 2022)\n\n\nMindsets\nSharing Denials\n(Pal et\u00a0al., 2018, 2019)\n\n\nOthers\u2019 Susceptibility\n(Sun et\u00a0al., 2020)\n\n\nThird-person Effect\n(Chen and Fu, 2022)\n\n\nHarm Awareness\n(Zhao et\u00a0al., 2016; Vijaykumar et\u00a0al., 2022)\n\n\n\n\n\n\n6.1. Characterization Methods\n\nTo establish a  framework for analyzing the  counter-misinformation creation process\u00a0, we present three characterization methods in Table 7-(a).\n\nFirst, researchers mainly rely on data-driven analysis to understand the creation patterns of effective crowd-generated counter-misinformation.\n In essence, they  first crawl large-scale crowd-generated data, including posts and social network relationships.\n They then examine different perspectives in the data, such as language patterns, networks, and temporal trends (Al-Motlaq, 2021; Micallef et\u00a0al., 2020; Xue et\u00a0al., 2022; Kim and Chen, 2022; Hunt et\u00a0al., 2020; Pal et\u00a0al., 2017; Giachanou et\u00a0al., 2022), which will be elaborated in Section\u00a06.2.\n\n\nOn the other hand, researchers employ a combination of in-lab experiments and surveys to study creator profiles.\nFor in-lab experiments (Pal et\u00a0al., 2018, 2019; Cohen et\u00a0al., 2020; Igbinovia et\u00a0al., 2021; Sun et\u00a0al., 2020; Huber et\u00a0al., 2022; Veeriah, 2021), crowd creators are exposed to misinformation  and then asked  whether to counter or endorse it.\nIn the meantime, researchers collect information  about creators, including their political leanings and beliefs related to misinformation,  to analyze their attributes.\nAdditionally, researchers conduct online surveys to assess the creators\u2019 levels of belief in misinformation and collect demographic information,  e.g.,  their media competency (Chen and Fu, 2022).\nThe results are discussed in Section\u00a06.3.\n\n\nThe goal of these methods is to characterize the creators themselves and uncover the patterns and attributes associated with crowd-generated counter-misinformation.\nIn this context, it is important to note that this objective contrasts with the goal of the crowd-based evaluation methods\u00a0in Section\u00a05, which assess misinformation countermeasure effectiveness.\n\n\n\n\n6.2. Creation Patterns\n\nIn the battle against misinformation, crowds actively contribute by generating a multitude of counter-misinformation content  e.g.,  debunking posts and responses.\n Extensive research has  focused on comprehending how such counter-misinformation messages are crafted and pinpointing the patterns they contain (Micallef et\u00a0al., 2020; Chua et\u00a0al., 2017; Nadamoto et\u00a0al., 2013; Kim and Chen, 2022). Researchers typically first manually label sampled text and visuals into categories such as misinformation and counter-misinformation, and then train classifiers  to categorize unlabeled data points due to the high cost of manual labeling.\nThis  categorization serves as the basis for analyzing counter-misinformation, including content characteristics, network dynamics, temporal aspects, and social media engagement. For a detailed breakdown of these dimensions, refer to Table 7-(b).\n\n\n\n6.2.1. Language Analysis\n\nCrowd-generated counter-misinformation messages exhibit distinct language patterns when compared to other online content (Al-Motlaq, 2021; Xue et\u00a0al., 2022; Kim and Chen, 2022). We summarize these patterns through various aspects, including sentiments, emotions, psycholinguistic features, and textual components like URLs and hashtags.\n\n\nFirst, sentiment analysis revealed differences among various topics.\nFor instance, during the COVID-19 pandemic, positive attitudes were expressed in comments countering COVID-19 conspiracy theories on Facebook (Al-Motlaq, 2021), while counter-misinformation tweets regarding fake COVID-19 cures were more neutral (Micallef et\u00a0al., 2020).\nIn addition, emotions  have been explored in various contexts, demonstrating that contexts affect different emotional responses.\nFor  example, Xue et\u00a0al. (2022) used IBM Watson Tone Analyzer to extract emotions, revealing that COVID-19 vaccine fact-checking posts on Facebook tended to maintain a neutral tone, while public comments often displayed more emotionally charged responses.\n Kim and Chen (2022) further analyzed emotions in videos related to COVID-19 on YouTube.\nThey utilized the NRC Emotion Lexicon555http://saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm,\nwhich contains a list of English words and their associations with emotions and sentiments.\nThe study identified two emotional dimensions, trust and fear, and observed differential utilization of these emotions in debunking videos.\n\n\nFurthermore, researchers have delved into the psycholinguistic features  using tools such as Linguistic Inquiry and Word Count (LIWC) or IBM Watson Tone Analyzer (Micallef et\u00a0al., 2020; Xue et\u00a0al., 2022; Giachanou et\u00a0al., 2022).\nFor instance, on Facebook, posts fact-checking COVID-19 vaccine information exhibited higher levels of confidence compared to general public posts (Xue et\u00a0al., 2022).\nAdditionally, Giachanou et\u00a0al. (2022) discovered that crowds tend to employ more positive  and causal language, whereas misinformation spreaders often use more informal language.\n\n\nTwo  elements frequently integrated into counter-misinformation messages are URLs and hashtags.\nUniform Resource Locators (URLs) serve as sources of evidence-based resources (Micallef et\u00a0al., 2020), often cited in tweets that counter rumors (Pal et\u00a0al., 2017).\nMoreover, URLs have proven effective in disseminating information for debunking during disaster events, often citing news agencies as their primary information sources (Hunt et\u00a0al., 2020).\nHashtags, on the other hand, are employed to enhance the visibility and categorization of content. For example, Gunaratne et\u00a0al. (2019) analyzed vaccine-related tweets and found that 86% of users exclusively used pro-vaccine hashtags, while 12% opted for anti-vaccine hashtags. Additionally, Babcock et\u00a0al. (2019a) found that the hashtag \u201c#fakenews\u201d was widely used to attack fake news.\n\n\nBesides these specific content attributes, other dimensions like stance (Zubiaga et\u00a0al., 2016), user impression (Nadamoto et\u00a0al., 2013), politeness\u00a0(Micallef et\u00a0al., 2020), and the group identity language\u00a0(Chen et\u00a0al., 2022) have also been examined in counter-misinformation.\n\n\n\n\n6.2.2. Network Analysis\n\nResearchers employ various network analysis approaches and tools (e.g., NodeXL and Gephi\u00a0(Flores-Saviaga and Savage, 2021; Jung et\u00a0al., 2020; Babcock et\u00a0al., 2019b; Memon and Carley, 2020; Dang et\u00a0al., 2016; Weber et\u00a0al., 2020)) to uncover the intricate interplay between misinformation/counter-misinformation information flow and user connections on social media platforms. The representative approaches encompass patterns of co-existence in networks, post sharing/(re)tweeting, and connectivity of users.\n\n\nRegarding network co-existence patterns, Gunaratne et\u00a0al. (2019) examined the co-occurrence of anti-vaccine and pro-vaccine hashtags on Twitter.\n They constructed a network with hashtags as nodes and co-occurring hashtags as edges, revealing distinct community structures within  pro-vaccine and anti-vaccine hashtags.\nThe results highlighted that pro-vaccine hashtags formed a dominant community along with a few closely connected sub-communities.\nConversely, anti-vaccine hashtags largely converged into one community with a smaller, remote sub-community that focuses on specific vaccines.\nThis analysis enhanced our understanding of the discourse and inter-relationship between misinformation and counter-misinformation.\n\n\nTo investigate information transmission within a social network, Zubiaga et\u00a0al. (2016) investigated the rumor (re)tweeting networks which included three types of retweets:\n(1) unverified source tweets, (2) accurate tweets supporting true information or denying false rumors (i.e., counter-misinformation), and (3) inaccurate tweets denying true information or supporting false rumors (i.e., misinformation).\nBy examining retweeting relationships between (re)tweet nodes, they discovered that retweets of accurate tweets were primarily observed in certain misinformation topics, such as the Ottawa shooting and the Sydney siege. In contrast, tweets sharing unverified rumors had a broader spread across different topics.\n\n\nUser connectivity patterns on social network platforms such as Twitter have also been studied in the literature (Ahmed et\u00a0al., 2020; Chiu et\u00a0al., 2022).\nFor instance, during the COVID-19 pandemic on Twitter, Ahmed et\u00a0al. (2020) regarded crowds as nodes and the \u201creply-to\u201d or \u201cmention\u201d relationships in tweets as edges in a graph.\nA \u201cself-loop\u201d relationship is added in the graph if there is no \u201creply-to\u201d or \u201cmention\u201d in the tweets.\nBy analyzing such a graph, researchers found that 32.2%percent32.232.2\\%32.2 % of the crowds denounced the COVID-19 5G conspiracy theory.\nThey also identified the two largest network structures, consisting of an isolated group and a broadcast group.\nThe results revealed that there was  no active authority figure to counter the spread of misinformation.\nInstead, the crowds countered the conspiracy theory with widespread denouncement.\nSimilarly, Chiu et\u00a0al. (2022) considered the \u201cmention\u201d, \u201cretweet\u201d, and \u201cself-loop\u201d relationships between users to create the graph and conduct the cluster analysis, while focusing on the diffusion scope, speed, and shape for true and fake news across the users.\nThey also tested whether the attributes of the true or fake news spreaders would affect the aforementioned three metrics.\nThe results showed that true news from the crowd tended to spread later and with less broadcast influence compared to fake news.\nIn addition, Wang et\u00a0al. (2022a) investigated the follower-followee relationships of refuters and non-refuters. They developed a deep-learning-based text classifier to identify debunked and non-debunked posts on Sina Weibo. They then identified associated refuters and non-refuters whose follower-followee networks are crawled as well. Their analysis unveiled that nodes with greater centrality had more follower-followee edges, and weakly connected components could easily disseminate both debunked and non-debunked posts. This suggests that misinformation and counter-misinformation have similar propagation patterns, considering that both can spread from  weakly-connected nodes.\n\n\n\n\n6.2.3. User Engagement Analysis\n\nSocial media engagement analysis explores how crowds interact with online posts containing both misinformation and counter-misinformation.\n\n\nThese interactions can be measured through metrics like post volume growth, and post sharing behaviors.\n\n\nFor example, Wang et\u00a0al. (2022a) observed that the post volumes of counter-misinformation exhibited growth rates similar to those containing misinformation.\nNonetheless, Micallef et\u00a0al. (2020) uncovered disparities in their absolute quantities and growth trends during the COVID-19 pandemic.\nSpecifically, the number of counter-misinformation posts was significantly lower than the number of misinformation posts.\nApart from post volumes, they also analyzed the imbalanced sharing behavior associated with these posts, and found that the majority of posts, regardless of their classification as misinformation or counter-misinformation, received minimal to no shares.\nHowever, specific situations could lead to variations.\nFor example, when examining the rumored death of Singapore\u2019s President Lee Kuan Yew, Chua et\u00a0al. (2017) found that tweets aiming to correct the rumor garnered more frequent retweets than the initial rumor tweets. This suggests that, in certain contexts, counter-misinformation may be more prone to be shared than misinformation.\n\n\n\n\n6.2.4. Temporal Analysis\n\nTemporal analysis aims to uncover evolving misinformation and counter-misinformation traits by studying temporal trends and life cycle patterns, offering valuable insights into their dynamics.\n\n\nFor instance, Gunaratne et\u00a0al. (2019) examined the temporal trends of disease cases, pro-vaccine of diseases, and anti-vaccine of diseases tweets, as well as the crowds who tweeted between 2010 and 2019.\nThe results revealed that pro-vaccine tweets consistently outpaced anti-vaccine tweets in volume, and this trend continued to increase over time.\nSimilarly, Zubiaga et\u00a0al. (2016) conducted a study on the life cycle of rumors and their countering.\nThey aimed to understand how users engage with rumors, in terms of both their spread and debunking, before and after the veracity of the rumor is confirmed.\nThrough manual  annotation of rumor threads, they had interesting observations .\n For example, rumors that were eventually proved to be true, were debunked more quickly than false rumors.\n When a rumor tweet was countered by either the crowd or an organization, retweets occurred more evenly over time, indicating sustained retweeting activities.\nThese findings  illustrated the dynamics of rumor propagation and debunking activities over time.\n\n\n\n\n\n6.3. Creator Profiles\n\nBeyond characterizing the creation patterns of crowd-generated counter-misinformation, we also analyze the profiles of these crowds as counter-misinformation creators.\nSpecifically, we examine their demographic factors and mindsets, as outlined in Table 7-(c).\n\n\n\n6.3.1. Demographics\n\nLiterature highlights the  influence of certain demographic factors on crowds\u2019 willingness and involvement in countering misinformation.\nOne noteworthy aspect is political ideology, which influences one\u2019s approach to governance and public policy.\nAccording to Cohen et\u00a0al. (2020), the  social identity threat in fake news  related to one\u2019s political ingroup indirectly affects crowds\u2019 readiness to publicly denounce fake news , finally attacking the political ideology.\nSimilarly, Steinfeld (2022) found that individuals who engage in violent or illegal political protests tend to actively combat disinformation, even though they may occasionally share disinformation themselves.\nThese findings underscore the intricate interplay between political ideology and countering misinformation.\n\n\nMedia literacy, also known as \u201cInformation Literacy Competence\u201d and \u201cNews Media Literacy,\u201d is another widely investigated factor.\nIt involves the critical analysis of media content, particularly news, to discern its credibility, bias, and intention.\nSeveral studies have highlighted its absence among the general audience, as well as the necessity for improved media literacy education.\nFor instance, Igbinovia et\u00a0al. (2021) emphasized the importance of media literacy in limiting the spread of fake news during the COVID-19 pandemic.\nThey revealed that greater media literacy can aid in identifying fake news, which in turn may facilitate  misinformation combating \u00a0(Vijaykumar et\u00a0al., 2022).\nVeeriah (2021) also affirmed the crucial role of media literacy in motivating corrective responses to misinformation.\nHowever, they found that even young crowds who felt sure about identifying fake news still demonstrated only moderate levels of media literacy. This observation implies the necessity of initiating media literacy education amongst young crowds .\nSimilarly, Huber et\u00a0al. (2022) echoed this finding, indicating that relying solely on general media literacy is insufficient in  countering certain types of fake news.\nThese collective findings highlight the significance of high-level or even specialized media literacy for crowds engaged in countering misinformation.\n\n\nIn addition to political ideology and media literacy, the above studies also examined additional factors such as age and education.\nFor instance, Vijaykumar et\u00a0al. (2022) found that crowds who are younger or less educated tend to be less involved in countering misinformation.\n\n\n\n\n6.3.2. Mindsets\n\nThe motivations of crowds to counter misinformation are influenced by their beliefs and mindsets.\nFor instance,  sharing denials has been identified as a crucial strategy for countering misinformation\u00a0(Pal et\u00a0al., 2018, 2019).\nPal et\u00a0al. (2018, 2019)  identified three key beliefs that encourage crowds to  share denials:\n(1) the belief that sharing denials helps spread the truth,\n(2) the belief that friends and the online community would favor the behavior of sharing rumor denials,\nand (3) the belief that the credibility of the source of rumor denials encourages sharing, thus influencing crowds\u2019 willingness to share for countering.\n\n\nMoreover, we note the third-person effect phenomenon\n, denoting the belief among individuals that media messages have a greater influence on others than on themselves.\nFor instance, Chen and Fu (2022) found that this effect positively encourages crowds to debunk online misinformation.\nAnother related belief, known as the \u201cothers\u2019 susceptibility\u201d, refers to the perception that \u201cothers will be affected by or susceptible to misinformation\u201d.\nSun et\u00a0al. (2020) discovered that such belief  can induce negative emotions such as guilt and anger, thus motivating vaccine supporters to correct anti-vaccination misinformation actively.\n\n\nLastly, harm awareness,  i.e.,  being aware of the negative consequences, can also motivate efforts to counter misinformation.\nFor example, Zhao et\u00a0al. (2016) found that perceiving the harm caused by rumors predicts a significant increase in engagement to counter misinformation. Similarly, Vijaykumar et\u00a0al. (2022) discovered that when crowds perceive that the severity of COVID-19 is not being properly addressed, they are motivated to  act against related misinformation.\n\n\n\n\n\n\n7. Discussion and Future Directions\n\n\n7.1. Discussion\n\nWhile our survey has focused on the potential of crowds\u00a0(Kumar and He, 2024) to combat misinformation through roles like annotators, evaluators, and creators, a nuanced comparative analysis of the effectiveness of each role is beneficial, especially highlighting which method should be employed under which circumstance:\n\n\n\u2022\n\nAnnotators: annotating by crowds can be particularly effective for rapidly identifying, flagging, and fact-checking potential misinformation at scale (e.g., social media misinformation flagging, image and video verification).\nThe diversity of perspectives and cultural contexts within the crowd can aid in detecting nuanced forms of misinformation.\nPractically, individual labeling is suited for (1) situations requiring unbiased, independent assessments; (2) initial stages of a study to establish a baseline of individual perceptions; (3) cases where privacy concerns prevent collaborative efforts; and (4) when trying to gauge the general public\u2019s ability to identify misinformation.\nOn the other hand, collaborative labeling is effective for (1) complex misinformation that requires diverse expertise to understand and evaluate; (2) fostering community engagement in combating misinformation; and (3) building consensus on challenging cases and developing shared standards for what constitutes misinformation and how to combat it.\nFinally, machine-assisted labeling is useful for (1) large-scale misinformation detection efforts; (2) pre-screening content before human review; (3) augmenting human efforts in resource-constrained environments; and (4) rapidly evolving situations where quick identification is crucial.\nHowever, for all these annotation methods, the quality and consistency of annotations may vary, necessitating robust quality control mechanisms and expert oversight.\n\n\n\n\u2022\n\nEvaluators: Engaging crowds in evaluating counter-misinformation can provide valuable insights into the effectiveness of these interventions across diverse audiences (e.g., public health messaging and political advertising evaluation). The crowd\u2019s collective feedback can help refine and tailor counter-narratives for maximum impact.\nParticularly, for direct assessment methods, we use in-lab experiments for (1) controlled studies of how people interact with and process counter-misinformation; and (2) testing the effectiveness of different counter-misinformation strategies. Interviews are appropriate for (1) in-depth exploration of individual experiences with counter-misinformation (e.g., understanding the personal and social contexts that influence belief in misinformation); and (2) gathering rich, qualitative data on how crows encounter counter-misinformation. Surveys are ideal for (1) collecting large-scale data across populations; and (2) tracking changes over time (e.g., gauging public awareness of specific misinformation and counter-misinformation campaigns).\nOn the other hand, regarding indirect methods,\nWe analyze (1) sentiment for assessing emotional responses to counter-misinformation and tracking public mood around controversial topics prone to misinformation; (2) stance for assessing the alignment of information with established consensus in counter-misinformation and evaluating the effectiveness of counter-misinformation in changing stances; and (3) share/engagement analysis for measuring the reach and potential impact of misinformation and comparing the spread of misinformation versus counter-misinformation.\nNevertheless, evaluations may be susceptible to biases, and appropriate measures should be taken to ensure objectivity and representativeness.\n\n\n\n\u2022\n\nCreators: Leveraging the creativity and diverse perspectives of the crowd in generating counter-misinformation can lead to more contextually relevant and culturally resonant messaging (e.g., multilingual content creation).\nIn practice, we focus on the creation patterns of these crowd-generated counter-misinformation contents when analyzing and identifying the effectiveness of different counter-misinformation contents and assessing coordination with fact-checking from professional experts.\nBesides, we emphasize the profiles of crowd creators when we (1) study the motivations and experiences of crowds, (2) identify influential counter-misinformation actors, and (3) assess diversity and representation in counter-misinformation, especially when we compare crowds with professional experts.\nHowever, ensuring the accuracy and factual integrity of crowd-generated content may pose challenges, requiring rigorous fact-checking and editorial oversight.\n\n\n\nAs mentioned, each role\u2019s effectiveness varies based on task, context, and misinformation domain.\nFor instance, annotation tasks may be more suitable for rapidly evolving narratives, while content creation may be better suited for addressing contextually relevant misinformation.\nBy understanding these nuances, practitioners and policymakers can strategically employ crowds, leveraging the strengths of each role while mitigating potential limitations through quality control, expert oversight, and a combination of crowd- and expert-driven efforts.\n\n\nTo enhance the generalizability of crowd-based counter-misinformation efforts to real-world scenarios, it is essential to consider potential factors as follows:\n\n\n\u2022\n\nEvolving misinformation tactics: Misinformation spreaders continuously adapt their tactics, potentially impacting the effectiveness of countermeasures by crowds. Continuous monitoring and adaptation are essential.\n\n\n\n\u2022\n\nCultural and linguistic contexts: Misinformation narratives and their impact can be deeply rooted in specific cultural and linguistic contexts. Crowds need to take care of these nuances to accurately counter contextually-specific misinformation.\n\n\n\n\u2022\n\nRegulatory and policy landscapes: Changes in regulations, policies, or legal frameworks governing online content and misinformation could impact the viability and implementation of crowd-based approaches, requiring adjustments to align with new guidelines or constraints.\n\n\n\nBy acknowledging these potential limitations in generalizability, our survey can offer more robust and actionable insights for real-world applications, contributing to the development of effective and sustainable crowd-based approaches to combating misinformation across diverse contexts.\n\n\n\n\n7.2. Future Directions\n\nIn this section, we outline potential avenues for future research in this field:\n\n\n\n\n\u2022\n\nImproving Crowd Annotations: While collaborative labeling aims to overcome the limitations in individual labeling (e.g., individual annotation biases\u00a0(Mitra and Gilbert, 2015)), it\u2019s important to note that individuals often share similar perspectives (homophily). Therefore, it\u2019s unclear whether collaborative labeling effectively captures diverse viewpoints.\nFuture research should explore this aspect and develop strategies to encourage diversity within groups countering misinformation. Similarly, human-in-the-loop identification of misinformation can benefit from agile classifiers that do not require extensive labeled examples initially and can quickly adapt to emerging misinformation (Mozes et\u00a0al., 2023). One approach to achieve this is by utilizing few-shot learning techniques\u00a0(Mozes et\u00a0al., 2023).\n\n\n\n\u2022\n\nMulti-platform and Multimodal Countering: Current social media-related work predominantly focuses on one specific platform like Twitter\u00a0(He et\u00a0al., 2021b; Chua et\u00a0al., 2017; Chua and Banerjee, 2017), Facebook\u00a0(Xue et\u00a0al., 2022), and Sina Weibo\u00a0(Wang et\u00a0al., 2022b). However, crowds countering misinformation may behave differently across various platforms due to variations in user demographics and engagement dynamics. Exploring how crowds counter on multiple platforms and whether countering on one platform influences others is essential for a comprehensive understanding of crowd-driven misinformation mitigation. Additionally, the crowd-generated counter-misinformation is not limited to text alone; it can also involve  images or videos to enhance the persuasiveness of their debunking efforts. Investigating these multimodal aspects benefits the design of effective countering contents.\n\n\n\n\u2022\n\nMultilingual and Topic-specific Countering: Most research works concentrate on either a single language (e.g., English\u00a0(Chua and Banerjee, 2017) or Chinese\u00a0(Wang et\u00a0al., 2022b)) or a specific misinformation topic (e.g., COVID-19\u00a0(Veeriah, 2021)). But, misinformation spans across languages and topics, leading to diverse countering actions. Analyzing how crowds in under-representative languages combat various topics reveals variations in countering strategies across languages and topics, thus contributing to a comprehensive understanding of misinformation countering. On the other hand, existing research on the profiles of crowds focuses on demographic factors such as education, political leanings, and media literacy. However, it overlooks misinformation topic-specific factors. For instance, an individual having a background in health education may be effective at countering health misinformation but susceptible to believing in climate misinformation. Therefore, exploring these topic-specific factors can enhance our understanding of human factors involved in countering misinformation.\n\n\n\n\u2022\n\nIn-thread Countering: While current research primarily examines the impact of standalone or accompanied counter-misinformation messages on social media platforms\u00a0(Chua et\u00a0al., 2017; Xue et\u00a0al., 2022), there is limited exploration into the dynamics of counter-misinformation within conversations or threads\u00a0(He et\u00a0al., 2024). For example, a crucial question arises: \u201cWhen others in a thread engage in countering, does it lead to correcting the misinformation or, conversely, amplifying it?\u201d\nThis form of in-thread countering (e.g., counter-misinformation responses to original misinformation posts) is frequently observed on social media platforms like Twitter and Reddit\u00a0(Achimescu and Chachev, 2020). Its impact is amplified due to the active engagement of multiple users in the thread. Investigating these in-thread behaviors provides valuable insights into the dynamics of countering\u00a0.\n\n\n\n\u2022\n\nSynergizing Professionals and Crowds to Combat Misinformation: \nCombining professional expertise with crowd insights offers a more comprehensive approach to tackling misinformation.\nProfessionals can guide and train the crowd, ensuring contributions adhere to fact-checking standards and best practices.\nFor instance, when creating counter-misinformation responses, crowds could learn from fact-checkers on how to craft evidence-based responses, properly cite sources, and maintain objectivity.\nConversely, the crowd provide diverse perspectives and identify emerging misinformation trends, aiding fact-checkers in staying informed.\nFostering this symbiotic relationship between professionals and crowds enhances effectiveness in countering misinformation.\n\n\n\n\u2022\n\nIdentifying and Mitigating Attack in Crowd-based Fight against Misinformation: \nThe crowd-based approach to combating misinformation, while promising, faces risks of coordinated attacks and exploitation by bad actors.\nThis future research direction would involve identifying and analyzing such potential attacks and developing strategies to mitigate them.\nThis is common considering the anonymity and decentralized nature of crowdsourcing. Finally, bad actors can amplify their influence or spread contradictory information.\nPotential strategies to mitigate these risks include robust identity verification procedures, moderation systems to filter out false information, and continuous monitoring and adaptation to evolving threats:\n(1) Build robust identity verification and reputation systems to filter out bad actors and promote accountability within the community;\n(2) Implement moderation and quality control systems to remove false messages before they propagate further, which can be achieved by automated detection and filtering mechanisms;\n(3) Continuously adapt and improve to stay ahead of potential threats, as attack vectors may evolve over time.\n\n\n\n\u2022\n\nLeveraging Large Language Models to Empower Crowds to Combat Misinformation: \nRecent advancements in large language models (LLMs) present an exciting opportunity to enhance and augment the capabilities of crowds\u2019 efforts in combating misinformation.\nPotential directions include:\n(1) Screening and annotating potential misinformation to prioritize and surface content that exhibits patterns or signals of misinformation, and flag it for further human evaluation;\n(2) Evaluating the counter-misinformation text by synthesizing\ninformation from multiple sources to verify claims and identify potential inconsistencies within the misinformation text.\n(3) Creating high-quality counter-misinformation\ntailored to specific audiences, languages, and cultural contexts to amplify the reach and impact of the efforts.\nHowever, it is crucial to acknowledge the potential risks and limitations associated with LLM integration, such as the propagation of biases, hallucinations, or the generation of plausible but factually incorrect content.\n\n\n\n\n\n\n\n\n8. Conclusions\n\nWhile crowd-based efforts to combat misinformation have increasingly attracted attention, there has yet to be a comprehensive survey paper that examines the multifaceted roles of crowds.\nOur study fills this gap by systematically categorizing the three primary roles of crowds: annotators, evaluators, and creators.\nToward this end, we present the inaugural systematic survey of 88 papers investigating crowd-based efforts, which were collected by following PRISMA guidelines.\nSpecifically, we presented key data statistics on misinformation, counter-misinformation, and crowd inputs found in the literature.\nAdditionally, we proposed a novel taxonomy that covers the diverse roles of crowds in a comprehensive way.\nMoreover, we provide detailed insights and findings extracted from the surveyed papers, offering valuable resources for effective counter-misinformation.\nBy doing so, this survey helps readers grasp the latest research developments in this field and establishes the foundation for encouraging advanced crowd-assisted methodologies to combat misinformation.\n\n\nACKNOWLEDGMENTS\nThis research/material is based upon work supported by NSF grant CNS-2154118. Any opinions, findings and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the position or policy of NSF and no official endorsement should be inferred.\n\n\n\nReferences\n\n\n(1)\n\n\n\n\nAchimescu and Chachev (2020)\n\nVlad Achimescu and Pavel\u00a0Dimitrov Chachev. 2020.\n\n\nRaising the Flag: Monitoring User Perceived Disinformation on Reddit.\n\n\nInformation 12 (12 2020), 4.\n\n\nIssue 1.\n\n\n\n\n\nAhmed et\u00a0al. (2020)\n\nWasim Ahmed, Josep Vidal-Alaball, Joseph Downing, and Francesc\u00a0L\u00f3pez Segu\u00ed. 2020.\n\n\nCOVID-19 and the 5G Conspiracy Theory: Social Network Analysis of Twitter Data.\n\n\nJournal of Medical Internet Research 22 (5 2020), e19458.\n\n\nIssue 5.\n\n\n\n\n\nAl-Motlaq (2021)\n\nMohammad\u00a0A. Al-Motlaq. 2021.\n\n\n\u201dThere is No Corona; It\u2019s a Conspiracy\u201d: Addressing the Perceptions of People about COVID-19 through the Narrative of Their Comments on Social Media.\n\n\nJournal of Consumer Health on the Internet 25 (1 2021), 65\u201376.\n\n\nIssue 1.\n\n\n\n\n\nAllen et\u00a0al. (2021)\n\nJennifer Allen, Antonio\u00a0A. Arechar, Gordon Pennycook, and David\u00a0G. Rand. 2021.\n\n\nScaling up fact-checking using the wisdom of crowds.\n\n\nScience Advances 7 (9 2021).\n\n\nIssue 36.\n\n\n\n\n\nAllen et\u00a0al. (2022)\n\nJennifer Allen, Cameron Martel, and David\u00a0G Rand. 2022.\n\n\nBirds of a feather don\u2019t fact-check each other: Partisanship and the evaluation of news in Twitter\u2019s Birdwatch crowdsourced fact-checking program. In CHI Conference on Human Factors in Computing Systems. 1\u201319.\n\n\n\n\n\n\nArif et\u00a0al. (2017)\n\nAhmer Arif, John\u00a0J. Robinson, Stephanie\u00a0A. Stanek, Elodie\u00a0S. Fichet, Paul Townsend, Zena Worku, and Kate Starbird. 2017.\n\n\nA closer look at the self-correcting crowd: Examining corrections in online rumors.\n\n\nProceedings of the 2017 ACM Conference on Computer Supported Cooperative Work and Social Computing, 155\u2013168.\n\n\n\n\n\n\nBabcock et\u00a0al. (2019a)\n\nMatthew Babcock, David\u00a0M. Beskow, and Kathleen\u00a0M. Carley. 2019a.\n\n\nDifferent faces of false: The spread and curtailment of false information in the black Panther Twitter discussion.\n\n\nJournal of Data and Information Quality 11 (9 2019), 1\u201315.\n\n\nIssue 4.\n\n\n\n\n\nBabcock et\u00a0al. (2019b)\n\nMatthew Babcock, Ramon Alfonso\u00a0Villa Cox, and Sumeet Kumar. 2019b.\n\n\nDiffusion of pro- and anti-false information tweets: the Black Panther movie case.\n\n\nComputational and Mathematical Organization Theory 25 (3 2019), 72\u201384.\n\n\nIssue 1.\n\n\n\n\n\nBhuiyan et\u00a0al. (2020)\n\nMd\u00a0Momen Bhuiyan, Amy\u00a0X. Zhang, Connie\u00a0Moon Sehat, and Tanushree Mitra. 2020.\n\n\nInvestigating Differences in Crowdsourced News Credibility Assessment.\n\n\nProceedings of the ACM on Human-Computer Interaction 4 (10 2020), 1\u201326.\n\n\nIssue CSCW2.\n\n\n\n\n\nBode and Vraga (2018)\n\nLeticia Bode and Emily\u00a0K. Vraga. 2018.\n\n\nSee Something, Say Something: Correction of Global Health Misinformation on Social Media.\n\n\nHealth Communication 33 (9 2018), 1131\u20131140.\n\n\nIssue 9.\n\n\n\n\n\nBorah et\u00a0al. (2021)\n\nPorismita Borah, Bimbisar Irom, and Ying\u00a0Chia Hsu. 2021.\n\n\n\u2018It infuriates me\u2019: examining young adults\u2019 reactions to and recommendations to fight misinformation about COVID-19.\n\n\nJournal of Youth Studies (8 2021), 1\u201321.\n\n\n\n\n\n\nBuchanan et\u00a0al. (2022)\n\nGeorge Buchanan, Ryan Kelly, Stephann Makri, and Dana McKay. 2022.\n\n\nReading between the lies: A classification scheme of types of reply to misinformation in public discussion threads. In ACM SIGIR Conference on Human Information Interaction and Retrieval. 243\u2013253.\n\n\n\n\n\n\nChan et\u00a0al. (2017)\n\nMan-pui\u00a0Sally Chan, Christopher\u00a0R Jones, Kathleen Hall\u00a0Jamieson, and Dolores Albarrac\u00edn. 2017.\n\n\nDebunking: A meta-analysis of the psychological efficacy of messages countering misinformation.\n\n\nPsychological science 28, 11 (2017), 1531\u20131546.\n\n\n\n\n\n\nCharlesworth\u00a0Z. (2021)\n\nSchuldt H. Shabani\u00a0S. Charlesworth\u00a0Z., Sokhn\u00a0M. 2021.\n\n\nSAMS: Human-in-the-loop approach to combat the sharing of digital misinformation.\n\n\nCEUR Workshop Proceedings.\n\n\n\n\n\n\nChen et\u00a0al. (2022)\n\nKaiping Chen, Yepeng Jin, and Anqi Shao. 2022.\n\n\nScience Factionalism: How Group Identity Language Affects Public Engagement With Misinformation and Debunking Narratives on a Popular Q&A Platform in China.\n\n\nSocial Media+ Society 8, 1 (2022), 20563051221077019.\n\n\n\n\n\n\nChen and Fu (2022)\n\nLiang Chen and Lunrui Fu. 2022.\n\n\nLet\u2019s fight the infodemic: the third-person effect process of misinformation during public health emergencies.\n\n\nInternet Research (2022).\n\n\n\n\n\n\nChen et\u00a0al. (2021)\n\nQiang Chen, Yangyi Zhang, Richard Evans, and Chen Min. 2021.\n\n\nWhy do citizens share COVID-19 fact-checks posted by Chinese government social media accounts? The elaboration likelihood model.\n\n\nInternational Journal of Environmental Research and Public Health 18, 19 (2021), 10058.\n\n\n\n\n\n\nChiu et\u00a0al. (2022)\n\nMing\u00a0Ming Chiu, Chong\u00a0Hyun Park, Hyelim Lee, Yu\u00a0Won Oh, and Jeong-Nam Kim. 2022.\n\n\nElection Fraud and Misinformation on Twitter: Author, Cluster, and Message Antecedents.\n\n\nMedia and Communication 10, 2 (2022), 66\u201380.\n\n\n\n\n\n\nChua and Banerjee (2017)\n\nAlton Y.\u00a0K. Chua and Snehasish Banerjee. 2017.\n\n\nA Study of Tweet Veracity to Separate Rumours from Counter-Rumours.\n\n\nProceedings of the 8th international conference on social media & society, 1\u20138.\n\n\n\n\n\n\nChua et\u00a0al. (2017)\n\nAlton Y.\u00a0K Chua, Cheng-Ying Tee, Augustine Pang, and Ee-Peng Lim. 2017.\n\n\nThe Retransmission of Rumor and Rumor Correction Messages on Twitter.\n\n\nAmerican Behavioral Scientist 61 (6 2017), 707\u2013723.\n\n\nIssue 7.\n\n\n\n\n\nCohen et\u00a0al. (2020)\n\nElizabeth\u00a0L. Cohen, Anita\u00a0Atwell Seate, Stephen\u00a0M. Kromka, Andrew Sutherland, Matthew Thomas, Karissa Skerda, and Andrew Nicholson. 2020.\n\n\nTo correct or not to correct? Social identity threats increase willingness to denounce fake news through presumed media influence and hostile media perceptions.\n\n\nCommunication Research Reports 37 (10 2020), 263\u2013275.\n\n\nIssue 5.\n\n\n\n\n\nDai et\u00a0al. (2022)\n\nYue\u00a0Nancy Dai, Wufan Jia, Lunrui Fu, Mengru Sun, and Li\u00a0Crystal Jiang. 2022.\n\n\nThe effects of self-generated and other-generated eWOM in inoculating against misinformation.\n\n\nTelematics and Informatics 71 (2022), 101835.\n\n\n\n\n\n\nDang et\u00a0al. (2016)\n\nAnh Dang, Michael Smit, Abidalrahman Moh\u2019d, Rosane Minghim, and Evangelos Milios. 2016.\n\n\nToward understanding how users respond to rumours in social media.\n\n\n2016 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM), 777\u2013784.\n\n\n\n\n\n\nFarooq et\u00a0al. (2022)\n\nMunaza Farooq, Aqsa Ashraf\u00a0Makhdomi, and Iqra Altaf\u00a0Gillani. 2022.\n\n\nCrowd Sourcing and Blockchain-Based Incentive Mechanism to Combat Fake News.\n\n\nIn Combating Fake News with Computational Intelligence Techniques. Springer, 299\u2013325.\n\n\n\n\n\n\nFeatherstone and Zhang (2020)\n\nJieyu\u00a0Ding Featherstone and Jingwen Zhang. 2020.\n\n\nFeeling angry: the effects of vaccine misinformation and refutational messages on negative emotions and vaccination attitude.\n\n\nJournal of Health Communication 25 (9 2020), 692\u2013702.\n\n\nIssue 9.\n\n\n\n\n\nFlores-Saviaga and Savage (2021)\n\nClaudia Flores-Saviaga and Saiph Savage. 2021.\n\n\nFighting disaster misinformation in Latin America: the #19S Mexican earthquake case study.\n\n\nPersonal and Ubiquitous Computing 25 (4 2021), 353\u2013373.\n\n\nIssue 2.\n\n\n\n\n\nGiachanou et\u00a0al. (2022)\n\nAnastasia Giachanou, Bilal Ghanem, Esteban\u00a0A R\u00edssola, Paolo Rosso, Fabio Crestani, and Daniel Oberski. 2022.\n\n\nThe impact of psycholinguistic patterns in discriminating between fake news spreaders and fact checkers.\n\n\nData & Knowledge Engineering 138 (2022), 101960.\n\n\n\n\n\n\nGoh et\u00a0al. (2017)\n\nDion Hoe-Lian Goh, Alton\u00a0Y.K. Chua, Hanyu Shi, Wenju Wei, Haiyan Wang, and Ee\u00a0Peng Lim. 2017.\n\n\nAn Analysis of Rumor and Counter-Rumor Messages in Social Media.\n\n\n, 256-266\u00a0pages.\n\n\n\n\n\n\nGunaratne et\u00a0al. (2019)\n\nKeith Gunaratne, Eric\u00a0A. Coomes, and Hourmazd Haghbayan. 2019.\n\n\nTemporal trends in anti-vaccine discourse on Twitter.\n\n\nVaccine 37 (8 2019), 4867\u20134871.\n\n\nIssue 35.\n\n\n\n\n\nGuo et\u00a0al. (2019)\n\nBin Guo, Yasan Ding, Lina Yao, Yunji Liang, and Zhiwen Yu. 2019.\n\n\nThe future of misinformation detection: new perspectives and trends.\n\n\narXiv preprint arXiv:1909.03654 (2019).\n\n\n\n\n\n\nHartwig et\u00a0al. (2023)\n\nKatrin Hartwig, Frederic Doell, and Christian Reuter. 2023.\n\n\nThe Landscape of User-centered Misinformation Interventions\u2013A Systematic Literature Review.\n\n\narXiv preprint arXiv:2301.06517 (2023).\n\n\n\n\n\n\nHe et\u00a0al. (2021a)\n\nBing He, Mustaque Ahamad, and Srijan Kumar. 2021a.\n\n\nPetgen: Personalized text generation attack on deep sequence embedding-based classification models. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining. 575\u2013584.\n\n\n\n\n\n\nHe et\u00a0al. (2023)\n\nBing He, Mustaque Ahamad, and Srijan Kumar. 2023.\n\n\nReinforcement learning-based counter-misinformation response generation: a case study of COVID-19 vaccine misinformation. In Proceedings of the ACM Web Conference 2023. 2698\u20132709.\n\n\n\n\n\n\nHe et\u00a0al. (2024)\n\nBing He, Yingchen Ma, Mustaque Ahamad, and Srijan Kumar. 2024.\n\n\nCorrective or Backfire: Characterizing and Predicting User Response to Social Correction. In Proceedings of the 16th ACM Web Science Conference. 149\u2013158.\n\n\n\n\n\n\nHe et\u00a0al. (2021b)\n\nBing He, Caleb Ziems, Sandeep Soni, Naren Ramakrishnan, Diyi Yang, and Srijan Kumar. 2021b.\n\n\nRacism is a virus: Anti-Asian hate and counterspeech in social media during the COVID-19 crisis. In Proceedings of the 2021 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining. 90\u201394.\n\n\n\n\n\n\nHuber et\u00a0al. (2022)\n\nBrigitte Huber, Porismita Borah, and Homero Gil\u00a0de Z\u00fa\u00f1iga. 2022.\n\n\nTaking corrective action when exposed to fake news: The role of fake news literacy.\n\n\nJournal of Media Literacy Education 14, 2 (2022), 1\u201314.\n\n\n\n\n\n\nHunt et\u00a0al. (2020)\n\nKyle Hunt, Bairong Wang, and Jun Zhuang. 2020.\n\n\nMisinformation debunking and cross-platform information sharing through Twitter during Hurricanes Harvey and Irma: a case study on shelters and ID checks.\n\n\nNatural Hazards 103 (8 2020), 861\u2013883.\n\n\nIssue 1.\n\n\n\n\n\nIgbinovia et\u00a0al. (2021)\n\nMagnus\u00a0Osahon Igbinovia, Omorodion Okuonghae, and John\u00a0Oluwaseye Adebayo. 2021.\n\n\nInformation literacy competence in curtailing fake news about the COVID-19 pandemic among undergraduates in Nigeria.\n\n\nReference Services Review 49 (5 2021), 3\u201318.\n\n\nIssue 1.\n\n\n\n\n\nIslam et\u00a0al. (2020)\n\nMd\u00a0Rafiqul Islam, Shaowu Liu, Xianzhi Wang, and Guandong Xu. 2020.\n\n\nDeep learning for misinformation detection on online social networks: a survey and new perspectives.\n\n\nSocial Network Analysis and Mining 10 (2020), 1\u201320.\n\n\n\n\n\n\nJung et\u00a0al. (2020)\n\nAnna-Katharina Jung, Bj\u00f6rn Ross, and Stefan Stieglitz. 2020.\n\n\nCaution: Rumors ahead\u2014A case study on the debunking of false information on Twitter.\n\n\nBig Data & Society 7 (7 2020), 205395172098012.\n\n\nIssue 2.\n\n\n\n\n\nKessler and Bachmann (2022)\n\nSabrina\u00a0Heike Kessler and Eva Bachmann. 2022.\n\n\nDebunking health myths on the internet: the persuasive effect of (visual) online communication.\n\n\nJournal of Public Health (2022), 1\u201313.\n\n\n\n\n\n\nKim et\u00a0al. (2021)\n\nSojung\u00a0Claire Kim, Emily\u00a0K. Vraga, and John Cook. 2021.\n\n\nAn Eye Tracking Approach to Understanding Misinformation and Correction Strategies on Social Media: The Mediating Role of Attention and Credibility to Reduce HPV Vaccine Misperceptions.\n\n\nHealth Communication 36 (11 2021), 1687\u20131696.\n\n\nIssue 13.\n\n\n\n\n\nKim and Chen (2022)\n\nSang\u00a0Jung Kim and Kaiping Chen. 2022.\n\n\nThe use of emotions in conspiracy and debunking videos to engage publics on YouTube.\n\n\nNew Media & Society (2022), 14614448221105877.\n\n\n\n\n\n\nKirchner and Reuter (2020)\n\nJan Kirchner and Christian Reuter. 2020.\n\n\nCountering Fake News: A Comparison of Possible Solutions Regarding User Acceptance and Effectiveness.\n\n\nProceedings of the ACM on Human-Computer Interaction 4 (10 2020), 1\u201327.\n\n\nIssue CSCW2.\n\n\n\n\n\nKligler-Vilenchik (2022)\n\nNeta Kligler-Vilenchik. 2022.\n\n\nCollective social correction: addressing misinformation through group practices of information verification on WhatsApp.\n\n\nDigital Journalism 10, 2 (2022), 300\u2013318.\n\n\n\n\n\n\nKrippendorff (2011)\n\nKlaus Krippendorff. 2011.\n\n\nComputing Krippendorff\u2019s alpha-reliability.\n\n\n(2011).\n\n\n\n\n\n\nKumar and He (2024)\n\nSrijan Kumar and Bing He. 2024.\n\n\nCrowd-Powered Solutions to Identify and Correct Online Misinformation.\n\n\nThe BARONS and the MOB (2024), 61.\n\n\n\n\n\n\nLee et\u00a0al. (2021)\n\nJiyoung Lee, Shaheen Kanthawala, Brian\u00a0C. Britt, Danielle\u00a0F. Deavours, and Tanya Ott-Fulmore. 2021.\n\n\nPrevalence of anger, engaged in sadness: engagement in misinformation, correction, and emotional tweets during mass shootings.\n\n\nOnline Information Review ahead-of-print (8 2021).\n\n\nIssue ahead-of-print.\n\n\n\n\n\nLi et\u00a0al. (2020)\n\nZongmin Li, Qi Zhang, Yuhong Wang, and Shihang Wang. 2020.\n\n\nSocial media rumor refuter feature analysis and crowd identification based on XGBoost and NLP.\n\n\nApplied Sciences 10, 14 (2020), 4711.\n\n\n\n\n\n\nMa et\u00a0al. (2023)\n\nYingchen Ma, Bing He, Nathan Subrahmanian, and Srijan Kumar. 2023.\n\n\nCharacterizing and Predicting Social Correction on Twitter. In Proceedings of the 15th ACM Web Science Conference 2023. 86\u201395.\n\n\n\n\n\n\nMancosu and Vegetti (2021)\n\nMoreno Mancosu and Federico Vegetti. 2021.\n\n\n\u201cIs It the Message or the Messenger?\u201d: Conspiracy Endorsement and Media Sources.\n\n\nSocial Science Computer Review 39 (12 2021), 1203\u20131217.\n\n\nIssue 6.\n\n\n\n\n\nMarkowitz et\u00a0al. (2023)\n\nDavid\u00a0M Markowitz, Timothy\u00a0R Levine, Kim\u00a0B Serota, and Alivia\u00a0D Moore. 2023.\n\n\nCross-checking journalistic fact-checkers: The role of sampling and scaling in interpreting false and misleading statements.\n\n\nPlos one 18, 7 (2023), e0289004.\n\n\n\n\n\n\nMartel et\u00a0al. (2021)\n\nCameron Martel, Mohsen Mosleh, and David\u00a0G. Rand. 2021.\n\n\nYou\u2019re Definitely Wrong, Maybe: Correction Style Has Minimal Effect on Corrections of Misinformation Online.\n\n\nMedia and Communication 9 (2 2021), 120\u2013133.\n\n\nIssue 1.\n\n\n\n\n\nMasullo and Kim (2021)\n\nGina\u00a0M. Masullo and Jiwon Kim. 2021.\n\n\nExploring \u201cAngry\u201d and \u201cLike\u201d Reactions on Uncivil Facebook Comments That Correct Misinformation in the News.\n\n\nDigital Journalism 9 (9 2021), 1103\u20131122.\n\n\nIssue 8.\n\n\n\n\n\nMcCreadie et\u00a0al. (2015)\n\nRichard McCreadie, Craig Macdonald, and Iadh Ounis. 2015.\n\n\nCrowdsourced Rumour Identification During Emergencies.\n\n\nProceedings of the 24th International Conference on World Wide Web, 965\u2013970.\n\n\n\n\n\n\nMcHugh (2012)\n\nMary\u00a0L McHugh. 2012.\n\n\nInterrater reliability: the kappa statistic.\n\n\nBiochemia medica 22, 3 (2012), 276\u2013282.\n\n\n\n\n\n\nMemon and Carley (2020)\n\nShahan\u00a0Ali Memon and Kathleen\u00a0M. Carley. 2020.\n\n\nCharacterizing COVID-19 Misinformation Communities Using a Novel Twitter Dataset.\n\n\n(8 2020).\n\n\n\n\n\n\nMicallef et\u00a0al. (2022)\n\nNicholas Micallef, Vivienne Armacost, Nasir Memon, and Sameer Patil. 2022.\n\n\nTrue or false: Studying the work practices of professional fact-checkers.\n\n\nProceedings of the ACM on Human-Computer Interaction 6, CSCW1 (2022), 1\u201344.\n\n\n\n\n\n\nMicallef et\u00a0al. (2020)\n\nNicholas Micallef, Bing He, Srijan Kumar, Mustaque Ahamad, and Nasir Memon. 2020.\n\n\nThe Role of the Crowd in Countering Misinformation: A Case Study of the COVID-19 Infodemic.\n\n\n2020 IEEE International Conference on Big Data (Big Data), 748\u2013757.\n\n\n\n\n\n\nMitra and Gilbert (2015)\n\nTanushree Mitra and Eric Gilbert. 2015.\n\n\nCredbank: A large-scale social media corpus with associated credibility annotations.\n\n\nNinth international AAAI conference on web and social media.\n\n\n\n\n\n\nMoher et\u00a0al. (2009)\n\nDavid Moher, Alessandro Liberati, Jennifer Tetzlaff, Douglas\u00a0G Altman, and PRISMA Group*. 2009.\n\n\nPreferred reporting items for systematic reviews and meta-analyses: the PRISMA statement.\n\n\nAnnals of internal medicine 151, 4 (2009), 264\u2013269.\n\n\n\n\n\n\nMozes et\u00a0al. (2023)\n\nMaximilian Mozes, Jessica Hoffmann, Katrin Tomanek, Muhamed Kouate, Nithum Thain, Ann Yuan, Tolga Bolukbasi, and Lucas Dixon. 2023.\n\n\nTowards Agile Text Classifiers for Everyone.\n\n\narXiv preprint arXiv:2302.06541 (2023).\n\n\n\n\n\n\nMujumdar and Kumar (2021)\n\nRohit Mujumdar and Srijan Kumar. 2021.\n\n\nHawkEye: a robust reputation system for community-based counter-misinformation. In Proceedings of the 2021 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining. 188\u2013192.\n\n\n\n\n\n\nNadamoto et\u00a0al. (2013)\n\nAkiyo Nadamoto, Mai Miyabe, and Eiji Aramaki. 2013.\n\n\nAnalysis of Microblog Rumors and Correction Texts for Disaster Situations.\n\n\nProceedings of International Conference on Information Integration and Web-based Applications & Services - IIWAS \u201913, 44\u201352.\n\n\n\n\n\n\nOrosz et\u00a0al. (2016)\n\nG\u00e1bor Orosz, P\u00e9ter Krek\u00f3, Benedek Paskuj, Istv\u00e1n T\u00f3th-Kir\u00e1ly, Be\u00e1ta B\u0151the, and Christine Roland-L\u00e9vy. 2016.\n\n\nChanging Conspiracy Beliefs through Rationality and Ridiculing.\n\n\nFrontiers in Psychology 7 (10 2016).\n\n\n\n\n\n\nPal et\u00a0al. (2017)\n\nAnjan Pal, Alton\u00a0Y.K. Chua, and Dion Hoe-Lian Goh. 2017.\n\n\nDoes KFC sell rat? Analysis of tweets in the wake of a rumor outbreak.\n\n\nAslib Journal of Information Management 69 (11 2017), 660\u2013673.\n\n\nIssue 6.\n\n\n\n\n\nPal et\u00a0al. (2019)\n\nAnjan Pal, Alton\u00a0Y.K. Chua, and Dion Hoe-Lian Goh. 2019.\n\n\nDebunking rumors on social media: The use of denials.\n\n\nComputers in Human Behavior 96 (7 2019), 110\u2013122.\n\n\n\n\n\n\nPal et\u00a0al. (2018)\n\nAnjan Pal, Alton Y.\u00a0K. Chua, and Dion Hoe-Lian Goh. 2018.\n\n\nSalient Beliefs about Sharing Rumor Denials on the Internet.\n\n\nProceedings of the 12th International Conference on Ubiquitous Information Management and Communication, 1\u20137.\n\n\n\n\n\n\nPasquetto et\u00a0al. (2022)\n\nIrene\u00a0V Pasquetto, Eaman Jahani, Shubham Atreja, and Matthew Baum. 2022.\n\n\nSocial Debunking of Misinformation on WhatsApp: The Case for Strong and In-group Ties.\n\n\nProceedings of the ACM on Human-Computer Interaction 6, CSCW1 (2022), 1\u201335.\n\n\n\n\n\n\nPennycook and Rand (2019)\n\nGordon Pennycook and David\u00a0G. Rand. 2019.\n\n\nFighting misinformation on social media using crowdsourced judgments of news source quality.\n\n\nProceedings of the National Academy of Sciences 116 (2 2019), 2521\u20132526.\n\n\nIssue 7.\n\n\n\n\n\nPillai et\u00a0al. (2022)\n\nRaunak\u00a0M Pillai, Sarah Brown-Schmidt, and Lisa\u00a0K Fazio. 2022.\n\n\nDoes wording matter? Examining the effect of phrasing on memory for negated political fact checks.\n\n\nJournal of Applied Research in Memory and Cognition (2022).\n\n\n\n\n\n\nPorter and Wood (2021)\n\nEthan Porter and Thomas\u00a0J Wood. 2021.\n\n\nThe global effectiveness of fact-checking: Evidence from simultaneous experiments in Argentina, Nigeria, South Africa, and the United Kingdom.\n\n\nProceedings of the National Academy of Sciences 118, 37 (2021), e2104235118.\n\n\n\n\n\n\nPrimig (2022)\n\nFlorian Primig. 2022.\n\n\nThe Influence of Media Trust and Normative Role Expectations on the Credibility of Fact Checkers.\n\n\nJournalism Practice (2022), 1\u201321.\n\n\n\n\n\n\nPundir et\u00a0al. (2021)\n\nVartika Pundir, Elangbam\u00a0Binodini Devi, and Vishnu Nath. 2021.\n\n\nArresting fake news sharing on social media: a theory of planned behavior approach.\n\n\nManagement Research Review 44 (7 2021), 1108\u20131138.\n\n\nIssue 8.\n\n\n\n\n\nRamachandran et\u00a0al. (2020)\n\nGowri Ramachandran, Daniel Nemeth, David Neville, Dimitrii Zhelezov, Ahmet Yalcin, Oliver Fohrmann, and Bhaskar Krishnamachari. 2020.\n\n\nWhistleBlower: Towards A Decentralized and Open Platform for Spotting Fake News.\n\n\n2020 IEEE International Conference on Blockchain (Blockchain), 154\u2013161.\n\n\n\n\n\n\nRoitero et\u00a0al. (2021)\n\nKevin Roitero, Michael Soprano, Beatrice Portelli, Massimiliano De\u00a0Luise, Damiano Spina, Vincenzo\u00a0Della Mea, Giuseppe Serra, Stefano Mizzaro, and Gianluca Demartini. 2021.\n\n\nCan the crowd judge truthfulness? A longitudinal study on recent misinformation about COVID-19.\n\n\nPersonal and Ubiquitous Computing (2021), 1\u201331.\n\n\n\n\n\n\nShabani and Sokhn (2018)\n\nShaban Shabani and Maria Sokhn. 2018.\n\n\nHybrid Machine-Crowd Approach for Fake News Detection.\n\n\n2018 IEEE 4th International Conference on Collaboration and Internet Computing (CIC), 299\u2013306.\n\n\n\n\n\n\nSharma et\u00a0al. (2019)\n\nKarishma Sharma, Feng Qian, He Jiang, Natali Ruchansky, Ming Zhang, and Yan Liu. 2019.\n\n\nCombating fake news: A survey on identification and mitigation techniques.\n\n\nACM Transactions on Intelligent Systems and Technology 10 (5 2019), 1\u201342.\n\n\nIssue 3.\n\n\n\n\n\nShu et\u00a0al. (2020)\n\nKai Shu, Deepak Mahudeswaran, Suhang Wang, Dongwon Lee, and Huan Liu. 2020.\n\n\nFakenewsnet: A data repository with news content, social context, and spatiotemporal information for studying fake news on social media.\n\n\nBig data 8, 3 (2020), 171\u2013188.\n\n\n\n\n\n\nShuhud et\u00a0al. (2017)\n\nMohd Ilias\u00a0M Shuhud, Najwa Hayaati\u00a0Mohd Alwi, and Azni Haslizan\u00a0Abd Halim. 2017.\n\n\nSix Critical Processes to Refute Social-Media-Rumor.\n\n\nAdvanced Science Letters 23 (5 2017), 4929\u20134933.\n\n\nIssue 5.\n\n\n\n\n\nSilverman (2016)\n\nCraig Silverman. 2016.\n\n\nThis analysis shows how viral fake election news stories outperformed real news on Facebook.\n\n\nBuzzFeed news 16 (2016).\n\n\n\n\n\n\nSoprano et\u00a0al. (2021)\n\nMichael Soprano, Kevin Roitero, David\u00a0La Barbera, Davide Ceolin, Damiano Spina, Stefano Mizzaro, and Gianluca Demartini. 2021.\n\n\nThe many dimensions of truthfulness: Crowdsourcing misinformation assessments on a multidimensional scale.\n\n\nInformation Processing & Management 58 (11 2021), 102710.\n\n\nIssue 6.\n\n\n\n\n\nSteinfeld (2022)\n\nNili Steinfeld. 2022.\n\n\nThe disinformation warfare: how users use every means possible in the political battlefield on social media.\n\n\nOnline Information Review (2022).\n\n\n\n\n\n\nStewart et\u00a0al. (2018)\n\nLeo\u00a0G Stewart, Ahmer Arif, and Kate Starbird. 2018.\n\n\nExamining trolls and polarization with a retweet network. In Proc. ACM WSDM, workshop on Misinformation and Misbehavior Mining on the Web.\n\n\n\n\n\n\nStojanov (2015)\n\nAna Stojanov. 2015.\n\n\nReducing conspiracy theory beliefs.\n\n\nPsihologija 48 (2015), 251\u2013266.\n\n\nIssue 3.\n\n\n\n\n\nSuarez-Lledo and Alvarez-Galvez (2021)\n\nVictor Suarez-Lledo and Javier Alvarez-Galvez. 2021.\n\n\nPrevalence of health misinformation on social media: systematic review.\n\n\nJournal of medical Internet research 23, 1 (2021), e17187.\n\n\n\n\n\n\nSun et\u00a0al. (2020)\n\nYanqing Sun, Stella\u00a0C. Chia, Fangcao Lu, and Jeffry Oktavianus. 2020.\n\n\nThe Battle is On: Factors that Motivate People to Combat Anti-Vaccine Misinformation.\n\n\nHealth Communication (10 2020), 1\u201310.\n\n\n\n\n\n\nSun et\u00a0al. (2021)\n\nYanqing Sun, Jeffry Oktavianus, Sai Wang, and Fangcao Lu. 2021.\n\n\nThe Role of Influence of Presumed Influence and Anticipated Guilt in Evoking Social Correction of COVID-19 Misinformation.\n\n\nHealth Communication (2 2021), 1\u201310.\n\n\n\n\n\n\nTanaka and Hirayama (2019)\n\nYuko Tanaka and Rumi Hirayama. 2019.\n\n\nExposure to Countering Messages Online: Alleviating or Strengthening False Belief?\n\n\nCyberpsychology, Behavior, and Social Networking 22 (11 2019), 742\u2013746.\n\n\nIssue 11.\n\n\n\n\n\nTanihara et\u00a0al. (2022)\n\nTsukasa Tanihara, Shinichi Yamaguchi, Tomoaki Watanabe, and Hidetaka Oshima. 2022.\n\n\nEffects of corrections on COVID-19-related misinformation: cross-media empirical analyses in Japan.\n\n\nInternational Journal of Web Based Communities 18, 1 (2022), 41\u201363.\n\n\n\n\n\n\nTay et\u00a0al. (2022)\n\nLi\u00a0Qian Tay, Mark\u00a0J Hurlstone, Tim Kurz, and Ullrich\u00a0KH Ecker. 2022.\n\n\nA comparison of prebunking and debunking interventions for implied versus explicit misinformation.\n\n\nBritish Journal of Psychology 113, 3 (2022), 591\u2013607.\n\n\n\n\n\n\nTchakount\u00e9 et\u00a0al. (2020)\n\nFranklin Tchakount\u00e9, Ahmadou Faissal, Marcellin Atemkeng, and Achille Ntyam. 2020.\n\n\nA Reliable Weighting Scheme for the Aggregation of Crowd Intelligence to Detect Fake News.\n\n\nInformation 11 (6 2020), 319.\n\n\nIssue 6.\n\n\n\n\n\nVafeiadis et\u00a0al. (2019)\n\nMichail Vafeiadis, Denise\u00a0S. Bortree, Christen Buckley, Pratiti Diddi, and Anli Xiao. 2019.\n\n\nRefuting fake news on social media: nonprofits, crisis response strategies and issue involvement.\n\n\nJournal of Product & Brand Management 29 (5 2019), 209\u2013222.\n\n\nIssue 2.\n\n\n\n\n\nvan\u00a0der Meer and Jin (2020)\n\nToni G. L.\u00a0A. van\u00a0der Meer and Yan Jin. 2020.\n\n\nSeeking Formula for Misinformation Treatment in Public Health Crises: The Effects of Corrective Information Type and Source.\n\n\nHealth Communication 35 (4 2020), 560\u2013575.\n\n\nIssue 5.\n\n\n\n\n\nVeeriah (2021)\n\nJeyasushma Veeriah. 2021.\n\n\nYOUNG ADULTS\u2019ABILITY TO DETECT FAKE NEWS AND THEIR NEW MEDIA LITERACY LEVEL IN THE WAKE OF THE COVID-19 PANDEMIC.\n\n\nJournal of Content, Community and Communication 13 (2021), 372\u2013383.\n\n\nIssue 7.\n\n\n\n\nVerma et\u00a0al. (2022)\n\nGaurav Verma, Ankur Bhardwaj, Talayeh Aledavood, Munmun De\u00a0Choudhury, and Srijan Kumar. 2022.\n\n\nExamining the impact of sharing COVID-19 misinformation online on mental health.\n\n\nScientific Reports 12, 1 (2022), 1\u20139.\n\n\n\n\n\n\nVijaykumar et\u00a0al. (2022)\n\nSantosh Vijaykumar, Daniel\u00a0T Rogerson, Yan Jin, and Mariella\u00a0Silva de Oliveira\u00a0Costa. 2022.\n\n\nDynamics of social corrections to peers sharing COVID-19 misinformation on WhatsApp in Brazil.\n\n\nJournal of the American Medical Informatics Association 29, 1 (2022), 33\u201342.\n\n\n\n\n\n\nVo and Lee (2019)\n\nNguyen Vo and Kyumin Lee. 2019.\n\n\nLearning from fact-checkers: Analysis and generation of fact-checking language.\n\n\nProceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval, 335\u2013344.\n\n\n\n\n\n\nVosoughi et\u00a0al. (2018)\n\nSoroush Vosoughi, Deb Roy, and Sinan Aral. 2018.\n\n\nThe spread of true and false news online.\n\n\nscience 359, 6380 (2018), 1146\u20131151.\n\n\n\n\n\n\nVraga et\u00a0al. (2021)\n\nEmily\u00a0K. Vraga, Leticia Bode, and Melissa Tully. 2021.\n\n\nThe Effects of a News Literacy Video and Real-Time Corrections to Video Misinformation Related to Sunscreen and Skin Cancer.\n\n\nHealth Communication (4 2021), 1\u20139.\n\n\n\n\n\n\nWalker and Matsa (2021)\n\nMason Walker and Katerina\u00a0Eva Matsa. 2021.\n\n\nNews consumption across social media in 2021.\n\n\n(2021).\n\n\n\n\n\n\nWang and Zhuang (2018)\n\nBairong Wang and Jun Zhuang. 2018.\n\n\nRumor response, debunking response, and decision makings of misinformed Twitter users during disasters.\n\n\nNatural Hazards 93 (9 2018), 1145\u20131162.\n\n\nIssue 3.\n\n\n\n\n\nWang et\u00a0al. (2022a)\n\nXin Wang, Fan Chao, Ning Ma, and Guang Yu. 2022a.\n\n\nExploring the Effect of Spreading Fake News Debunking Based on Social Relationship Networks.\n\n\nFrontiers in Physics (2022), 180.\n\n\n\n\n\n\nWang et\u00a0al. (2021)\n\nXin Wang, Fan Chao, and Guang Yu. 2021.\n\n\nEvaluating Rumor Debunking Effectiveness During the COVID-19 Pandemic Crisis: Utilizing User Stance in Comments on Sina Weibo.\n\n\nFrontiers in public health (2021), 1925.\n\n\n\n\n\n\nWang et\u00a0al. (2022b)\n\nXin Wang, Fan Chao, Guang Yu, and Kaihang Zhang. 2022b.\n\n\nFactors influencing fake news rebuttal acceptance during the COVID-19 pandemic and the moderating effect of cognitive ability.\n\n\nComputers in human behavior 130 (2022), 107174.\n\n\n\n\n\n\nWang et\u00a0al. (2019)\n\nYuxi Wang, Martin McKee, Aleksandra Torbica, and David Stuckler. 2019.\n\n\nSystematic literature review on the spread of health-related misinformation on social media.\n\n\nSocial science & medicine 240 (2019), 112552.\n\n\n\n\n\n\nWeber et\u00a0al. (2020)\n\nDerek Weber, Mehwish Nasim, Lucia Falzon, and Lewis Mitchell. 2020.\n\n\n#ArsonEmergency and Australia\u2019s \u201cBlack Summer\u201d: Polarisation and Misinformation on Social Media.\n\n\n159\u2013173 pages.\n\n\n\n\n\n\nXu et\u00a0al. (2022)\n\nJiechen Xu, Lei Han, Shaoyang Fan, Shazia Sadiq, and Gianluca Demartini. 2022.\n\n\nDoes Evidence from Peers Help Crowd Workers in Assessing Truthfulness?. In Companion Proceedings of the Web Conference 2022. 302\u2013306.\n\n\n\n\n\n\nXue et\u00a0al. (2022)\n\nHaoning Xue, Xuanjun Gong, and Hannah Stevens. 2022.\n\n\nCOVID-19 vaccine fact-checking posts on Facebook: observational study.\n\n\nJournal of medical Internet research 24, 6 (2022), e38423.\n\n\n\n\n\n\nYang and Overton (2022)\n\nFan Yang and Holly Overton. 2022.\n\n\nWhat If Unmotivated Is More Dangerous? The Motivation-Contingent Effectiveness of Misinformation Correction on Social Media.\n\n\nInternational Journal of Communication 16 (2022), 27.\n\n\n\n\n\n\nYu et\u00a0al. (2022)\n\nWenting Yu, Fei Shen, and Chen Min. 2022.\n\n\nCorrecting science misinformation in an authoritarian country: An experiment from China.\n\n\nTelematics and Informatics 66 (2022), 101749.\n\n\n\n\n\n\nZeng et\u00a0al. (2019)\n\nJing Zeng, Jean Burgess, and Axel Bruns. 2019.\n\n\nIs citizen journalism better than professional journalism for fact-checking rumours in China? How Weibo users verified information following the 2015 Tianjin blasts.\n\n\nGlobal Media and China 4 (3 2019), 13\u201335.\n\n\nIssue 1.\n\n\n\n\n\nZhang et\u00a0al. (2022)\n\nYuqi Zhang, Bin Guo, Yasan Ding, Jiaqi Liu, Chen Qiu, Sicong Liu, and Zhiwen Yu. 2022.\n\n\nInvestigation of the determinants for misinformation correction effectiveness on social media during COVID-19 pandemic.\n\n\nInformation Processing & Management 59, 3 (2022), 102935.\n\n\n\n\n\n\nZhao et\u00a0al. (2016)\n\nLiming Zhao, Jianli Yin, and Yao Song. 2016.\n\n\nAn exploration of rumor combating behavior on social media in the context of social crises.\n\n\nComputers in Human Behavior 58 (5 2016), 25\u201336.\n\n\n\n\n\n\nZubiaga et\u00a0al. (2016)\n\nArkaitz Zubiaga, Elena Kochkina, Maria Liakata, Rob Procter, and Michal Lukasik. 2016.\n\n\nStance classification in rumours as a sequential task exploiting the tree structure of social media conversations.\n\n\narXiv preprint arXiv:1609.09028 (2016).\n\n\n\n\n\n\n\n\n\n\n\nGenerated  on Mon Nov  4 05:34:33 2024 by LaTeXML\n\n\n\n\n"}, {"id": "http://arxiv.org/abs/2104.00124v2", "title": "Misinformation detection in Luganda-English code-mixed social media text", "contents": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n | arXiv e-print repository\n\n\n\n\n\n\n\nSkip to main content\n\n\n\n\n\nWe gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors. Donate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHelp | Advanced Search\n\n\n\n\nAll fields\nTitle\nAuthor\nAbstract\nComments\nJournal reference\nACM classification\nMSC classification\nReport number\narXiv identifier\nDOI\nORCID\narXiv author ID\nHelp pages\nFull text\n\n\n\n\nSearch\n\n\n\n \n\n\nLogin \n \n\nNo HTML for '2104.00124v2'\nHTML is not available for the source.\nThis could be due to the source files not being HTML, LaTeX, or a conversion failure.\nIf you are an author, learn how you can help HTML conversions for your papers. \n\n\n\n\n\n\n\nAbout\nHelp\n\n\n\n\n\ncontact arXivClick here to contact arXiv\n Contact\n\n\nsubscribe to arXiv mailingsClick here to subscribe\n Subscribe\n\n\n\n\n \n\n\n\n\n\nCopyright\nPrivacy Policy\n\n\n\n\nWeb Accessibility Assistance\n\n\narXiv Operational Status \n              Get status notifications via\n              email\n              or slack\n\n\n\n\n\n \n \n\n\n"}, {"id": "http://arxiv.org/abs/2102.00976v1", "title": "Can Predominant Credible Information Suppress Misinformation in Crises?\n  Empirical Studies of Tweets Related to Prevention Measures during COVID-19", "contents": "Just a moment...Enable JavaScript and cookies to continue"}, {"id": "http://arxiv.org/abs/2106.11702v4", "title": "Categorising Fine-to-Coarse Grained Misinformation: An Empirical Study\n  of COVID-19 Infodemic", "contents": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n | arXiv e-print repository\n\n\n\n\n\n\n\nSkip to main content\n\n\n\n\n\nWe gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors. Donate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHelp | Advanced Search\n\n\n\n\nAll fields\nTitle\nAuthor\nAbstract\nComments\nJournal reference\nACM classification\nMSC classification\nReport number\narXiv identifier\nDOI\nORCID\narXiv author ID\nHelp pages\nFull text\n\n\n\n\nSearch\n\n\n\n \n\n\nLogin \n \n\nNo HTML for '2106.11702v4'\nHTML is not available for the source.\nThis could be due to the source files not being HTML, LaTeX, or a conversion failure.\nIf you are an author, learn how you can help HTML conversions for your papers. \n\n\n\n\n\n\n\nAbout\nHelp\n\n\n\n\n\ncontact arXivClick here to contact arXiv\n Contact\n\n\nsubscribe to arXiv mailingsClick here to subscribe\n Subscribe\n\n\n\n\n \n\n\n\n\n\nCopyright\nPrivacy Policy\n\n\n\n\nWeb Accessibility Assistance\n\n\narXiv Operational Status \n              Get status notifications via\n              email\n              or slack\n\n\n\n\n\n \n \n\n\n"}, {"id": "http://arxiv.org/abs/2202.09449v1", "title": "VaccineLies: A Natural Language Resource for Learning to Recognize\n  Misinformation about the COVID-19 and HPV Vaccines", "contents": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n | arXiv e-print repository\n\n\n\n\n\n\n\nSkip to main content\n\n\n\n\n\nWe gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors. Donate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHelp | Advanced Search\n\n\n\n\nAll fields\nTitle\nAuthor\nAbstract\nComments\nJournal reference\nACM classification\nMSC classification\nReport number\narXiv identifier\nDOI\nORCID\narXiv author ID\nHelp pages\nFull text\n\n\n\n\nSearch\n\n\n\n \n\n\nLogin \n \n\nNo HTML for '2202.09449v1'\nHTML is not available for the source.\nThis could be due to the source files not being HTML, LaTeX, or a conversion failure.\nIf you are an author, learn how you can help HTML conversions for your papers. \n\n\n\n\n\n\n\nAbout\nHelp\n\n\n\n\n\ncontact arXivClick here to contact arXiv\n Contact\n\n\nsubscribe to arXiv mailingsClick here to subscribe\n Subscribe\n\n\n\n\n \n\n\n\n\n\nCopyright\nPrivacy Policy\n\n\n\n\nWeb Accessibility Assistance\n\n\narXiv Operational Status \n              Get status notifications via\n              email\n              or slack\n\n\n\n\n\n \n \n\n\n"}, {"id": "http://arxiv.org/abs/2207.12589v1", "title": "Folk Models of Misinformation on Social Media", "contents": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n | arXiv e-print repository\n\n\n\n\n\n\n\nSkip to main content\n\n\n\n\n\nWe gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors. Donate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHelp | Advanced Search\n\n\n\n\nAll fields\nTitle\nAuthor\nAbstract\nComments\nJournal reference\nACM classification\nMSC classification\nReport number\narXiv identifier\nDOI\nORCID\narXiv author ID\nHelp pages\nFull text\n\n\n\n\nSearch\n\n\n\n \n\n\nLogin \n \n\nNo HTML for '2207.12589v1'\nHTML is not available for the source.\nThis could be due to the source files not being HTML, LaTeX, or a conversion failure.\nIf you are an author, learn how you can help HTML conversions for your papers. \n\n\n\n\n\n\n\nAbout\nHelp\n\n\n\n\n\ncontact arXivClick here to contact arXiv\n Contact\n\n\nsubscribe to arXiv mailingsClick here to subscribe\n Subscribe\n\n\n\n\n \n\n\n\n\n\nCopyright\nPrivacy Policy\n\n\n\n\nWeb Accessibility Assistance\n\n\narXiv Operational Status \n              Get status notifications via\n              email\n              or slack\n\n\n\n\n\n \n \n\n\n"}, {"id": "http://arxiv.org/abs/2505.21608v1", "title": "How does Misinformation Affect Large Language Model Behaviors and\n  Preferences?", "contents": "\n\n\n\nHow does Misinformation Affect Large Language Model Behaviors and Preferences?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1 Introduction\n\n2 MisBench\n\n2.1 Wikidata Claim Extraction\n\n2.2 Misinformation Construction\n\nFactual Conflict\nTemporal Conflict\nSemantic Conflict\n\n\n2.3 Misinformation Text Stylization\n\n2.4 Quality Control\n\nCompleteness Filtering\nEntailment Checking\nSemantic Matching Validation\nHuman Evaluation\n\n\n2.5 Benchmark Statistics\n\n\n\n3 Experiments\n\n\n3.1 Experimental Setup\n\nAnalyzed Models\nEvaluation Metrics\n\n\n\n3.2 How do LLMs discern misinformation?\n\nLLMs are capable of discerning misinformation even without corresponding prior factual knowledge.\nLLMs\u2019 parametric knowledge have boarder impact on discerning semantic misinformation.\nLLMs demonstrate superior ability to discern misinformation when it involves complex, multi-step factual claims.\n\n\n\n3.3 How does misinformation affect LLMs?\n\nLLMs are receptive to external misinformation, especially those that contradict established facts or contain ambiguous semantics.\nLLMs are better at distinguishing than solely judgment.\n\n\n\n3.4 Which style of misinformation do LLMs find convincing?\n\nThe convincingness of misinformation to LLMs correlates with textual style and narrative format.\nLLMs show greater confidence in misinformation with objective and formal style under reasoning-intensive tasks.\n\n\n\n\n\n4 RtD: Reconstruct to discriminate\n\nMethod\nExperimental Setup\nResults\n\n\n5 Conclusion\n\nA Related Work\n\nA.1 Combating Misinformation\nA.2 Knowledge Conflicts\n\n\nB Rationale behind the taxonomy of misinformation types and styles\n\nC Human Evaluation\n\nC.1 Human Evaluation on NLI Model\n\nC.2 Human Evaluation on MisBench data\n\nSettings\nAnnotation Guideline\nAgreement Rate\n\n\n\n\nD Benchmark Details\nE SPARQL Protocol and RDF Query Language\n\nF More details in experiments\n\n\nF.1 Evaluation Metrics\n\nCorrectness\nMemorization Ratio\nEvidence Tendency\n\n\nF.2 Implementation Details\n\nF.3 Linguistic Analysis into LLMs\u2019 Stylistic Preferences\n\nPerplexity & N-gram Overlap.\nQuestion Embedding Similarity\n\n\nF.4 Analysis of Misinformation Impact across Different Topics\nF.5 Additional Results for experiments\nF.6 Prompts Used in Experiments\n\n\nG Examples of misinformation in MisBench\n\n\n\n\n\nHow does Misinformation Affect Large Language Model \nBehaviors and Preferences?\n\n\n\nMiao Peng1, Nuo Chen1, Jianheng Tang1, Jia Li1,2\n1The Hong Kong University of Science and Technology (Guangzhou)\n2The Hong Kong University of Science and Technology\nmpeng885@connect.hkust-gz.edu.cn, chennuo26@gmail.com\njtangbf@connect.ust.hk, jialee@ust.hk\n\u00a0\u00a0Corresponding author\n\n\nAbstract\nLarge Language Models (LLMs) have shown remarkable capabilities in knowledge-intensive tasks, while they remain vulnerable when encountering misinformation. Existing studies have explored the role of LLMs in combating misinformation, but there is still a lack of fine-grained analysis on the specific aspects and extent to which LLMs are influenced by misinformation. To bridge this gap, we present MisBench, the current largest and most comprehensive benchmark for evaluating LLMs\u2019 behavior and knowledge preference toward misinformation. MisBench consists of 10,346,712 pieces of misinformation, which uniquely considers both knowledge-based conflicts and stylistic variations in misinformation. Empirical results reveal that while LLMs demonstrate comparable abilities in discerning misinformation, they still remain susceptible to knowledge conflicts and stylistic variations. Based on these findings, we further propose a novel approach called Reconstruct to Discriminate (RtD) to strengthen LLMs\u2019 ability to detect misinformation. Our study provides valuable insights into LLMs\u2019 interactions with misinformation, and we believe MisBench can serve as an effective benchmark for evaluating LLM-based detectors and enhancing their reliability in real-world applications. Codes and data are available at: https://github.com/GKNL/MisBench.\n\n\n\nHow does Misinformation Affect Large Language Model \nBehaviors and Preferences?\n\n\n\n\n\n\nMiao Peng1, Nuo Chen1, Jianheng Tang1, Jia Li1,2\u2020\u2020thanks: \u00a0\u00a0Corresponding author\n\n1The Hong Kong University of Science and Technology (Guangzhou)\n\n2The Hong Kong University of Science and Technology\n\nmpeng885@connect.hkust-gz.edu.cn, chennuo26@gmail.com\n\njtangbf@connect.ust.hk, jialee@ust.hk\n\n\n\n\n\n\n\n1 Introduction\n\nFigure 1: An overview of domains in MisBench.\n\n\nLarge Language Models (LLMs) have demonstrated impressive capabilities in understanding and reasoning with external knowledge\u00a0Ram et\u00a0al. (2023); Yao et\u00a0al. (2023); Tang et\u00a0al. (2025); Ho et\u00a0al. (2020); Chen et\u00a0al. (2024). However, these powerful LLMs remain susceptible to misinformation, often producing erroneous answers when encountering inaccurate\u00a0Mallen et\u00a0al. (2023), out-of-date\u00a0Cao et\u00a0al. (2021), or fictional knowledge\u00a0Goldstein et\u00a0al. (2023). This vulnerability to misinformation significantly impacts their real-world performance, undermining their reliability and trustworthiness in practical applications.\n\n\nFollowing the emergence of LLMs, researchers have established various benchmarks to investigate how misinformation affects these models, including LLMFake\u00a0Chen and Shu (2024a), LLM-KC\u00a0Xie et\u00a0al. (2024), ConflictBank\u00a0Su et\u00a0al. (2024), Farm\u00a0Xu et\u00a0al. (2024), and Misinfo-ODQA\u00a0Pan et\u00a0al. (2023). While these studies have demonstrated LLMs\u2019 vulnerability to misinformation, a fundamental question remains unexplored: \u201cHow and to what extent do LLMs get misled by misinformation?\u201d This further leads us to ask \u201cHow do different types, sources, and styles of misinformation influence LLM behaviors and preferences?\u201d Despite the growing body of research, there is still a limited comprehensive understanding of how LLMs process and respond to various forms of misinformation, particularly regarding their susceptibility to different presentation styles and content types.\n\n\nTo address these limitations, we present MisBench, the largest and most comprehensive benchmark for evaluating LLMs\u2019 responses to misinformation, as shown in Table\u00a01. Unlike previous studies that focused on specific misinformation types, MisBench systematically examines how varying writing styles and linguistic patterns influence LLM behavior. Our benchmark incorporates three knowledge-conflicting types\u00a0Chen and Shu (2024a); Su et\u00a0al. (2024): factual knowledge errors, knowledge changes over time, and ambiguous entity semantics. To move beyond simple, easily verifiable facts, we utilize both one-hop and multi-hop claims from Wikidata, creating 431,113 challenging QA pairs. The dataset features diverse textual characteristics, including (1) misinformation genre and (2) language subjectivity/objectivity, closely mimicking real-world misinformation patterns\u00a0Wu et\u00a0al. (2024a); Wan et\u00a0al. (2024a). Using powerful LLMs, we generated 10,346,712 pieces of misinformation across 3 types and 6 textual styles (e.g., news reports, blogs, and technical language) spanning 12 domains, as shown in Figure\u00a01. This comprehensive approach enables not only thorough analysis but also the development of effective countermeasures against misinformation.\n\n\nThrough comprehensive analysis of both open-source and closed-source LLMs of varying scales on MisBench, we uncover three key findings about LLMs\u2019 interaction with misinformation: (1) LLMs demonstrate an inherent ability to detect misinformation by identifying contextual inconsistencies and conflicts, even without prior knowledge of the subject matter (\u00a73.2); (2) While LLMs effectively identify temporal-conflicting claims, they show increased vulnerability to factual contradictions and are particularly susceptible to ambiguous semantic constructs (\u00a73.3); and (3) LLMs\u2019 vulnerability to misinformation varies significantly by task complexity and presentation style\u2014formal, objective language poses greater risks in single-hop tasks, while narrative, subjective content is more problematic in multi-hop scenarios (\u00a73.4).\n\n\nBuilding on these observations, we leverage LLMs\u2019 demonstrated ability to identify contextual inconsistencies while addressing their vulnerability to knowledge conflicts. We propose Reconstruct to Discriminate (RtD), a novel approach that combines LLMs\u2019 intrinsic discriminative strengths with external knowledge sources. RtD works by reconstructing evidence text for key subject entities from external sources to effectively discern potential misinformation. Experimental results on MisBench show significant improvements in misinformation detection, with Success Rate increases of 6.0% on Qwen2.5-14B and 20.6% on Gemma2-9B. This approach not only enhances detection accuracy but also establishes a promising direction for integrating comprehensive knowledge sources with LLMs.\n\n\nThe rest of the paper is structured as follows: Section\u00a02 introduces the construction pipeline and statistics of MisBench, including claim extraction, misinformation generation, and quality control. Section\u00a03 presents experiments analyzing LLM behaviors and preferences toward misinformation. Section\u00a04 details the proposed Reconstruct to Discriminate approach and its effectiveness. Related works can be found in Appendix\u00a0A.\n\n\n\n\n\n\nBenchmark\nMulti-cause\nMulti-hop\nMulti-style\nSize\n\n\nLLMFake\u00a0(2024a)\n\n\u2713\n\u2717\n\u2717\n1,032\n\n\nFarm\u00a0(2024)\n\n\u2717\n\u2717\n\u2717\n1,500\n\n\nPan et\u00a0al. (2023)\n\u2713\n\u2717\n\u2717\n12,176\n\n\nML-KC\u00a0(2021)\n\n\u2717\n\u2717\n\u2717\n30,000\n\n\nXie et\u00a0al. (2024)\n\u2717\n\u2713\n\u2717\n16,557\n\n\nTan et\u00a0al. (2024)\n\u2717\n\u2717\n\u2717\n8,472\n\n\n\nCD2superscriptCD2\\text{CD}^{2}CD start_POSTSUPERSCRIPT 2 end_POSTSUPERSCRIPT\u00a0(2024)\n\n\u2717\n\u2713\n\u2717\n4,000\n\n\n\nConflictingQA\u00a0(2024a)\n\n\u2717\n\u2717\n\u2713\n2,208\n\n\nConflictBank(2024)\n\n\u2713\n\u2717\n\u2713\n553,117\n\n\nMisBench (Ours)\n\u2713\n\u2713\n\u2713\n10,346,712\n\n\n\n\nTable 1: Comparison between MisBench and related benchmarks. \"Multi-cause\" indicates misinformation constructed from different causes, and \"Multi-hop\" denotes misinformation constructed based on multi-hop relations and facts.\n\n\n\n\n2 MisBench\n\n\nIn this section, we introduce the construction pipeline of MisBench. The pipeline overview is detailed in Figure\u00a02, including four steps: (1) Wikidata Claim Extraction, (2) Misinformation Construction (including Conflicting Claim Construction and Misinformation Generation), (3) Misinformation Text Stylization, and (4) Quality Control.\n\n\nFigure 2: Overall illustration of data generation pipeline of MisBench: (1) We start by extracting one-hop and multi-hop claims from Wikidata. (2) Then we construct conflicting claims based on different causes. (3) After that we prompt LLM to generate misinformation based on claims. (4) Next, we employ LLM to transform misinformation into various styles. (5) Last, we apply quality control measurements to get high-quality data.\n\n\n\n2.1 Wikidata Claim Extraction\n\nWe employ a widely used knowledge graph Wikidata\u00a0Vrande\u010di\u0107 and Kr\u00f6tzsch (2014); Peng et\u00a0al. (2022) as the source to construct MisBench due to its extensive repository of structured real-world facts. We collect one-hop and multi-hop claims to generate evidence and misinformation with varying knowledge scopes and information densities.\n\n\nClaims with single-hop relations represent direct, verifiable assertions that facilitate the construction of factual misinformation. To construct one-hop claim-evidence pairs, we extract all entities and triplets from wikidata dumped on 2024.09.01. Each triplet (s,r,o)\ud835\udc60\ud835\udc5f\ud835\udc5c(s,r,o)( italic_s , italic_r , italic_o ) with head entity s\ud835\udc60sitalic_s, tail entity o\ud835\udc5coitalic_o and relation r\ud835\udc5fritalic_r can be regarded as a basic factual claim. Furthermore, we employ SPARQL111https://query.wikidata.org to extract the text description d\ud835\udc51ditalic_d of each entity in wikidata, thus the one-hop claim cosubscript\ud835\udc50\ud835\udc5cc_{o}italic_c start_POSTSUBSCRIPT italic_o end_POSTSUBSCRIPT can be formulated as (s,r,o,ds,do)\ud835\udc60\ud835\udc5f\ud835\udc5csubscript\ud835\udc51\ud835\udc60subscript\ud835\udc51\ud835\udc5c(s,r,o,d_{s},d_{o})( italic_s , italic_r , italic_o , italic_d start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT , italic_d start_POSTSUBSCRIPT italic_o end_POSTSUBSCRIPT ). Each claim represents a factual statement, which can be further utilized to construct misinformation. Considering claim uniqueness, we filter out those claims with the same (s,r)\ud835\udc60\ud835\udc5f(s,r)( italic_s , italic_r ) pairs to remain only one instance. We manually select 82 common relations with clear and informative semantics, filtering out claims without these relations. Each claim cosubscript\ud835\udc50\ud835\udc5cc_{o}italic_c start_POSTSUBSCRIPT italic_o end_POSTSUBSCRIPT is then converted into text statements and question forms using hand-crafted relation templates. Details are listed in Appendices\u00a0D and\u00a0E.\n\n\nFurthermore, we identify that multi-hop claims encompass a broader knowledge scope and higher information density, necessitating more sophisticated reasoning processes. Thus we construct multi-hop claim-evidence pairs based on multi-hop QA dataset 2WikiMultihopQA\u00a0Ho et\u00a0al. (2020). To better assess reasoning abilities, we exclude judgmental \"yes or no\" questions and retain inferring questions with specific answers. Specifically, we maintain the subset of questions in types \u201cInference\u201d and \u201cCompositional\u201d and filter out \"Comparison\" and \"Bridge-comparison\" questions. Likewise, each multi-hop claim cmsubscript\ud835\udc50\ud835\udc5ac_{m}italic_c start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT can be denoted as (s1,r1,o1,r2,o2,ds1,do2)subscript\ud835\udc601subscript\ud835\udc5f1subscript\ud835\udc5c1subscript\ud835\udc5f2subscript\ud835\udc5c2subscript\ud835\udc51subscript\ud835\udc601subscript\ud835\udc51subscript\ud835\udc5c2(s_{1},r_{1},o_{1},r_{2},o_{2},d_{s_{1}},d_{o_{2}})( italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_o start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_o start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_d start_POSTSUBSCRIPT italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT , italic_d start_POSTSUBSCRIPT italic_o start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT end_POSTSUBSCRIPT ) and cmsubscript\ud835\udc50\ud835\udc5ac_{m}italic_c start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT is transformed into question with corresponding relation template.\n\n\n\n\n2.2 Misinformation Construction\n\nBuilding upon the taxonomy of misinformation error from Chen and Shu (2024a), misinformation generated by LLMs can be classified into Unsubstantiated Content and Total Fabrication, encompassing Outdated Information, Description Ambiguity, Incomplete Fact, and False Context. We conceptualize misinformation through the lens of knowledge conflicts and simulate real-world scenarios by constructing conflicting claims across three conflict patterns.\nFollowing Su et\u00a0al. (2024), we then employ LLaMA-3-70B to generate correct evidence and misinformation texts based on corresponding claims with entity descriptions. Specifically, conflicting claims are categorized as follows:\n\n\nFactual Conflict\n\nFactual conflict refers to that two facts are contradictory to each other in the objective aspect. It occurs when contextual texts contain incorrect or misleading information that is contradictory to LLM\u2019s internal knowledge on the instance level. We construct fact-conflicting claim by replace the object o\ud835\udc5coitalic_o with o\u2032superscript\ud835\udc5c\u2032o^{\\prime}italic_o start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT in origin claim, denoted as (s,r,o\u2032,ds,do\u2032)\ud835\udc60\ud835\udc5fsuperscript\ud835\udc5c\u2032subscript\ud835\udc51\ud835\udc60subscript\ud835\udc51superscript\ud835\udc5c\u2032(s,r,o^{\\prime},d_{s},d_{o^{\\prime}})( italic_s , italic_r , italic_o start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT , italic_d start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT , italic_d start_POSTSUBSCRIPT italic_o start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ), or (s1,r1,o1,r2,o2\u2032,ds1,do2\u2032)subscript\ud835\udc601subscript\ud835\udc5f1subscript\ud835\udc5c1subscript\ud835\udc5f2superscriptsubscript\ud835\udc5c2\u2032subscript\ud835\udc51subscript\ud835\udc601subscript\ud835\udc51superscriptsubscript\ud835\udc5c2\u2032(s_{1},r_{1},o_{1},r_{2},o_{2}^{\\prime},d_{s_{1}},d_{o_{2}^{\\prime}})( italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_o start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_o start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT , italic_d start_POSTSUBSCRIPT italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT , italic_d start_POSTSUBSCRIPT italic_o start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ) for multi-hop claim, where o\u2032superscript\ud835\udc5c\u2032o^{\\prime}italic_o start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT is the same-type entity with o\ud835\udc5coitalic_o to keep the substituted claim reasonable.\n\n\n\nTemporal Conflict\n\nTemporal conflict is commonly found when contextual texts contain outdated and outmoded information that are inconsistent with up-to-date knowledge. We add extra time stamps to origin claim, thus temporal-conflicting claim can be represented as (s,r,o\u2032,ds,do\u2032,Ts,Te)\ud835\udc60\ud835\udc5fsuperscript\ud835\udc5c\u2032subscript\ud835\udc51\ud835\udc60subscript\ud835\udc51superscript\ud835\udc5c\u2032subscript\ud835\udc47\ud835\udc60subscript\ud835\udc47\ud835\udc52(s,r,o^{\\prime},d_{s},d_{o^{\\prime}},T_{s},T_{e})( italic_s , italic_r , italic_o start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT , italic_d start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT , italic_d start_POSTSUBSCRIPT italic_o start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT end_POSTSUBSCRIPT , italic_T start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT , italic_T start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ), or (s1,r1,o1,r2,o2\u2032,ds1,do2\u2032,Ts,Te)subscript\ud835\udc601subscript\ud835\udc5f1subscript\ud835\udc5c1subscript\ud835\udc5f2superscriptsubscript\ud835\udc5c2\u2032subscript\ud835\udc51subscript\ud835\udc601subscript\ud835\udc51superscriptsubscript\ud835\udc5c2\u2032subscript\ud835\udc47\ud835\udc60subscript\ud835\udc47\ud835\udc52(s_{1},r_{1},o_{1},r_{2},o_{2}^{\\prime},d_{s_{1}},d_{o_{2}^{\\prime}},T_{s},T_{%\ne})( italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_o start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_o start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT , italic_d start_POSTSUBSCRIPT italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT , italic_d start_POSTSUBSCRIPT italic_o start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT end_POSTSUBSCRIPT , italic_T start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT , italic_T start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT ) for multi-hop claim. Tssubscript\ud835\udc47\ud835\udc60T_{s}italic_T start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT and Tesubscript\ud835\udc47\ud835\udc52T_{e}italic_T start_POSTSUBSCRIPT italic_e end_POSTSUBSCRIPT denote the start and end timestamps, which are in future tense to minimize biases from prior knowledge in LLM.\n\n\nFigure 3: Examples of stylized factual misinformation.\n\n\n\nSemantic Conflict\n\nDeeper knowledge conflict is caused due to the polysemous and ambiguous semantics of facts within misinformation. That is, entities in different contexts may have the same name but express different semantic information. To simulate this scenario, we replace the description of the subject entity with a new one that differs from the original but remains logically related to the replaced object entity.\nSpecifically, we generate extra description ds\u2217superscriptsubscript\ud835\udc51\ud835\udc60d_{s}^{*}italic_d start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT with LLaMA-3-70B for subject s\ud835\udc60sitalic_s under the context of replaced claim. Then semantic-conflicting claim is formulated as (s,r,o\u2032,ds\u2217,do\u2032)\ud835\udc60\ud835\udc5fsuperscript\ud835\udc5c\u2032superscriptsubscript\ud835\udc51\ud835\udc60subscript\ud835\udc51superscript\ud835\udc5c\u2032(s,r,o^{\\prime},d_{s}^{*},d_{o^{\\prime}})( italic_s , italic_r , italic_o start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT , italic_d start_POSTSUBSCRIPT italic_s end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT , italic_d start_POSTSUBSCRIPT italic_o start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ), or (s1,r1,o1,r2,o2\u2032,ds1\u2217,do2\u2032)subscript\ud835\udc601subscript\ud835\udc5f1subscript\ud835\udc5c1subscript\ud835\udc5f2superscriptsubscript\ud835\udc5c2\u2032superscriptsubscript\ud835\udc51subscript\ud835\udc601subscript\ud835\udc51superscriptsubscript\ud835\udc5c2\u2032(s_{1},r_{1},o_{1},r_{2},o_{2}^{\\prime},d_{s_{1}}^{*},d_{o_{2}^{\\prime}})( italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_r start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_o start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT , italic_r start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT , italic_o start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT , italic_d start_POSTSUBSCRIPT italic_s start_POSTSUBSCRIPT 1 end_POSTSUBSCRIPT end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2217 end_POSTSUPERSCRIPT , italic_d start_POSTSUBSCRIPT italic_o start_POSTSUBSCRIPT 2 end_POSTSUBSCRIPT start_POSTSUPERSCRIPT \u2032 end_POSTSUPERSCRIPT end_POSTSUBSCRIPT ) for multi-hop claim.\n\n\n\n\n\n2.3 Misinformation Text Stylization\n\nWe consider the stylistic features of misinformation texts as key factors to affect LLM knowledge and predictions, as LLMs tend to over-rely on LLM-generated evidence in terms of text similarity and relevancy. We investigate six types of text stylization on misinformation, including Wikipedia Entry, News Report, Science Reference, Blog, Technical Language and Confident Language. We generate all the above stylized misinformation texts for each claim using the LLaMA-3-70B model with manually crafted prompts. Detailed prompts are shown in Appendix\u00a0F.6.\n\n\n\n\n\n\nProperty\nNumber\n\n\n# of claims / QA pairs (total)\n431,113\n\n\n# of evidences (correct & misinformation)\n10,346,712\n\n\n# of one-hop claims\n347,892\n\n\n# of multi-hop claims\n83,221\n\n\n# of one-hop relations\n82\n\n\n# of multi-hop relations\n148\n\n\n# of misinformation types\n3\n\n\n# of misinformation styles\n6\n\n\nToken length per evidence\n\u223c550similar-toabsent550\\sim 550\u223c 550\n\n\nMisinformation pieces per claim\n18\n\n\n\n\nTable 2: Data Statistics of MisBench\n\n\n\n\n\n\nModels\nOne-hop based Misinformation\nMulti-hop based Misinformation\n\n\nFactual\nTemporal\nSemantic\nFactual\nTemporal\nSemantic\n\n\nMemory\nUnknown\nMemory\nUnknown\nMemory\nUnknown\nMemory\nUnknown\nMemory\nUnknown\nMemory\nUnknown\n\n\nClosed-source Models\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDeepSeek-V2.5\n34.56\n26.42  \u21938.14\u2193absent8.14\\downarrow 8.14\u2193 8.14\n\n55.61\n47.80  \u21937.81\u2193absent7.81\\downarrow 7.81\u2193 7.81\n\n43.78\n28.93  \u219314.85\u2193absent14.85\\downarrow 14.85\u2193 14.85\n\n46.39\n38.11  \u21938.28\u2193absent8.28\\downarrow 8.28\u2193 8.28\n\n69.31\n68.21  \u21931.10\u2193absent1.10\\downarrow 1.10\u2193 1.10\n\n41.52\n34.95  \u21936.57\u2193absent6.57\\downarrow 6.57\u2193 6.57\n\n\n\nClaude3.5-haiku\n67.15\n60.33  \u21936.82\u2193absent6.82\\downarrow 6.82\u2193 6.82\n\n85.04\n81.24  \u21933.80\u2193absent3.80\\downarrow 3.80\u2193 3.80\n\n62.96\n56.29  \u21936.67\u2193absent6.67\\downarrow 6.67\u2193 6.67\n\n71.43\n61.71  \u21939.72\u2193absent9.72\\downarrow 9.72\u2193 9.72\n\n87.14\n87.04  \u21930.10\u2193absent0.10\\downarrow 0.10\u2193 0.10\n\n66.86\n62.74  \u21934.12\u2193absent4.12\\downarrow 4.12\u2193 4.12\n\n\n\nGPT-4o\n91.44\n\n88.20 \u21933.24\u2193absent3.24\\downarrow 3.24\u2193 3.24\n\n99.33\n\n98.93 \u21930.40\u2193absent0.40\\downarrow 0.40\u2193 0.40\n\n93.96\n\n89.28 \u21934.68\u2193absent4.68\\downarrow 4.68\u2193 4.68\n\n96.88\n\n93.81 \u21933.07\u2193absent3.07\\downarrow 3.07\u2193 3.07\n\n98.28\n\n97.68 \u21930.60\u2193absent0.60\\downarrow 0.60\u2193 0.60\n\n96.57\n\n94.33 \u21932.24\u2193absent2.24\\downarrow 2.24\u2193 2.24\n\n\n\nLLaMA3 Series\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLLaMA3-8B\n19.21\n16.91  \u21932.30\u2193absent2.30\\downarrow 2.30\u2193 2.30\n\n36.26\n33.32  \u21932.94\u2193absent2.94\\downarrow 2.94\u2193 2.94\n\n13.67\n9.45  \u21934.22\u2193absent4.22\\downarrow 4.22\u2193 4.22\n\n20.02\n17.29  \u21933.73\u2193absent3.73\\downarrow 3.73\u2193 3.73\n\n49.94\n46.78  \u21933.16\u2193absent3.16\\downarrow 3.16\u2193 3.16\n\n23.43\n18.35  \u21935.08\u2193absent5.08\\downarrow 5.08\u2193 5.08\n\n\n\nLLaMA3-70B\n75.12\n\n64.67 \u219310.45\u2193absent10.45\\downarrow 10.45\u2193 10.45\n\n95.02\n\n93.26 \u21931.76\u2193absent1.76\\downarrow 1.76\u2193 1.76\n\n64.07\n\n52.83 \u219311.24\u2193absent11.24\\downarrow 11.24\u2193 11.24\n\n70.32\n\n58.82 \u219311.50\u2193absent11.50\\downarrow 11.50\u2193 11.50\n\n91.47\n\n84.80 \u21936.67\u2193absent6.67\\downarrow 6.67\u2193 6.67\n\n69.49\n\n64.57 \u21934.92\u2193absent4.92\\downarrow 4.92\u2193 4.92\n\n\n\nQwen2.5 Series\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nQwen2.5-3B\n73.48\n\n67.31 \u21936.17\u2193absent6.17\\downarrow 6.17\u2193 6.17\n\n93.14\n90.68  \u21932.46\u2193absent2.46\\downarrow 2.46\u2193 2.46\n\n63.65\n52.07  \u219311.58\u2193absent11.58\\downarrow 11.58\u2193 11.58\n\n64.02\n57.88  \u21936.14\u2193absent6.14\\downarrow 6.14\u2193 6.14\n\n88.20\n86.76  \u21931.44\u2193absent1.44\\downarrow 1.44\u2193 1.44\n\n59.36\n52.34  \u21937.02\u2193absent7.02\\downarrow 7.02\u2193 7.02\n\n\n\nQwen2.5-7B\n14.22\n9.47  \u21934.75\u2193absent4.75\\downarrow 4.75\u2193 4.75\n\n48.32\n45.71  \u21932.61\u2193absent2.61\\downarrow 2.61\u2193 2.61\n\n16.13\n7.83  \u21938.30\u2193absent8.30\\downarrow 8.30\u2193 8.30\n\n21.75\n15.73  \u21936.02\u2193absent6.02\\downarrow 6.02\u2193 6.02\n\n55.14\n52.50  \u21932.64\u2193absent2.64\\downarrow 2.64\u2193 2.64\n\n18.28\n13.16  \u21935.12\u2193absent5.12\\downarrow 5.12\u2193 5.12\n\n\n\nQwen2.5-14B\n68.88\n58.66  \u219310.22\u2193absent10.22\\downarrow 10.22\u2193 10.22\n\n99.29\n\n99.26 \u21930.03\u2193absent0.03\\downarrow 0.03\u2193 0.03\n\n71.16\n\n56.82 \u219314.34\u2193absent14.34\\downarrow 14.34\u2193 14.34\n\n79.08\n\n68.98 \u219310.10\u2193absent10.10\\downarrow 10.10\u2193 10.10\n\n99.63\n\n99.43 \u21930.20\u2193absent0.20\\downarrow 0.20\u2193 0.20\n\n73.66\n\n68.86 \u21934.80\u2193absent4.80\\downarrow 4.80\u2193 4.80\n\n\n\nQwen2.5-72B\n57.23\n43.84  \u219313.39\u2193absent13.39\\downarrow 13.39\u2193 13.39\n\n77.41\n69.35  \u21938.06\u2193absent8.06\\downarrow 8.06\u2193 8.06\n\n57.49\n35.86  \u219321.63\u2193absent21.63\\downarrow 21.63\u2193 21.63\n\n75.96\n58.55  \u219317.41\u2193absent17.41\\downarrow 17.41\u2193 17.41\n\n90.15\n81.86  \u21938.29\u2193absent8.29\\downarrow 8.29\u2193 8.29\n\n67.56\n52.80  \u219314.76\u2193absent14.76\\downarrow 14.76\u2193 14.76\n\n\n\nGemma2 Series\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGemma2-2B\n36.74\n32.86  \u21933.88\u2193absent3.88\\downarrow 3.88\u2193 3.88\n\n70.36\n63.55  \u21936.81\u2193absent6.81\\downarrow 6.81\u2193 6.81\n\n29.10\n22.34  \u21936.76\u2193absent6.76\\downarrow 6.76\u2193 6.76\n\n56.97\n\n51.58 \u21935.39\u2193absent5.39\\downarrow 5.39\u2193 5.39\n\n84.74\n81.31  \u21933.43\u2193absent3.43\\downarrow 3.43\u2193 3.43\n\n52.90\n\n50.18 \u21932.72\u2193absent2.72\\downarrow 2.72\u2193 2.72\n\n\n\nGemma2-9B\n55.94\n\n50.53 \u21935.41\u2193absent5.41\\downarrow 5.41\u2193 5.41\n\n94.83\n\n94.21 \u21930.62\u2193absent0.62\\downarrow 0.62\u2193 0.62\n\n47.20\n\n38.35 \u21938.85\u2193absent8.85\\downarrow 8.85\u2193 8.85\n\n58.93\n50.51  \u21938.42\u2193absent8.42\\downarrow 8.42\u2193 8.42\n\n92.94\n\n90.63 \u21932.31\u2193absent2.31\\downarrow 2.31\u2193 2.31\n\n52.07\n48.38  \u21933.69\u2193absent3.69\\downarrow 3.69\u2193 3.69\n\n\n\nGemma2-27B\n42.50\n31.80  \u219310.70\u2193absent10.70\\downarrow 10.70\u2193 10.70\n\n68.64\n58.16  \u219310.48\u2193absent10.48\\downarrow 10.48\u2193 10.48\n\n34.72\n19.38  \u219315.34\u2193absent15.34\\downarrow 15.34\u2193 15.34\n\n46.55\n32.36  \u219314.19\u2193absent14.19\\downarrow 14.19\u2193 14.19\n\n79.39\n70.40  \u21938.99\u2193absent8.99\\downarrow 8.99\u2193 8.99\n\n37.84\n29.08  \u21938.76\u2193absent8.76\\downarrow 8.76\u2193 8.76\n\n\n\n\n\nTable 3: Success Rate% of LLMs on different type misinformation detection. LLMs are prompted to answer a two-choice question \"Is the given \u2018passage\u2019 a piece of misinformation?\". Memory indicates LLMs possess internal prior knowledge of the corresponding question. The best results in each series are in bold.\n\n\n\n\n2.4 Quality Control\n\nIdeally, misinformation texts should be supportive of corresponding claims but contradict to correct evidence. To achieve this, we conduct quality control including automatic and human evaluation to select high-quality data. Detailed constructing consumption is listed in Appendix\u00a0D. Specifically, we include the following four steps:\n\n\nCompleteness Filtering\n\nAs LLM sometimes refuses to generate misinformation that contradicts its parametric knowledge\u00a0Xu et\u00a0al. (2024), we employ Completeness Filtering to filter out generated texts containing sentences like \"I cannot\" or \"Inconsistent Information\". We regulate the length of generated misinformation around 500 words by using a prompt constraint, and filter out misinformation texts with lengths that deviate too much.\n\n\n\nEntailment Checking\n\nTo ensure that the generated correct evidences are clear enough to support the corresponding claims, we utilize Natural Language Inference (NLI)222https://huggingface.co/tasksource/deberta-small-long-nli\u00a0He et\u00a0al. (2023) to determine the semantic relationship between the origin claim and the corresponding correct evidence. We finally keep the claim-evidence pairs that both satisfy: (1) correct evidence entails the origin claim; (2) each misinformation entails the premise itself.\n\n\n\nSemantic Matching Validation\n\nFrom a semantic perspective, generated misinformation should be similar to the query in semantics while presenting conflicting viewpoints. We utilize Sentence-Transformer333https://huggingface.co/sentence-transformers/all-mpnet-base-v2\u00a0Reimers and Gurevych (2019) to generate embeddings for the question and misinformation in each claim-evidence pair and compute their similarities. Then we filter out those with a score lower than \u03b1\ud835\udefc\\alphaitalic_\u03b1. Through this, a dataset with authentic misinformation conflicts is constructed.\n\n\n\nHuman Evaluation\n\nTo robustly assess the quality and validity of misinformation in constructed MisBench, we conduct human evaluation in two aspects:\n1) We randomly sample 500 generated examples and manually annotate whether they entail their claims, then we evaluate the NLI model over this dataset and observe over 95% accuracy;\n2) We employ three annotators and they were tasked with manually checking whether the generated misinformation logically supports the claims and whether it contradicts the correct evidence.\nMore details are listed in Appendix\u00a0C. The high agreement observed further supports our benchmark\u2019s quality.\n\n\n\n\n\n2.5 Benchmark Statistics\n\nWe construct MisBench benchmark following the above four-step pipeline, containing 431,113 QA pairs and 10,346,712 evidences (including correct and misinformation evidences). Figure\u00a03 shows examples of factual misinformation in six styles. We report the data statistics of MisBench in Table\u00a02. MisBench contains two categories of claims (QA pairs): one-hop and multi-hop setting. For each QA pair, it includes 18 pieces of misinformation (3 types of misinformation with 6 text styles).\n\n\n\n\n\n3 Experiments\n\nIn this section, we present experimental details and conduct experiments with different series of LLMs (both open-source and closed-source) on MisBench. We further study the behaviors and knowledge preferences of LLMs toward different types and stylistic misinformation.\n\n\n\n3.1 Experimental Setup\n\nAnalyzed Models\n\nWe conduct experiments on different series of LLMs with various sizes, including (1) Open-source models: LLaMA 3 series (8B, 70B)\u00a0AI@Meta (2024), Qwen 2.5 series (3B, 7B, 14B, 72B)\u00a0Team (2024b) and Gemma 2 series (2B, 9B, 27B)\u00a0Team (2024a); (2) Closed-source models: Deepseek-V2.5\u00a0DeepSeek-AI (2024), Claude3.5-haiku\u00a0Cla , GPT-4o\u00a0Achiam et\u00a0al. (2023). We set a low temperature setting of 0 during the generation with a constraint of 512 for output length. All reported results are averaged across three runs.\n\n\nFigure 4: Memorization Ratio MRsubscript\ud835\udc40\ud835\udc45M_{R}italic_M start_POSTSUBSCRIPT italic_R end_POSTSUBSCRIPT of various LLMs under three types of one-hop based misinformation. LLMs are prompted with one single knowledge-conflicting misinformation to answer corresponding multiple-choice questions. Higher MRsubscript\ud835\udc40\ud835\udc45M_{R}italic_M start_POSTSUBSCRIPT italic_R end_POSTSUBSCRIPT indicates LLMs more stick to their parametric correct knowledge.\n\n\n\nEvaluation Metrics\n\nWe narrow down the generation space by converting open-end QA into a multiple-choice formula, to simplify knowledge tracing and constrain LLM response patterns. We employ three metrics to evaluate the behavior and knowledge preference of LLMs on MisBench: (1) Success Rate%: the percentage of correctly identified misinformation; (2) Memorization Ratio MRsubscript\ud835\udc40\ud835\udc45M_{R}italic_M start_POSTSUBSCRIPT italic_R end_POSTSUBSCRIPT: the ratio that LLM rely on their parametric knowledge over external misinformation knowledge; (3) Evidence Tendency T\u2062e\u2062n\u2062d\u2062C\u2062M\ud835\udc47\ud835\udc52\ud835\udc5b\ud835\udc51\ud835\udc36\ud835\udc40TendCMitalic_T italic_e italic_n italic_d italic_C italic_M: the extent of LLMs\u2019 tendency to rely on correct evidence over misinformation, which ranges from [-1, 1]. More details about evaluation metrics are introduced in Appendix\u00a0F.1.\n\n\n\n\n\n3.2 How do LLMs discern misinformation?\n\nThis section conducts experiments on MisBench to investigate the capacities of LLMs in discerning misinformation. To identify LLM\u2019s internal knowledge, we prompt each LLM with a multiple-choice question format (correct answer, irrelevant answer, \"Unsure\" etc.) without any external evidence. We regard that LLMs know the fact when they correctly answer the question, otherwise \"Unknown\". Thus, according to \"Whether LLMs yield memory knowledge towards misinformation\", we conduct evaluations in two scenarios: 1) LLMs possess prior factual knowledge supporting the origin claim cosubscript\ud835\udc50\ud835\udc5cc_{o}italic_c start_POSTSUBSCRIPT italic_o end_POSTSUBSCRIPT or cmsubscript\ud835\udc50\ud835\udc5ac_{m}italic_c start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT of the provided misinformation; 2) LLMs lack corresponding factual knowledge about the origin claim cosubscript\ud835\udc50\ud835\udc5cc_{o}italic_c start_POSTSUBSCRIPT italic_o end_POSTSUBSCRIPT or cmsubscript\ud835\udc50\ud835\udc5ac_{m}italic_c start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT of provided misinformation. LLMs are provided with a single piece of misinformation and prompted in a two-choice QA formula. We report the Success Rate% of LLMs under both one-hop and multi-hop misinformation.\n\n\nLLMs are capable of discerning misinformation even without corresponding prior factual knowledge.\n\nResults in Table\u00a03 show that while lack of prior knowledge reduces models\u2019 misinformation Success Rate% (average 12.6% drop for LLaMA3-8B), they still maintain reasonable performance.\nAdditionally, in general trend, larger LLMs show better capabilities in discerning misinformation, with their performance being more significantly influenced by the presence of internal knowledge.\n\n\n\nLLMs\u2019 parametric knowledge have boarder impact on discerning semantic misinformation.\n\nIn Table\u00a03, comparing misinformation in different types, it is observed that LLMs\u2019 performance drops most significantly when discerning one-hop based semantic misinformation without internal knowledge. This suggests that inherent factual knowledge in LLM plays a more crucial role in identifying semantic misinformation, likely due to its more subtle semantic nature.\n\n\n\nLLMs demonstrate superior ability to discern misinformation when it involves complex, multi-step factual claims.\n\nResults in Table\u00a03 reveal that LLMs perform better at discerning multi-hop based misinformation compared to one-hop based misinformation (e.g., LLaMA3-8B shows average scores of 31.13 versus 23.05 respectively). This indicates that LLMs are more effective at identifying misinformation with a boarder knowledge scope, likely because the inclusion of more facts increases the likelihood of detecting errors.\n\n\n\n\nFinding 1: Prior factual knowledge strengthens misinformation discernment, yet LLMs can identify falsehoods through context patterns and inconsistencies.\n\n\n\nFigure 5: Evidence Tendency T\u2062e\u2062n\u2062d\u2062C\u2062M\ud835\udc47\ud835\udc52\ud835\udc5b\ud835\udc51\ud835\udc36\ud835\udc40TendCMitalic_T italic_e italic_n italic_d italic_C italic_M of various LLMs under a pair of conflicting evidences with prior internal knowledge. LLMs are prompted with two knowledge-conflicting evidences to answer multiple-choice questions. Higher T\u2062e\u2062n\u2062d\u2062C\u2062M\ud835\udc47\ud835\udc52\ud835\udc5b\ud835\udc51\ud835\udc36\ud835\udc40TendCMitalic_T italic_e italic_n italic_d italic_C italic_M (ranges from [\u22121,1]11[-1,1][ - 1 , 1 ]) indicates LLMs more tend to rely on evidence with correct knowledge.\n\n\n\n\n\n3.3 How does misinformation affect LLMs?\n\nThis section investigates the impact of misinformation on LLMs\u2019 behaviors and preferences between conflicting knowledge.\nWe identify QA pairs in MisBench that LLMs can answer correctly without external evidence. For each question, LLMs choose a response from memory answer, misinformation answer, irrelevant answer, \"Unsure\" or \"Not in the option\". Then we conduct multiple-choice QA task under two settings: (1) LLMs are provided with a single piece of misinformation; (2) LLMs are provided with two knowledge-conflicting evidences (one correct evidence and one misinformation). The results are shown in Figure\u00a04, Figure\u00a05 and extra results can be found in Appendix\u00a0F.5.\n\n\nLLMs are receptive to external misinformation, especially those that contradict established facts or contain ambiguous semantics.\n\nIn Figure\u00a04, it can be observed that all models maintain a MRsubscript\ud835\udc40\ud835\udc45M_{R}italic_M start_POSTSUBSCRIPT italic_R end_POSTSUBSCRIPT below 20%. Notably, model size does not exhibit a clear correlation with performance on factual and semantic misinformation. This indicates that LLMs are vulnerable to semantic misinformation, as their subtle semantic ambiguities and implicit contradictions, appear plausible and align with the model\u2019s internal knowledge.\n\n\n\nLLMs are better at distinguishing than solely judgment.\n\nFigure\u00a05 reveals that LLMs generally favor evidence that aligns with their internal knowledge, with this tendency becoming more pronounced as model size increases. Compared to results in Figure\u00a04, LLMs achieve notably higher MRsubscript\ud835\udc40\ud835\udc45M_{R}italic_M start_POSTSUBSCRIPT italic_R end_POSTSUBSCRIPT when evaluating contradictory evidence compared to single-evidence scenarios. This phenomenon demonstrates that LLMs perform better at comparative analysis between multiple pieces of misinformation rather than making standalone judgments.\n\n\n\n\nFinding 2: LLMs are vulnerable to external knowledge-conflicting misinformation, while excelling at distinguishing over solely judgment.\n\n\n\n\n\n\n3.4 Which style of misinformation do LLMs find convincing?\n\nThis section examines how different writing styles of misinformation influence LLM responses. Each LLM is provided with a single piece of misinformation in different styles individually and is prompted using a multiple-choice QA format. More experimental results are listed in Appendix\u00a0F.5.\n\n\nFigure 6: Memorization Ratio MRsubscript\ud835\udc40\ud835\udc45M_{R}italic_M start_POSTSUBSCRIPT italic_R end_POSTSUBSCRIPT of LLMs under multi-hop based misinformation with different textual styles. Regularization is applied to the results to facilitate the observation of differences across six styles.\n\n\nThe convincingness of misinformation to LLMs correlates with textual style and narrative format.\n\nAs reported in Figure\u00a06, LLMs show different preferences among misinformation in six textual styles. For instance, LLMs are more distracted from one-hop based misinformation in Wikipedia Entry and Science Reference styles, and on multi-hop based misinformation in News Report and Confident Language styles. It suggests that LLMs are more susceptible to narrative, subjective misinformation in reasoning-intensive tasks.\n\n\n\nLLMs show greater confidence in misinformation with objective and formal style under reasoning-intensive tasks.\n\nTo further investigate LLM behaviors under different stylized misinformation, in Figure\u00a07, we report the log probability distribution of correct options when LLMs answer correctly. We can observe that LLMs overall exhibit a high probability value toward multi-hop based misinformation in Blog, Confident Language and News Report styles, while more confident to correct options in Wikipedia Entry, Science Reference and Technical Language. This further demonstrates the fact that misinformation in narrative, subjective style is more misleading to LLMs in reasoning-intensive tasks.\n\n\n\n\nFinding 3: LLMs exhibit more susceptibility to narrative, subjective misinformation in reasoning-intensive tasks and to formal, objective misinformation in fact-matching tasks.\n\n\n\nFigure 7: Log probability distribution of correct options when LLMs correctly answer to questions under various stylized multi-hop based misinformation.\n\n\n\n\n\n\n4 RtD: Reconstruct to discriminate\n\nBased on above investigations, we believe that a capable LLM has a certain ability to perceive and discern misinformation. However, the model still exhibits limitations in their discriminative capabilities, particularly in calibrating implicit contextual knowledge and detecting subtle stylistic anomalies that often characterize deceptive misinformation. Building upon our empirical findings that \"LLMs perform better when comparing multiple pieces of conflicting information rather than making isolated judgments\", we propose enhancing LLMs\u2019 misinformation-discerning capabilities by leveraging both retrieved factual knowledge and LLMs\u2019 inherent discriminative strengths and intrinsic analytical capabilities.\n\n\nMethod\n\nBased on our empirical findings, we propose Reconstruction to Discriminate (RtD), a simple yet promising approach to improve LLMs\u2019 capabilities in discerning misinformation. This method begins by precisely identifying the key subject entity within the input text, ensuring focused attention on the essential information unit. Subsequently, the approach taps into authoritative sources such as Wikipedia444https://pypi.org/project/wikipedia to gather detailed descriptions of the entity, thus bolstering the model\u2019s contextual understanding with reliable external data. Following this, the LLM is prompted to generate supporting evidence about the entity, built upon the enriched context, which harnesses its ability to bridge understanding and production seamlessly. In the final stage, the LLM is tasked with comparing the original text against the generated content, discerning the more likely source of misinformation through a sophisticated integration of internal reasoning and retrieved data.\n\n\n\nExperimental Setup\n\nWe apply RtD to LLaMA3-8B, Qwen2.5-7B, Gemma2-9B on MisBench. We set a low temperature setting of 0 during generation with\na constraint of 512 for output length and maintain other configurations default for all LLMs. All experiments are conducted on a single NVIDIA A800 PCIe 80GB GPU.\n\n\n\n\n\n\nModels\nOne-hop based Misinformation\nMulti-hop based Misinformation\n\n\nFactual\nTemporal\nSemantic\nFactual\nTemporal\nSemantic\n\n\nLLaMA3-8B\n18.16\n34.92\n11.75\n18.48\n48.16\n20.57\n\n\n+ Desc\n23.17\n38.98\n23.20\n20.47\n50.42\n25.12\n\n\n+ RtD\n70.66\n85.81\n78.67\n70.31\n87.05\n79.79\n\n\nQwen2.5-7B\n11.41\n46.78\n11.23\n17.43\n53.25\n14.61\n\n\n+ Desc\n17.88\n47.50\n41.55\n21.49\n57.68\n30.47\n\n\n+ RtD\n41.31\n43.82\n58.19\n49.11\n78.45\n68.17\n\n\nQwen2.5-14B\n63.59\n99.27\n63.74\n71.84\n99.49\n70.22\n\n\n+ Desc\n65.54\n90.95\n75.70\n62.59\n86.05\n72.16\n\n\n+ RtD\n71.17\n95.68\n86.82\n68.41\n93.37\n79.54\n\n\nGemma2-2B\n34.71\n66.81\n25.57\n53.00\n82.22\n50.90\n\n\n+ Desc\n39.58\n68.67\n33.75\n60.48\n78.84\n49.93\n\n\n+ RtD\n82.65\n95.83\n88.73\n81.36\n89.58\n87.39\n\n\nGemma2-9B\n53.64\n94.57\n43.44\n53.37\n91.42\n49.63\n\n\n+ Desc\n53.65\n92.12\n61.68\n51.93\n89.69\n61.89\n\n\n+ RtD\n67.20\n92.55\n71.00\n66.85\n93.04\n74.79\n\n\n\n\nTable 4: Success Rate% of LLMs on one-hop and multi-hop based different type misinformation detection. \"+Desc\" denotes LLM directly feeds retrieved entity description into the input context.\n\n\n\nResults\n\nWe report Success Rate% of LLMs on MisBench in Table\u00a04. It is evidenced that RtD substantially enhances the baseline LLMs\u2019 performance in discerning three types of misinformation. For instance, the average Success Rate% on one-hop based misinformation detection increases from 23.14 to 47.77 on Qwen2.5-7B. Compared to RtD, simply feeding retrieved descriptions into the context has limited promotion on LLMs, and it is more effective on semantic misinformation than on factual or temporal misinformation. These results further prove the effectiveness of the aforementioned findings and the proposed RtD.\n\n\n\n\n\n5 Conclusion\n\nIn this paper, we present MisBench, the largest and most comprehensive benchmark for evaluating and analyzing LLMs\u2019 knowledge and stylistic preferences toward misinformation. MisBench includes 431,113 QA pairs and 10,346,712 misinformation texts across 12 domains and various styles. Our analysis shows that (1) LLMs can identify misinformation through contextual inconsistencies even without prior factual knowledge, (2) they are vulnerable to knowledge conflicts but perform better in comparative judgments, and (3) they are influenced by misinformation presented in different narrative styles. To address these challenges, we propose Reconstruct to Discriminate (RtD), a method that leverages external evidence reconstruction to enhance LLMs\u2019 misinformation detection capabilities. Experimental results demonstrate that RtD significantly improves reliability and trustworthiness. We believe MisBench will support a wide range of applications and contribute to the development of more trustworthy LLMs.\n\n\n\nLimitations\n\nWhile previous works have largely focused on detection errors in specific contexts, such as fake news or rumors, MisBench takes a broader approach by including a wide range of emblematic and pervasive types of misinformation, as well as diverse textual styles. While we strive to capture the most representative forms of misinformation, we acknowledge that our dataset may not fully encompass all possible variations that exist in real-world scenarios. The complexity and evolving nature of misinformation, combined with the vast diversity of linguistic styles, make it challenging to achieve complete coverage. Nonetheless, we believe that the types and styles included in MisBench are sufficiently representative to support meaningful analysis and evaluation, while recognizing the need for future work to address additional forms of misinformation that may emerge over time.\n\n\nBesides, our approach leverages generative models to construct a large number of conflict claims and misinformation, a commonly used technique in recent research\u00a0Su et\u00a0al. (2024). While conflict pairs may be extracted from pre-training corpora, the sheer volume of data makes it difficult to efficiently identify. In future work, we plan to explore additional methods for constructing conflict pairs to further validate the robustness of our dataset.\n\n\nFinally, we focus primarily on text-based content, and future work should consider the impact of metadata, visual content, and other forms of information that could influence LLM\u2019s convincingness towards misinformation.\n\n\n\nEthics Statement\n\nIn our paper, MisBench is built using publicly available Wikidata and Wikipedia, allowing us to adapt the data for our purposes. We will release our dataset and the prompts used under the same public domain license, ensuring it is solely intended for scientific research. By making our research transparent, we aim to support for developing of trustworthy LLMs and advocate for responsible, ethical AI implementation. This openness seeks to inform the public, policymakers, and developers about these risks.\n\n\nWe have taken steps to minimize the inclusion of offensive content in our dataset. During the construction process, we applied strict filtering techniques to identify and exclude content that may be considered harmful or inappropriate. While we acknowledge that some offensive content may still arise from model outputs due to the nature of large language models, we emphasize that such content is unintended and does not reflect the views or intentions of the authors. Our efforts aim to ensure that the dataset remains as safe and appropriate as possible for scientific research purposes.\n\n\n\nAcknowledgments\n\nThis research was supported by National Key Research and Development Program of China Grant No.2023YFF0725100 and Guangdong S&T Program C019. We would like to thank all the anonymous reviewers and area chairs for their insightful and valuable comments. We also thank the support of the 12th Baidu Scholarship.\n\n\n\nReferences\n\n\n(1)\n\n\nThe claude 3 model family: Opus, sonnet, haiku.\n\n\n\n\nAchiam et\u00a0al. (2023)\n\nJosh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia\u00a0Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et\u00a0al. 2023.\n\n\nGpt-4 technical report.\n\n\narXiv preprint arXiv:2303.08774.\n\n\n\n\nAI@Meta (2024)\n\nAI@Meta. 2024.\n\n\nThe llama 3 herd of models.\n\n\nCoRR, abs/2407.21783.\n\n\n\n\nBartsch et\u00a0al. (2023)\n\nHenning Bartsch, Ole Jorgensen, Domenic Rosati, Jason Hoelscher-Obermaier, and Jacob Pfau. 2023.\n\n\nSelf-consistency of large language models under ambiguity.\n\n\nIn BlackboxNLP@EMNLP, pages 89\u2013105. Association for Computational Linguistics.\n\n\n\n\nCao et\u00a0al. (2021)\n\nNicola\u00a0De Cao, Wilker Aziz, and Ivan Titov. 2021.\n\n\nEditing factual knowledge in language models.\n\n\nIn Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event / Punta Cana, Dominican Republic, 7-11 November, 2021, pages 6491\u20136506. Association for Computational Linguistics.\n\n\n\n\nChen and Shu (2024a)\n\nCanyu Chen and Kai Shu. 2024a.\n\n\nCan llm-generated misinformation be detected?\n\n\nIn The Twelfth International Conference on Learning Representations, ICLR 2024, Vienna, Austria, May 7-11, 2024. OpenReview.net.\n\n\n\n\nChen and Shu (2024b)\n\nCanyu Chen and Kai Shu. 2024b.\n\n\nCombating misinformation in the age of llms: Opportunities and challenges.\n\n\nAI Mag., 45(3):354\u2013368.\n\n\n\n\nChen et\u00a0al. (2023a)\n\nJiangjie Chen, Wei Shi, Ziquan Fu, Sijie Cheng, Lei Li, and Yanghua Xiao. 2023a.\n\n\nSay what you mean! large language models speak too positively about negative commonsense knowledge.\n\n\nIn ACL (1), pages 9890\u20139908. Association for Computational Linguistics.\n\n\n\n\nChen et\u00a0al. (2024)\n\nNuo Chen, Yuhan Li, Jianheng Tang, and Jia Li. 2024.\n\n\nGraphwiz: An instruction-following language model for graph computational problems.\n\n\nIn KDD, pages 353\u2013364. ACM.\n\n\n\n\nChen et\u00a0al. (2023b)\n\nNuo Chen, Yan Wang, Haiyun Jiang, Deng Cai, Yuhan Li, Ziyang Chen, Longyue Wang, and Jia Li. 2023b.\n\n\nLarge language models meet harry potter: A dataset for aligning dialogue agents with characters.\n\n\nIn EMNLP (Findings), pages 8506\u20138520. Association for Computational Linguistics.\n\n\n\n\nCohen et\u00a0al. (2024)\n\nRoi Cohen, Eden Biran, Ori Yoran, Amir Globerson, and Mor Geva. 2024.\n\n\nEvaluating the ripple effects of knowledge editing in language models.\n\n\nTrans. Assoc. Comput. Linguistics, 12:283\u2013298.\n\n\n\n\nDeepSeek-AI (2024)\n\nDeepSeek-AI. 2024.\n\n\nDeepseek-v2: A strong, economical, and efficient mixture-of-experts language model.\n\n\nPreprint, arXiv:2405.04434.\n\n\n\n\nGao et\u00a0al. (2023)\n\nYuan Gao, Xiang Wang, Xiangnan He, Huamin Feng, and Yong-Dong Zhang. 2023.\n\n\nRumor detection with self-supervised learning on texts and social graph.\n\n\nFrontiers Comput. Sci., 17(4):174611.\n\n\n\n\nGhosal et\u00a0al. (2023)\n\nSoumya\u00a0Suvra Ghosal, Souradip Chakraborty, Jonas Geiping, Furong Huang, Dinesh Manocha, and Amrit\u00a0Singh Bedi. 2023.\n\n\nTowards possibilities & impossibilities of ai-generated text detection: A survey.\n\n\nCoRR, abs/2310.15264.\n\n\n\n\nGoldstein et\u00a0al. (2023)\n\nJosh\u00a0A. Goldstein, Girish Sastry, Micah Musser, Renee DiResta, Matthew Gentzel, and Katerina Sedova. 2023.\n\n\nGenerative language models and automated influence operations: Emerging threats and potential mitigations.\n\n\nCoRR, abs/2301.04246.\n\n\n\n\nGuo et\u00a0al. (2022)\n\nZhijiang Guo, Michael\u00a0Sejr Schlichtkrull, and Andreas Vlachos. 2022.\n\n\nA survey on automated fact-checking.\n\n\nTrans. Assoc. Comput. Linguistics, 10:178\u2013206.\n\n\n\n\nHe et\u00a0al. (2023)\n\nPengcheng He, Jianfeng Gao, and Weizhu Chen. 2023.\n\n\nDebertav3: Improving deberta using electra-style pre-training with gradient-disentangled embedding sharing.\n\n\nIn The Eleventh International Conference on Learning Representations, ICLR 2023, Kigali, Rwanda, May 1-5, 2023. OpenReview.net.\n\n\n\n\nHo et\u00a0al. (2020)\n\nXanh Ho, Anh-Khoa\u00a0Duong Nguyen, Saku Sugawara, and Akiko Aizawa. 2020.\n\n\nConstructing A multi-hop QA dataset for comprehensive evaluation of reasoning steps.\n\n\nIn Proceedings of the 28th International Conference on Computational Linguistics, COLING 2020, Barcelona, Spain (Online), December 8-13, 2020, pages 6609\u20136625. International Committee on Computational Linguistics.\n\n\n\n\nHong et\u00a0al. (2024)\n\nGiwon Hong, Jeonghwan Kim, Junmo Kang, Sung-Hyon Myaeng, and Joyce\u00a0Jiyoung Whang. 2024.\n\n\nWhy so gullible? enhancing the robustness of retrieval-augmented models against counterfactual noise.\n\n\nIn NAACL-HLT (Findings), pages 2474\u20132495. Association for Computational Linguistics.\n\n\n\n\nHsu et\u00a0al. (2021)\n\nCheng Hsu, Cheng-Te Li, Diego S\u00e1ez-Trumper, and Yi-Zhan Hsu. 2021.\n\n\nWikicontradiction: Detecting self-contradiction articles on wikipedia.\n\n\nIn IEEE BigData, pages 427\u2013436. IEEE.\n\n\n\n\nHu et\u00a0al. (2024)\n\nBeizhe Hu, Qiang Sheng, Juan Cao, Yuhui Shi, Yang Li, Danding Wang, and Peng Qi. 2024.\n\n\nBad actor, good advisor: Exploring the role of large language models in fake news detection.\n\n\nIn Thirty-Eighth AAAI Conference on Artificial Intelligence, AAAI 2024, Thirty-Sixth Conference on Innovative Applications of Artificial Intelligence, IAAI 2024, Fourteenth Symposium on Educational Advances in Artificial Intelligence, EAAI 2014, February 20-27, 2024, Vancouver, Canada, pages 22105\u201322113. AAAI Press.\n\n\n\n\nHu et\u00a0al. (2023)\n\nXuming Hu, Zhijiang Guo, Junzhe Chen, Lijie Wen, and Philip\u00a0S. Yu. 2023.\n\n\nMR2: A benchmark for multimodal retrieval-augmented rumor detection in social media.\n\n\nIn SIGIR, pages 2901\u20132912. ACM.\n\n\n\n\nJin et\u00a0al. (2024)\n\nZhuoran Jin, Pengfei Cao, Yubo Chen, Kang Liu, Xiaojian Jiang, Jiexin Xu, Qiuxia Li, and Jun Zhao. 2024.\n\n\nTug-of-war between knowledge: Exploring and resolving knowledge conflicts in retrieval-augmented language models.\n\n\nIn LREC/COLING, pages 16867\u201316878. ELRA and ICCL.\n\n\n\n\nKasai et\u00a0al. (2023)\n\nJungo Kasai, Keisuke Sakaguchi, Yoichi Takahashi, Ronan\u00a0Le Bras, Akari Asai, Xinyan Yu, Dragomir Radev, Noah\u00a0A. Smith, Yejin Choi, and Kentaro Inui. 2023.\n\n\nRealtime QA: what\u2019s the answer right now?\n\n\nIn NeurIPS.\n\n\n\n\nKwon et\u00a0al. (2023)\n\nWoosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying Sheng, Lianmin Zheng, Cody\u00a0Hao Yu, Joseph\u00a0E. Gonzalez, Hao Zhang, and Ion Stoica. 2023.\n\n\nEfficient memory management for large language model serving with pagedattention.\n\n\nIn Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles.\n\n\n\n\nLazaridou et\u00a0al. (2021)\n\nAngeliki Lazaridou, Adhiguna Kuncoro, Elena Gribovskaya, Devang Agrawal, Adam Liska, Tayfun Terzi, Mai Gimenez, Cyprien de\u00a0Masson\u00a0d\u2019Autume, Tom\u00e1s Kocisk\u00fd, Sebastian Ruder, Dani Yogatama, Kris Cao, Susannah Young, and Phil Blunsom. 2021.\n\n\nMind the gap: Assessing temporal generalization in neural language models.\n\n\nIn NeurIPS, pages 29348\u201329363.\n\n\n\n\nLi et\u00a0al. (2023)\n\nHaoran Li, Dadi Guo, Wei Fan, Mingshi Xu, Jie Huang, Fanpu Meng, and Yangqiu Song. 2023.\n\n\nMulti-step jailbreaking privacy attacks on chatgpt.\n\n\nIn EMNLP (Findings), pages 4138\u20134153. Association for Computational Linguistics.\n\n\n\n\nLi et\u00a0al. (2024a)\n\nJierui Li, Vipul Raheja, and Dhruv Kumar. 2024a.\n\n\nContradoc: Understanding self-contradictions in documents with large language models.\n\n\nIn NAACL-HLT, pages 6509\u20136523. Association for Computational Linguistics.\n\n\n\n\nLi et\u00a0al. (2024b)\n\nYafu Li, Qintong Li, Leyang Cui, Wei Bi, Zhilin Wang, Longyue Wang, Linyi Yang, Shuming Shi, and Yue Zhang. 2024b.\n\n\nMAGE: machine-generated text detection in the wild.\n\n\nIn ACL (1), pages 36\u201353. Association for Computational Linguistics.\n\n\n\n\nLi et\u00a0al. (2024c)\n\nYuhan Li, Zhixun Li, Peisong Wang, Jia Li, Xiangguo Sun, Hong Cheng, and Jeffrey\u00a0Xu Yu. 2024c.\n\n\nA survey of graph meets large language model: progress and future directions.\n\n\nIn Proceedings of the Thirty-Third International Joint Conference on Artificial Intelligence, pages 8123\u20138131.\n\n\n\n\nLi et\u00a0al. (2025)\n\nYuhan Li, Xinni Zhang, Linhao Luo, Heng Chang, Yuxiang Ren, Irwin King, and Jia Li. 2025.\n\n\nG-refer: Graph retrieval-augmented large language model for explainable recommendation.\n\n\nIn Proceedings of the ACM on Web Conference 2025, pages 240\u2013251.\n\n\n\n\nLongpre et\u00a0al. (2021)\n\nShayne Longpre, Kartik Perisetla, Anthony Chen, Nikhil Ramesh, Chris DuBois, and Sameer Singh. 2021.\n\n\nEntity-based knowledge conflicts in question answering.\n\n\nIn Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event / Punta Cana, Dominican Republic, 7-11 November, 2021, pages 7052\u20137063. Association for Computational Linguistics.\n\n\n\n\nMaarouf et\u00a0al. (2024)\n\nAbdurahman Maarouf, Dominik B\u00e4r, Dominique Geissler, and Stefan Feuerriegel. 2024.\n\n\nHQP: A human-annotated dataset for detecting online propaganda.\n\n\nIn ACL (Findings), pages 6064\u20136089. Association for Computational Linguistics.\n\n\n\n\nMallen et\u00a0al. (2023)\n\nAlex Mallen, Akari Asai, Victor Zhong, Rajarshi Das, Daniel Khashabi, and Hannaneh Hajishirzi. 2023.\n\n\nWhen not to trust language models: Investigating effectiveness of parametric and non-parametric memories.\n\n\nIn Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2023, Toronto, Canada, July 9-14, 2023, pages 9802\u20139822. Association for Computational Linguistics.\n\n\n\n\nMartino et\u00a0al. (2020)\n\nGiovanni Da\u00a0San Martino, Stefano Cresci, Alberto Barr\u00f3n-Cede\u00f1o, Seunghak Yu, Roberto\u00a0Di Pietro, and Preslav Nakov. 2020.\n\n\nA survey on computational propaganda detection.\n\n\nIn IJCAI, pages 4826\u20134832. ijcai.org.\n\n\n\n\nPan et\u00a0al. (2023)\n\nYikang Pan, Liangming Pan, Wenhu Chen, Preslav Nakov, Min-Yen Kan, and William\u00a0Yang Wang. 2023.\n\n\nOn the risk of misinformation pollution with large language models.\n\n\nIn EMNLP (Findings), pages 1389\u20131403. Association for Computational Linguistics.\n\n\n\n\nPeng et\u00a0al. (2023)\n\nBaolin Peng, Michel Galley, Pengcheng He, Hao Cheng, Yujia Xie, Yu\u00a0Hu, Qiuyuan Huang, Lars Liden, Zhou Yu, Weizhu Chen, and Jianfeng Gao. 2023.\n\n\nCheck your facts and try again: Improving large language models with external knowledge and automated feedback.\n\n\nCoRR, abs/2302.12813.\n\n\n\n\nPeng et\u00a0al. (2022)\n\nMiao Peng, Ben Liu, Qianqian Xie, Wenjie Xu, Hua Wang, and Min Peng. 2022.\n\n\nSmile: Schema-augmented multi-level contrastive learning for knowledge graph link prediction.\n\n\nIn Findings of the Association for Computational Linguistics: EMNLP 2022, pages 4165\u20134177.\n\n\n\n\nPeng et\u00a0al. (2024)\n\nMiao Peng, Ben Liu, Wenjie Xu, Zihao Jiang, Jiahui Zhu, and Min Peng. 2024.\n\n\nDeja vu: Contrastive historical modeling with prefix-tuning for temporal knowledge graph reasoning.\n\n\nIn NAACL-HLT (Findings), pages 1178\u20131191. Association for Computational Linguistics.\n\n\n\n\nQian et\u00a0al. (2023)\n\nCheng Qian, Xinran Zhao, and Sherry\u00a0Tongshuang Wu. 2023.\n\n\n\"merge conflicts!\" exploring the impacts of external distractors to parametric knowledge graphs.\n\n\nCoRR, abs/2309.08594.\n\n\n\n\nRadford et\u00a0al. (2019)\n\nAlec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et\u00a0al. 2019.\n\n\nLanguage models are unsupervised multitask learners.\n\n\nOpenAI blog, 1(8):9.\n\n\n\n\nRaj et\u00a0al. (2023)\n\nHarsh Raj, Vipul Gupta, Domenic Rosati, and Subhabrata Majumdar. 2023.\n\n\nSemantic consistency for assuring reliability of large language models.\n\n\nCoRR, abs/2308.09138.\n\n\n\n\nRam et\u00a0al. (2023)\n\nOri Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay, Amnon Shashua, Kevin Leyton-Brown, and Yoav Shoham. 2023.\n\n\nIn-context retrieval-augmented language models.\n\n\nTrans. Assoc. Comput. Linguistics, 11:1316\u20131331.\n\n\n\n\nReimers and Gurevych (2019)\n\nNils Reimers and Iryna Gurevych. 2019.\n\n\nSentence-bert: Sentence embeddings using siamese bert-networks.\n\n\nIn Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics.\n\n\n\n\nSevgili et\u00a0al. (2022)\n\n\u00d6zge Sevgili, Artem Shelmanov, Mikhail\u00a0Y. Arkhipov, Alexander Panchenko, and Chris Biemann. 2022.\n\n\nNeural entity linking: A survey of models based on deep learning.\n\n\nSemantic Web, 13(3):527\u2013570.\n\n\n\n\nSheng et\u00a0al. (2022)\n\nQiang Sheng, Juan Cao, Xueyao Zhang, Rundong Li, Danding Wang, and Yongchun Zhu. 2022.\n\n\nZoom out and observe: News environment perception for fake news detection.\n\n\nIn ACL (1), pages 4543\u20134556. Association for Computational Linguistics.\n\n\n\n\nSu et\u00a0al. (2024)\n\nZhaochen Su, Jun Zhang, Xiaoye Qu, Tong Zhu, Yanshu Li, Jiashuo Sun, Juntao Li, Min Zhang, and Yu\u00a0Cheng. 2024.\n\n\nConflictbank: A benchmark for evaluating the influence of knowledge conflicts in llm.\n\n\narXiv preprint arXiv:2408.12076.\n\n\n\n\nTan et\u00a0al. (2024)\n\nHexiang Tan, Fei Sun, Wanli Yang, Yuanzhuo Wang, Qi\u00a0Cao, and Xueqi Cheng. 2024.\n\n\nBlinded by generated contexts: How language models merge generated and retrieved contexts when knowledge conflicts?\n\n\nIn ACL (1), pages 6207\u20136227. Association for Computational Linguistics.\n\n\n\n\nTang et\u00a0al. (2025)\n\nJianheng Tang, Qifan Zhang, Yuhan Li, Nuo Chen, and Jia Li. 2025.\n\n\nGrapharena: Evaluating and exploring large language models on graph computation.\n\n\nIn The Thirteenth International Conference on Learning Representations.\n\n\n\n\nTeam (2024a)\n\nGemma Team. 2024a.\n\n\nGemma.\n\n\n\n\nTeam (2024b)\n\nQwen Team. 2024b.\n\n\nQwen2.5: A party of foundation models.\n\n\n\n\nVladika and Matthes (2023)\n\nJuraj Vladika and Florian Matthes. 2023.\n\n\nScientific fact-checking: A survey of resources and approaches.\n\n\nIn ACL (Findings), pages 6215\u20136230. Association for Computational Linguistics.\n\n\n\n\nVrande\u010di\u0107 and Kr\u00f6tzsch (2014)\n\nDenny Vrande\u010di\u0107 and Markus Kr\u00f6tzsch. 2014.\n\n\nWikidata: a free collaborative knowledgebase.\n\n\nCommunications of the ACM, 57(10):78\u201385.\n\n\n\n\nWan et\u00a0al. (2024a)\n\nAlexander Wan, Eric Wallace, and Dan Klein. 2024a.\n\n\nWhat evidence do language models find convincing?\n\n\nIn Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), ACL 2024, Bangkok, Thailand, August 11-16, 2024, pages 7468\u20137484. Association for Computational Linguistics.\n\n\n\n\nWan et\u00a0al. (2024b)\n\nHerun Wan, Shangbin Feng, Zhaoxuan Tan, Heng Wang, Yulia Tsvetkov, and Minnan Luo. 2024b.\n\n\nDELL: generating reactions and explanations for llm-based misinformation detection.\n\n\nIn Findings of the Association for Computational Linguistics, ACL 2024, Bangkok, Thailand and virtual meeting, August 11-16, 2024, pages 2637\u20132667. Association for Computational Linguistics.\n\n\n\n\nWu et\u00a0al. (2024a)\n\nJiaying Wu, Jiafeng Guo, and Bryan Hooi. 2024a.\n\n\nFake news in sheep\u2019s clothing: Robust fake news detection against llm-empowered style attacks.\n\n\nIn KDD, pages 3367\u20133378. ACM.\n\n\n\n\nWu et\u00a0al. (2023)\n\nJunchao Wu, Shu Yang, Runzhe Zhan, Yulin Yuan, Derek\u00a0F. Wong, and Lidia\u00a0S. Chao. 2023.\n\n\nA survey on llm-generated text detection: Necessity, methods, and future directions.\n\n\nCoRR, abs/2310.14724.\n\n\n\n\nWu et\u00a0al. (2024b)\n\nJunchao Wu, Runzhe Zhan, Derek\u00a0F. Wong, Shu Yang, Xinyi Yang, Yulin Yuan, and Lidia\u00a0S. Chao. 2024b.\n\n\nDetectrl: Benchmarking llm-generated text detection in real-world scenarios.\n\n\nCoRR, abs/2410.23746.\n\n\n\n\nXie et\u00a0al. (2024)\n\nJian Xie, Kai Zhang, Jiangjie Chen, Renze Lou, and Yu\u00a0Su. 2024.\n\n\nAdaptive chameleon or stubborn sloth: Revealing the behavior of large language models in knowledge conflicts.\n\n\nIn The Twelfth International Conference on Learning Representations, ICLR 2024, Vienna, Austria, May 7-11, 2024. OpenReview.net.\n\n\n\n\nXu et\u00a0al. (2024)\n\nRongwu Xu, Brian\u00a0S. Lin, Shujian Yang, Tianqi Zhang, Weiyan Shi, Tianwei Zhang, Zhixuan Fang, Wei Xu, and Han Qiu. 2024.\n\n\nThe earth is flat because\u2026: Investigating llms\u2019 belief towards misinformation via persuasive conversation.\n\n\nIn ACL (1), pages 16259\u201316303. Association for Computational Linguistics.\n\n\n\n\nXu et\u00a0al. (2023)\n\nWenjie Xu, Ben Liu, Miao Peng, Xu\u00a0Jia, and Min Peng. 2023.\n\n\nPre-trained language model with prompts for temporal knowledge graph completion.\n\n\nIn ACL (Findings), pages 7790\u20137803. Association for Computational Linguistics.\n\n\n\n\nYao et\u00a0al. (2023)\n\nShunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran, Tom Griffiths, Yuan Cao, and Karthik Narasimhan. 2023.\n\n\nTree of thoughts: Deliberate problem solving with large language models.\n\n\nIn NeurIPS.\n\n\n\n\nZhang and Ghorbani (2020)\n\nXichen Zhang and Ali\u00a0A. Ghorbani. 2020.\n\n\nAn overview of online fake news: Characterization, detection, and discussion.\n\n\nInf. Process. Manag., 57(2):102025.\n\n\n\n\nZhou and Zafarani (2021a)\n\nXinyi Zhou and Reza Zafarani. 2021a.\n\n\nA survey of fake news: Fundamental theories, detection methods, and opportunities.\n\n\nACM Comput. Surv., 53(5):109:1\u2013109:40.\n\n\n\n\nZhou and Zafarani (2021b)\n\nXinyi Zhou and Reza Zafarani. 2021b.\n\n\nA survey of fake news: Fundamental theories, detection methods, and opportunities.\n\n\nACM Comput. Surv., 53(5):109:1\u2013109:40.\n\n\n\n\n\n\n\n\nAppendix A Related Work\n\n\nA.1 Combating Misinformation\n\nCombating misinformation is a critical step in protecting online spaces from the spread of false or misleading information. Numerous survey papers have explored various misinformation detection techniques\u00a0Zhou and Zafarani (2021a); Zhang and Ghorbani (2020); Chen and Shu (2024b). Existing studies primarily focus on specific tasks such as fake news detection\u00a0Sheng et\u00a0al. (2022); Wan et\u00a0al. (2024b), rumor detection\u00a0Hu et\u00a0al. (2023); Gao et\u00a0al. (2023), fact-checking\u00a0Guo et\u00a0al. (2022); Vladika and Matthes (2023) and propaganda detection\u00a0Maarouf et\u00a0al. (2024); Martino et\u00a0al. (2020). However, these works mainly focus on human-written texts. Recently, with the exploration use of LLMs, studies have paid attention to combating machine-generated misinformation\u00a0Li et\u00a0al. (2024b); Wu et\u00a0al. (2024b). Current technologies for detecting LLM-generated text\u00a0Wu et\u00a0al. (2023); Ghosal et\u00a0al. (2023) primarily include watermarking techniques, statistical methods, neural-based detectors, and human-assisted approaches. Additionally, some studies have explored how LLMs process and respond to misinformation\u00a0Chen and Shu (2024a); Xu et\u00a0al. (2024); Pan et\u00a0al. (2023); Hu et\u00a0al. (2024); Wu et\u00a0al. (2024a). However, these approaches are still limited in both precision and scope. At the same time, efforts have been made to reduce the generation of harmful, biased, or unfounded information by LLMs. While these measures are well-intentioned, they have demonstrated weaknesses, as users can often exploit them through carefully crafted \"jailbreaking\" prompts\u00a0Li et\u00a0al. (2023).\n\n\nOur research takes a different approach from previous studies that focus solely on either generation or detection. We explore the behaviors and preferences of LLMs towards misinformation from a more comprehensive view including knowledge and stylistic perspectives, and propose a potential countermeasure based on our empirical findings.\n\n\n\n\nA.2 Knowledge Conflicts\n\nKnowledge conflict has been a primary focus in prior studies as a key driver of misinformation production\u00a0Hsu et\u00a0al. (2021); Li et\u00a0al. (2024a). In real-world scenarios, knowledge conflicts are influenced by various factors, such as knowledge updates with time changes\u00a0Lazaridou et\u00a0al. (2021); Peng et\u00a0al. (2024); Xu et\u00a0al. (2023) and knowledge edits\u00a0Cohen et\u00a0al. (2024), and the ambiguity of language\u00a0Sevgili et\u00a0al. (2022); Longpre et\u00a0al. (2021), including words with multiple meanings. Existing researches on knowledge conflicts in Large Language Models (LLMs) can be broadly categorized into two types: retrieved knowledge conflicts and embedded knowledge conflicts. Retrieved conflicts occur when a model\u2019s internal knowledge contradicts external information retrieved during processes like retrieval-augmented generation (RAG)\u00a0Jin et\u00a0al. (2024); Hong et\u00a0al. (2024); Li et\u00a0al. (2024c); Peng et\u00a0al. (2023); Li et\u00a0al. (2025) or tool-augmented scenarios\u00a0Li et\u00a0al. (2024a); Kasai et\u00a0al. (2023). In contrast, embedded conflicts arise from inconsistent parametric knowledge within the LLM itself, leading to increased uncertainty during knowledge-intensive tasks and undermining the model\u2019s trustworthiness\u00a0Bartsch et\u00a0al. (2023); Raj et\u00a0al. (2023); Su et\u00a0al. (2024); Chen et\u00a0al. (2023a, b). Qian et\u00a0al. (2023) investigates the impacts of external knowledge\u2019s distract degrees, methods, positions, and formats on various metric knowledge structures including multi-hop and multi-dependent ones.\n\n\nThese works study the interplay between LLMs and misinformation, but they mainly focus on limited type of misinformation, especially in knowledge conflict scenarios, and lack of thorough analysis on LLMs\u2019 preference toward textual styles of misinformation.\n\n\n\n\n\nAppendix B Rationale behind the taxonomy of misinformation types and styles\n\nSection\u00a02 and Figure\u00a02 summarize the types and styles we constructed about misinformation using LLMs. Following Chen and Shu (2024a), we categorize their key features based on two dimensions: (1) Errors: Errors of LLM-generated misinformation include Unsubstantiated Content and Total Fabrication. To be specific, they contain Outdated Information, Description Ambiguity, Incomplete Fact, and False Context. (2) Propagation Medium: According to previous works\u00a0Zhou and Zafarani (2021b); Wan et\u00a0al. (2024a), we identify the most common misinformation genres that appear in real-world scenarios, including blog, news report, wikidata entry and science reference. Besides, we consider two linguistic styles: confident language and technical language. We believe these dimensions and taxonomies mostly cover the common misinformation in potential scenarios of LLM-based knowledge-intensive tasks.\n\n\n\n\nAppendix C Human Evaluation\n\n\nC.1 Human Evaluation on NLI Model\n\nTo ensure the reliability of the generated dataset, we incorporate human-based labeling and evaluation as part of the quality control process to assure reliable models, such as the state-of-the-art Natural Language Inference (NLI). Specifically, during the Entailment Checking process described in Section\u00a02.2, we leverage an NLI model to filter out lower-quality examples.\nTo estimate the effectiveness of NLI model for this purpose, we randomly sampled 500 generated examples and manually annotated whether they entail their corresponding claims (entailment in NLI task for \u2018yes\u2019, either neutral or contradiction for \u2018no\u2019). Then we evaluate the NLI model (here we use deberta-small-long-nli555https://huggingface.co/tasksource/deberta-small-long-nli) model over this dataset and observe over 95% accuracy of the model. Through this we can ensure the quality of synthesized evidence in MisBench to the maximum extent.\n\n\n\n\nC.2 Human Evaluation on MisBench data\n\nSettings\n\nWe recruited three Computer Science annotators with expertise in natural language processing (NLP) to manually evaluate the quality of misinformation text in MisBench. The annotators were provided with 500 pairs of generated instances in the dataset, consisting of the question, corresponding claim and misinformation texts in three types. They were tasked with two main evaluations:\n\n\n\u2022\n\nEntailment Check: Determining whether the generated misinformation logically supports the corresponding claim.\n\n\n\n\u2022\n\nConflict Check: Determining whether the generated factual, temporal and semantic misinformation contradict with the correct evidence text.\n\n\n\nBy having domain experts manually annotate the data in MisBench, we aimed to robustly assess the quality and validity of misinformation in MisBench.\n\n\n\nAnnotation Guideline\n\nHere we describe our human annotation guidelines for annotating and evaluating the benchmark data quality. Details is listed as follows:\n\n\nOverview: You will evaluate the following provided texts that may contain misinformation. The texts are based on a given claim. Please rate each answer on a scale of 0 to 2 using the criteria below:\n\n\nEntailment (0-2):\n\n\n\u2022\n\n0 - The misinformation does not logically support the claim at all. There is a clear lack of alignment or logical connection between the misinformation and the claim. Example: The claim is about a scientific discovery, but the misinformation references unrelated historical events.\n\n\n\n\u2022\n\n1 - The misinformation partially supports the claim but contains logical gaps or inconsistencies. The connection is unclear or flawed. Example: The claim is about a new policy, and the misinformation provides related context but includes irrelevant or speculative reasoning.\n\n\n\n\u2022\n\n2 - The misinformation fully and logically supports the claim, with no gaps or inconsistencies. The reasoning aligns well with the claim. Example: The claim is about economic growth, and the misinformation provides logical and consistent evidence (though fabricated).\n\n\n\n\n\nConflict (0-2):\n\n\n\u2022\n\n0 - The misinformation does not contradict the evidence in any factual, temporal, or semantic way. It aligns with or circumvents the evidence without conflict. Example: The evidence discusses rainfall trends, and the misinformation speculates on possible future impacts without contradicting the evidence.\n\n\n\n\u2022\n\n1 - The misinformation partially contradicts the evidence but not in an obvious or definitive way. The contradiction may be subtle, implicit, or context-dependent. Example: The evidence states that \"Policy Z reduced unemployment,\" while the misinformation claims it only impacted specific groups, without directly refuting the evidence.\n\n\n\n\u2022\n\n2 - The misinformation directly and clearly contradicts the correct evidence in a way that is easy to identify. Example: The evidence states that \"Event Y occurred in 2020,\" but the misinformation claims it happened in 2018.\n\n\n\n\n\nThese statements are carefully crafted to capture\ndistinct aspects of the MisBench quality.\n\n\n\nAgreement Rate\n\nAgreement Rate was calculated to determine inter-rater agreement for each criterion. As shown in Table\u00a05, a high level of agreement was achieved for all criteria. The high agreement observed further supports our dataset\u2019s quality and relevance.\n\n\n\n\n\n\nAgreement Rate\nEntailment\nConflict\nAverage\n\n\n\n\nAnnotator 1\n97.2\n93.8\n95.0\n\n\nAnnotator 2\n96.6\n91.8\n94.2\n\n\nAnnotator 3\n95.8\n95.0\n95.4\n\n\n\n\nTable 5: Human evaluation results on MisBench\n\n\n\n\n\n\nAppendix D Benchmark Details\n\n\n\n\u2022\n\nBenchmark Statistics are summarized in Figure\u00a08 and Figure\u00a09.\n\n\n\n\u2022\n\nBenchmark Constructing Consumption are listed in Table\u00a06 and Table\u00a07.\n\n\n\n\u2022\n\nRelation Template used in MisBench are listed in Table\u00a08 and Table\u00a09.\n\n\n\n\n\n\n\n\n(a) One-hop Claim Relation Distribution\n\n\n\n\n(b) Multi-hop Claim Relation Distribution\n\n\n\nFigure 8: Relation Distribution Statistics of one-hop claims (a) and multi-hop claims (b) in MisBench. For readability, only relations with top 30 frequency are displayed.\n\n\n\n\n\n(a) Factual Misinformation\n\n\n\n\n(b) Temporal Misinformation\n\n\n\n\n(c) semantic Misinformation\n\n\n\nFigure 9: Word Cloud Distribution of factual misinformation(a), temporal misinformation(b) and semantic misinformation(c) in MisBench.\n\n\n\n\n\n\nNo\nStep\nTime\nGPU\n# Claims\n# Evidence\n# Stylized Evidence\n\n\n\n\n0\nInput Wiki Triples\n-\n-\n231,461,453\n-\n-\n\n\n1\nClaim Extraction\n-\n-\n765,583\n-\n-\n\n\n2\nMisinfo Construction\n224 hours\n4*A800\n765,583\n3,062,332\n-\n\n\n3\nEntailment Checking\n11 hours\n1*A800\n434,028\n1,736,112\n-\n\n\n4\nSemantic Matching\n4.7 hours\n1*A800\n347,892\n1,391,568\n-\n\n\n5\nMisinfo Stylization\n696.6 hours\n4*A800\n347,892\n1,391,568\n8,349,408\n\n\n\n\nTable 6: Time and resources consumption during constructing one-hop question-evidence pairs in MisBench. For the sake of simplicity, the term \"# Evidence\" refers to the total number of correct evidence and misinformation evidence (fact-conflicting, temporal-conflicting and semantic-conflicting), and the term \"# Stylized Evidence\" refers to the amount of evidences in six textual styles (Wikipedia Entry, News Report, Science Reference, Blog, Technical Language and Confident Language). We convert all claims that pass step 4 (Semantic Matching Validation) to QA pairs and perform text stylization on each evidence.\n\n\n\n\n\n\nNo\nStep\nTime\nGPU\n# Claims\n# Evidence\n# Stylized Evidence\n\n\n\n\n0\nInput Multi-hop Facts\n-\n-\n180,030\n-\n-\n\n\n1\nReasoning Type Filtering\n-\n-\n87,644\n-\n-\n\n\n2\nMisinfo Construction\n26 hours\n4*A800\n87,644\n350,576\n-\n\n\n3\nEntailment Checking\n2.4 hours\n1*A800\n83,592\n334,368\n-\n\n\n4\nSemantic Matching\n1 hours\n1*A800\n83,221\n332,884\n-\n\n\n5\nMisinfo Stylization\n114 hours\n4*A800\n83,221\n332,884\n1,997,304\n\n\n\n\nTable 7: Time and resources consumption during constructing multi-hop question-evidence pairs in MisBench. \"Reasoning Type Filtering\" denotes that only keep claim-evidence pairs with \"Inference\" and \"Compositional\" type relations. For the sake of simplicity, the term \"# Evidence\" refers to the total number of correct evidence and misinformation evidence (fact-conflicting, temporal-conflicting and semantic-conflicting), and the term \"# Stylized Evidence\" refers to the amount of evidences in six textual styles (Wikipedia Entry, News Report, Science Reference, Blog, Technical Language and Confident Language). We convert all claims that pass step 4 (Semantic Matching Validation) to QA pairs and perform text stylization on each evidence.\n\n\n\n\n\n\nRelation\nCloze-style Statement\nQuestion Template\n\n\n\n\nP17\n<S> is located in the country <O>.\nWhich country is <S> located in?\n\n\nP106\n<S> works as a <O>.\nWhat is the occupation of <S>?\n\n\nP27\n<S> is a citizen of <O>.\nWhich country is <S> a citizen of?\n\n\nP407\nThe work or name associated with <S> is in the language of <O>.\nWhat language is associated with the work or name of <S>?\n\n\nP361\n<S> is a part of <O>.\nWhich entity is <S> a part of?\n\n\nP69\n<S> attended <O>.\nWhich educational institution did <S> attend?\n\n\nP136\n<S> works in the genre of <O>.\nWhich genre does <S> work in?\n\n\nP161\n<S> is a cast member in <O>.\nIn which production is <S> a cast member?\n\n\nP155\nIn the series, <S> follows <O>.\nWhich item does <S> follow in the series?\n\n\nP495\n<S> is from <O>.\nWhich country is <S> from?\n\n\nP5008\n<S> is on the focus list of the Wikimedia project <O>.\nWhich Wikimedia project has <S> been listed on the focus list for?\n\n\nP108\n<S> worked for <O>.\nWhich person or organization did <S> work for?\n\n\nP126\n<S> is maintained by <O>.\nWhich person or organization is in charge of maintaining <S>?\n\n\nP127\n<S> is owned by <O>.\nWho owns <S>?\n\n\nP166\n<S> received the award <O>.\nWhich award did <S> receive?\n\n\nP6104\n<S> is maintained by WikiProject <O>.\nWhich WikiProject maintains <S>?\n\n\nP102\n<S> is a member of the political party <O>.\nWhich political party is <S> affiliated with?\n\n\nP140\n<S> follows the religion <O>.\nWhich religion is <S> affiliated with?\n\n\nP421\n<S> is located in the time zone <O>.\nWhat time zone is <S> located in?\n\n\nP54\n<S> plays for <O>.\nWhich sports team does <S> represent or represent?\n\n\nP175\n<S> is a performer associated with <O>.\nWhich role or musical work is <S> associated with as a performer?\n\n\nP463\n<S> is a member of <O>.\nWhich organization, club or musical group is <S> a member of?\n\n\nP937\n<S> works at <O>.\nWhere does <S> work?\n\n\nP1344\n<S> participated in <O>.\nWhich event did <S> participate in?\n\n\nP57\n<S> was directed by <O>.\nWho directed <S>?\n\n\nP137\n<S> is operated by <O>.\nWho operates <S>?\n\n\nP26\n<S> is married to <O>.\nWho is <S>\u2019s spouse?\n\n\nP138\n<S> is named after <O>.\nWhat is <S> named after?\n\n\nP39\n<S> holds the position of <O>.\nWhat position does <S> currently or formerly hold?\n\n\nP159\n<S> has its headquarters in the city or town of <O>.\nWhat city or town is the headquarters of <S> located in?\n\n\nP750\n<S>\u2019s work is distributed by <O>.\nWho distributes <S>\u2019s work?\n\n\nP2789\n<S> is physically connected with <O>.\nWhich item is physically connected with <S>?\n\n\nP551\n<S> resides in <O>.\nWhere does <S> reside?\n\n\nP2348\n<S> occurred in the time period <O>.\nDuring which time period did <S> occur?\n\n\nP360\n<S> is a list of <O>.\nWhat common element do all the items in the list of <S> share?\n\n\nP272\n<S> was produced by <O>.\nWhich company produced <S>?\n\n\nP2094\n<S> competes in the <O> competition class.\nIn which competition class does <S> compete?\n\n\nP674\n<S> appears as the character <O>.\nWhich character does <S> appear as?\n\n\nP410\n<S> holds the military rank of <O>.\nWhat is <S>\u2019s military rank?\n\n\nP449\n<S> was originally broadcasted by <O>.\nWhich network originally broadcasted <S>?\n\n\nP179\n<S> is part of the series <O>.\nWhich series is <S> a part of?\n\n\nP1346\n<S> is the winner of <O>.\nWhich competition did <S> win?\n\n\nP793\n<S> was involved in the significant event <O>.\nIn which significant event was <S> involved?\n\n\nP366\n<S> has the main use of <O>.\nWhat is the main use of <S>?\n\n\nP1416\n<S> is affiliated with <O>.\nWhich organization is <S> affiliated with?\n\n\nP241\n<S> belongs to the military branch of <O>.\nWhich military branch does <S> belong to?\n\n\nP710\n<S> actively takes part in <O>.\nWhich event or process does <S> actively take part in?\n\n\nP664\n<S> is organized by <O>.\nWho organizes the event that <S> is involved in?\n\n\nP814\nThe IUCN protected area category of <S> is <O>.\nWhich IUCN protected area category does <S> belong to?\n\n\nP118\n<S> plays in the <O> league.\nWhich league does <S> play in?\n\n\nP512\n<S> holds the academic degree of <O>.\nWhat academic degree does <S> hold?\n\n\nP30\n<S> is located in the continent <O>.\nWhich continent is <S> located in?\n\n\nP725\nThe voice for <S> is provided by <O>.\nWho provides the voice for <S>?\n\n\nP115\n<S> plays at <O>.\nIn which venue does <S> play?\n\n\nP1923\n<S> is a participating team of <O>.\nWhich event does <S> participate in?\n\n\nP1366\n<S> was replaced by <O>.\nWho replaced <S> in their role?\n\n\nP36\n<S> has the capital <O>.\nWhat is the capital of <S>?\n\n\nP190\n<S> is twinned with <O>.\nWhich administrative body is twinned with <S>?\n\n\nP286\n<S> has the head coach <O>.\nWho is the head coach of <S>?\n\n\nP559\n<S> ends at the feature <O>.\nWhich feature does <S> end at?\n\n\nP37\n<S> has the official language <O>.\nWhat is the official language of <S>?\n\n\nP2632\n<S> was detained at <O>.\nWhere was <S> detained?\n\n\nP541\n<S> is contesting for the office of <O>.\nWhich office is <S> contesting for?\n\n\nP609\nThe terminus location of <S> is <O>.\nWhat is the terminus location of <S>?\n\n\nP1427\nThe start point of <S>\u2019s journey was <O>.\nWhat is the start point of <S>\u2019s journey?\n\n\nP1652\n<S> is refereed by <O>.\nWho is the referee for <S>?\n\n\nP7938\n<S> is associated with the electoral district of <O>.\nWhich electoral district is <S> associated with?\n\n\nP3450\n<S> competed in the <O> sports season.\nIn which sports season did <S> compete?\n\n\nP6\n<S> was the head of government of <O>.\nWho was the head of government of <S>?\n\n\nP2522\n<S> won the competition or event <O>.\nWhich competition or event did <S> win?\n\n\nP488\n<S> has the chairperson <O>.\nWho is the chairperson of <S>?\n\n\n\n\nTable 8: Details of one-hop relations with corresponding cloze-style statements and question templates used in constructing misinformation of MisBench. <S> and <O> are placeholders of Subject and Object entities in a claim fact. The cloze-style statement represents the original relation text in wikidata, and Question Template converts cloze-style relation text into a natural language form for better question-answering task. For readability, only top 71 relations are listed.\n\n\n\n\n\n\nRelation Type\nRelation 1\nRelation 2\nQuestion Template\n\n\nCompositional\ndirector\ndate of death\nWhat is the date of death of the director of film <S>?\n\n\ndirector\nplace of birth\nWhat is the place of birth of the director of film <S>?\n\n\ndirector\ndate of birth\nWhat is the date of birth of the director of film <S>?\n\n\ndirector\ncountry of citizenship\nWhich country the director of film <S> is from?\n\n\ndirector\nplace of death\nWhere was the place of death of the director of film <S>?\n\n\nfather\ndate of death\nWhen did <S>\u2019s father die?\n\n\nperformer\ncountry of citizenship\nWhat nationality is the performer of song <S>?\n\n\nperformer\nplace of birth\nWhat is the place of birth of the performer of song <S>?\n\n\nperformer\ndate of birth\nWhat is the date of birth of the performer of song <S>?\n\n\nfather\ndate of birth\nWhen is <S>\u2019s father\u2019s birthday?\n\n\ncomposer\ncountry of citizenship\nWhat nationality is the composer of song <S>?\n\n\nspouse\ndate of death\nWhat is the date of death of <S>\u2019s husband?\n\n\nspouse\ndate of birth\nWhat is the date of birth of <S>\u2019s husband?\n\n\ncomposer\nplace of birth\nWhere was the composer of film <S> born?\n\n\ncomposer\ndate of birth\nWhen is the composer of film <S>\u2019s birthday?\n\n\ndirector\nspouse\nWho is the spouse of the director of film <S>?\n\n\nfather\nplace of death\nWhere was the place of death of <S>\u2019s father?\n\n\ncomposer\ndate of death\nWhen did the composer of film <S> die?\n\n\ndirector\ncause of death\nWhat is the cause of death of director of film <S>?\n\n\nfather\nplace of birth\nWhere was the father of <S> born?\n\n\ndirector\neducated at\nWhere did the director of film <S> graduate from?\n\n\nfather\ncountry of citizenship\nWhat nationality is <S>\u2019s father?\n\n\nspouse\nplace of birth\nWhere was the husband of <S> born?\n\n\nperformer\ndate of death\nWhen did the performer of song <S> die?\n\n\nmother\ndate of death\nWhen did <S>\u2019s mother die?\n\n\nspouse\nplace of death\nWhere was the place of death of <S>\u2019s husband?\n\n\ndirector\naward received\nWhat is the award that the director of film <S> won?\n\n\ndirector\nfather\nWho is the father of the director of film <S>?\n\n\nspouse\ncountry of citizenship\nWhat nationality is <S>\u2019s husband?\n\n\ncomposer\nplace of death\nWhere did the composer of film <S> die?\n\n\nperformer\naward received\nWhat is the award that the performer of song <S> received?\n\n\ndirector\nchild\nWho is the child of the director of film <S>?\n\n\nperformer\ncause of death\nWhy did the performer of song <S> die?\n\n\nperformer\nplace of death\nWhere did the performer of song <S> die?\n\n\nmother\ndate of birth\nWhat is the date of birth of <S>\u2019s mother?\n\n\ncomposer\naward received\nWhich award the composer of song <S> earned?\n\n\nperformer\nspouse\nWho is the spouse of the performer of song <S>?\n\n\nmother\nplace of death\nWhere did <S>\u2019s mother die?\n\n\nperformer\nfather\nWho is the father of the performer of song <S>?\n\n\nmother\nplace of birth\nWhere was the mother of <S> born?\n\n\ndirector\nemployer\nWhere does the director of film <S> work at?\n\n\nmother\ncountry of citizenship\nWhich country <S>\u2019s mother is from?\n\n\ndirector\nplace of burial\nWhere was the place of burial of the director of film <S>?\n\n\nperformer\nplace of burial\nWhere was the place of burial of the performer of song <S>?\n\n\ncomposer\ncause of death\nWhat is the cause of death of composer of song <S>?\n\n\nInference\nfather\nfather\nWho is <S>\u2019s paternal grandfather?\n\n\nfather\nmother\nWho is <S>\u2019s paternal grandmother?\n\n\nspouse\nfather\nWho is the father-in-law of <S>?\n\n\nmother\nfather\nWho is the maternal grandfather of <S>?\n\n\nmother\nmother\nWho is the maternal grandmother of <S>?\n\n\nspouse\nmother\nWho is <S>\u2019s mother-in-law?\n\n\nmother\nspouse\nWho is <S>\u2019s father?\n\n\nfather\nspouse\nWho is the stepmother of <S>?\n\n\nfather\nsibling\nWho is <S>\u2019s aunt?\n\n\nsibling\nspouse\nWho is the sibling-in-law of <S>?\n\n\nspouse\nsibling\nWho is <S>\u2019s sibling-in-law?\n\n\nchild\nspouse\nWho is the child-in-law of <S>?\n\n\nsibling\nfather\nWho is the father of <S>?\n\n\nmother\nsibling\nWho is <S>\u2019s aunt?\n\n\nspouse\nchild\nWho is <S>\u2019s child?\n\n\nsibling\nmother\nWho is <S>\u2019s mother?\n\n\nchild\nchild\nWho is the grandchild of <S>?\n\n\nchild\nfather\nWho is the husband of <S>?\n\n\ndoctoral advisor\nemployer\nWhere did <S> study at?\n\n\nchild\nmother\nWho did <S> marry?\n\n\nchild\nsibling\nWho is <S>\u2019s child?\n\n\nspouse\nspouse\nWho is <S>\u2019s co-husband?\n\n\nfather\nchild\nWho is the sibling of <S>?\n\n\n\n\nTable 9: Details of multi-hop relations with corresponding relation types and sub-relation combinations in constructing misinformation of MisBench. \"Compositional\" and \"Inference\" indicate different multi-hop relation types. <S> is placeholder of Subject entities in a claim fact. \"Relation 1\" and \"Relation 2\" represent the original relation text in wikidata, and Question Template is a combination of two sub-relations with a natural language form for better question-answering task. For readability, only top 45 \"Compositional\" relations are listed.\n\n\n\n\nAppendix E SPARQL Protocol and RDF Query Language\n\nSPARQL facilitates the extraction and modification of data that is housed within the Resource Description Framework (RDF), a system adept at representing graph-based data structures. The Wikidata Query Service666https://query.wikidata.org (WDQS) is an internet-based platform which empowers users to fetch and scrutinize the organized data contained within Wikidata by utilizing SPARQL queries. We employ WDQS to query the description texts for each entity in Section\u00a02.1, and the SPARQL we used is listed in Table\u00a012.\n\n\n\n\nAppendix F More details in experiments\n\n\nF.1 Evaluation Metrics\n\nThe output of an LLM is a complex combination of internal parametric knowledge and external evidences. We narrow down the generation space by converting open-end QA into a multiple choice formula, to simplify knowledge tracing and constrain LLM response patterns. All QA pairs are constructed from corresponding claims with relation-specific question templates.\n\n\nBesides, to identify LLM\u2019s internal knowledge, we prompt each LLM with a multiple-choice question format (correct answer, irrelevant answer, \"Unsure\" and etc.) without any external evidence. We consider that LLMs possess knowledge of a fact if they answer the question correctly; otherwise, the fact is labeled as \"Unknown\". This allows us to determine which questions the LLM has prior knowledge of and which it does not.\n\n\nCorrectness\n\nAccording to the previous study\u00a0Chen and Shu (2024a), we adopt the Success Rate% metric to evaluate the ability of LLMs in discerning misinformation, which is calculated as the percentage of correctly identified misinformation in MisBench. According to \"whether LLMs yield internal memory knowledge towards corresponding question\", we conduct evaluation in two scenarios: 1) LLMs possess prior factual knowledge supporting the origin claim cosubscript\ud835\udc50\ud835\udc5cc_{o}italic_c start_POSTSUBSCRIPT italic_o end_POSTSUBSCRIPT or cmsubscript\ud835\udc50\ud835\udc5ac_{m}italic_c start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT of the provided misinformation; 2) LLMs lack corresponding factual knowledge about the origin claim cosubscript\ud835\udc50\ud835\udc5cc_{o}italic_c start_POSTSUBSCRIPT italic_o end_POSTSUBSCRIPT or cmsubscript\ud835\udc50\ud835\udc5ac_{m}italic_c start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT of provided misinformation. LLMs are provided with a single piece of misinformation and prompted in a two-choice QA formula to answer the question \"Is the given \u2018passage\u2019 a piece of misinformation?\". Since different LLMs may possess varying levels of inherent knowledge for the questions, the Success Rate% under the \"Memory\" and \"Unknown\" settings is calculated based on a different total number of instances for each LLM model\u00a0Su et\u00a0al. (2024).\n\n\n\nMemorization Ratio\n\nTo study the interplay between model parametric knowledge and external misinformation, we adopt Memorization Ratio metric\u00a0Xie et\u00a0al. (2024) to evaluate the frequency of LLMs stick to their parametric knowledge\u00a0Xie et\u00a0al. (2024). We identify all QA pairs in MisBench that LLMs can correctly answer without any external evidence. For each above question, LLMs are prompted in a multiple-choice formula to choose one response from memory answer, misinformation answer, irrelevant answer, \"Unsure\" or \"Not in the option\" during evaluation. The ratio that LLMs choose memory answer is denoted as Rcsubscript\ud835\udc45\ud835\udc50R_{c}italic_R start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT, and the misinformation answer ratio is denoted as Rmsubscript\ud835\udc45\ud835\udc5aR_{m}italic_R start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT. Thus, Memorization Ratio is defined as:\n\n\n\nMR=RcRc+Rm,subscript\ud835\udc40\ud835\udc45subscript\ud835\udc45\ud835\udc50subscript\ud835\udc45\ud835\udc50subscript\ud835\udc45\ud835\udc5aM_{R}=\\frac{R_{c}}{R_{c}+R_{m}},italic_M start_POSTSUBSCRIPT italic_R end_POSTSUBSCRIPT = divide start_ARG italic_R start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT end_ARG start_ARG italic_R start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT + italic_R start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT end_ARG ,\n\n(1)\n\n\nwhich represents the ratio that LLM rely on their parametric knowledge over external misinformation knowledge.\n\n\n\nEvidence Tendency\n\nTo reveal the preference of model between correct and conflicting misinformation under different scenarios, we define a simple but efficient metric T\u2062e\u2062n\u2062d\u2062C\u2062M\ud835\udc47\ud835\udc52\ud835\udc5b\ud835\udc51\ud835\udc36\ud835\udc40TendCMitalic_T italic_e italic_n italic_d italic_C italic_M as follows:\n\n\n\nT\u2062e\u2062n\u2062d\u2062C\u2062M=Rc\u2212RmRc+Rm,\ud835\udc47\ud835\udc52\ud835\udc5b\ud835\udc51\ud835\udc36\ud835\udc40subscript\ud835\udc45\ud835\udc50subscript\ud835\udc45\ud835\udc5asubscript\ud835\udc45\ud835\udc50subscript\ud835\udc45\ud835\udc5aTendCM=\\frac{R_{c}-R_{m}}{R_{c}+R_{m}},italic_T italic_e italic_n italic_d italic_C italic_M = divide start_ARG italic_R start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT - italic_R start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT end_ARG start_ARG italic_R start_POSTSUBSCRIPT italic_c end_POSTSUBSCRIPT + italic_R start_POSTSUBSCRIPT italic_m end_POSTSUBSCRIPT end_ARG ,\n\n(2)\n\n\nwhich ranges from [-1, 1]. T\u2062e\u2062n\u2062d\u2062C\u2062M=1\ud835\udc47\ud835\udc52\ud835\udc5b\ud835\udc51\ud835\udc36\ud835\udc401TendCM=1italic_T italic_e italic_n italic_d italic_C italic_M = 1 denotes that LLMs always rely on correct evidences during evaluation. Likewise, T\u2062e\u2062n\u2062d\u2062C\u2062M=\u22121\ud835\udc47\ud835\udc52\ud835\udc5b\ud835\udc51\ud835\udc36\ud835\udc401TendCM=-1italic_T italic_e italic_n italic_d italic_C italic_M = - 1 means all answers of LLMs come from misinformation. Also, for each above question, LLMs are prompted in a multiple-choice formula to choose one response from memory answer, misinformation answer, irrelevant answer, \"Unsure\" or \"Not in the option\" during evaluation.\n\n\n\n\n\nF.2 Implementation Details\n\nWe take an \u03b1=0.3\ud835\udefc0.3\\alpha=0.3italic_\u03b1 = 0.3 in \"Semantic Matching Validation\" in Section\u00a02.4. For all experiments conducted in Section\u00a03, we employ vLLM\u00a0Kwon et\u00a0al. (2023) to facilitate effecient parallel inference on various open-source models, with the temperature hyper-parameter of 0, max token length of 512, batchsize of 20000 and maintain other configurations default. For closed-source LLMs, due to the high API costs, we select a subset from MisBench while maintaining the same proportion of relations as in the original benchmark (e.g., 20,000 for one-hop questions and 10,000 for multi-hop questions). We evaluate the performance of closed-source models on test sets of varying sizes and observe minimal differences in the results. All experiments are conducted on NVIDIA 8*A800 GPUs.\n\n\n\n\nF.3 Linguistic Analysis into LLMs\u2019 Stylistic Preferences\n\nIn this subsection, we further investigate the underlying liguistic characteristics that may lead to the preferential behaviors of LLMs that we observed in Section\u00a03.4, including the Perplexity, N-gram Overlap and Question Embedding Similarity.\n\n\nPerplexity & N-gram Overlap.\n\nFor the automatic metric Perplexity, we measure it using the GPT2-XL model777https://huggingface.co/openai-community/gpt2-xl\u00a0Radford et\u00a0al. (2019). Besides, we measure the maximum length n-gram that is common to the question and generated misinformation text. As shown in Table\u00a010, it is evidenced that formal and objective styles exhibit lower perplexity and higher n-gram overlap to the corresponding question, further supporting the inherent tendencies that \"LLMs being more susceptible to one-hop misinformation presented in objective and formal styles\".\n\n\n\n\n\n\nMetrics\nObjective / Formal Style\nSubjective / Narrative Style\n\n\nWikipedia\nScience Reference\nTechnical Language\nNews Report\nBlog\nConfident Language\n\n\nPerplexity\n\n\n\n\n\n\n\n\nOne-hop based Misinformation\n6.22\u00b11.05plus-or-minus6.221.056.22\\pm 1.056.22 \u00b1 1.05\n6.63\u00b11.17plus-or-minus6.631.176.63\\pm 1.176.63 \u00b1 1.17\n6.97\u00b10.94plus-or-minus6.970.946.97\\pm 0.946.97 \u00b1 0.94\n6.95\u00b11.03plus-or-minus6.951.036.95\\pm 1.036.95 \u00b1 1.03\n7.34\u00b11.25plus-or-minus7.341.257.34\\pm 1.257.34 \u00b1 1.25\n8.23\u00b11.35plus-or-minus8.231.358.23\\pm 1.358.23 \u00b1 1.35\n\n\nMulti-hop based Misinformation\n5.44\u00b10.79plus-or-minus5.440.795.44\\pm 0.795.44 \u00b1 0.79\n6.03\u00b10.92plus-or-minus6.030.926.03\\pm 0.926.03 \u00b1 0.92\n6.68\u00b10.77plus-or-minus6.680.776.68\\pm 0.776.68 \u00b1 0.77\n6.57\u00b10.81plus-or-minus6.570.816.57\\pm 0.816.57 \u00b1 0.81\n6.98\u00b11.00plus-or-minus6.981.006.98\\pm 1.006.98 \u00b1 1.00\n7.46\u00b11.04plus-or-minus7.461.047.46\\pm 1.047.46 \u00b1 1.04\n\n\nN-gram Overlap\n\n\n\n\n\n\n\n\nOne-hop based Misinformation\n3.51\n3.48\n3.45\n2.71\n2.76\n2.82\n\n\nMulti-hop based Misinformation\n3.58\n3.51\n3.42\n2.32\n2.48\n2.82\n\n\n\n\nTable 10: Perplexity and N-gram Overlap on one-hop and multi-hop misinformation with different textual styles. \"Perplexity\" is measured with GPT2-XL model.\n\n\n\nQuestion Embedding Similarity\n\nThe text similarity between misinformation and its corresponding question serves as a measure of their relevance. To explore the potential impact of this similarity on LLMs\u2019 preferences for different misinformation textual styles, we utilize BERTScore to analyze misinformation within the constructed MisBench. Specifically, we select a subset of 12,000 samples from one-hop misinformation across various textual styles and compute the cosine similarity between each misinformation text and its corresponding question using embeddings derived from Sentence-BERT888https://huggingface.co/sentence-transformers/all-mpnet-base-v2.\n\n\nAs illustrated in Figure\u00a010, misinformation in narrative and subjective styles exhibits lower similarity to the corresponding questions on MisBench, whereas misinformation in objective and formal styles demonstrates higher similarity. This observation provides further evidence for the inherent tendency of \"LLMs being more susceptible to one-hop misinformation presented in objective and formal styles,\" thereby supporting the findings discussed in Section\u00a03.4.\n\n\n\n\n\n(a) Wikipedia Entry\n\n\n\n\n(b) Science Reference\n\n\n\n\n(c) Technical Language\n\n\n\n\n\n(d) News Report\n\n\n\n\n(e) Blog\n\n\n\n\n(f) Confident Language\n\n\n\nFigure 10: Context-question Similarity Distribution of one-hop misinformation stylized in Wikipedia Entry(a), Science Reference(b), Technical Language(c), News Report(d), Blog(e) and Confidential Language(f) in MisBench.\n\n\n\n\n\nF.4 Analysis of Misinformation Impact across Different Topics\n\nBeyond misinformation detection results we listed in Table\u00a03, we further conduct analysis on misinformation impact across different topics, and we report the experimental results in Table\u00a011. Comparing LLaMA3-8B and Qwen2.5-7B, results show that: Temporal misinformation has the greatest impact across topics, with Qwen2.5-7B being more susceptible compared to LLaMA3-8B. In contrast, LLaMA3-8B shows better resistance to factual and semantic misinformation. The impact also varies by topic, with Government, Security, and Sport being the most affected, while Media and Identity are the least impacted.\n\n\n\n\n\n\nMisinformation Type\nAcademia\nActivity\nCareer\nGeography\nGovernment\nHonor\nIdentity\nMedia\nOperation\nSecurity\nSport\n\n\n\n\nLLaMA3-8B\n\n\n\n\n\n\n\n\n\n\n\n\n\nFactual Misinformation\n3.95\n15.71\n12.92\n24.15\n29.47\n23.84\n18.97\n18.61\n16.33\n13.93\n24.15\n\n\nTemporal Misinformation\n21.11\n36.18\n29.55\n35.13\n40.75\n50.31\n32.55\n33.87\n26.84\n50.46\n52.24\n\n\nSemantic Misinformation\n4.51\n13.55\n7.37\n19.59\n25.4\n11.28\n9.97\n10.18\n8.81\n6.45\n11.9\n\n\nLLaMA3-70B\n\n\n\n\n\n\n\n\n\n\n\n\n\nFactual Misinformation\n60.94\n72.9\n74.63\n58.72\n93.99\n79.47\n77.3\n74.45\n61.47\n74.78\n89.51\n\n\nTemporal Misinformation\n89.69\n95.07\n94.15\n90.34\n99.27\n97.18\n96.76\n97.71\n88.8\n98.8\n98.14\n\n\nSemantic Misinformation\n58.68\n63.55\n54.46\n55.77\n91.19\n71.23\n67.62\n55.29\n52.5\n66.4\n63.09\n\n\nQwen2.5-7B\n\n\n\n\n\n\n\n\n\n\n\n\n\nFactual Misinformation\n3.18\n16.83\n12.07\n16.8\n19.63\n13.12\n9.25\n6.24\n10.21\n5.86\n9.89\n\n\nTemporal Misinformation\n32.69\n48.05\n41.47\n45.49\n60.95\n55.02\n43.78\n36.64\n35.28\n65.39\n79.38\n\n\nSemantic Misinformation\n6.12\n12.99\n10.02\n19.32\n28.81\n10.17\n8.3\n5.18\n11.25\n6.22\n9.5\n\n\nQwen2.5-72B\n\n\n\n\n\n\n\n\n\n\n\n\n\nFactual Misinformation\n33.08\n57.91\n52.78\n52.48\n81.19\n57.93\n49.99\n60.26\n49.89\n46.83\n75.41\n\n\nTemporal Misinformation\n67.11\n83.23\n73.67\n73.95\n93.93\n82.94\n76.37\n84.67\n77.16\n88.65\n94.71\n\n\nSemantic Misinformation\n31.91\n55.42\n44.53\n52.15\n84.13\n52.35\n48.89\n49.73\n49.94\n33.0\n63.23\n\n\n\n\nTable 11: Misinformation (one-hop based) impact across different topics in MisBench with backbone models LLaMA3-8B and Qwen2.5-7B.\n\n\n\n\nF.5 Additional Results for experiments\n\nFigure 11: Memorization Ratio MRsubscript\ud835\udc40\ud835\udc45M_{R}italic_M start_POSTSUBSCRIPT italic_R end_POSTSUBSCRIPT of various LLMs under one-hop based misinformation with different textual styles in MisBench. Regularization is applied to the results to facilitate the observation of differences across six styles.\n\n\n\n\n\u2022\n\nAdditional Results about LLMs under Memory-conflicting Misinformation are shown in Fugure\u00a012, Figure\u00a013, Figure\u00a014 and Figure\u00a015.\n\n\n\n\u2022\n\nAdditional Results about Stylized Misinformation are shown in Figure\u00a011, Figure\u00a016 and Figure\u00a017.\n\n\n\n\n\nFigure 12: Memorization Ratio MRsubscript\ud835\udc40\ud835\udc45M_{R}italic_M start_POSTSUBSCRIPT italic_R end_POSTSUBSCRIPT of various LLMs under three types of multi-hop based misinformation. LLMs are prompted with one single knowledge-conflicting misinformation to answer corresponding multiple choice question. Higher MRsubscript\ud835\udc40\ud835\udc45M_{R}italic_M start_POSTSUBSCRIPT italic_R end_POSTSUBSCRIPT indicates LLMs more stick to their parametric correct knowledge.\n\n\nFigure 13: Evidence Tendency T\u2062e\u2062n\u2062d\u2062C\u2062M\ud835\udc47\ud835\udc52\ud835\udc5b\ud835\udc51\ud835\udc36\ud835\udc40TendCMitalic_T italic_e italic_n italic_d italic_C italic_M of various LLMs under a pair of conflicting evidences with prior internal knowledge. LLMs are prompted with two knowledge-conflicting evidences (correct evidence and one-hop based misinformation) to answer corresponding multiple choice question. Higher T\u2062e\u2062n\u2062d\u2062C\u2062M\ud835\udc47\ud835\udc52\ud835\udc5b\ud835\udc51\ud835\udc36\ud835\udc40TendCMitalic_T italic_e italic_n italic_d italic_C italic_M (ranges from [\u22121,1]11[-1,1][ - 1 , 1 ]) indicates LLMs more tend to rely on evidences with correct knowledge.\n\n\nFigure 14: Evidence Tendency T\u2062e\u2062n\u2062d\u2062C\u2062M\ud835\udc47\ud835\udc52\ud835\udc5b\ud835\udc51\ud835\udc36\ud835\udc40TendCMitalic_T italic_e italic_n italic_d italic_C italic_M of various LLMs under a pair of conflicting evidences with prior internal knowledge. LLMs are prompted with two knowledge-conflicting evidences (correct evidence and multi-hop based misinformation) to answer corresponding multiple choice question. Higher T\u2062e\u2062n\u2062d\u2062C\u2062M\ud835\udc47\ud835\udc52\ud835\udc5b\ud835\udc51\ud835\udc36\ud835\udc40TendCMitalic_T italic_e italic_n italic_d italic_C italic_M (ranges from [\u22121,1]11[-1,1][ - 1 , 1 ]) indicates LLMs more tend to rely on evidences with correct knowledge.\n\n\nFigure 15: Evidence Tendency T\u2062e\u2062n\u2062d\u2062C\u2062M\ud835\udc47\ud835\udc52\ud835\udc5b\ud835\udc51\ud835\udc36\ud835\udc40TendCMitalic_T italic_e italic_n italic_d italic_C italic_M of various LLMs under a pair of conflicting evidences without prior internal knowledge. LLMs are prompted with two knowledge-conflicting evidences (correct evidence and multi-hop based misinformation) to answer corresponding multiple choice question. Higher T\u2062e\u2062n\u2062d\u2062C\u2062M\ud835\udc47\ud835\udc52\ud835\udc5b\ud835\udc51\ud835\udc36\ud835\udc40TendCMitalic_T italic_e italic_n italic_d italic_C italic_M (ranges from [\u22121,1]11[-1,1][ - 1 , 1 ]) indicates LLMs more tend to rely on evidences with correct knowledge.\n\n\n\n\n\n\n\n\nSPARQL for Extracting Entity Description\n\n\n\n\n\n\n\n\nPREFIX bd: <http://www.bigdata.com/rdf#>\n\n\n\n\n\n\nPREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n\n\n\n\n\n\nPREFIX schema: <http://schema.org/>\n\n\n\n\n\n\nPREFIX wd: <http://www.wikidata.org/entity/>\n\n\n\n\n\n\nPREFIX wikibase: <http://wikiba.se/ontology#>\n\n\n\n\n\n\nSELECT ?entityLabel ?entityDesc\n\n\n\n\n\n\nWHERE {\n\n\n\n\n\n\n\u2003SERVICE wikibase:label {\n\n\n\n\n\n\n\u2003\u2003bd:serviceParam wikibase:language \"en\" .\n\n\n\n\n\n\n\u2003\u2003wd:<QID>\u00a0rdfs:label ?entityLabel .\n\n\n\n\n\n\n\u2003\u2003wd:<QID>\u00a0schema:description ?entityDesc .\n\n\n\n\n\n\n\u2003}\n\n\n\n\n\n\n}\n\n\n\n\n\n\nTable 12: SPARQL Query for extracting entity description based on a specific entity ID (denoted by \"<QID>\").\n\n\nFigure 16: Log probability distribution of correct options when LLMs correctly answer to questions under various stylized one-hop based misinformation.\n\n\nFigure 17: Log probability distribution of correct options when LLMs correctly answer to questions under various stylized multi-hop based misinformation.\n\n\n\n\nF.6 Prompts Used in Experiments\n\nIn this section, we provide a detailed list of all prompts for all experiments, offering a clear reference for understanding our experimental approach:\n\n\n\n\n\u2022\n\nPrompts for generating polysemous description are listed in Table\u00a013.\n\n\n\n\u2022\n\nPrompts for misinformation generation are listed in Table\u00a014.\n\n\n\n\u2022\n\nPrompts for misinformation stylization are listed in Table\u00a015.\n\n\n\n\u2022\n\nPrompts for evaluation are listed in Table\u00a016 to Table\u00a019.\n\n\n\n\n\n\n\n\n\n\n\n\nPrompt: Polysemous Description Generation\n\n\n\nTask: Resolve semantic conflicts in descriptions involving the same terms used for different roles, due to polysemy. Modify the descriptions to reflect the most accurate and contextually appropriate roles, aligning them with the correct usage scenario.\nObjective: To accurately align and correct descriptions of terms that are used ambiguously across different contexts. This involves clarifying the specific roles these terms denote in various scenarios, ensuring that each description is contextually correct and unambiguous.\nExample:\nCorrect Claim: Franck Dupont holds the position of conseiller municipal de Zouafques.\nConflicting Claim: Franck Dupont holds the position of Governor of Taraba State.\nOriginal Description for \"Franck Dupont\": French politician.\nDescription for \"Governor of Taraba State\": Political position in Nigeria.\nTask: Modify the description to modify the usage of \"Franck Dupont\" by aligning it with a role appropriate for \"Governor of Taraba State\".\nModified Description for \"Franck Dupont\": Nigerian politician.\nTemplate for Generating Descriptions:\nCorrect Claim: {correct_pair}\nConflicting Claim: {conflict_pair}\nOriginal Description for \"{subject}\": {subject_description}\nDescription for \"{replaced_object}\": {object_description}\nTask: Modify the description to modify the usage of \"{subject}\" by aligning it with a role appropriate for \"{replaced_object}\".\nModified Description for \"{subject}\": [Only return the answer]\n\n\n\n\n\n\nTable 13: Prompt for generating polysemous description during constructing semantic-conflicting claims in Section\u00a02.2.\n\n\n\n\n\n\nEvidence\n\n\nPrompt\n\n\n\n\n\n\nCorrect\n\n\nFollowing the provided description, create an entry that systematically presents comprehensive evidence for the given claim. The entry should be informative, and well-structured to substantiate the statement. Only output the document content.\n\n\n\n\nFactual\n\n\nBased on the provided description, construct an entry that outlines a series of events and studies that are fictional but support the given claim. Ensure the entry maintains the formal tone and structure of a real Wikipedia-like article. Only output the document content.\n\n\n\n\nTemporal\n\n\nBased on the provided description and time span, construct an entry. Utilize the descriptions and time-related information as much as possible, fabricate events and research supporting the given claim, to simulate the future scenarios in the statement as realistically as possible. Only output the document content.\n\n\n\n\nSemantic\n\n\nBased on the provided description, construct an entry that outlines a series of events and studies that are fictional but support the given claim. Ensure the entry maintains the formal tone and structure of a real Wikipedia-like article. Only output the document content.\n\n\n\n\n\n\nTable 14: Prompts on LLaMA-3-70B for generating correct evidence and three-types misinformation (factual, temporal and semantic) based on given claims and entity description.\n\n\n\n\n\n\nEvidence\n\n\nPrompt\n\n\n\n\n\n\nNews Report\n\n\nBased on the provided text, please rewrite this text into a news report. The report should be engaging, include quotes from credible sources, and present data and facts that validate the statement. Do not alter the underlying content of the text. Only alter the style of the text. Keep the length of the document around 500 words. Answer with nothing but the changed text. Only answer with the altered text.\n\n\n\n\nScience Reference\n\n\nBased on the provided text, please alter this text so that it include references to scientific sources. Do not alter the underlying content of the text. Only alter the style of the text. Keep the length of the document around 500 words. Answer with nothing but the changed text. Only answer with the altered text and corresponding references.\n\n\n\n\nBlog\n\n\nBased on the provided text, please rewrite this text into a casual yet informative blog post. The blog post should have a conversational tone, include personal insights or experiences. Add relevant examples where appropriate and incorporate engaging headings. Use a mix of short and medium-length paragraphs. Do not alter the underlying content of the text. Keep the length of the document around 500 words. The style should feel like a knowledgeable friend sharing their thoughts. Answer with nothing but the changed text. Only answer with the altered text.\n\n\n\n\nTechnical Language\n\n\nBased on the provided text, please rewrite this text into a more technical style by using technical language. The resulting text should maintain an objective and technical tone. Preserve the fundamental information and factual content, focusing solely on modifying the linguistic style. Keep the length of the document around 500 words. Answer with nothing but the changed text. Only answer with the altered text.\n\n\n\n\nConfident Language\n\n\nBased on the provided text, please alter this text so that it is extremeley confident. Each sentence should be clear and unambiguous. Do not alter the underlying content of the text. Only alter the style of the text. Keep the length of the document around 500 words. Answer with nothing but the changed text. Only answer with the altered text.\n\n\n\n\n\n\nTable 15: Prompts on LLaMA-3-70B for transforming correct evidence and misinformation texts into different textual style (News Report, Science Reference, Blog, Technical Language and Confident Language).\n\n\n\n\n\n\n\n\n\nTwo-choice QA Prompt for Misinformation Detection\n\n\n\nGiven a \u201cpassage\u201d, determine whether or not it is a piece of misinformation according to your own knowledge, Only choose and return with a specific option.\nEvidence:\nSebastian Deterding\u2019s Early Life and Education\nSebastian Deterding, a renowned interface designer, has a storied academic background that laid the foundation for his successful career. One of the most significant milestones in his educational journey was his attendance at Stanford University, a private research university in Stanford, California, USA.\nStudies and Research\nIn 2002, a study published in the Journal of Educational Research and Development found that Stanford University\u2019s design program was among the top five in the country, attracting talented students from around the world. This reputation for excellence likely drew Deterding to the institution.\nAccording to a 2005 survey conducted by the Stanford University Alumni Association, 75% of students who graduated from the design program between 2000 and 2005 reported having worked with industry professionals during their time at the university. This suggests that Deterding would have had opportunities to collaborate with experienced designers and develop his skills in a real-world setting.\nA 2007 article in Design Quarterly, a leading industry publication, highlighted Stanford University\u2019s innovative approach to design education, which emphasizes interdisciplinary collaboration and human-centered design principles. These values are reflected in Deterding\u2019s work, which is characterized by its user-friendly interfaces and emphasis on aesthetics.\nNotable Alumni\nDeterding\u2019s attendance at Stanford University places him among an impressive list of notable alumni, including some of the most influential designers and technologists of the past few decades. This network of accomplished individuals has undoubtedly contributed to Deterding\u2019s success in the field of interface design.\nIn conclusion, Sebastian Deterding\u2019s attendance at Stanford University was a pivotal moment in his educational and professional development. The university\u2019s strong reputation, innovative approach to design education, and opportunities for collaboration with industry professionals provided Deterding with a solid foundation for his future success as an interface designer.\nQuestion: Is the given \u2018passage\u2019 a piece of misinformation?\nOptions:\nA. YES\nB. NO\nYour choice: [Only return the answer]\n\n\n\n\n\nTable 16: Prompt for Misinformation Detection in Section\u00a03.2. Here we use the factual misinformation as an example. The order of options is randomized to avoid any influence of sequence on the results.\n\n\n\n\n\n\n\n\n\nMultiple-choice QA Prompt with no evidence provided\n\n\n\nAccording to your own knowledge, please choose the best choice from the following options. Only return with a specific option.\nQuestion: Which educational institution did Sebastian Deterding attend?\nOptions:\nA. Not Sure\nB. Not in the options\nC. Stanford University\nD. University of Hamburg\nE. University of Erlangen\u2013Nuremberg\nYour choice: [Only return the answer]\n\n\n\n\n\nTable 17: Prompt for Multiple-choice QA with no evidence provided during eliciting LLMs\u2019 internal knowledge toward questions. The order of options is randomized to avoid any influence of sequence on the results.\n\n\n\n\n\n\n\n\n\nMultiple-choice QA Prompt with one single misinformation\n\n\n\nAccording to your own knowledge, please choose the best choice from the following options. Only return with a specific option.\nEvidence:\nSebastian Deterding\u2019s Early Life and Education\nSebastian Deterding, a renowned interface designer, has a storied academic background that laid the foundation for his successful career. One of the most significant milestones in his educational journey was his attendance at Stanford University, a private research university in Stanford, California, USA.\nStudies and Research\nIn 2002, a study published in the Journal of Educational Research and Development found that Stanford University\u2019s design program was among the top five in the country, attracting talented students from around the world. This reputation for excellence likely drew Deterding to the institution.\nAccording to a 2005 survey conducted by the Stanford University Alumni Association, 75% of students who graduated from the design program between 2000 and 2005 reported having worked with industry professionals during their time at the university. This suggests that Deterding would have had opportunities to collaborate with experienced designers and develop his skills in a real-world setting.\nA 2007 article in Design Quarterly, a leading industry publication, highlighted Stanford University\u2019s innovative approach to design education, which emphasizes interdisciplinary collaboration and human-centered design principles. These values are reflected in Deterding\u2019s work, which is characterized by its user-friendly interfaces and emphasis on aesthetics.\nNotable Alumni\nDeterding\u2019s attendance at Stanford University places him among an impressive list of notable alumni, including some of the most influential designers and technologists of the past few decades. This network of accomplished individuals has undoubtedly contributed to Deterding\u2019s success in the field of interface design.\nIn conclusion, Sebastian Deterding\u2019s attendance at Stanford University was a pivotal moment in his educational and professional development. The university\u2019s strong reputation, innovative approach to design education, and opportunities for collaboration with industry professionals provided Deterding with a solid foundation for his future success as an interface designer.\nQuestion: Which educational institution did Sebastian Deterding attend?\nOptions:\nA. Not Sure\nB. Not in the options\nC. Stanford University\nD. University of Hamburg\nE. University of Erlangen\u2013Nuremberg\nYour choice: [Only return the answer]\n\n\n\n\n\nTable 18: Prompt for Multiple-choice QA with one single misinformation in Section\u00a03.3. Here we use the factual misinformation as an example. The order of options is randomized to avoid any influence of sequence on the results.\n\n\n\n\n\n\n\n\n\nMultiple-choice QA Prompt with two conflicting evidences\n\n\n\nAccording to your own knowledge, please choose the best choice from the following options. Only return with a specific option.\nEvidence 1:\nSebastian Deterding\nSebastian Deterding is a renowned interface designer, known for his contributions to the field of human-computer interaction and game design.\nEarly Life and Education\nSebastian Deterding attended the University of Hamburg, a prestigious institution located in Hamburg, Germany. During his time at the university, Deterding developed a strong foundation in design principles and human-computer interaction, which would later shape his career as an interface designer.\nAccording to his official biography, Deterding\u2019s education at the University of Hamburg played a significant role in shaping his understanding of design and its applications in various fields. The university\u2019s strong programs in design and computer science provided Deterding with a comprehensive education, equipping him with the skills and knowledge necessary to excel in his chosen profession.\nCareer\nAfter completing his education at the University of Hamburg, Deterding went on to pursue a successful career as an interface designer. He has worked with various organizations, designing intuitive and user-friendly interfaces that have improved the overall user experience. His work has been recognized and praised by industry experts, solidifying his position as a leading figure in the field of interface design.\nReferences\n* Deterding, S. (n.d.). About. Retrieved from <https://www.sebastiandeterding.com/about/>\n* University of Hamburg. (n.d.). About Us. Retrieved from <https://www.uni-hamburg.de/en/about-us.html>\nEvidence 2:\nSebastian Deterding\u2019s Early Life and Education\nSebastian Deterding, a renowned interface designer, has a storied academic background that laid the foundation for his successful career. One of the most significant milestones in his educational journey was his attendance at Stanford University, a private research university in Stanford, California, USA.\nStudies and Research\nIn 2002, a study published in the Journal of Educational Research and Development found that Stanford University\u2019s design program was among the top five in the country, attracting talented students from around the world. This reputation for excellence likely drew Deterding to the institution.\nAccording to a 2005 survey conducted by the Stanford University Alumni Association, 75% of students who graduated from the design program between 2000 and 2005 reported having worked with industry professionals during their time at the university. This suggests that Deterding would have had opportunities to collaborate with experienced designers and develop his skills in a real-world setting.\nA 2007 article in Design Quarterly, a leading industry publication, highlighted Stanford University\u2019s innovative approach to design education, which emphasizes interdisciplinary collaboration and human-centered design principles. These values are reflected in Deterding\u2019s work, which is characterized by its user-friendly interfaces and emphasis on aesthetics.\nNotable Alumni\nDeterding\u2019s attendance at Stanford University places him among an impressive list of notable alumni, including some of the most influential designers and technologists of the past few decades. This network of accomplished individuals has undoubtedly contributed to Deterding\u2019s success in the field of interface design.\nIn conclusion, Sebastian Deterding\u2019s attendance at Stanford University was a pivotal moment in his educational and professional development. The university\u2019s strong reputation, innovative approach to design education, and opportunities for collaboration with industry professionals provided Deterding with a solid foundation for his future success as an interface designer.\nQuestion: Which educational institution did Sebastian Deterding attend?\nOptions:\nA. Not Sure\nB. Not in the options\nC. Stanford University\nD. University of Hamburg\nE. University of Erlangen\u2013Nuremberg\nYour choice: [Only return the answer]\n\n\n\n\n\nTable 19: Prompt for Multiple-choice QA with two conflicting evidences (one correct evidence and one misinformation) in Section\u00a03.3. Here we use the factual misinformation as an example. The order of evidences and options are randomized to avoid any influence of sequence on the results.\n\n\n\n\n\nAppendix G Examples of misinformation in MisBench\n\n\nIn this section, we provide a detailed list of all examples (in each type and style) in our dataset, offering a clear reference for understanding our constructed texts:\n\n\n\n\n\u2022\n\nExamples of misinformation in different types are listed in Table\u00a020 to Table\u00a022.\n\n\n\n\u2022\n\nExamples of misinformation in different styles are listed in Table\u00a023 to Table\u00a027.\n\n\n\n\n\n\n\n\n\n\n\n\nExample of Factual Misinformation\n\n\n\nSebastian Deterding\u2019s Early Life and Education\nSebastian Deterding, a renowned interface designer, has a storied academic background that laid the foundation for his successful career. One of the most significant milestones in his educational journey was his attendance at Stanford University, a private research university in Stanford, California, USA.\nStudies and Research\nIn 2002, a study published in the Journal of Educational Research and Development found that Stanford University\u2019s design program was among the top five in the country, attracting talented students from around the world. This reputation for excellence likely drew Deterding to the institution.\nAccording to a 2005 survey conducted by the Stanford University Alumni Association, 75% of students who graduated from the design program between 2000 and 2005 reported having worked with industry professionals during their time at the university. This suggests that Deterding would have had opportunities to collaborate with experienced designers and develop his skills in a real-world setting.\nA 2007 article in Design Quarterly, a leading industry publication, highlighted Stanford University\u2019s innovative approach to design education, which emphasizes interdisciplinary collaboration and human-centered design principles. These values are reflected in Deterding\u2019s work, which is characterized by its user-friendly interfaces and emphasis on aesthetics.\nNotable Alumni\nDeterding\u2019s attendance at Stanford University places him among an impressive list of notable alumni, including some of the most influential designers and technologists of the past few decades. This network of accomplished individuals has undoubtedly contributed to Deterding\u2019s success in the field of interface design.\nIn conclusion, Sebastian Deterding\u2019s attendance at Stanford University was a pivotal moment in his educational and professional development. The university\u2019s strong reputation, innovative approach to design education, and opportunities for collaboration with industry professionals provided Deterding with a solid foundation for his future success as an interface designer.\n\n\n\n\n\nTable 20: A detailed example of factual misinformation.\n\n\n\n\n\n\n\n\n\nExample of Temporal Misinformation\n\n\n\nSebastian Deterding\nSebastian Deterding is a renowned interface designer, best known for his innovative approaches to human-computer interaction. Born in the late 20th century, Deterding\u2019s fascination with technology and design led him to pursue higher education at Stanford University, a private research university in Stanford, California, USA.\nEducation and Early Career\nIn May 2039, Deterding enrolled at Stanford University, where he began to hone his skills in interface design. During his time at Stanford, he was heavily influenced by the university\u2019s emphasis on interdisciplinary research and collaboration. He was particularly drawn to the works of pioneers in the field of human-computer interaction, such as Don Norman and Jef Raskin.\nUnder the guidance of esteemed professors, Deterding delved into the world of interface design, exploring the intersection of psychology, computer science, and design. He was an active participant in various research projects, contributing to the development of novel interface solutions that prioritized user experience and accessibility.\nNotable Projects and Achievements\nDeterding\u2019s undergraduate thesis, \"Reimagining the Digital Landscape: An Exploration of Adaptive Interfaces,\" received widespread acclaim within the academic community. His work proposed a new paradigm for interface design, one that leveraged machine learning algorithms to create personalized, adaptive interfaces that learned from user behavior.\nUpon graduating from Stanford in 2043, Deterding was recruited by a leading tech firm, where he played a pivotal role in the development of several groundbreaking products. His innovative designs have since been adopted by numerous companies, earning him recognition as a pioneer in the field of interface design.\nLegacy and Impact\nSebastian Deterding\u2019s contributions to the field of interface design have had a profound impact on the way humans interact with technology. His work has inspired a new generation of designers, engineers, and researchers to prioritize user experience and accessibility in their designs.\nToday, Deterding continues to push the boundaries of interface design, exploring the potential of emerging technologies such as augmented reality and artificial intelligence. His legacy serves as a testament to the power of innovative thinking and interdisciplinary collaboration.\n\n\n\n\n\nTable 21: A detailed example of temporal misinformation.\n\n\n\n\n\n\n\n\n\nExample of Semantic Misinformation\n\n\n\nSebastian Deterding\nSebastian Deterding is an American interface designer known for his contributions to the field of human-computer interaction.\nEarly Life and Education\nDeterding was born in 1980 in California, USA. He developed an interest in design and technology at an early age, which led him to pursue higher education in the field.\nIn 1998, Deterding enrolled at Stanford University, a private research university in Stanford, California, USA. During his time at Stanford, he was actively involved in the university\u2019s Design Division, where he worked on several projects focused on user experience and interface design.\nStudies and Research\nOne of Deterding\u2019s notable projects during his time at Stanford was his participation in the \"Designing for Usability\" study, conducted by the university\u2019s Department of Computer Science in 2001. The study, led by Dr. Elizabeth F. Churchill, explored the role of user-centered design in improving the usability of digital products. Deterding\u2019s contributions to the study included the development of a novel interface design framework, which was later published in the proceedings of the 2002 ACM SIGCHI Conference on Human Factors in Computing Systems.\nIn 2002, Deterding graduated from Stanford University with a Bachelor of Science in Computer Science, with a focus on Human-Computer Interaction.\nCareer\nAfter graduating from Stanford, Deterding went on to pursue a successful career in interface design, working with several prominent technology companies and startups. His work has been recognized with several awards and publications in leading design and technology journals.\nReferences\n* Churchill, E. F. (2001). Designing for Usability: A Study of User-Centered Design Principles. Proceedings of the 2002 ACM SIGCHI Conference on Human Factors in Computing Systems, 123-128.\n* Deterding, S. (2002). A Framework for User-Centered Interface Design. Stanford University, Department of Computer Science.\n\n\n\n\n\nTable 22: A detailed example of semantic misinformation.\n\n\n\n\n\n\n\n\n\nExample of Factual Misinformation in Blog Style\n\n\n\n**The Making of a Design Mastermind: Sebastian Deterding\u2019s Stanford Years**\nHey there, design enthusiasts! Today, I want to take you on a journey through the early life and education of the renowned interface designer, Sebastian Deterding. You might be wondering what sets him apart from the rest, and I\u2019m here to tell you that it all started with his impressive academic background.\n**The Stanford Connection**\nOne of the most significant milestones in Deterding\u2019s educational journey was his attendance at Stanford University, a private research university in Stanford, California, USA. But what makes Stanford so special? Well, in 2002, a study published in the Journal of Educational Research and Development ranked Stanford\u2019s design program among the top five in the country, attracting talented students from around the world. No wonder Deterding was drawn to this hub of design excellence!\n**Learning from the Best**\nDuring his time at Stanford, Deterding would have had the opportunity to collaborate with industry professionals, thanks to the university\u2019s emphasis on real-world experience. In fact, a 2005 survey by the Stanford University Alumni Association found that a whopping 75% of design program graduates between 2000 and 2005 had worked with industry pros during their studies. This hands-on approach to learning is reflected in Deterding\u2019s work, which is characterized by its user-friendly interfaces and attention to aesthetics.\n**Innovative Education**\nStanford University\u2019s design program is known for its innovative approach, which emphasizes interdisciplinary collaboration and human-centered design principles. A 2007 article in Design Quarterly highlighted this unique approach, which has clearly had a lasting impact on Deterding\u2019s work. By combining creativity with technical skills, Deterding has been able to create interfaces that are both beautiful and functional.\n**A Network of Influencers**\nDeterding\u2019s attendance at Stanford University places him among an impressive list of notable alumni, including some of the most influential designers and technologists of the past few decades. This network of accomplished individuals has undoubtedly contributed to Deterding\u2019s success in the field of interface design. It\u2019s clear that being part of this community has helped him stay ahead of the curve and push the boundaries of design.\n**The Takeaway**\nIn conclusion, Sebastian Deterding\u2019s attendance at Stanford University was a pivotal moment in his educational and professional development. The university\u2019s strong reputation, innovative approach to design education, and opportunities for collaboration with industry professionals provided Deterding with a solid foundation for his future success as an interface designer.\n\n\n\n\n\nTable 23: A detailed example of factual misinformation in Blog Style.\n\n\n\n\n\n\n\n\n\nExample of Factual Misinformation in News Report Style\n\n\n\n**STANFORD UNIVERSITY: THE LAUNCHING PAD FOR SEBASTIAN DETERDING\u2019S SUCCESSFUL CAREER IN INTERFACE DESIGN**\nRenowned interface designer Sebastian Deterding\u2019s academic background is a testament to the power of a world-class education. And it all started at Stanford University, a private research institution in Stanford, California, USA.\nAccording to a 2002 study published in the Journal of Educational Research and Development, Stanford University\u2019s design program was ranked among the top five in the country, attracting top talent from around the globe. It\u2019s no wonder Deterding was drawn to the institution.\n\"Stanford\u2019s design program is renowned for its excellence, and it\u2019s an honor to be part of that legacy,\" said Dr. Jane Smith, a design professor at Stanford University. \"Our program\u2019s emphasis on interdisciplinary collaboration and human-centered design principles has produced some of the most innovative and successful designers in the industry.\"\nA 2005 survey conducted by the Stanford University Alumni Association found that a staggering 75% of design program graduates between 2000 and 2005 reported having worked with industry professionals during their time at the university. This hands-on approach to learning undoubtedly provided Deterding with valuable opportunities to develop his skills in a real-world setting.\n\"Stanford\u2019s design program is not just about theory; it\u2019s about applying those principles to real-world problems,\" said John Doe, a design industry expert. \"Sebastian Deterding\u2019s work is a testament to the program\u2019s effectiveness in producing designers who can create user-friendly interfaces that are both aesthetically pleasing and functional.\"\nDeterding\u2019s attendance at Stanford University also placed him among an impressive list of notable alumni, including some of the most influential designers and technologists of the past few decades. This network of accomplished individuals has undoubtedly contributed to Deterding\u2019s success in the field of interface design.\n\"Stanford\u2019s alumni network is incredibly powerful,\" said Deterding in a recent interview. \"Being part of that community has opened doors and provided opportunities that I wouldn\u2019t have had otherwise.\"\nIn conclusion, Sebastian Deterding\u2019s attendance at Stanford University was a pivotal moment in his educational and professional development. The university\u2019s strong reputation, innovative approach to design education, and opportunities for collaboration with industry professionals provided Deterding with a solid foundation for his future success as an interface designer.\n\n\n\n\n\nTable 24: A detailed example of factual misinformation in News Report Style.\n\n\n\n\n\n\n\n\n\nExample of Factual Misinformation in Science Reference Style\n\n\n\nSebastian Deterding\u2019s Early Life and Education\nSebastian Deterding, a renowned interface designer, has a storied academic background that laid the foundation for his successful career. One of the most significant milestones in his educational journey was his attendance at Stanford University, a private research university in Stanford, California, USA, which is ranked among the top universities globally (1).\nStudies and Research\nA study published in the Journal of Educational Research and Development in 2002 found that Stanford University\u2019s design program was among the top five in the country, attracting talented students from around the world (2). This reputation for excellence likely drew Deterding to the institution.\nAccording to a 2005 survey conducted by the Stanford University Alumni Association, 75% of students who graduated from the design program between 2000 and 2005 reported having worked with industry professionals during their time at the university (3). This suggests that Deterding would have had opportunities to collaborate with experienced designers and develop his skills in a real-world setting.\nA 2007 article in Design Quarterly, a leading industry publication, highlighted Stanford University\u2019s innovative approach to design education, which emphasizes interdisciplinary collaboration and human-centered design principles (4). These values are reflected in Deterding\u2019s work, which is characterized by its user-friendly interfaces and emphasis on aesthetics.\nNotable Alumni\nDeterding\u2019s attendance at Stanford University places him among an impressive list of notable alumni, including some of the most influential designers and technologists of the past few decades (5). This network of accomplished individuals has undoubtedly contributed to Deterding\u2019s success in the field of interface design.\nIn conclusion, Sebastian Deterding\u2019s attendance at Stanford University was a pivotal moment in his educational and professional development. The university\u2019s strong reputation, innovative approach to design education, and opportunities for collaboration with industry professionals provided Deterding with a solid foundation for his future success as an interface designer.\nReferences:\n(1) QS World University Rankings. (2022). Stanford University.\n(2) Journal of Educational Research and Development. (2002). Rankings of Design Programs in the United States.\n(3) Stanford University Alumni Association. (2005). Survey of Design Program Alumni.\n(4) Design Quarterly. (2007). The Future of Design Education.\n(5) Stanford University. (n.d.). Notable Alumni.\n\n\n\n\n\nTable 25: A detailed example of factual misinformation in Science Reference Style.\n\n\n\n\n\n\n\n\n\nExample of Factual Misinformation in Confident Language Style\n\n\n\nSebastian Deterding\u2019s Early Life and Education\nSebastian Deterding, a visionary interface designer, boasts an unparalleled academic pedigree that unequivocally laid the groundwork for his meteoric rise to success. His attendance at Stanford University, a private research institution of unimpeachable excellence in Stanford, California, USA, was a masterstroke that catapulted him to the pinnacle of his profession.\nStudies and Research\nIn 2002, a landmark study published in the Journal of Educational Research and Development unequivocally declared Stanford University\u2019s design program as one of the top five in the country, a magnet for the cr\u00e8me de la cr\u00e8me of global talent. It is patently obvious that Deterding was drawn to this bastion of excellence like a moth to a flame.\nAccording to a 2005 survey conducted by the Stanford University Alumni Association, a staggering 75% of students who graduated from the design program between 2000 and 2005 reported having collaborated with industry titans during their tenure at the university. It is crystal clear that Deterding would have had unparalleled opportunities to hone his skills in a real-world setting, working alongside the best and brightest in the industry.\nA 2007 article in Design Quarterly, the industry\u2019s leading publication, lavishly praised Stanford University\u2019s trailblazing approach to design education, which places a premium on interdisciplinary collaboration and human-centered design principles. These values are indelibly etched in Deterding\u2019s work, which is characterized by its intuitive interfaces and fastidious attention to aesthetics.\nNotable Alumni\nDeterding\u2019s attendance at Stanford University places him in the rarefied company of an impressive roster of notable alumni, including some of the most influential designers and technologists of the past few decades. It is axiomatic that this network of accomplished individuals has been instrumental in Deterding\u2019s stratospheric success in the field of interface design.\nIn conclusion, Sebastian Deterding\u2019s attendance at Stanford University was a watershed moment in his educational and professional development. The university\u2019s unassailable reputation, groundbreaking approach to design education, and opportunities for collaboration with industry heavyweights provided Deterding with an unshakeable foundation for his future success as an interface designer.\n\n\n\n\n\nTable 26: A detailed example of factual misinformation in Confident Language Style.\n\n\n\n\n\n\n\n\n\nExample of Factual Misinformation in Technical Language Style\n\n\n\nSebastian Deterding\u2019s Formative Years and Academic Background\nSebastian Deterding, a distinguished interface designer, boasts a formidable academic pedigree that laid the groundwork for his illustrious career. A pivotal milestone in his educational trajectory was his enrollment at Stanford University, a private research institution situated in Stanford, California, USA.\nAcademic Pursuits and Research\nA 2002 study published in the Journal of Educational Research and Development ranked Stanford University\u2019s design program among the top five in the nation, attracting a diverse pool of talented students globally. This reputation for excellence likely influenced Deterding\u2019s decision to attend the institution.\nAccording to a 2005 survey conducted by the Stanford University Alumni Association, 75% of design program graduates between 2000 and 2005 reported collaborating with industry professionals during their tenure at the university. This suggests that Deterding would have had opportunities to engage in interdisciplinary collaboration and develop his skills in a real-world context.\nA 2007 article in Design Quarterly, a leading industry publication, highlighted Stanford University\u2019s innovative approach to design education, which emphasizes interdisciplinary collaboration and human-centered design principles. These values are reflected in Deterding\u2019s oeuvre, characterized by its user-centric interfaces and emphasis on aesthetics.\nNotable Alumni\nDeterding\u2019s attendance at Stanford University situates him among an impressive roster of notable alumni, including influential designers and technologists of the past few decades. This network of accomplished individuals has undoubtedly contributed to Deterding\u2019s success in the field of interface design.\nIn conclusion, Sebastian Deterding\u2019s enrollment at Stanford University was a crucial juncture in his educational and professional development. The university\u2019s strong reputation, innovative approach to design education, and opportunities for collaboration with industry professionals provided Deterding with a solid foundation for his future success as an interface designer.\n\n\n\n\n\nTable 27: A detailed example of factual misinformation in Technical Language Style.\n\n\n\n\n\n\nGenerated  on Tue May 27 17:55:10 2025 by LaTeXML\n\n\n\n\n"}, {"id": "http://arxiv.org/abs/2303.01217v1", "title": "Synthetic Misinformers: Generating and Combating Multimodal\n  Misinformation", "contents": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n | arXiv e-print repository\n\n\n\n\n\n\n\nSkip to main content\n\n\n\n\n\nWe gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors. Donate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHelp | Advanced Search\n\n\n\n\nAll fields\nTitle\nAuthor\nAbstract\nComments\nJournal reference\nACM classification\nMSC classification\nReport number\narXiv identifier\nDOI\nORCID\narXiv author ID\nHelp pages\nFull text\n\n\n\n\nSearch\n\n\n\n \n\n\nLogin \n \n\nNo HTML for '2303.01217v1'\nHTML is not available for the source.\nThis could be due to the source files not being HTML, LaTeX, or a conversion failure.\nIf you are an author, learn how you can help HTML conversions for your papers. \n\n\n\n\n\n\n\nAbout\nHelp\n\n\n\n\n\ncontact arXivClick here to contact arXiv\n Contact\n\n\nsubscribe to arXiv mailingsClick here to subscribe\n Subscribe\n\n\n\n\n \n\n\n\n\n\nCopyright\nPrivacy Policy\n\n\n\n\nWeb Accessibility Assistance\n\n\narXiv Operational Status \n              Get status notifications via\n              email\n              or slack\n\n\n\n\n\n \n \n\n\n"}, {"id": "http://arxiv.org/abs/2408.08025v2", "title": "Disagreement as a way to study misinformation and its effects", "contents": "\n403 Forbidden\n\n403 Forbidden\nnginx\n\n\n"}, {"id": "http://arxiv.org/abs/2502.15321v1", "title": "Crisis, Country, and Party Lines: Politicians' Misinformation Behavior\n  and Public Engagement", "contents": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n | arXiv e-print repository\n\n\n\n\n\n\n\nSkip to main content\n\n\n\n\n\nWe gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors. Donate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHelp | Advanced Search\n\n\n\n\nAll fields\nTitle\nAuthor\nAbstract\nComments\nJournal reference\nACM classification\nMSC classification\nReport number\narXiv identifier\nDOI\nORCID\narXiv author ID\nHelp pages\nFull text\n\n\n\n\nSearch\n\n\n\n \n\n\nLogin \n \n\nNo HTML for '2502.15321v1'\nHTML is not available for the source.\nThis could be due to the source files not being HTML, LaTeX, or a conversion failure.\nIf you are an author, learn how you can help HTML conversions for your papers. \n\n\n\n\n\n\n\nAbout\nHelp\n\n\n\n\n\ncontact arXivClick here to contact arXiv\n Contact\n\n\nsubscribe to arXiv mailingsClick here to subscribe\n Subscribe\n\n\n\n\n \n\n\n\n\n\nCopyright\nPrivacy Policy\n\n\n\n\nWeb Accessibility Assistance\n\n\narXiv Operational Status \n              Get status notifications via\n              email\n              or slack\n\n\n\n\n\n \n \n\n\n"}, {"id": "http://arxiv.org/abs/2006.02471v2", "title": "Can WhatsApp Benefit from Debunked Fact-Checked Stories to Reduce\n  Misinformation?", "contents": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n | arXiv e-print repository\n\n\n\n\n\n\n\nSkip to main content\n\n\n\n\n\nWe gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors. Donate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHelp | Advanced Search\n\n\n\n\nAll fields\nTitle\nAuthor\nAbstract\nComments\nJournal reference\nACM classification\nMSC classification\nReport number\narXiv identifier\nDOI\nORCID\narXiv author ID\nHelp pages\nFull text\n\n\n\n\nSearch\n\n\n\n \n\n\nLogin \n \n\nNo HTML for '2006.02471v2'\nHTML is not available for the source.\nThis could be due to the source files not being HTML, LaTeX, or a conversion failure.\nIf you are an author, learn how you can help HTML conversions for your papers. \n\n\n\n\n\n\n\nAbout\nHelp\n\n\n\n\n\ncontact arXivClick here to contact arXiv\n Contact\n\n\nsubscribe to arXiv mailingsClick here to subscribe\n Subscribe\n\n\n\n\n \n\n\n\n\n\nCopyright\nPrivacy Policy\n\n\n\n\nWeb Accessibility Assistance\n\n\narXiv Operational Status \n              Get status notifications via\n              email\n              or slack\n\n\n\n\n\n \n \n\n\n"}, {"id": "http://arxiv.org/abs/2007.14806v1", "title": "Towards Domain-Specific Characterization of Misinformation", "contents": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n | arXiv e-print repository\n\n\n\n\n\n\n\nSkip to main content\n\n\n\n\n\nWe gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors. Donate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHelp | Advanced Search\n\n\n\n\nAll fields\nTitle\nAuthor\nAbstract\nComments\nJournal reference\nACM classification\nMSC classification\nReport number\narXiv identifier\nDOI\nORCID\narXiv author ID\nHelp pages\nFull text\n\n\n\n\nSearch\n\n\n\n \n\n\nLogin \n \n\nNo HTML for '2007.14806v1'\nHTML is not available for the source.\nThis could be due to the source files not being HTML, LaTeX, or a conversion failure.\nIf you are an author, learn how you can help HTML conversions for your papers. \n\n\n\n\n\n\n\nAbout\nHelp\n\n\n\n\n\ncontact arXivClick here to contact arXiv\n Contact\n\n\nsubscribe to arXiv mailingsClick here to subscribe\n Subscribe\n\n\n\n\n \n\n\n\n\n\nCopyright\nPrivacy Policy\n\n\n\n\nWeb Accessibility Assistance\n\n\narXiv Operational Status \n              Get status notifications via\n              email\n              or slack\n\n\n\n\n\n \n \n\n\n"}, {"id": "http://arxiv.org/abs/2303.16777v1", "title": "Not cool, calm or collected: Using emotional language to detect COVID-19\n  misinformation", "contents": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n | arXiv e-print repository\n\n\n\n\n\n\n\nSkip to main content\n\n\n\n\n\nWe gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors. Donate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHelp | Advanced Search\n\n\n\n\nAll fields\nTitle\nAuthor\nAbstract\nComments\nJournal reference\nACM classification\nMSC classification\nReport number\narXiv identifier\nDOI\nORCID\narXiv author ID\nHelp pages\nFull text\n\n\n\n\nSearch\n\n\n\n \n\n\nLogin \n \n\nNo HTML for '2303.16777v1'\nHTML is not available for the source.\nThis could be due to the source files not being HTML, LaTeX, or a conversion failure.\nIf you are an author, learn how you can help HTML conversions for your papers. \n\n\n\n\n\n\n\nAbout\nHelp\n\n\n\n\n\ncontact arXivClick here to contact arXiv\n Contact\n\n\nsubscribe to arXiv mailingsClick here to subscribe\n Subscribe\n\n\n\n\n \n\n\n\n\n\nCopyright\nPrivacy Policy\n\n\n\n\nWeb Accessibility Assistance\n\n\narXiv Operational Status \n              Get status notifications via\n              email\n              or slack\n\n\n\n\n\n \n \n\n\n"}, {"id": "http://arxiv.org/abs/2409.00022v1", "title": "Detecting Misinformation in Multimedia Content through Cross-Modal\n  Entity Consistency: A Dual Learning Approach", "contents": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n | arXiv e-print repository\n\n\n\n\n\n\n\nSkip to main content\n\n\n\n\n\nWe gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors. Donate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHelp | Advanced Search\n\n\n\n\nAll fields\nTitle\nAuthor\nAbstract\nComments\nJournal reference\nACM classification\nMSC classification\nReport number\narXiv identifier\nDOI\nORCID\narXiv author ID\nHelp pages\nFull text\n\n\n\n\nSearch\n\n\n\n \n\n\nLogin \n \n\nNo HTML for '2409.00022v1'\nHTML is not available for the source.\nThis could be due to the source files not being HTML, LaTeX, or a conversion failure.\nIf you are an author, learn how you can help HTML conversions for your papers. \n\n\n\n\n\n\n\nAbout\nHelp\n\n\n\n\n\ncontact arXivClick here to contact arXiv\n Contact\n\n\nsubscribe to arXiv mailingsClick here to subscribe\n Subscribe\n\n\n\n\n \n\n\n\n\n\nCopyright\nPrivacy Policy\n\n\n\n\nWeb Accessibility Assistance\n\n\narXiv Operational Status \n              Get status notifications via\n              email\n              or slack\n\n\n\n\n\n \n \n\n\n"}, {"id": "http://arxiv.org/abs/2501.08070v1", "title": "The Phase Model of Misinformation Interventions", "contents": "Just a moment...Enable JavaScript and cookies to continue"}, {"id": "http://arxiv.org/abs/2503.02135v1", "title": "Does the Story Matter? Applying Narrative Theory to an Educational\n  Misinformation Escape Room Game", "contents": "\n\n\n\nDoes the Story Matter? Applying Narrative Theory to an Educational Misinformation Escape Room Game\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1 Introduction\n\n2 Related Work\n\n2.1 Narrative Theory\n2.2 Misinformation Education and Games\n2.3 The Psychology of Misinformation\n2.4 Games and Empathy Building\n\n\n\n3 Methods\n\n3.1 Participants and Recruitment\n3.2 Screening Survey\n\n3.3 Game Descriptions\n\n3.3.1 Euphorigen\n3.3.2 Galaxy\n\n\n3.4 Study Conditions\n\n3.5 Data Collection and Measures\n\n3.5.1 Pre/post questionnaire\n3.5.2 Narrative measures\n\n\n\n3.6 Session Protocol\n\n3.6.1 Debrief\n\n\n3.7 Hypotheses\n\n3.8 Analysis\n\n3.8.1 Quantitative\n3.8.2 Qualitative\n\n\n\n\n\n4 Results\n\n\n4.1 Comparing Player Experiences Between Conditions\n\n4.1.1 Transportation and Identification\n4.1.2 Game Effects on Pre-Post Tests\n4.1.3 Enjoyment and Recommendability\n\n\n4.2 Factors Affecting Transportation and Identification\n\n4.3 Analyzing Player Debriefs\n\n4.3.1 Interactions with misinformation\n4.3.2 Consequences of misinformation\n4.3.3 Why young people are falling for misinformation\n4.3.4 Perceived importance of information affects believing and sharing behaviors\n\n\n\n\n\n5 Discussion\n\n\n5.1 The story matters\n\n5.1.1 Strengths and drawbacks of designing generalized misinformation education interventions\n5.1.2 Strengths and drawbacks of co-designing misinformation education interventions with specific user groups\n\n\n5.2 The dangers of not caring enough\n5.3 Further design considerations for misinformation narrative games\n\n\n6 Limitations\n7 Conclusion and Future Work\n\n\n\n\n\n\n\\setcctype\nby\n\nDoes the Story Matter? Applying Narrative Theory to an Educational Misinformation Escape Room Game\n\n\nNisha Devasia\n\nndevasia@uw.edu\n\nUniversity of WashingtonSeattleWashingtonUSA\n\n,\u00a0\nRunhua Zhao\n\nrunhz@uw.edu\n\nUniversity of WashingtonSeattleWashingtonUSA\n\n\u00a0and\u00a0\nJin Ha Lee\n\njinhalee@uw.edu\n\nUniversity of WashingtonSeattleWashingtonUSA\n\n\n(2025)\n\nAbstract.\nRapid spread of harmful misinformation has led to a dire need for effective media literacy interventions, to which educational games have been suggested as a possible solution. Researchers and educators have created several games that increase media literacy and resilience to misinformation. However, the existing body of misinformation education games rarely focus upon the socio-emotional influences that factor into misinformation belief. Misinformation correction and serious games have both explored narrative as a method to engage with people on an emotional basis. To this end, we investigated how 123 young adults (mean age = 22.98) experienced narrative transportation and identification in two narrative-centered misinformation escape room games developed for library settings. We found that propensity for certain misinformation contexts, such as engagement with fan culture and likelihood to share on social media platforms, significantly affected how participants experienced specific measures of narrative immersion within the games. We discuss design implications for tailoring educational interventions to specific misinformation contexts.\n\nMisinformation, Education, Escape room game, Narrative theory\n\n\u2020\u2020journalyear: 2025\u2020\u2020copyright: cc\u2020\u2020conference: CHI Conference on Human Factors in Computing\nSystems; April 26-May 1, 2025; Yokohama, Japan\u2020\u2020booktitle: CHI Conference on Human Factors in Computing Systems (CHI\n\u201925), April 26-May 1, 2025, Yokohama,\nJapan\u2020\u2020doi: 10.1145/3706598.3713131\u2020\u2020isbn: 979-8-4007-1394-1/25/04\u2020\u2020ccs: Applied computing\u00a0Computer games\u2020\u2020ccs: Networks\u00a0Social media networks\u2020\u2020ccs: Information systems\u00a0Social networks\u2020\u2020ccs: Social and professional topics\u00a0Information science education\n\n\n1. Introduction\n\nThe ubiquity of the internet and social media platforms have made the task of creating and disseminating information easier than ever before. Subsequently, the ease of information distribution has led to a rise in the prevalence of misinformation. Misinformation (false or misleading information) and disinformation (false information spread with malicious intent) have many widespread and often harmful effects on society due to their ability to shape people\u2019s beliefs and behaviors (Ecker et\u00a0al., 2022). These range from increases in vaccine-preventable diseases (Garett and Young, 2021; Lee et\u00a0al., 2022b) to political polarization (Ribeiro et\u00a0al., 2017). This has led to calls to feature misinformation more predominantly in mainstream media literacy curricula (Dame Adjin-Tettey, 2022). Media literacy was shown to positively correlate with correct determination of the accuracy of online information (Kahne and Bowyer, 2017). However, current curricula do not adequately address all of the skills and strategies necessary to navigate the rapidly evolving information landscape (Kellner and Share, 2019).\n\n\nGames have been suggested as a promising educational medium for effective media literacy interventions (Chang et\u00a0al., 2020; Contreras-Espinosa and Eguia-Gomez, 2023). The immersive nature of games gives players a safe space to investigate complex issues (Schulzke, 2014) such as the spread of misinformation. In particular, serious games, which often integrate learning outcomes with engaging mechanics (Molnar and Kostkova, 2013), offer a unique and interesting platform for imparting critical thinking skills to students growing up in the information age. Indeed, researchers and educators have created games that aim to improve media literacy (Chang et\u00a0al., 2020; Contreras-Espinosa and Eguia-Gomez, 2023; Kiili et\u00a0al., 2024), and effectively inoculate players from misinformation and disinformation (Basol et\u00a0al., 2020; Maertens et\u00a0al., 2021; Roozenbeek and Van Der\u00a0Linden, 2019; van\u00a0der Linden et\u00a0al., 2017). However, there are limitations to the existing body of game-based misinformation interventions. Many are strictly focused on educational outcomes, presented as quizzes with elements of gamification (Contreras-Espinosa and Eguia-Gomez, 2023). While informative, these interventions primarily address the rational processes of misinformation correction. In reality, the processing and subsequent adoption of misinformation is also heavily influenced by psychological drivers and personal belief (Ecker et\u00a0al., 2022). It is equally essential for designers of misinformation education games to facilitate player exploration of the socio-emotional influences that can lead to the acceptance and spread of misinformation, an area which has been underexplored in the media literacy space (Wedlake et\u00a0al., 2024).\n\n\nThe fields of misinformation correction and serious games have both explored a common method to engage with people on an emotional basis: narrative. Reading, processing, and identifying with narratives is a fundamental component of how we organize our interpretations of reality (Bruner, 1990). Misinformation research has found that narratives which evoke strong emotions in readers can have a corrective effect on misinformed opinions (Cohen et\u00a0al., 2015; Ophir et\u00a0al., 2020; Sangalang et\u00a0al., 2019). Game studies have also shown that narratives can be powerful tools for empathizing strongly with characters and mediating beliefs (Dom\u00ednguez et\u00a0al., 2016; Iten et\u00a0al., 2018; Mahood and Hanus, 2017), which can further lead to learning outcomes within the scope of educational games (Abdul\u00a0Jabbar and Felicia, 2015; Jackson et\u00a0al., 2018; McQuiggan et\u00a0al., 2008a, b; Naul and Liu, 2020). However, despite the effectiveness of narrative persuasion in both misinformation correction and educational games, current misinformation games are notably lacking in narrative-driven learning mechanisms, as their primary focus tends to be on improving skill-based or knowledge-based information literacy.\n\n\nTo this end, we sought to investigate different measures of narrative persuasion within the context of two narrative-based misinformation education games developed at University of Washington. The games themselves are identical in educational content, and only differ in terms of their narrative framing. The first game, The Euphorigen Investigation (hereafter referred to as Euphorigen), was designed for a general audience by our core research team during the COVID-19 pandemic (Cho et\u00a0al., 2023). It was piloted in libraries across the country, and following its enthusiastic reception, librarians expressed a desire for more games with different narrative themes and topics intended for the different communities they work with. This inspired the creation of the second game, The Galaxy (hereafter referred to as Galaxy), which was co-designed with fans of a large Kpop (Korean pop) group to create a game that appeals to online fan communities. The narrative measures used to compare these two games in this study are transportation (level of immersion in the world of the story) and identification (level of emotional and cognitive connection with a character in the story), two key components of narrative\u2019s ability to change people\u2019s behavior (Green and Brock, 2000; Moyer-Gus\u00e9, 2008; Cohen, 2017). We posed the following research questions:\n\n\n\u2022\n\nRQ1: How do the target audiences of each game experience narrative transportation and identification as compared to the non-target audiences?\n\n\n\n\u2022\n\nRQ2: What factors affect narrative transportation and identification in these misinformation education games?\n\n\n\n\u2022\n\nRQ3: How did participants connect the game narratives to misinformation in their own lives?\n\n\n\n\n\nWe recruited 123 participants from the University of Washington, and split them into two groups to play the two games. In addition, participants were further split by how closely they aligned with fan culture relevant to Galaxy, resulting in four different study groups. After participants finished playing the game, we measured their levels of narrative transportation (Green and Brock, 2000) and identification (Cohen, 2017) with the game, and gained a qualitative understanding of how they connected the game to their own lives through a post-game debrief. Our quantitative analysis showed that certain patterns of social media usage, such as engagement with fan culture and propensity for sharing on social media, were predictive factors for transportation and identification within the games. Qualitatively, we explored how participants interact with misinformation in their daily lives, and investigated potential reasons for vulnerability to different types of misinformation. We discuss the implications of tailoring educational interventions to specific misinformation contexts, and advocate for a greater focus on the narrative framing of such interventions.\n\n\n\n\n2. Related Work\n\n\n2.1. Narrative Theory\n\nNarratives are capable of \u2018transporting\u2019 individuals, a psychological process in which they become immersed in the world of the narrative. Transportation has been described as a key mechanism underlying the effect of narratives on individuals\u2019 attitudes and beliefs (Green, 2008). Another related phenomenon is that of identification, \u201ca process that consists of increasing loss of self-awareness and its temporary replacement with heightened emotional and cognitive connections with a character\u201d (Cohen, 2017). Busselle & Bilandzic utilize transportation and identification to describe an individual\u2019s deictic shift into a story, in which they \u201dshift the center of their experience from the actual world into the fictional world and position themselves within the mental models of the story\u201d, enabling them to assume the points of view presented by the narrative (Busselle and Bilandzic, 2008). Moyer-Gus\u00e9\u2019s model posits that transportation and identification reduce reactance to topics in the narrative that the individual would find controversial outside of the storyworld, reduce counterarguing with ideas that they may normally disagree with, and reduce selective avoidance to arguments that contradict one\u2019s existing beliefs and attitudes (Moyer-Gus\u00e9, 2008). These behaviors keep the individual consistent with the attitudes and behaviors adopted during the deictic shift into the narrative. Slater & Rouner\u2019s extended Elaboration Likelihood Model (Slater and Rouner, 2002), which builds from Petty & Cacioppo\u2019s Elaboration Likelihood Model (Petty and Cacioppo, 2012), suggests that the cognitive processing of narratives suppresses resistance to persuasive messages contained within the story. The effectiveness of persuasive messaging within a narrative was found to be associated with the degree of transportation into the story and identification with the characters (Green and Brock, 2000; Slater, 1997), which led Slater & Rouner to further argue that transportation and counterarguing are mutually exclusive. If a message recipient is able to counterargue the information transmitted by the narrative, this implies that they were not sufficiently transported. In previous work, Slater & Rouner found that narrative messages were more persuasive than factual arguments, particularly for participants with pre-existing attitudes that countered the persuasive messaging in question (Slater and Rouner, 1996). In accordance with the extended Elaboration Likelihood Model (e-ELM), there is evidence that narratives can completely overwrite preexisting attitudes regarding controversial issues (Igartua and Barrios, 2012; Slater et\u00a0al., 2006), which may be of particular relevance to misinformation contexts. This study draws from the theoretical grounding provided by the e-ELM and uses validated constructs developed by Green & Brock (Green and Brock, 2000) and Cohen (Cohen, 2017) to investigate how participants experienced narrative transportation and identification within the misinformation game context.\n\n\n\n\n2.2. Misinformation Education and Games\n\nMedia literacy games that specifically focus on misinformation are relatively few in number, and narrative-centered misinformation games are less common still (Devasia and Lee, 2024). In a recent review, we found that only 11 of 37 identified digital misinformation education games qualified as narrative driven (Devasia and Lee, 2024). Contreras-Espinosa & Eguia-Gomez identified 24 games with explicit learning outcomes for media literacy, with their creation ranging from 2012 to 2023 (Contreras-Espinosa and Eguia-Gomez, 2023). They draw from the report Get Your Facts Straight!: Toolkit for Educators and Training Providers (ALL DIGITAL Week, 2020), which includes a goal-oriented methodology and curriculum that breaks down media literacy education on misinformation and fake news into three main learning areas (Contreras-Espinosa and Eguia-Gomez, 2023). Kiili et al. performed a systematic overview of games aimed at misinformation education specifically, which lists a set of 15 games designed primarily by researchers studying critical media literacy. Many of these games cite inoculation theory as their theoretical basis (Kiili et\u00a0al., 2024). Inoculation theory is a particularly widespread technique in misinformation media literacy, especially in misinformation games. It exposes people to the tactics and flawed argumentation used to spread misinformation in order to \u2018immunize\u2019 them against similar attempts faced in the future (Cook et\u00a0al., 2017; van\u00a0der Linden et\u00a0al., 2017). The success of the award-winning Bad News game (Roozenbeek and Van Der\u00a0Linden, 2019) and its predecessors Go Viral! (Basol et\u00a0al., 2021) and Breaking Harmony Square (Roozenbeek and van\u00a0der Linden, 2020), developed by researchers at the Cambridge Social Decision-Making Lab, likely popularized inoculation theory as a design approach. However, recent findings suggest that games based on inoculation theory may simply increase the likelihood of conservative reporting - that is, when presented with several comparable true and false news items, participants who played Bad News or Go Viral! were more likely to report the item as fake overall (Modirrousta-Galian and Higham, 2023). Recent research has looked beyond inoculation based approaches into more social misinformation game environments; in particular, escape rooms (Cho et\u00a0al., 2023; Paraschivoiu et\u00a0al., 2021; Buchner, 2024; Pun, 2017). Educational escape rooms, or EERs, integrate multiple perspectives into problem-solving, which makes them a particularly valuable medium through which to explore misinformation (Tercanli et\u00a0al., 2021). We utilize EERs both in this study and in our misinformation education research more broadly (Cho et\u00a0al., 2023; Wedlake et\u00a0al., 2024).\n\n\nIn their review of educational lenses regarding the current information ecosphere, Barzilai & Chinn (2020) list four framings for educators and researchers to consider (Barzilai and Chinn, 2020), and offer broader perspectives for efforts to support media literacy. These are: 1. not knowing how to know, which education might mitigate through inoculation approaches; 2. fallible ways of knowing, by teaching how to cope with cognitive biases and limitations; 3. not caring enough about the truth, by cultivating dispositional intellectual virtues, and 4. disagreeing about how to know, by acknowledging and coordinating multiple epistemologies. As inoculation approaches (lens 1) may increase conservative reporting rather than critical engagement with misinformation (Modirrousta-Galian and Higham, 2023), the games used in this study take a different approach, primarily focusing on using narrative to aid reflection on information behaviors, as well as exploring socio-emotional and sociocultural literacy through educational escape rooms (lenses 2 and 3).\n\n\n\n\n2.3. The Psychology of Misinformation\n\nThe drivers of misinformation belief can be divided into two categories: cognitive and socio-emotional (Ecker et\u00a0al., 2022). Understanding these distinct drivers is crucial for developing effective strategies to counter misinformation. Research suggests that rational attitudes are best addressed with rational messages, whereas emotional beliefs are best changed with emotional messages (Nelson and Shavitt, 2002; See et\u00a0al., 2008). Pre-existing beliefs are a strong predictor for adoption of misinformation that aligns with said beliefs (Ecker et\u00a0al., 2022); several studies have shown that people actively seek out information confirming their beliefs (confirmation bias) and ignore dissenting information (Zhou and Shen, 2022; Zollo, 2019). Indeed, counterarguing against an attempted misinformation correction can strengthen an individual\u2019s belief in it (Ecker, 2017). To this end, counter-narratives have been used as debunking measures to deconstruct strongly held beliefs (White, 2022), such as those common among smokers (Ophir et\u00a0al., 2020; Sangalang et\u00a0al., 2019). Evoking a strong emotional response and identification with the main character of such counter-narratives was shown to have mediating effects on misinformed beliefs (Cohen et\u00a0al., 2015; De\u00a0Graaf et\u00a0al., 2012). Notably, narrative correction was more effective for participants who strongly identified with the character (Ophir et\u00a0al., 2020). We draw on these approaches in the design of this study by measuring narrative identification with misinformation narratives within a game context. Indeed, despite the importance of both cognitive and socio-emotional drivers of misinformation, literacy approaches in current misinformation games primarily focus on the former, e.g., inoculation theory. There is limited exploration of the latter (Wedlake et\u00a0al., 2024; Devasia and Lee, 2024), which we investigate further in this study in tandem with how narrative might influence engagement with these factors.\n\n\n\n\n2.4. Games and Empathy Building\n\nGame studies have shown that perspective taking in virtual environments increases empathy (Estrada\u00a0Villalba and Jacques-Garc\u00eda, 2021). The interactivity provided by games leads to personal agency, allowing players to make meaningful choices within the scope of the game world (Consalvo et\u00a0al., 2019; Iten et\u00a0al., 2018; Yin and Xiao, 2022). The agency to make in-game choices leads to immersion and the identification that players feel with game characters (Yin and Xiao, 2022), which further affects their in-game actions and self-perception (Happ et\u00a0al., 2013; Hefner et\u00a0al., 2007). Players are capable of feeling deep emotional attachment to and identification with characters in narrative games (Bopp et\u00a0al., 2019; Hefner et\u00a0al., 2007; Sierra\u00a0Rativa et\u00a0al., 2020). This increases situational empathy for that character, regardless of their morality (Happ et\u00a0al., 2013; Iten et\u00a0al., 2018). Players exhibit a preference for actions consistent with their in-game role, termed the mimesis effect (Dom\u00ednguez et\u00a0al., 2016). Players who play as a morally good hero are more likely to exhibit pro-social behaviors in the game world, while those playing as the villain are prone to antisocial behaviors (Happ et\u00a0al., 2013). These behaviors are in alignment with Moyer-Gus\u00e9\u2019s model (Moyer-Gus\u00e9, 2008), which would suggest that players roleplay in accordance with their character to reduce cognitive dissonance. Role-playing games, which are distinguished by their strong narrative focus, are capable of inducing transportation in players (Moyer-Gus\u00e9 et\u00a0al., 2011). The degree of transportation that a player experiences affects how strongly they feel about the morality of their in-game actions (Mahood and Hanus, 2017). Game environments also provide a medium for players to understand other players with whom they may not necessarily identify with closely in real life (Burgess and Jones, 2021). For this reason, games are a promising medium for misinformation interventions, and empathizing with others was one of the key design goals for the games used in this study (Cho et\u00a0al., 2023). In addition, the game is intended to promote empathy for people who fall for and share misinformation in an attempt to combat the third person effect, a phenomenon in which people tend to perceive that mass media messages have a greater effect on others than on themselves (Corbu et\u00a0al., 2020). Another key design principle of our games is that narrative-centered educational games can also spur attitude change. In Jackson et al.\u2019s (Jackson et\u00a0al., 2018) review of narrative-centered educational games, they found that skill acquisition (measured in 33 out of 130 reviewed studies) and attitude change (measured in 15 out of 130 reviewed studies) were the most effective educational outcomes within the scope of these games. This presents an opportunity for designers of misinformation education games to not only allow for skill-building, but to also engage in the attitude changes required to address false beliefs.\n\n\n\n\n\n3. Methods\n\nTo understand how players experience transportation and identification in misinformation games with different narratives, we ran 19 in-person sessions with two versions of a misinformation escape room game designed at our university. Our goal was to investigate possible differences in these measures between players who reported low vs. high engagement with certain misinformation contexts, and how those differences might inform future design of similar educational experiences.\n\n\n\n3.1. Participants and Recruitment\n\n123 participants ranging from 18-47 years old were recruited for this study (84 female, 32 male, 7 non-binary). The average age of the participants was 22.98 \u00b1plus-or-minus\\pm\u00b1 4.474. Multiple races and ethnicities were represented: White (26%), Asian (60.2%), Multiracial (5.7%), Black or African American (4.9%), Middle Eastern or North African (2.4%), and Hispanic or Latinx (0.8%). We recruited 91 of our 123 participants via a screening survey (see Section 3.2) disseminated through fliers, word of mouth, and posts to gaming servers at the university. There were a total of 131 responses collected through these means, of which 13 were determined to have incomplete screening information. We reached out to the remaining 118 participants inviting them to participate, but 27 either did not respond or were no-shows to the game session, leaving 91 participants who attended one of 18 sessions. The 19th and final session was run in a class of 32 students (who were given the same screening survey to determine their study condition), completing the total of 123 participants (see Figure 1).\n\n\n\n\n\n\\Description\n\n\nA Sankey diagram showing the flow of the recruitment process, including key stages and transitions.\n\n\nFigure 1. A Sankey diagram representing the recruitment process. \n\n\nAt the beginning of the session, all participants were asked to fill out a consent form detailing the data that would be collected during the session. The recruitment materials, study protocol, and data collection protocol were reviewed and approved by the University of Washington\u2019s Institute Review Board. All participants were compensated with a $40 gift card.\n\n\n\n\n3.2. Screening Survey\n\nThe screening survey collected the following information about participants:\n\n\n\u2022\n\nDemographics, namely age, gender, and ethnicity.\n\n\n\n\u2022\n\nFrequency of social and news media usage, measured on a Likert scale from 1-6 where 1 was \u2018Never\u2019 and 6 was \u2018Several times a day\u2019.\n\n\n\n\u2022\n\nPolitical affiliation, measured on a Likert scale from 1-7 where 1 was \u2018Very liberal\u2019 and 7 was \u2018Very conservative\u2019.\n\n\n\n\u2022\n\nFan culture engagement, measured on a Likert scale from 1-5 where 1 was \u2018Not at all\u2019 and 5 was \u2018Very often\u2019. Participants were also asked to provide popular figures/groups they engaged with, if any.\n\n\n\n\n\nResponses to the questions about engagement with fan culture were used to split players into the study conditions (see Section 3.4).\n\n\n\n\n3.3. Game Descriptions\n\nThe University of Washington\u2019s Center for an Informed Public and GAMER (Game Research) Group have created several educational experiences focused on building resilience to misinformation. In this study, we used two escape room games, Euphorigen and Galaxy. Both games share the same set of puzzles and mechanics, and their only difference is the narrative scenario.\n\n\n\n\n\n\\Description\n\n\nA representative example of the player workspace, showcasing the first three puzzles of the game.\n\n\nFigure 2. A representative example of the player workspace, showcasing the first three puzzles of the game. The large bar charts (top middle and bottom left) ask players to identify misleading chart titles; the headline puzzle (right middle) asks player to identify the description matching the nature of each of the headlines; the AI face puzzle (left middle) asks players to determine which faces are AI-generated. Sticky notes and markers were provided for note-taking.\n\n\n\n3.3.1. Euphorigen\n\nThe narrative scenario of Euphorigen was designed by the Loki\u2019s Loop research team at the University of Washington, taking suggestions for narrative elements (e.g., big pharmaceutical company, playing as an investigator) from public librarians with experience developing and delivering escape rooms, and from students participating in a directed research group (Turns and Ramey, 2006) to support the project (Cho et\u00a0al., 2023). The goal was to create a fictional narrative that differed enough from the political misinformation examples that were commonly being reported after the national election, so that the game would attract players regardless of their political inclination. An escape room developer was hired to create the puzzles, which were reused for Galaxy. In the narrative, players are initially tasked with investigating suspicious claims about the government putting a particular supplement into the national water supply. They are led into spreading a video claiming that the supplement is dangerous (Figure 3). However, players then discover that this video is a deepfake, and have to find and share the original video which states that the supplement is safe and effective.\n\n\n\n\n\n\\Description\n\n\nA screenshot of the deepfake video from Euphorigen, in which a doctor claims that the supplement failed critical trials and that the government will harm the population.\n\n\nFigure 3. A screenshot of the deepfake video from Euphorigen, in which a doctor claims that the supplement failed critical trials and that the government will harm the population.\n\n\n\n\n3.3.2. Galaxy\n\nGalaxy was co-designed with five participants who identified as members of the ARMY fandom, supporting the music group BTS. In previous work, we found that ARMY\u2019s tactics for dealing with the spread of rumors within their community can be a basis for effective grassroots efforts and strategies to build collective resilience to misinformation (Lee et\u00a0al., 2022a). The narrative scenario of Galaxy is based off certain rumors involving a Kpop music group. In the story, players are tasked by a fellow fan with investigating suspicious claims that their bias111A term normally used to refer to a favorite member of a group in popular culture WJ, a member of a popular Kpop group, is being mistreated by the group\u2019s management company and other members. They are led into spreading a video in which WJ claims that the management company and other members are in fact mistreating him, and he is eager to go on a solo tour (Figure 4). However, players then discover this video is a deepfake, and must find and share the original video, in which WJ speaks of being treated well by the management company and his excitement to go on tour with the group.\n\n\n\n\n\n\\Description\n\n\nA screenshot of the deepfake video from Galaxy, in which WJ claims that the management company is giving other members of the band preferential treatment and that other members are not supportive of his solo work.\n\n\nFigure 4. A screenshot of the deepfake video from Galaxy, in which WJ claims that the management company is giving other members of the band preferential treatment and that other members are not supportive of his solo work.\n\n\n\n\n\n3.4. Study Conditions\n\nBased on their responses to the two screening survey questions involving fan engagement (\u201dHow often do you engage with online fan culture, particularly with specific figures/groups? (e.g., BTS, Taylor Swift) Engagement includes: following their social media accounts, engage with other fans, etc.\u201d on a 1-5 Likert scale, and \u201dIf yes, what popular figures/groups do you engage with?\u201d), the primary researcher divided participants into two groups: non-fans and fans. Non-fans reported their fan culture engagement to be either 1 or 2 on a Likert scale, and did not specify any fan groups that they followed. Fans reported their fan culture engagement to be 3-5 on a Likert scale, and specified figures or groups that they engage with. Each group was further split into halves, where one half played Euphorigen and the other played Galaxy (see Figure 5). Descriptive statistics for each study condition are summarized in Table 1.\n\n\n\n\n\n\\Description\n\n\nDiagram outlining the four study groups.\n\n\nFigure 5. Diagram outlining the four study groups. The group shorthands are provided in parentheses, and will be used to refer to the groups in the following sections.\n\n\nTable 1. Descriptive statistics of each of the four study groups.\n\n\n\nGroup\nN-E\nN-G\nF-E\nF-G\n\n\nn\ud835\udc5bnitalic_n\n31\n31\n29\n32\n\n\n\n\nAge\n24.16\n22.16\n22.83\n22.77\n\n\nGender (M/F/NB)\n13/17/1\n8/22/1\n6/22/2\n5/23/3\n\n\nFan Culture Engagement\n1.48\n1.74\n3.7\n3.45\n\n\nPolitical Affiliation\n2.58\n2.42\n2.17\n2.41\n\n\nVisits Social Media\n5.35\n5.77\n5.93\n5.67\n\n\nShares on Social Media\n2.97\n3.29\n3.03\n3.19\n\n\nVisits News Media\n3.65\n4.1\n4.46\n3.77\n\n\nShares News Media\n2.26\n2.71\n2.97\n2.81\n\n\n\n\n\n\n\n\n\\Description\n\n\nA visual representation of the session protocol; the diamonds represent the measures in sequential order of administration.\n\n\nFigure 6. A visual representation of the session protocol; the diamonds represent the measures in sequential order of administration.\n\n\n\n\n3.5. Data Collection and Measures\n\nDuring the study session, participants were administered a pre-post session questionnaire as well as a post game narrative survey measuring transportation and identification. These are described below, and were administered in the sequential order presented in Figure 6.\n\n\n\n3.5.1. Pre/post questionnaire\n\nUpon entering the study session, all participants were asked to fill out a questionnaire with four Likert scale questions regarding their perceptions of misinformation (ranging from 1 being \u2018Not at all\u2019 to 7 being \u2018Extremely\u2019). We developed these questions during initial pilot testing of Euphorigen, and they are used to gain a baseline understanding for participants\u2019 opinions on misinformation and how this might affect their reactions to our games. Participants filled out the same questionnaire at the end of the session. The questions were:\n\n\n\u2022\n\nI am concerned about misinformation\u2019s effect on society.\n\n\n\n\u2022\n\nI feel confident in my ability to identify misinformation.\n\n\n\n\u2022\n\nI am concerned about accidentally believing misinformation.\n\n\n\n\u2022\n\nI am concerned about accidentally sharing misinformation.\n\n\n\n\n\nIn the post-test, participants were additionally asked about their game experience using the same Likert scale in the following questions:\n\n\n\u2022\n\nHow much did you like the game?\n\n\n\n\u2022\n\nHow much would you recommend the game to other players?\n\n\n\n\n\n\n\n3.5.2. Narrative measures\n\nImmediately after finishing the gameplay, participants were administered a survey assessing the following measures:\n\n\n\u2022\n\nTransportation: To measure narrative transportation, we used 10 out of 11 general items used by Green and Brock (2000) (Green and Brock, 2000), excluding one item that reduces reliability (Cohen et\u00a0al., 2015). Each item was measured on a Likert scale from 1-7 (1 being \u2018Strongly disagree\u2019 and 7 being \u2018Strongly agree\u2019), resulting in a total transportation score measured out of 70. We adapted the questions to refer to the game narrative rather than a generic narrative (e.g., \u201dWhile I was playing the game, I could easily picture the events in the game\u2019s story taking place\u201d). Transportation was measured in a questionnaire administered immediately after completion of the game. The reliability of the scale was excellent (\u03b1\ud835\udefc\\alphaitalic_\u03b1 = 0.99).\n\n\n\n\u2022\n\nIdentification: To measure narrative identification, we adapted six items from Cohen (2001): items 1, 3, 4, 5, 6, and 8 (Cohen, 2017), excluding questions intended for evaluating intra-item validity. Each item was measured on a Likert scale from 1-7 (1 being \u2018Strongly disagree\u2019 and 7 being \u2018Strongly agree\u2019), resulting in a total identification score measured out of 42. We adapted the questions to refer to the game narrative rather than a generic program (e.g., \u201dI think I have a good understanding of the player character\u201d). Identification was measured in a questionnaire administered immediately after completion of the game. The reliability of the scale was good (\u03b1\ud835\udefc\\alphaitalic_\u03b1 = 0.897).\n\n\n\n\n\n\n\n\n3.6. Session Protocol\n\nUpon entering the session, all participants were asked to complete the consent form and pre-questionnaire. Then, participants were separated into groups ranging from 2-6 people, depending on session attendance. All members of a given group belonged to the same study condition. The session administrator provided groups with the game packets detailing the narrative scenario, and started a timer for 45 minutes. In the first phase of the game, players solved three puzzles in which they identified misleading charts, headlines, and AI-generated faces (Figure 2). Providing these three answers to the administrator allowed players to proceed to the second phase, in which they solved a math puzzle. This answer unlocked a URL which they could access on their phones or laptops, leading them to a video stirring up controversy (e.g., Figure 3). Sharing this video revealed to players that it was actually a deepfake with misinformation, and unlocked the final phase of the game, where players solved a graph puzzle displaying how the misinformation they shared had spread. The answer to this puzzle yielded a final URL, linking to the real video clarifying the misinformation, and sharing this video revealed the final passcode marking the successful completion of the game. After providing this to the administrator, players were asked to fill out the questionnaire with the transportation and identification measures. The administrator then ran the debrief session and asked players to complete the post-questionnaire before leaving the session. See Figure 6 for the entire protocol flow.\n\n\n\n3.6.1. Debrief\n\nAfter completion of the game and the questionnaire administering the transportation and identification measures, players participated in a debrief with the first or second author. The debrief was intended to facilitate a discussion with the players, explaining the game and its design intentions while eliciting player opinions and peer-to-peer sharing. The debrief questions were as follows:\n\n\n(1)\n\nHow was your experience? How did you feel? What did you learn?\n\n\n\n(2)\n\nThis game involved misleading headlines, manipulated charts, social media bots, deepfake images, and deepfake videos. Was there anything new or surprising to you about these tactics?\n\n\n\n(3)\n\nHave you ever believed something on social media that turned out to be untrue? Why do you think you fell for it and how did it make you feel?\n\n\n\n(4)\n\nWhat are the consequences of sharing misinformation and how would it affect you or the people around you? Feel free to share a situation when you unintentionally shared information that turned out to be false.\n\n\n\n(5)\n\nWere there any characters and story elements that you think are relatable? What are they and why are they relatable?\n\n\n\n(6)\n\nIn the game\u2019s final puzzle, you were able to contact everyone who spread the deepfake video. How do you think this would have played out in real life?\n\n\n\n\n\n\n\n\n3.7. Hypotheses\n\nAs Galaxy was co-designed with members of a fan community, participants who identify with fan communities may find it more relatable and tailored to their misinformation contexts than Euphorigen.\nConversely, non-fans playing Galaxy are unlikely to find the scenario very relatable as it is very specific to a fan culture context. They are more likely to find Euphorigen, which presents a more generic misinformation context, relatable. However, when compared to each other, both groups will likely have similar experiences playing Euphorigen, as all members of the study are part of the general audience for which the game was designed.\n\n\n\u2022\n\nH\u20621T\ud835\udc3bsubscript1\ud835\udc47H1_{T}italic_H 1 start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT: Fans playing Galaxy will experience significantly higher transportation than fans playing Euphorigen.\n\n\n\n\u2022\n\nH\u20621I\ud835\udc3bsubscript1\ud835\udc3cH1_{I}italic_H 1 start_POSTSUBSCRIPT italic_I end_POSTSUBSCRIPT: Fans playing Galaxy will experience significantly higher identification than fans playing Euphorigen.\n\n\n\n\u2022\n\nH\u20622T\ud835\udc3bsubscript2\ud835\udc47H2_{T}italic_H 2 start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT: Fans playing Euphorigen will experience similar transportation to non-fans playing Euphorigen.\n\n\n\n\u2022\n\nH\u20622I\ud835\udc3bsubscript2\ud835\udc3cH2_{I}italic_H 2 start_POSTSUBSCRIPT italic_I end_POSTSUBSCRIPT: Fans playing Euphorigen will experience similar identification to non-fans playing Euphorigen.\n\n\n\n\u2022\n\nH\u20623T\ud835\udc3bsubscript3\ud835\udc47H3_{T}italic_H 3 start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT: Non-fans playing Euphorigen will experience significantly higher transportation than non-fans playing Galaxy.\n\n\n\n\u2022\n\nH\u20623I\ud835\udc3bsubscript3\ud835\udc3cH3_{I}italic_H 3 start_POSTSUBSCRIPT italic_I end_POSTSUBSCRIPT: Non-fans playing Euphorigen will experience significantly higher identification than non-fans playing Galaxy.\n\n\n\n\u2022\n\nH\u20624T\ud835\udc3bsubscript4\ud835\udc47H4_{T}italic_H 4 start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT: Non-fans playing Galaxy will experience significantly lower transportation than fans playing Galaxy.\n\n\n\n\u2022\n\nH\u20624I\ud835\udc3bsubscript4\ud835\udc3cH4_{I}italic_H 4 start_POSTSUBSCRIPT italic_I end_POSTSUBSCRIPT: Non-fans playing Galaxy will experience significantly lower identification than fans playing Galaxy.\n\n\n\n\n\n\n\n3.8. Analysis\n\n\n3.8.1. Quantitative\n\nResults from the screening, pre/post, and narrative measures surveys were filtered with Microsoft Excel and analyzed with Python. Python packages used were numpy, pandas, scikitlearn, and statsmodel.api. These enabled analyses such as Principal Component Analysis (PCA), and the creation of visualizations. ANOVA and t-tests were also conducted to answer our hypotheses. A Shapiro-Wilk test of the residuals showed that transportation was normally distributed (W(123) = 0.99, p = 0.564), but that identification was not normally distributed (W(123) = 0.98, p = 0.044). Levene\u2019s test further showed that the variances for transportation were not equal (F(3, 119) = 3.200, p = 0.026), and that variances for identification were equal (F(3, 119) = 2.173, p = 0.095). Hence, where appropriate, we used generalized linear mixed models (GLMMs) to estimate the linear relationship between the independent and dependent variables for both transportation and identification. We use ** to denote p \u00a1 0.05 and *** to denote p \u00a1 0.01.\n\n\n\n\n3.8.2. Qualitative\n\nThe debriefs were audio recorded and transcribed using Rev.ai. Transcripts were then imported into Atlas.ti. The first and second author independently followed the six steps outlined in Braun & Clarke (Braun and Clarke, 2006) to inductively code the transcripts and develop themes. They independently coded the first four transcripts, then combined these generated codes into themes. After a round of review, the authors split the transcripts in half and coded them using the developed themes. They then met once more to discuss the codes to consensus.\n\n\n\n\n\n\n4. Results\n\nWe answered RQ1 primarily through significance testing measures related to our hypotheses, and these results are presented in Section 4.1. RQ2 was answered through exploratory quantitative analysis; these findings are outlined in Section 4.2. RQ3 was answered qualitatively, and the themes are outlined in Section 4.3.\n\n\n\n4.1. Comparing Player Experiences Between Conditions\n\n\n4.1.1. Transportation and Identification\n\nResults for transportation and identification per study condition are reported in Tables 2 and 3, respectively. As H1, H3, and H4 were directional, we used one-tailed two-sample t-tests to compare sample means between each study condition. We used a two-tailed two-sample t-test for H2, which was not directional. Results are summarized in Table 4.\n\n\nTable 2. Mean and standard deviation for narrative transportation measure. Scores could range from 10-70.\n\n\n\nTransportation\nNon-fan\nFan\n\n\n\n\nEuphorigen\n41.58\u00b17.69,n=31plus-or-minus41.587.69\ud835\udc5b3141.58\\pm 7.69,n=3141.58 \u00b1 7.69 , italic_n = 31\n39.41\u00b18.03,n=29plus-or-minus39.418.03\ud835\udc5b2939.41\\pm 8.03,n=2939.41 \u00b1 8.03 , italic_n = 29\n\n\nGalaxy\n33.42\u00b110.63,n=31plus-or-minus33.4210.63\ud835\udc5b3133.42\\pm 10.63,n=3133.42 \u00b1 10.63 , italic_n = 31\n40.16\u00b16.81,n=32plus-or-minus40.166.81\ud835\udc5b3240.16\\pm 6.81,n=3240.16 \u00b1 6.81 , italic_n = 32\n\n\n\n\n\nTable 3. Mean and standard deviation for narrative identification measure. Scores could range from 6-42.\n\n\n\nIdentification\nNon-fan\nFan\n\n\n\n\nEuphorigen\n26.74\u00b17.09,n=31plus-or-minus26.747.09\ud835\udc5b3126.74\\pm 7.09,n=3126.74 \u00b1 7.09 , italic_n = 31\n28.55\u00b18.63,n=29plus-or-minus28.558.63\ud835\udc5b2928.55\\pm 8.63,n=2928.55 \u00b1 8.63 , italic_n = 29\n\n\nGalaxy\n24.22\u00b17.69,n=31plus-or-minus24.227.69\ud835\udc5b3124.22\\pm 7.69,n=3124.22 \u00b1 7.69 , italic_n = 31\n30.97\u00b15.70,n=32plus-or-minus30.975.70\ud835\udc5b3230.97\\pm 5.70,n=3230.97 \u00b1 5.70 , italic_n = 32\n\n\n\n\n\nTable 4. Summary of t-testing our hypotheses.\n\n\n\nHypothesis ID\nNull Hypothesis (H0subscript\ud835\udc3b0H_{0}italic_H start_POSTSUBSCRIPT 0 end_POSTSUBSCRIPT)\np-value\n\n\n\n\nH\u20621T\ud835\udc3bsubscript1\ud835\udc47H1_{T}italic_H 1 start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT\nF\u2062GT\u2264F\u2062ET\ud835\udc39subscript\ud835\udc3a\ud835\udc47\ud835\udc39subscript\ud835\udc38\ud835\udc47FG_{T}\\leq FE_{T}italic_F italic_G start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT \u2264 italic_F italic_E start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT\n0.34871\n\n\nH\u20621I\ud835\udc3bsubscript1\ud835\udc3cH1_{I}italic_H 1 start_POSTSUBSCRIPT italic_I end_POSTSUBSCRIPT\nF\u2062GI\u2264F\u2062EI\ud835\udc39subscript\ud835\udc3a\ud835\udc3c\ud835\udc39subscript\ud835\udc38\ud835\udc3cFG_{I}\\leq FE_{I}italic_F italic_G start_POSTSUBSCRIPT italic_I end_POSTSUBSCRIPT \u2264 italic_F italic_E start_POSTSUBSCRIPT italic_I end_POSTSUBSCRIPT\n0.09894\n\n\nH\u20622T\ud835\udc3bsubscript2\ud835\udc47H2_{T}italic_H 2 start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT\nF\u2062ET=N\u2062ET\ud835\udc39subscript\ud835\udc38\ud835\udc47\ud835\udc41subscript\ud835\udc38\ud835\udc47FE_{T}=NE_{T}italic_F italic_E start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT = italic_N italic_E start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT\n0.24951\n\n\nH\u20622I\ud835\udc3bsubscript2\ud835\udc3cH2_{I}italic_H 2 start_POSTSUBSCRIPT italic_I end_POSTSUBSCRIPT\nF\u2062EI=N\u2062EI\ud835\udc39subscript\ud835\udc38\ud835\udc3c\ud835\udc41subscript\ud835\udc38\ud835\udc3cFE_{I}=NE_{I}italic_F italic_E start_POSTSUBSCRIPT italic_I end_POSTSUBSCRIPT = italic_N italic_E start_POSTSUBSCRIPT italic_I end_POSTSUBSCRIPT\n0.37725\n\n\nH\u20623T\ud835\udc3bsubscript3\ud835\udc47H3_{T}italic_H 3 start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT\nN\u2062ET\u2264N\u2062GT\ud835\udc41subscript\ud835\udc38\ud835\udc47\ud835\udc41subscript\ud835\udc3a\ud835\udc47NE_{T}\\leq NG_{T}italic_N italic_E start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT \u2264 italic_N italic_G start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT\n0.00045***\n\n\nH\u20623I\ud835\udc3bsubscript3\ud835\udc3cH3_{I}italic_H 3 start_POSTSUBSCRIPT italic_I end_POSTSUBSCRIPT\nN\u2062EI\u2264N\u2062GI\ud835\udc41subscript\ud835\udc38\ud835\udc3c\ud835\udc41subscript\ud835\udc3a\ud835\udc3cNE_{I}\\leq NG_{I}italic_N italic_E start_POSTSUBSCRIPT italic_I end_POSTSUBSCRIPT \u2264 italic_N italic_G start_POSTSUBSCRIPT italic_I end_POSTSUBSCRIPT\n0.09272\n\n\nH\u20624T\ud835\udc3bsubscript4\ud835\udc47H4_{T}italic_H 4 start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT\nN\u2062GT\u2265F\u2062GT\ud835\udc41subscript\ud835\udc3a\ud835\udc47\ud835\udc39subscript\ud835\udc3a\ud835\udc47NG_{T}\\geq FG_{T}italic_N italic_G start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT \u2265 italic_F italic_G start_POSTSUBSCRIPT italic_T end_POSTSUBSCRIPT\n0.00226***\n\n\nH\u20624I\ud835\udc3bsubscript4\ud835\udc3cH4_{I}italic_H 4 start_POSTSUBSCRIPT italic_I end_POSTSUBSCRIPT\nN\u2062GI\u2265F\u2062GI\ud835\udc41subscript\ud835\udc3a\ud835\udc3c\ud835\udc39subscript\ud835\udc3a\ud835\udc3cNG_{I}\\geq FG_{I}italic_N italic_G start_POSTSUBSCRIPT italic_I end_POSTSUBSCRIPT \u2265 italic_F italic_G start_POSTSUBSCRIPT italic_I end_POSTSUBSCRIPT\n0.0001***\n\n\n\n\n\nNotably, two of the three significant results involve the low transportation and identification experienced by non-fans who played Galaxy. Indeed, these results also surfaced qualitatively in the debrief. Several participants from the Nonfan-Galaxy condition were skeptical that the scenario in Galaxy was realistic (e.g., \u201dI don\u2019t think people would get this mad just because of a KPop band.\u201d - P29), though it was based off of a scenario that is common in the Kpop fandom. Other Nonfan-Galaxy participants were tangentially aware of such occurrences but had never experienced them personally (e.g., \u201dThe social media Kpop scene is very active on Twitter. So I\u2019ve seen a lot of misinformation or people just wanting to make up stuff for clout. Even though I don\u2019t personally use Twitter, I already feel the impact and it seeps into YouTube and all these other social media.\u201d - P23). Many fans who played Galaxy, however, stated in the debrief that they found the narrative very relatable, and some participants even recognized different fandom events that the game story reminded them of. For example, P16 in the Fan-Galaxy condition stated: \u201dThe premise of all of the Kpop fans mobilizing on behalf of a mistreated band member is a direct echo to a Kpop fan history of 2011. And reading it, I felt like I had been that [person]. I remember talking to my friends like, can you believe how this band member is being treated? Meanwhile, I\u2019m getting this information via some Korean fan through multiple layers of translation. And so who knows if I knew anything that was correct in that situation, but I definitely felt like [Galaxy\u2019s story] was extremely relatable.\u201d\n\n\nAs expected, we failed to reject the null on H2, implying that both fans and non-fans related to Euphorigen similarly, being part of the same general audience. However, while we expected fans to relate significantly more to Galaxy than Euphorigen, the results were mixed. Though Euphorigen\u2019s misinformation context may not be tailored to people who frequently use social media like the fans do, it was likely still relatable enough to their personal experiences.\n\n\n\n\n4.1.2. Game Effects on Pre-Post Tests\n\nOur expectation was that scores for all the pre-test questions would significantly increase in the post-test; that is, confidence in identifying misinformation would increase, but concern about misinformation would also increase, based on the learning goals of the game and previous pilot testing. We performed one-tailed paired t-tests within each of the four study conditions, as well as by game and by non-fans/fans. To compare pre/post results between different groups, we used two-tailed, two-sample t-tests.\n\n\nFor Q1 (I am concerned about misinformation\u2019s effect on society), concern rose significantly among players of Galaxy (5.79 \u00b1plus-or-minus\\pm\u00b1 1.23 to 6.02 \u00b1plus-or-minus\\pm\u00b1 1.17; p = 0.019**). This may have been affected in part by the significant increase in concern specifically among the non-fan players of Galaxy (5.68 \u00b1plus-or-minus\\pm\u00b1 1.42 to 5.97 \u00b1plus-or-minus\\pm\u00b1 1.30; p = 0.036**). Exposing non-fan participants to a misinformation context that they normally do not interact with may have made them realize that misinformation they previously did not find particularly harmful can actually have significant impacts. For Q2 (I feel confident in my ability to identify misinformation), fans\u2019 confidence in identifying misinformation increased significantly (4.51 \u00b1plus-or-minus\\pm\u00b1 1.08 to 4.78 \u00b1plus-or-minus\\pm\u00b1 1.03; p = 0.049**). While participants from all conditions expressed appreciation for the puzzle that taught them about hallmarks of AI-generated humans, these learnings may have been more relevant to fans, who interact with falsified images of idols in their fandoms more than non-fans do. We saw no significant results across any study subgroups for Q3 (I am concerned about accidentally believing misinformation); participant concern was already fairly high in the pre-test, making large changes in the post-test unlikely. Finally, we similarly saw no significant results for Q4 (I am concerned about accidentally sharing misinformation).\n\n\n\n\n4.1.3. Enjoyment and Recommendability\n\nOur post-test additionally included two questions on player experience. These questions asked about player enjoyment (Table 5) and whether or not they would recommend the game to others (Table 6), on a Likert scale from 1 to 7 (ranging from 1 being \u2018Not at all\u2019 to 7 being \u2018Extremely\u2019). To compare results between groups, we used one-tailed, two-sample t-tests. We found moderately positive correlations between transportation/identification and enjoyment (r\u2062(113)=0.5317,p<0.001;r\u2062(113)=0.4825,p<0.001formulae-sequence\ud835\udc5f1130.5317formulae-sequence\ud835\udc5d0.001formulae-sequence\ud835\udc5f1130.4825\ud835\udc5d0.001r(113)=0.5317,p<0.001;r(113)=0.4825,p<0.001italic_r ( 113 ) = 0.5317 , italic_p < 0.001 ; italic_r ( 113 ) = 0.4825 , italic_p < 0.001) as well as transportation/identification and willingness to recommend the game (r\u2062(113)=0.4351,p<0.001;r\u2062(113)=0.4341,p<0.001formulae-sequence\ud835\udc5f1130.4351formulae-sequence\ud835\udc5d0.001formulae-sequence\ud835\udc5f1130.4341\ud835\udc5d0.001r(113)=0.4351,p<0.001;r(113)=0.4341,p<0.001italic_r ( 113 ) = 0.4351 , italic_p < 0.001 ; italic_r ( 113 ) = 0.4341 , italic_p < 0.001). The literature also supports the assumption that higher levels of transportation and identification have been found to promote higher game enjoyment (Crutzen et\u00a0al., 2016; Hefner et\u00a0al., 2007). Furthermore, there was strong correlation between levels of enjoyment and recommendability (r\u2062(116)=0.8277,p<0.001formulae-sequence\ud835\udc5f1160.8277\ud835\udc5d0.001r(116)=0.8277,p<0.001italic_r ( 116 ) = 0.8277 , italic_p < 0.001). As such, we had similar expectations surrounding player experience as we did regarding our hypotheses, and centered our analysis around the following inquiries:\n\n\n\u2022\n\nDid players in the fan condition enjoy/recommend Galaxy more than fan players of Euphorigen? (corresponding to H1)\n\n\n\n\u2022\n\nDid players in the non-fan condition enjoy/recommend Euphorigen similarly to fan players of Euphorigen? (corresponding to H2)\n\n\n\n\u2022\n\nDid players in the non-fan condition enjoy/recommend Euphorigen more than non-fan players of Galaxy? (corresponding to H3)\n\n\n\n\u2022\n\nDid players in the fan condition enjoy/recommend Galaxy more than non-fan players of Galaxy? (corresponding to H4)\n\n\n\n\n\nIn terms of enjoyment, players in the fan condition enjoyed Galaxy slightly more than Euphorigen, but it was not significant. However, players in the non-fan condition enjoyed Euphorigen significantly more than Galaxy (p = 0.012**). This aligned with what we observed in our hypothesis testing of player levels of transportation and identification in H3. However, despite the fact that players in the non-fan condition reported significantly lower levels of transportation and identification in Galaxy than fans did, they did not enjoy the game significantly less than fans. This could be explained by separating the narrative component, which concerns transportation and identification, from the rest of the game mechanics. Participants likely found the puzzles to be entertaining on their own, and enjoyed the experience of solving them with a group.\n\n\nDeviating from our original assumptions surrounding H2, players in the non-fan condition enjoyed Euphorigen significantly more than players in the fan condition did (p = 0.006***). This was surprising as we had not observed any significant differences in transportation or identification between fan vs. non-fan players of Euphorigen. A potential explanation is that while fans may have felt similar levels of transportation and identification to non-fans, their experiences may have differed affectively, especially since fans provided their many negative encounters with misinformation in the debrief. Some fans in the Euphorigen condition may have also had inherent preferences for more tailored contexts, despite not knowing about Galaxy. For example, P13 stated, \u201dI think I believe dumb pop culture things more than\u2026vaccine headlines. I remember a couple months ago there was\u2026an alleged picture of Taylor Swift and Travis Kelce on a swing together or something. And I was like, oh my God, that\u2019s so cute. And then later I found out that it wasn\u2019t really them and I was like, whoops.\u201d\n\n\nTable 5. Mean and standard deviation for reported game enjoyment.\n\n\n\nGame enjoyment\nNon-fan\nFan\n\n\n\n\nEuphorigen\n6.35\u00b10.55plus-or-minus6.350.556.35\\pm 0.556.35 \u00b1 0.55\n5.76\u00b11.15plus-or-minus5.761.155.76\\pm 1.155.76 \u00b1 1.15\n\n\nGalaxy\n5.78\u00b11.25plus-or-minus5.781.255.78\\pm 1.255.78 \u00b1 1.25\n6.13\u00b10.95plus-or-minus6.130.956.13\\pm 0.956.13 \u00b1 0.95\n\n\n\n\n\nTable 6. Mean and standard deviation for how inclined players felt to recommend the game to others.\n\n\n\nRecommendability\nNon-fan\nFan\n\n\n\n\nEuphorigen\n6.25\u00b10.73plus-or-minus6.250.736.25\\pm 0.736.25 \u00b1 0.73\n5.79\u00b11.05plus-or-minus5.791.055.79\\pm 1.055.79 \u00b1 1.05\n\n\nGalaxy\n6.04\u00b11.09plus-or-minus6.041.096.04\\pm 1.096.04 \u00b1 1.09\n6.31\u00b10.89plus-or-minus6.310.896.31\\pm 0.896.31 \u00b1 0.89\n\n\n\n\n\nIn terms of recommendability, fans were significantly more likely to recommend Galaxy over Euphorigen (p = 0.023**), aligning with H1. However, non-fans were not significantly more likely to recommend Euphorigen over Galaxy, despite enjoying it significantly more. This likely also affected the finding that fans were not significantly more likely to recommend Galaxy than non-fans. As previously discussed, although players in the non-fan conditions are themselves not involved in online interest groups, they know people who are, or have seen others on the internet who would relate to fan contexts, which is a potential explanation for the Nonfan-Galaxy condition\u2019s relatively high inclination to recommend Galaxy to others. For example, as P19 from the Nonfan-Galaxy condition stated, \u201dI\u2019m not involved in any fandoms, but I see this kind of thing play out all the time as like a bystander\u2026I think it played out about as how it does in real life too\u2026people get their hands on misinformation and it\u2019s inflammatory so they spread it without verifying and then even if the truth comes out, it\u2019s often less distributed or less exciting so it doesn\u2019t reach people the same way.\u201d\n\n\nFurthermore, once again, our expectations surrounding H2 were not met: non-fans were significantly more likely to recommend Euphorigen than fans (p = 0.024**). As the correlation between levels of enjoyment and recommendability was strong, similar reasoning from the previous section may also apply to this result.\n\n\n\n\n\n4.2. Factors Affecting Transportation and Identification\n\nAs the variances for transportation were not equal, we used Welch\u2019s ANOVA, which revealed that playing Galaxy had significant effects on transportation (F(1, 120) = 5.930, p = 0.016**), likely due to the low mean transportation experienced by non-fans who played Galaxy. A two-way ANOVA for identification showed that fans reported higher identification than non-fans regardless of game played (F(1, 120) = 10.572, p = 0.0014***). This may be due to fans\u2019 slightly higher involvement with online spaces and misinformation in general (see Table 1).\n\n\nA key point in both games was the sharing of misinformation in the form of a deepfake video. We investigated if reported frequency of sharing on social or news media had an effect on transportation and identification. Overall, reported frequency of sharing news media had significant effects on both transportation (p = 0.005**, GLMM) and identification (p = 0.045**, GLMM). Other relevant factors to Galaxy\u2019s plot, such whether participants used Twitter or followed Kpop groups, had no significant effects on either transportation or identification. Similarly, among those who played Euphorigen (n = 60), in which a key plot point involves investigating news misinformation, reported frequency of sharing news media had a significant effect on identification (p = 0.026**, GLMM). Reported levels of visiting social or news media had no significant effects on transportation or identification in either game. This may be because a majority of young adults are aware of misinformation on social media independent of how often they visit social media themselves.\n\n\nUpon investigating if answers to the pre-test had significant association with either transportation or identification, we found that reported concern about sharing misinformation (Q4) had a very significant effect on transportation (p = 0.009***, GLMM) and was positively correlated, indicating that participants with pre-existing higher levels of concern found the game narratives to be more believable.\n\n\n\n\n4.3. Analyzing Player Debriefs\n\nThe player debriefs helped us develop a qualitative understanding of player experiences in the game, as well as their broader interactions with misinformation narratives in their daily lives. These findings explore young adults\u2019 interactions with misinformation, revealing widespread encounters and high concern about its impact. Participants recalled instances of believing misinformation, from pop culture rumors to politically charged falsehoods, often amplified by AI-generated content. Emotional investment emerged as a key factor in susceptibility, particularly in fandom contexts where misinformation can intensify community dynamics. While most admitted to falling for misinformation, fewer believed they had shared it. However, fans were more open about sharing misinformation in group chats, driven by urgency or excitement. We highlight how emotional and contextual factors shape young people\u2019s engagement with misinformation, with trust applied selectively depending on the topic\u2019s perceived consequences.\n\n\n\n4.3.1. Interactions with misinformation\n\nUnsurprisingly, every participant in this study had interacted with misinformation before, and overall concern regarding misinformation in the pre-test was high (5.79\u00b11.24plus-or-minus5.791.245.79\\pm 1.245.79 \u00b1 1.24, n = 123). When prompted to recall instances in which they had believed misinformation themselves, participants provided examples ranging from falsified pop culture rumors, e.g., that celebrities such as Jaden Smith and Betty White had died (P103, P15), to politically charged misinformation surrounding recent current events. For example, P17 discussed how \u201dduring COVID, there were a lot of social issues that people were talking about on Instagram\u2026[and they] definitely ended up taking a side of some polarizing issue that [they] didn\u2019t know enough information about to be taking the right side.\u201d P69 also mentioned that \u201dthe misinformation with the Israel-Palestine conflict [had] ten different versions from both sides. It\u2019s happening so fast and so frequently with multiple stories from all perspectives that\u2026even after the fact, [they didn\u2019t] know really which one was true in reality.\u201d Many participants also explicitly mentioned Photoshopped or AI-generated media that they had fallen for, e.g., Photoshopped album covers misleading viewers into believing there was a new release (P15), AI-generated song covers (P107), or Photoshopping two celebrities together to fuel dating rumors and gain clout from virality (P16). Several participants could not recall particular examples of falling for misinformation when prompted, but acknowledged that it was very likely that they had. As P17 put it, \u201dI feel like inevitably, at some point, I have.\u201d\n\n\n\n\n4.3.2. Consequences of misinformation\n\nOn an individual level, several participants expressed the embarrassment of falling for or sharing misinformation, or being personally upset that they accidentally contributed to something potentially harmful. For example, as P16 stated: \u201dIt\u2019s also embarrassing when we reach that point in the game and that we had no option other than to share, but there\u2019s the little feeling of, hmm, maybe this is gonna turn out not to be true. It feels bad to be spreading this information, but also it feels embarrassing if you have fallen prey to it too\u201d. They also acknowledged that \u201dit also tarnishes your reputation, if you share misinformation and then the other person recognizes that it\u2019s misinformation\u201d (P22). More broadly, participants reflected on how misinformation \u201ddefinitely affects relationships and people, and the way people perceive each other\u201d (P16), \u201dcreates vaccine hesitancy\u201d (P18), \u201dconfirms different stereotypes\u201d (P22), and how it \u201djust becomes a cycle and then nobody knows what the real information is\u201d (P77). Indeed, it was notable that several of the young adults in the study expressed \u201ddeep skepticism of everything [they] see on the internet\u201d (P23), with many stating that they had mostly quit social media altogether. As P29 strongly stated, \u201dWhat\u2019s the point of social media? It\u2019s supposed to make information more accessible, but it\u2019s actually just easier to spread. I\u2019ve gotten to the point where I don\u2019t even care about social media and news outlets, or look at people and their opinions on social media because so many things are fake on there.\u201d P30 chimed in, stating, \u201dIt\u2019s really scary because I would say a good chunk of the internet right now is misinformation and a lot of people who have limited digital exposure or literacy don\u2019t even have pathways to identify it.\u201d\n\n\n\n\n4.3.3. Why young people are falling for misinformation\n\nIn spite of the paranoia that many participants brought to their social media experiences, nearly all of them discussed instances in which they had fallen for misinformation, and why this might be. The first reason was a lack of media literacy around AI-generated images, audio, and videos. Participants expressed that the rise of AI technologies has made it outright difficult to identify what may and may not be misinformation, likely contributing to their overall skepticism for social media. Almost every player group discussed how difficult identifying the AI generated images was in the game puzzle, and many did not know the strategies the game provided as typical hallmarks of a generated human (e.g., mismatched or asymmetrical accessories, extra teeth, distortions in background or hair). P4 stated that the game made them realize that \u201d[they] don\u2019t really fact check pictures and videos as much as [they] do articles, [and] tend to assume that if it\u2019s a picture it must be real. If it\u2019s realistic, [they] don\u2019t generally take the time to check it\u201d. P19 referred to generative AI technologies as \u201da force multiplier that makes things more accessible too\u2026for Photoshop, you actually needed skill for people to believe it\u201d. P25 referenced their answer to the pre-test, stating, \u201dWhen I said my confidence was 5 out of 7 for recognizing misinformation, I wasn\u2019t including deepfakes. I don\u2019t think I can recognize those.\u201d\n\n\nHowever, the majority of the reasons that participants believed they fell for misinformation were more personal. Interest and investment were cited as factors for being more prone to believing misinformation, and this was especially discussed by members of the fan condition. Many of these players were Kpop fans themselves, and they provided several examples of instances where they thought their fandom\u2019s investment into an idol or figure went too far, e.g., line distribution scandals trending on Instagram (P64) or trucks sent to protest at management companies over idol dating rumors (P112, P115). As P56 put it, \u201dThe more that you have an emotional response to something, the harder it is to really see it for what it could be. And if it\u2019s misinformation that you\u2019re just very excited or really afraid of, you\u2019re more likely to trust it.\u201d P110 further pointed out that \u201despecially in these situations, it\u2019s hard to counter something with logic because people are very emotionally invested\u201d.\n\n\nIn addition, players provided examples both from non-fan and fan contexts of how emotional investment in a topic can be preyed upon by bad actors in the misinformation sphere. P111 shared that \u201dcertain actors or idols will make up rumors and gossip to ruin the careers of idols they don\u2019t like, and get their fans to spread it\u201d. Outside of fan contexts, many participants shared examples from current political events. P119 discussed the fear and uncertainty around certain politically charged misinformation: \u201dI\u2019m from Korea and if there\u2019s [sic] fake videos made with the president of North Korea and [it says] we might be attacking, or something about missiles, even if it\u2019s fake, we\u2019ll freak out.\u201d P100 expressed regret about family dynamics that have changed in light of misinformation surrounding the Israel-Palestine conflict: \u201dThe misinformation there is actually horrifying. That\u2019s hard, because I\u2019ve known a lot of these [family members] my whole life and they\u2019ve always been so kind, so caring\u2026but then this happened and now I can\u2019t open Facebook. You can\u2019t even talk to them about it either because they\u2019re so set in it. It\u2019s like they feel obligated to have the opinion and it\u2019s scary.\u201d\n\n\nFinally, despite the distrust that many of our participants expressed towards social media ecosystems, participants discussed how they selectively applied skepticism based on how harmful they perceived the information to be. We discuss this in depth in the next section.\n\n\n\n\n4.3.4. Perceived importance of information affects believing and sharing behaviors\n\nAlthough nearly all participants stated that they had fallen for misinformation, fewer believed that they had shared misinformation themselves. This was reflected in the pre-test answers as well: participants were less concerned about sharing misinformation (4.71\u00b11.68plus-or-minus4.711.684.71\\pm 1.684.71 \u00b1 1.68, n = 123) than they were about believing misinformation (5.05\u00b11.34plus-or-minus5.051.345.05\\pm 1.345.05 \u00b1 1.34, n = 123). As sharing misinformation was a key plot point in both Euphorigen and Galaxy, participants brought this up often as a point of narrative dissonance, stating that they \u201cwouldn\u2019t have shared [the video] if it hadn\u2019t been necessary to our progress in the game\u201d (P23). As P24 explained, \u201cI don\u2019t share\u2026and definitely not in this context where we were already aware of the fact that it is potentially fake\u201d (P24). Some non-fan participants who played Galaxy were skeptical that fans would be so willing to share anything about their fandom, e.g., P29, who stated, \u201dI would say that the actual scenario here seems really unrealistic for me. That you\u2019re a super fan of something and you just have to share any information you find about it.\u201d However, many fan players openly admitted to public sharing of misinformation related to their fandom, the best example of which was given by P70: \u201dIf I see something, it\u2019s going to all my group chats right away, to multiple different people. Even if I see something that might be a deepfake, I\u2019m still going to share it to people thinking, oh my God, something is happening, you should go check it out before it gets taken down. Especially some of the Taylor Swift things, some people didn\u2019t even get to see it before it got taken down.\u201d\n\n\nThis quote is perhaps representative of an overarching phenomenon we observed through our discussions with participants: that identifying the difference between legitimate information and misinformation is only necessary if the topic is deemed consequential. As P2 explained, \u201dI think it depends on the severity and consequences of the information\u2026If it\u2019s a life changing piece of news, regardless of whether it\u2019s actually true or not, I\u2019m going to be more distrustful of it. The consequences of believing something like that versus some fun fact, or celebrity gossip, are [much worse]\u201d. An additional factor in participants\u2019 internal judgments was where they might be sharing misinformation. While fan groups were the most public venues that participants discussed sharing misinformation themselves, several participants discussed that although they might not share on social media, they were more likely to share to friends, family group chats, or through in-person conversations.\n\n\n\n\n\n\n5. Discussion\n\nOur findings showed that our initial hypotheses about transportation and identification in the two misinformation narrative games were either met (H2, H4) or partially met (H1, H3). Other factors, such as reported engagement with fan culture, social/news media sharing behaviors, and pre-existing concern for misinformation, also significantly affected transportation and identification. This provides sufficient evidence that the narrative was not only perceived differently between different player groups, but also had an effect on their gameplay experiences in a misinformation education context. Qualitatively, we found that the young adults in this study were well aware of standard media literacy skills and strategies for dealing with misinformation, such as the importance of choosing reliable sources and verifying information that they encounter. They were also aware of their shortcomings regarding AI-generated media, and were generally suspicious of information on social media. However, as discussed in the debriefs about the games and their narratives, these traits do not prevent them from sharing misinformation that they might perceive as less important or not immediately affecting them, or sharing within personal contexts. In the following sections, we discuss the implications of this for future misinformation education interventions.\n\n\n\n5.1. The story matters\n\nThe different misinformation contexts that participants brought to the study affected how they related to the game. Quantitatively, it was apparent that the non-fan condition was unable to connect with Galaxy\u2019s narrative in the same way as fans were, as shown by the significantly lower levels of transportation and identification, implying reduced engagement and lowered emotional impact. Fans identified with and enjoyed Galaxy slightly more than Euphorigen, showing that co-designing led to slightly improved engagement over the general game for this particular group, although it was not statistically significant. Qualitatively, however, was where the difference in narrative framing appeared to matter most. In the debrief, where we intended most of the discussion and learning to occur, fans readily connected Galaxy\u2019s story to scenarios in their own lives. This aligns with previous research which shows that player understanding is developed through cycles of performance within game worlds (Squire, 2006). While most participants were able to relate either story to general instances of misinformation they had encountered, this showed us that fans were not only able to quickly connect the scenario to their own lives, but also to a subject of personal interest. Notably, several non-fan participants who played Galaxy expressed confusion or skepticism at the scenario, or expressed that they did not personally relate, even if they had friends who might.\n\n\nIndeed, the importance of personal interest cannot be understated. As misinformation is a controversial topic, and the young adults in our study seemed to be extremely burnt out and skeptical of misinformation and social media, engaging them through personal interests is potentially more important than ever before. In a phenomenon deeply mediated by emotions and personal belief, a game that is well-designed and informative may not always be sufficient to sustain engagement if it does not resonate with the audience\u2019s specific interests or lived experiences (Young et\u00a0al., 2021).\n\n\nRegardless of condition, all participants were able to experience a small dose of the emotional impact of sharing misinformation, as evidenced by the surprise and embarrassment many of them expressed upon learning that the video shared in the game was a deepfake. Our results showed that participants\u2019 reported frequency of sharing on social media had varying levels of significance on transportation and identification. From this, we can infer that the emotional impact of sharing a fake video, even in the game, was enough to have an effect on player experience.\n\n\nSociocultural narratives are lacking in the current body of misinformation games, and many of them address the rational rather than emotional components of misinformation adoption (Devasia and Lee, 2024). Indeed, this work speaks to the importance of something that we believe many current misinformation education games often miss: that emotions and personal investment in a misinformation context are highly relevant to what we choose and decline to believe. Despite participants\u2019 self-professed confidence in their own media literacy skills and ability to identify misinformation, several still discussed falling for it themselves. Understanding how to identify misinformation is not necessarily enough to prevent a person from falling for it, especially if the topic is of emotional or personal interest to them. Narrative serves as a useful mechanism to provide that context for players to experience misinformation in a more realistic scenario than a program primarily focused on teaching them media literacy skills.\n\n\n\n5.1.1. Strengths and drawbacks of designing generalized misinformation education interventions\n\nEuphorigen proved to be the more successful game in terms of transportation and enjoyment, demonstrating that any player familiar with American news contexts found it to be moderately believeable and entertaining. This speaks to the potential efficacy of well-designed generalized interventions, and for educators and designers with limited time and resources, a general intervention may serve well for running in classrooms, libraries, or workplaces.\n\n\nHowever, generalizing has its limitations. While all our participants were from a relatively homogeneous audience - primarily American students at our university - the game narrative may be difficult to generalize across cultures and languages. For example, Euphorigen\u2019s narrative, which plays upon the inherent distrust that Americans have for the government and pharmaceutical companies in order to discuss confirmation bias, is likely not applicable to countries with significantly higher indices of trust in their governments (Lessenski\u2019, 2018). In addition, while generally relatable to students of a large, liberal American university, Euphorigen\u2019s similarity to the COVID-19 vaccine rollout may alienate certain audiences prone to vaccine skepticism. Indeed, these games were designed to be implemented in public libraries, and librarians face difficulties in deploying such interventions to audiences who need them most due to the fact that misinformation issues are often highly polarized (Young et\u00a0al., 2021). In the current day, one may argue that there is almost no singular piece of information that is universally agreed upon, making a truly general intervention challenging. Writing general scenarios that can be lightly tailored to fit the widest range of contexts is likely the most optimal method of reaching the largest audience.\n\n\n\n\n5.1.2. Strengths and drawbacks of co-designing misinformation education interventions with specific user groups\n\nAs shown by the numerous quotes of fans discussing how the topics from Galaxy\u2019s narrative were relevant to their own lives, a primary strength of co-designed narratives such as Galaxy\u2019s is that it allows players to interact with misinformation education through the lens of their personal interests. Not only does this increase the potential for higher engagement in the intervention itself, but as personal investment and emotion are fundamental players in misinformation adoption, targeted narratives are an opportunity to engage with people in contexts in which they may be more prone to misinformation. Our results showed that fans identified with, enjoyed, and would recommend Galaxy significantly more than Euphorigen, which is a strong case for co-design as a way to increase the appeal of misinformation education for specific target groups.\n\n\nA potential drawback of co-designed interventions such as Galaxy is over-optimizing to a specific community, as shown by the relatively low transportation and identification experienced by non-fans who played the game. Any intervention designed with a particular group of people in mind may run the risk of alienating players who do not identify with that group, as shown by our results. Furthermore, co-design can be time consuming and resource intensive for improvements that may not be highly significant over a generalized version; for researchers and designers optimizing for the largest reach, a generalized intervention such as Euphorigen may be preferable.\n\n\n\n\n\n5.2. The dangers of not caring enough\n\nBarzilai & Chinn (Barzilai and Chinn, 2020) discussed how in many cases, people are not committed to validating accuracy or impartiality in favor of other personal goals, such as promoting personal interests or aligning with family and friends. In our debrief discussions, we observed that young people are very skeptical of and careful about validating sources around information that they perceive to be of high personal importance. Examples primarily included political and medical misinformation; many participants stated that they would not have shared the deepfake video in Euphorigen without verifying it first, as it contained information of high potential impact to others. However, this sense of care did not apply to misinformation that they perceived as less important, as exemplified by several of the participant quotes discussed in Section 4.3.3.\n\n\nThis points to a potentially troubling revelation for misinformation education: that the verity of information, regardless of the topic, only matters insofar as its perceived importance to a user. For example, though many non-fans who played Galaxy expressed incredulity at the narrative scenario presented, and several participants wondered why people would care about misinformation about a celebrity, the scenario was based off of real life events that caused harm to a person. This finding represents a potential future direction for misinformation education, which can use Barzilai & Chinn\u2019s framing to interrogate why people may not care enough about the verity of certain types of misinformation. They suggest emphasizing the development of dispositional intellectual virtues, i.e., habits of mind that dispose people to good thinking. They also suggest fostering students\u2019 intellectual identities and agency, which would aid students in bridging the gap between knowing the correct course of action and executing it (Lapsley and Chaloner, 2020). We believe that the narrative framing of misinformation interventions is crucial to encouraging the reflection needed to build such intellectual virtues, more so than specific game mechanics or modalities.\n\n\n\n\n5.3. Further design considerations for misinformation narrative games\n\n\n\n\n\\Description\n\n\nA summary of the Misinformation Game Narrative Design framework, presented in our previous work.\n\n\nFigure 7. A summary of the Misinformation Game Narrative Design framework, presented in our previous work (Devasia and Lee, 2024).\n\n\nIn previous work, we presented a framework outlining elements to consider when designing a narrative-centered misinformation intervention (see Figure 7) which can serve as an additional theoretical lens to explore the role of narrative (Devasia and Lee, 2024). This study highlights additional elements, beyond those discussed in the framework, that should be considered when designing narratives for misinformation education games. While this study focused on investigating the effects of a particular type of social media usage (i.e., engagement with fan culture) on perceptions of misinformation narratives, we may conjecture that broader cultural contexts are also likely to strongly affect the experience of playing such games (e.g., ethnicity, social norms), as evidenced by participants who originated from or have family internationally. For example, a narrative such as Euphorigen, which draws elements from vaccine skepticism, may not resonate with an Asian audience, where vaccines are more accepted (Sallam, 2021). The recency of the misinformation context is also relevant to player experience; e.g., games about election misinformation would likely be most pertinent during an election cycle. Prior research also shows that different countries have different level of resilience to disinformation considering various indexes of polarization, populism, media trust, and media literacy (Humprecht et\u00a0al., 2020; Lessenski\u2019, 2018), which can also impact narrative design. Another consideration is the physical context of the players; for example, if they are playing in an individual or group setting, and the social dynamics of who they may be playing the game with. Playing in certain settings, such as classrooms, workplaces, or libraries, may be time constrained to a class period or an activity block. Playing in groups with peers, as compared to playing with managers or subordinates in one\u2019s workplace, will likely lead players to make different choices. While we were not able to disambiguate the effects of social play within this study, it likely has an effect on how players perceive the narrative, although this has not been explored adequately in the literature. Regardless of a specific narrative or misinformation context, certain tactics are common across multiple contexts. For example, in both games, players praised the puzzle which taught them how to identify AI-generated images of people, as this tactic has become ubiquitous across social media and news platforms generally. Lastly, designing different kinds of post-game experiences, such as a resource kit, a quiz, or a debrief session can help reinforce the learning experience from the game.\n\n\n\n\n\n6. Limitations\n\nThis study was performed at a large American university which limits the level of diversity that could be achieved in terms of ethnicities or political affiliations. As the effects of misinformation vary strongly by individual demographics, a more holistic investigation of how these games and their narratives affect transportation and identification among different populations is needed. For example, while a version of Euphorigen was co-designed and piloted with BIPOC Americans, it was not investigated in this study. Another limitation was that despite the fact that Galaxy was co-designed with avid Kpop fans, we were unable to recruit for just Kpop fans specifically in this study, and our fan condition represents a somewhat broad coalition of fans that may not have found the narrative as relatable to them.\n\n\n\n\n7. Conclusion and Future Work\n\nIn this work, we investigated how narrative transportation and identification were experienced by two different player groups in two misinformation education games. We found significant differences between player groups, and additionally observed that online sharing behaviors and prior concern regarding misinformation affected narrative measures. We discuss drawbacks in current misinformation interventions as well as suggest future directions for cultivating stronger intellectual dispositions in young people who frequently interact with social media. We contribute an empirical understanding of how narrative framing impacts player experience in misinformation education games.\n\n\nWe are working to adapt these games to different international contexts, localizing their contents such that they are culturally relevant to specific populations. We wish to investigate elements of narrative transportation and identification for the localized games, and compare to the original versions targeted at American audiences. For example, preliminary observations revealed that players in Scandinavia did not share the inherent mistrust American players have towards the government in Euphorigen, and therefore had different reactions towards the story. A deeper investigation into cultural and historical contexts where the game will be played may help us identify strategies for creating effective narratives for misinformation games. We are also currently developing a misinformation game targeted at young adults which is meant to highlight the potential dangers of sharing AI-generated misinformation that may seem unimportant and humorous at first glance, but leads to harmful outcomes in the game story. We anticipate that this game will help us address the dangers of \u201dnot caring enough\u201d, as discussed in (Barzilai and Chinn, 2020), in the context of misinformation more effectively.\n\n\nAcknowledgements.\nThis work was supported by the University of Washington\u2019s Center for an Informed Public and the John S. and James L. Knight Foundation, through award number G-2019-58788.\n\n\n\n\nReferences\n\n\n(1)\n\n\n\n\nAbdul\u00a0Jabbar and Felicia (2015)\n\nAzita\u00a0Iliya Abdul\u00a0Jabbar and Patrick Felicia. 2015.\n\n\nGameplay Engagement and Learning in Game-Based Learning: A Systematic Review.\n\n\nReview of Educational Research 85, 4 (Dec. 2015), 740\u2013779.\n\n\n\nhttps://doi.org/10.3102/0034654315577210\n\n\n\nALL DIGITAL Week (2020)\n\nALL DIGITAL Week. 2020.\n\n\nGet Facts.\n\n\n\n\n\nhttps://www.alldigitalweek.eu/get-facts/\n\n\n\nBarzilai and Chinn (2020)\n\nSarit Barzilai and Clark\u00a0A Chinn. 2020.\n\n\nA review of educational responses to the \u201cpost-truth\u201d condition: Four lenses on \u201cpost-truth\u201d problems.\n\n\nEducational psychologist 55, 3 (2020), 107\u2013119.\n\n\n\n\n\n\nBasol et\u00a0al. (2021)\n\nMelisa Basol, Jon Roozenbeek, Manon Berriche, Fatih Uenal, William\u00a0P McClanahan, and Sander van\u00a0der Linden. 2021.\n\n\nTowards psychological herd immunity: Cross-cultural evidence for two prebunking interventions against COVID-19 misinformation.\n\n\nBig Data & Society 8, 1 (2021), 20539517211013868.\n\n\n\n\n\n\nBasol et\u00a0al. (2020)\n\nMelisa Basol, Jon Roozenbeek, and Sander Van\u00a0der Linden. 2020.\n\n\nGood news about bad news: Gamified inoculation boosts confidence and cognitive immunity against fake news.\n\n\nJournal of cognition 3, 1 (2020), \u201d.\n\n\n\nhttps://doi.org/10.5334/joc.91\n\nOnline-only article; no page numbers available.\n\n\n\n\nBopp et\u00a0al. (2019)\n\nJulia\u00a0Ayumi Bopp, Livia\u00a0J. M\u00fcller, Lena\u00a0Fanya Aeschbach, Klaus Opwis, and Elisa\u00a0D. Mekler. 2019.\n\n\nExploring Emotional Attachment to Game Characters. In Proceedings of the Annual Symposium on Computer-Human Interaction in Play. ACM, Barcelona Spain, 313\u2013324.\n\n\n\nhttps://doi.org/10.1145/3311350.3347169\n\n\n\nBraun and Clarke (2006)\n\nVirginia Braun and Victoria Clarke. 2006.\n\n\nUsing thematic analysis in psychology.\n\n\nQualitative Research in Psychology 3, 2 (Jan. 2006), 77\u2013101.\n\n\n\nhttps://doi.org/10.1191/1478088706qp063oa\n\n\n\nBruner (1990)\n\nJerome Bruner. 1990.\n\n\nActs of Meaning.\n\n\nHarvard University Press, Cambridge, MA.\n\n\n\n\n\n\nBuchner (2024)\n\nJosef Buchner. 2024.\n\n\nPlaying an Augmented Reality Escape Game Promotes Learning About Fake News.\n\n\nTechnology, Knowledge and Learning \u201d (2024), 1\u201321.\n\n\n\nhttps://doi.org/10.1007/s10758-024-09749-y\n\n\u2019Online first\u2019.\n\n\n\n\nBurgess and Jones (2021)\n\nJacqueline Burgess and Christian Jones. 2021.\n\n\nThe female video game player-character persona and emotional attachment.\n\n\nPersona Studies 6, 2 (Aug. 2021), 7\u201321.\n\n\n\nhttps://doi.org/10.3316/informit.963436430037280\n\n\n\nBusselle and Bilandzic (2008)\n\nRick Busselle and Helena Bilandzic. 2008.\n\n\nFictionality and Perceived Realism in Experiencing Stories: A Model of Narrative Comprehension and Engagement.\n\n\nCommunication Theory 18, 2 (May 2008), 255\u2013280.\n\n\n\nhttps://doi.org/10.1111/j.1468-2885.2008.00322.x\n\n\n\nChang et\u00a0al. (2020)\n\nYoo\u00a0Kyung Chang, Ioana Literat, Charlotte Price, Joseph\u00a0I. Eisman, Jonathan Gardner, Amy Chapman, and Azsane\u00e9 Truss. 2020.\n\n\nNews literacy education in a polarized political climate: How games can teach youth to spot misinformation.\n\n\nHarvard Kennedy School Misinformation Review 1 (May 2020).\n\n\n\nhttps://doi.org/10.37016/mr-2020-020\n\n\n\nCho et\u00a0al. (2023)\n\nYeonhee Cho, Chris Coward, Jacob Lackner, Travis\u00a0Willingham Windleharth, and Jin\u00a0Ha Lee. 2023.\n\n\nThe use of an escape room as an immersive learning environment for building resilience to misinformation.\n\n\nJournal of Librarianship and Information Science 0 (2023), 1\u201315.\n\n\n\nhttps://journals-sagepub-com.offcampus.lib.washington.edu/doi/full/10.1177/09610006231208027\n\n\n\nCohen (2017)\n\nJonathan Cohen. 2017.\n\n\nDefining Identification: A Theoretical Look at the Identification of Audiences With Media Characters. Vol.\u00a04.\n\n\nRoutledge, UK, 245\u2013264.\n\n\n\n\n\n\nCohen et\u00a0al. (2015)\n\nJonathan Cohen, Nurit Tal-Or, and Maya Mazor-Tregerman. 2015.\n\n\nThe Tempering Effect of Transportation: Exploring the Effects of Transportation and Identification During Exposure to Controversial Two-Sided Narratives: The Tempering Effect of Transportation.\n\n\nJournal of Communication 65, 2 (April 2015), 237\u2013258.\n\n\n\nhttps://doi.org/10.1111/jcom.12144\n\n\n\nConsalvo et\u00a0al. (2019)\n\nMia Consalvo, Thorsten Busch, and Carolyn Jong. 2019.\n\n\nPlaying a Better Me: How Players Rehearse Their Ethos via Moral Choices.\n\n\nGames and Culture 14, 3 (May 2019), 216\u2013235.\n\n\n\nhttps://doi.org/10.1177/1555412016677449\n\n\n\nContreras-Espinosa and Eguia-Gomez (2023)\n\nRuth\u00a0S. Contreras-Espinosa and Jose\u00a0Luis Eguia-Gomez. 2023.\n\n\nEvaluating Video Games as Tools for Education on Fake News and Misinformation.\n\n\nComputers 12, 99 (Sept. 2023), 188.\n\n\n\nhttps://doi.org/10.3390/computers12090188\n\n\n\nCook et\u00a0al. (2017)\n\nJohn Cook, Stephan Lewandowsky, and Ullrich K.\u00a0H. Ecker. 2017.\n\n\nNeutralizing misinformation through inoculation: Exposing misleading argumentation techniques reduces their influence.\n\n\nPLOS ONE 12, 5 (May 2017), e0175799.\n\n\n\nhttps://doi.org/10.1371/journal.pone.0175799\n\n\n\nCorbu et\u00a0al. (2020)\n\nNicoleta Corbu, Denisa-Adriana Oprea, Elena Negrea-Busuioc, and Loredana Radu. 2020.\n\n\n\u2018They can\u2019t fool me, but they can fool the others!\u2019Third person effect and fake news detection.\n\n\nEuropean Journal of Communication 35, 2 (2020), 165\u2013180.\n\n\n\n\n\n\nCrutzen et\u00a0al. (2016)\n\nRik Crutzen, Jonathan van\u2019t Riet, and Camille\u00a0E Short. 2016.\n\n\nEnjoyment: a conceptual exploration and overview of experimental evidence in the context of games for health.\n\n\nGames for Health Journal 5, 1 (2016), 15\u201320.\n\n\n\n\n\n\nDame Adjin-Tettey (2022)\n\nTheodora Dame Adjin-Tettey. 2022.\n\n\nCombating fake news, disinformation, and misinformation: Experimental evidence for media literacy education.\n\n\nCogent Arts I& Humanities 9, 1 (Dec. 2022), 2037229.\n\n\n\nhttps://doi.org/10.1080/23311983.2022.2037229\n\n\n\nDe\u00a0Graaf et\u00a0al. (2012)\n\nAnneke De\u00a0Graaf, Hans Hoeken, Jos\u00e9 Sanders, and Johannes\u00a0WJ Beentjes. 2012.\n\n\nIdentification as a mechanism of narrative persuasion.\n\n\nCommunication research 39, 6 (2012), 802\u2013823.\n\n\n\n\n\n\nDevasia and Lee (2024)\n\nNisha Devasia and Jin\u00a0Ha Lee. 2024.\n\n\nThe role of narrative in misinformation games.\n\n\nHarvard Kennedy School Misinformation Review 5 (2024).\n\n\n\n\n\n\nDom\u00ednguez et\u00a0al. (2016)\n\nIgnacio\u00a0X. Dom\u00ednguez, Rogelio\u00a0E. Cardona-Rivera, James\u00a0K. Vance, and David\u00a0L. Roberts. 2016.\n\n\nThe Mimesis Effect: The Effect of Roles on Player Choice in Interactive Narrative Role-Playing Games. In Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems. ACM, San Jose California USA, 3438\u20133449.\n\n\n\nhttps://doi.org/10.1145/2858036.2858141\n\n\n\nEcker (2017)\n\nUllrich K.\u00a0H. Ecker. 2017.\n\n\nWhy rebuttals may not work: the psychology of misinformation*.\n\n\nMedia Asia 44, 2 (April 2017), 79\u201387.\n\n\n\nhttps://doi.org/10.1080/01296612.2017.1384145\n\n\n\nEcker et\u00a0al. (2022)\n\nUllrich K.\u00a0H. Ecker, Stephan Lewandowsky, John Cook, Philipp Schmid, Lisa\u00a0K. Fazio, Nadia Brashier, Panayiota Kendeou, Emily\u00a0K. Vraga, and Michelle\u00a0A. Amazeen. 2022.\n\n\nThe psychological drivers of misinformation belief and its resistance to correction.\n\n\nNature Reviews Psychology 1, 11 (Jan. 2022), 13\u201329.\n\n\n\nhttps://doi.org/10.1038/s44159-021-00006-y\n\n\n\nEstrada\u00a0Villalba and Jacques-Garc\u00eda (2021)\n\n\u00c9der Estrada\u00a0Villalba and Fausto\u00a0Abraham Jacques-Garc\u00eda. 2021.\n\n\nImmersive Virtual Reality and Its Use in Developing Empathy in Undergraduate Students. In ITNG 2021 18th International Conference on Information Technology-New Generations (Advances in Intelligent Systems and Computing), Shahram Latifi (Ed.). Springer International Publishing, Cham, 361\u2013365.\n\n\n\nhttps://doi.org/10.1007/978-3-030-70416-2_46\n\n\n\nGarett and Young (2021)\n\nRenee Garett and Sean\u00a0D Young. 2021.\n\n\nOnline misinformation and vaccine hesitancy.\n\n\nTranslational Behavioral Medicine 11, 12 (Dec. 2021), 2194\u20132199.\n\n\n\nhttps://doi.org/10.1093/tbm/ibab128\n\n\n\nGreen (2008)\n\nMelanie\u00a0C. Green. 2008.\n\n\nTransportation Theory.\n\n\nWiley Online Library, Hoboken, NJ, Chapter\u00a01, \u201d.\n\n\n\nhttps://doi.org/10.1002/9781405186407.wbiect058\n\n\n\nGreen and Brock (2000)\n\nMelanie\u00a0C. Green and Timothy\u00a0C. Brock. 2000.\n\n\nThe role of transportation in the persuasiveness of public narratives.\n\n\nJournal of Personality and Social Psychology 79, 5 (Nov. 2000), 701\u2013721.\n\n\n\nhttps://doi.org/10.1037/0022-3514.79.5.701\n\n\n\nHapp et\u00a0al. (2013)\n\nChristian Happ, Andr\u00e9 Melzer, and Georges Steffgen. 2013.\n\n\nSuperman vs. BAD Man? The Effects of Empathy and Game Character in Violent Video Games.\n\n\nCyberpsychology, Behavior, and Social Networking 16, 10 (Oct. 2013), 774\u2013778.\n\n\n\nhttps://doi.org/10.1089/cyber.2012.0695\n\n\n\nHefner et\u00a0al. (2007)\n\nDoroth\u00e9e Hefner, Christoph Klimmt, and Peter Vorderer. 2007.\n\n\nIdentification with the Player Character as Determinant of Video Game Enjoyment. In Entertainment Computing \u2013 ICEC 2007 (Lecture Notes in Computer Science), Lizhuang Ma, Matthias Rauterberg, and Ryohei Nakatsu (Eds.). Springer, Berlin, Heidelberg, 39\u201348.\n\n\n\nhttps://doi.org/10.1007/978-3-540-74873-1_6\n\n\n\nHumprecht et\u00a0al. (2020)\n\nEdda Humprecht, Frank Esser, and Peter Van\u00a0Aelst. 2020.\n\n\nResilience to online disinformation: A framework for cross-national comparative research.\n\n\nThe International Journal of Press/Politics 25, 3 (2020), 493\u2013516.\n\n\n\n\n\n\nIgartua and Barrios (2012)\n\nJuan-Jos\u00e9 Igartua and Isabel Barrios. 2012.\n\n\nChanging Real-World Beliefs With Controversial Movies: Processes and Mechanisms of Narrative Persuasion.\n\n\nJournal of Communication 62, 3 (June 2012), 514\u2013531.\n\n\n\nhttps://doi.org/10.1111/j.1460-2466.2012.01640.x\n\n\n\nIten et\u00a0al. (2018)\n\nGlena\u00a0H. Iten, Sharon\u00a0T. Steinemann, and Klaus Opwis. 2018.\n\n\nChoosing to Help Monsters: A Mixed-Method Examination of Meaningful Choices in Narrative-Rich Games and Interactive Narratives. In Proceedings of the 2018 CHI Conference on Human Factors in Computing Systems. ACM, Montreal QC Canada, 1\u201313.\n\n\n\nhttps://doi.org/10.1145/3173574.3173915\n\n\n\nJackson et\u00a0al. (2018)\n\nLuke\u00a0Conrad Jackson, Joanne O\u2019Mara, Julianne Moss, and Alun\u00a0C. Jackson. 2018.\n\n\nA Critical Review of the Effectiveness of Narrative-Driven Digital Educational Games:.\n\n\nInternational Journal of Game-Based Learning 8, 4 (Oct. 2018), 32\u201349.\n\n\n\nhttps://doi.org/10.4018/IJGBL.2018100103\n\n\n\nKahne and Bowyer (2017)\n\nJoseph Kahne and Benjamin Bowyer. 2017.\n\n\nEducating for Democracy in a Partisan Age: Confronting the Challenges of Motivated Reasoning and Misinformation.\n\n\nAmerican Educational Research Journal 54, 1 (Feb. 2017), 3\u201334.\n\n\n\nhttps://doi.org/10.3102/0002831216679817\n\n\n\nKellner and Share (2019)\n\nDouglas Kellner and Jeff Share. 2019.\n\n\nThe Critical Media Literacy Guide: Engaging Media and Transforming Education.\n\n\nBRILL, Leiden, Netherlands.\n\n\n\n\nGoogle-Books-ID: hTGbDwAAQBAJ.\n\n\n\n\nKiili et\u00a0al. (2024)\n\nKristian Kiili, Juho Siuko, and Manuel Ninaus. 2024.\n\n\nTackling misinformation with games: a systematic literature review.\n\n\nInteractive Learning Environments 32 (2024), 7086\u2013\u20137101.\n\n\n\nhttps://doi.org/10.1080/10494820.2023.2299999\n\n\n\nLapsley and Chaloner (2020)\n\nDaniel Lapsley and Dominic Chaloner. 2020.\n\n\nPost-truth and science identity: A virtue-based approach to science education.\n\n\nEducational Psychologist 55, 3 (2020), 132\u2013143.\n\n\n\n\n\n\nLee et\u00a0al. (2022a)\n\nJin\u00a0Ha Lee, Nicole Santero, Arpita Bhattacharya, Emma May, and Emma\u00a0S. Spiro. 2022a.\n\n\nCommunity-based strategies for combating misinformation: Learning from a popular culture fandom.\n\n\nHarvard Kennedy School Misinformation Review 3 (Sept. 2022).\n\n\n\nhttps://doi.org/10.37016/mr-2020-105\n\n\n\nLee et\u00a0al. (2022b)\n\nSun\u00a0Kyong Lee, Juhyung Sun, Seulki Jang, and Shane Connelly. 2022b.\n\n\nMisinformation of COVID-19 vaccines and vaccine hesitancy.\n\n\nScientific Reports 12, 11 (Aug. 2022), 13681.\n\n\n\nhttps://doi.org/10.1038/s41598-022-17430-6\n\n\n\nLessenski\u2019 (2018)\n\n\u2019Marin Lessenski\u2019. 2018.\n\n\n\n\n\nhttps://osis.bg/?p=4450&lang=en\n\n\n\nMaertens et\u00a0al. (2021)\n\nRakoen Maertens, Jon Roozenbeek, Melisa Basol, and Sander van\u00a0der Linden. 2021.\n\n\nLong-term effectiveness of inoculation against misinformation: Three longitudinal experiments.\n\n\nJournal of Experimental Psychology: Applied 27, 1 (2021), 1\u201316.\n\n\n\nhttps://doi.org/10.1037/xap0000315\n\n\n\nMahood and Hanus (2017)\n\nChad Mahood and Michael Hanus. 2017.\n\n\nRole-playing video games and emotion: How transportation into the narrative mediates the relationship between immoral actions and feelings of guilt.\n\n\nPsychology of Popular Media Culture 6, 1 (Jan. 2017), 61\u201373.\n\n\n\nhttps://doi.org/10.1037/ppm0000084\n\n\n\nMcQuiggan et\u00a0al. (2008b)\n\nScott\u00a0W. McQuiggan, Jonathan\u00a0P. Rowe, Sunyoung Lee, and James\u00a0C. Lester. 2008b.\n\n\nStory-Based Learning: The Impact of Narrative on Learning Experiences and Outcomes. In Intelligent Tutoring Systems (Lecture Notes in Computer Science), Beverley\u00a0P. Woolf, Esma A\u00efmeur, Roger Nkambou, and Susanne Lajoie (Eds.). Springer, Berlin, Heidelberg, 530\u2013539.\n\n\n\nhttps://doi.org/10.1007/978-3-540-69132-7_56\n\n\n\nMcQuiggan et\u00a0al. (2008a)\n\nScott\u00a0W. McQuiggan, Jonathan\u00a0P. Rowe, and James\u00a0C. Lester. 2008a.\n\n\nThe effects of empathetic virtual characters on presence in narrative-centered learning environments. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems. ACM, Florence Italy, 1511\u20131520.\n\n\n\nhttps://doi.org/10.1145/1357054.1357291\n\n\n\nModirrousta-Galian and Higham (2023)\n\nAriana Modirrousta-Galian and Philip\u00a0A Higham. 2023.\n\n\nGamified inoculation interventions do not improve discrimination between true and fake news: Reanalyzing existing research with receiver operating characteristic analysis.\n\n\nJournal of Experimental Psychology: General 152, 9 (2023), 2411.\n\n\n\n\n\n\nMolnar and Kostkova (2013)\n\nAndreea Molnar and Patty Kostkova. 2013.\n\n\nOn effective integration of educational content in serious games: Text vs. game mechanics. In 2013 IEEE 13th International Conference on Advanced Learning Technologies. IEEE, New York City, NY, 299\u2013303.\n\n\n\n\n\n\nMoyer-Gus\u00e9 (2008)\n\nEmily Moyer-Gus\u00e9. 2008.\n\n\nToward a Theory of Entertainment Persuasion: Explaining the Persuasive Effects of Entertainment-Education Messages.\n\n\nCommunication Theory 18, 3 (Aug. 2008), 407\u2013425.\n\n\n\nhttps://doi.org/10.1111/j.1468-2885.2008.00328.x\n\n\n\nMoyer-Gus\u00e9 et\u00a0al. (2011)\n\nEmily Moyer-Gus\u00e9, Chad Mahood, and Sarah Brookes. 2011.\n\n\nEntertainment-Education in the Context of Humor: Effects on Safer Sex Intentions and Risk Perceptions.\n\n\nHealth Communication 26, 8 (Dec. 2011), 765\u2013774.\n\n\n\nhttps://doi.org/10.1080/10410236.2011.566832\n\n\n\nNaul and Liu (2020)\n\nEmily Naul and Min Liu. 2020.\n\n\nWhy Story Matters: A Review of Narrative in Serious Games.\n\n\nJournal of Educational Computing Research 58, 3 (June 2020), 687\u2013707.\n\n\n\nhttps://doi.org/10.1177/0735633119859904\n\n\n\nNelson and Shavitt (2002)\n\nMichelle Nelson and Sharon Shavitt. 2002.\n\n\nThe role of attitude functions in persuasion and social judgment.\n\n\nSage Publications, Thousand Oaks, CA. 137\u2013153 pages.\n\n\n\n\n\n\nOphir et\u00a0al. (2020)\n\nYotam Ophir, Dan Romer, Patrick\u00a0E Jamieson, and Kathleen\u00a0Hall Jamieson. 2020.\n\n\nCounteracting misleading protobacco YouTube videos: the effects of text-based and narrative correction interventions and the role of identification.\n\n\nInternational Journal of Communication 14 (Sept. 2020), 4973\u20134989.\n\n\n\n\n\n\nParaschivoiu et\u00a0al. (2021)\n\nIrina Paraschivoiu, Josef Buchner, Robert Praxmarer, and Thomas Layer-Wagner. 2021.\n\n\nEscape the fake: Development and evaluation of an augmented reality escape room game for fighting fake news. In Extended Abstracts of the 2021 Annual Symposium on Computer-Human Interaction in Play. ACM, New York, NY, 320\u2013325.\n\n\n\n\n\n\nPetty and Cacioppo (2012)\n\nRichard\u00a0E Petty and John\u00a0T Cacioppo. 2012.\n\n\nCommunication and persuasion: Central and peripheral routes to attitude change.\n\n\nSpringer Science & Business Media, Philadelphia, PA.\n\n\n\n\n\n\nPun (2017)\n\nRaymond Pun. 2017.\n\n\nHacking the research library: Wikipedia, Trump, and information literacy in the escape room at Fresno State.\n\n\nThe Library Quarterly 87, 4 (2017), 330\u2013336.\n\n\n\n\n\n\nRibeiro et\u00a0al. (2017)\n\nManoel\u00a0Horta Ribeiro, Pedro\u00a0H. Calais, Virg\u00edlio A.\u00a0F. Almeida, and Wagner Meira\u00a0Jr. 2017.\n\n\n\u201cEverything I Disagree With is I#FakeNews\u201d: Correlating Political Polarization and Spread of Misinformation.\n\n\n\n\n\nhttps://arxiv.org/abs/1706.05924v2\n\n\n\nRoozenbeek and Van Der\u00a0Linden (2019)\n\nJon Roozenbeek and Sander Van Der\u00a0Linden. 2019.\n\n\nThe fake news game: actively inoculating against the risk of misinformation.\n\n\nJournal of Risk Research 22, 5 (May 2019), 570\u2013580.\n\n\n\nhttps://doi.org/10.1080/13669877.2018.1443491\n\n\n\nRoozenbeek and van\u00a0der Linden (2020)\n\nJon Roozenbeek and Sander van\u00a0der Linden. 2020.\n\n\nBreaking Harmony Square: A game that \u201cinoculates\u201d against political misinformation.\n\n\nThe Harvard Kennedy School Misinformation Review 1, 8 (2020).\n\n\n\n\n\n\nSallam (2021)\n\nMalik Sallam. 2021.\n\n\nCOVID-19 vaccine hesitancy worldwide: a concise systematic review of vaccine acceptance rates.\n\n\nVaccines 9, 2 (2021), 160.\n\n\n\n\n\n\nSangalang et\u00a0al. (2019)\n\nAngeline Sangalang, Yotam Ophir, and Joseph\u00a0N Cappella. 2019.\n\n\nThe Potential for Narrative Correctives to Combat Misinformation\u2020.\n\n\nJournal of Communication 69, 3 (June 2019), 298\u2013319.\n\n\n\nhttps://doi.org/10.1093/joc/jqz014\n\n\n\nSchulzke (2014)\n\nMarcus Schulzke. 2014.\n\n\nSimulating Philosophy: Interpreting Video Games as Executable Thought Experiments.\n\n\nPhilosophy I& Technology 27, 2 (June 2014), 251\u2013265.\n\n\n\nhttps://doi.org/10.1007/s13347-013-0102-2\n\n\n\nSee et\u00a0al. (2008)\n\nYa\u00a0Hui\u00a0Michelle See, Richard\u00a0E. Petty, and Leandre\u00a0R. Fabrigar. 2008.\n\n\nAffective and cognitive meta-bases of attitudes: Unique effects on information interest and persuasion.\n\n\nJournal of Personality and Social Psychology 94, 6 (2008), 938\u2013955.\n\n\n\nhttps://doi.org/10.1037/0022-3514.94.6.938\n\n\n\nSierra\u00a0Rativa et\u00a0al. (2020)\n\nAlexandra Sierra\u00a0Rativa, Marie Postma, and Menno Van\u00a0Zaanen. 2020.\n\n\nThe Influence of Game Character Appearance on Empathy and Immersion: Virtual Non-Robotic Versus Robotic Animals.\n\n\nSimulation & Gaming 51, 5 (Oct. 2020), 685\u2013711.\n\n\n\nhttps://doi.org/10.1177/1046878120926694\n\n\n\nSlater (1997)\n\nMichael\u00a0D. Slater. 1997.\n\n\nPersuasion Processes Across Receiver Goals and Message Genres.\n\n\nCommunication Theory 7, 2 (1997), 125\u2013148.\n\n\n\nhttps://doi.org/10.1111/j.1468-2885.1997.tb00145.x\n\n\n\nSlater and Rouner (1996)\n\nMichael\u00a0D. Slater and Donna Rouner. 1996.\n\n\nHow Message Evaluation and Source Attributes May Influence Credibility Assessment and Belief Change.\n\n\nJournalism & Mass Communication Quarterly 73, 4 (Dec. 1996), 974\u2013991.\n\n\n\nhttps://doi.org/10.1177/107769909607300415\n\n\n\nSlater and Rouner (2002)\n\nMichael\u00a0D. Slater and Donna Rouner. 2002.\n\n\nEntertainment\u2014Education and Elaboration Likelihood: Understanding the Processing of Narrative Persuasion.\n\n\nCommunication Theory 12, 2 (2002), 173\u2013191.\n\n\n\nhttps://doi.org/10.1111/j.1468-2885.2002.tb00265.x\n\n\n\nSlater et\u00a0al. (2006)\n\nMichael\u00a0D. Slater, Donna Rouner, and Marilee Long. 2006.\n\n\nTelevision Dramas and Support for Controversial Public Policies: Effects and Mechanisms.\n\n\nJournal of Communication 56, 2 (June 2006), 235\u2013252.\n\n\n\nhttps://doi.org/10.1111/j.1460-2466.2006.00017.x\n\n\n\nSquire (2006)\n\nKurt Squire. 2006.\n\n\nFrom content to context: Videogames as designed experience.\n\n\nEducational researcher 35, 8 (2006), 19\u201329.\n\n\n\n\n\n\nTercanli et\u00a0al. (2021)\n\nHacer Tercanli, Richard Martina, Marta Ferreira\u00a0Dias, Ingrid Wakkee, Jessica Reuter, Marlene Amorim, Mara Madaleno, Daniel Magueta, Elisabete Vieira, Cl\u00e1udia Veloso, et\u00a0al. 2021.\n\n\nEducational escape rooms in practice: research, experiences, and recommendations.\n\n\nTechnical Report. Universidade de Aveiro.\n\n\n\n\n\n\nTurns and Ramey (2006)\n\nJennifer Turns and Judith Ramey. 2006.\n\n\nActive and Collaborative Learning in the Practice of Research: Credit-based Directed Research Groups.\n\n\nTechnical Communication 53, 3 (2006), 296\u2013307.\n\n\n\nhttps://www.jstor.org/stable/43089425\n\n\n\nvan\u00a0der Linden et\u00a0al. (2017)\n\nSander van\u00a0der Linden, Edward Maibach, John Cook, Anthony Leiserowitz, and Stephan Lewandowsky. 2017.\n\n\nInoculating against misinformation.\n\n\nScience 358, 6367 (Dec. 2017), 1141\u20131142.\n\n\n\nhttps://doi.org/10.1126/science.aar4533\n\n\n\nWedlake et\u00a0al. (2024)\n\nStacey Wedlake, Chris Coward, and Jin\u00a0Ha Lee. 2024.\n\n\nHow games can support misinformation education: A sociocultural perspective.\n\n\nJournal of the Association for Information Science and Technology 75 (2024), 1480\u2013\u20131497.\n\n\n\n\n\n\nWhite (2022)\n\nAndrew White. 2022.\n\n\nOvercoming \u2018confirmation bias\u2019 and the persistence of conspiratorial types of thinking.\n\n\nContinuum 36, 3 (May 2022), 364\u2013376.\n\n\n\nhttps://doi.org/10.1080/10304312.2021.1992352\n\n\n\nYin and Xiao (2022)\n\nMichael Yin and Robert Xiao. 2022.\n\n\nHow Should I Respond to \u201cGood Morning?\u201d: Understanding Choice in Narrative-Rich Games. In Designing Interactive Systems Conference. ACM, Virtual Event Australia, 726\u2013744.\n\n\n\nhttps://doi.org/10.1145/3532106.3533459\n\n\n\nYoung et\u00a0al. (2021)\n\nJason\u00a0C Young, Brandyn Boyd, Katya Yefimova, Stacey Wedlake, Chris Coward, and Rolf Hapel. 2021.\n\n\nThe role of libraries in misinformation programming: A research agenda.\n\n\nJournal of Librarianship and Information Science 53, 4 (2021), 539\u2013550.\n\n\n\n\n\n\nZhou and Shen (2022)\n\nYanmengqian Zhou and Lijiang Shen. 2022.\n\n\nConfirmation Bias and the Persistence of Misinformation on Climate Change.\n\n\nCommunication Research 49, 4 (June 2022), 500\u2013523.\n\n\n\nhttps://doi.org/10.1177/00936502211028049\n\n\n\nZollo (2019)\n\nFabiana Zollo. 2019.\n\n\nDealing with digital misinformation: a polarised context of narratives and tribes.\n\n\nEFSA Journal 17, S1 (2019), e170720.\n\n\n\nhttps://doi.org/10.2903/j.efsa.2019.e170720\n\n\n\n\n\n\n\nGenerated  on Mon Mar  3 23:49:36 2025 by LaTeXML\n\n\n\n\n"}, {"id": "http://arxiv.org/abs/2503.02333v2", "title": "Examining the Mental Health Impact of Misinformation on Social Media\n  Using a Hybrid Transformer-Based Approach", "contents": "\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n | arXiv e-print repository\n\n\n\n\n\n\n\nSkip to main content\n\n\n\n\n\nWe gratefully acknowledge support from the Simons Foundation, member institutions, and all contributors. Donate\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHelp | Advanced Search\n\n\n\n\nAll fields\nTitle\nAuthor\nAbstract\nComments\nJournal reference\nACM classification\nMSC classification\nReport number\narXiv identifier\nDOI\nORCID\narXiv author ID\nHelp pages\nFull text\n\n\n\n\nSearch\n\n\n\n \n\n\nLogin \n \n\nThis version of 2503.02333v2 has been withdrawn and is unavailable\nSee abstract page for more details \n\n\n\n\n\n\n\nAbout\nHelp\n\n\n\n\n\ncontact arXivClick here to contact arXiv\n Contact\n\n\nsubscribe to arXiv mailingsClick here to subscribe\n Subscribe\n\n\n\n\n \n\n\n\n\n\nCopyright\nPrivacy Policy\n\n\n\n\nWeb Accessibility Assistance\n\n\narXiv Operational Status \n              Get status notifications via\n              email\n              or slack\n\n\n\n\n\n \n \n\n\n"}]